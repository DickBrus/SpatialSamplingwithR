# Model-based optimisation of probability sampling designs {#MBpredictionofDesignVariance}

In Chapter \@ref(Modelassisted) on model-assisted estimation I explained how a linear regression model or a non-linear model obtained with a  machine learning algorithm, can be used to increase the precision of design-based estimates of the population mean or total using the data collected by a given probability sampling design. In this chapter I explain how a model of the study variable can be used at an earlier stage, to optimise probability sampling designs. I show how a model can be used to choose between alternative sampling design types, for instance between systematic random sampling spreading out the sampling units throughout the study area, and two-stage cluster random sampling resulting in spatial clusters of samplng units. Besides I explain  how a model can be used to optimise the sample size of a given sampling design type, for instance, the number of primary and secondary units with two-stage cluster random sampling. The final section of this chapter is about how a model can be used to optimise spatial strata for stratified simple random sampling.

The models used in this chapter are all geostatistical models of the spatial variation. Chapter \@ref(Introkriging) is an introduction to geostatistical modelling. Several geostatistical concepts explained in that chapter are needed here to predict the sampling variance.

A general geostatistical model of the spatial variation is

\begin{equation}
\begin{split}
Z(\mathbf{s}) &= \mu(\mathbf{s}) + \epsilon(\mathbf{s}) \\
\epsilon(\mathbf{s}) &\sim \mathcal{N}(0,\sigma^2) \\
\mathrm{Cov}(\epsilon(\mathbf{s}),\epsilon(\mathbf{s}^{\prime})) &= C(\mathbf{h}) 
\end{split}
\;,
(\#eq:geostatmodel)
\end{equation}

with $Z(\mathbf{s})$ the study variable at location $\mathbf{s}$, $\mu(\mathbf{s})$ the mean at location $\mathbf{s}$, $\epsilon(\mathbf{s})$ the residual at location $\mathbf{s}$, and $C(\mathbf{h})$ the covariance of the residuals at two locations separated by vector $\mathbf{h} = \mathbf{s}-\mathbf{s}^{\prime}$. Note that contrary to the mean $\mu$ the variance of the residuals $\sigma^2$ is assumed constant.

The model of the spatial variation has several parameters. In case of a model in which the mean is a linear combination of covariates, these are the regression coefficients associated with the covariates, and the parameters of a semivariogram describing the spatial dependence of the residuals. A semivariogram is a model for half the expectation of the squared difference of the study variable or the residuals of a model at two locations, referred to as the semivariance, as a function of the length (and direction) of the vector separating the two locations (Chapter \@ref(Introkriging)).

Use of the model for prediction of the sampling variance of a design-based estimator of the population mean requires prior knowledge of the semivariogram. When data are available collected from the study area of interest, these data can be used to choose a semivariogram model and estimate the parameters of the model. If no such data are available, we must make a best guess, based on data collected in other areas. In all cases I recommend to keep the model as simple as possible.


## Model-based optimisation of sampling design type and sample size

In Chapter \@ref(RequiredSampleSize) I presented methods and formulas for computing the required sample size given various measures to quantify the quality of the survey result. These required sample sizes are for simple random sampling. For other types of sampling design, the required sample size can be approximated by multiplying the required sample size for simple random sampling with the design effect, see Section \@ref(DesignEffect). An alternative is to use a model of the spatial variation to predict the sampling variance of the estimator of the mean for the type of sampling design under study and a range of sample sizes, plotting the predicted variance (or standard error) against the sample size, and using this plot inversely to derive the required sample size given a constraint on the sampling variance (standard error).

The computed required sample size applies to several given parameters of the sampling design. For instance, for stratified random sampling the sample size is computed for a given stratification and sample size allocation scheme, for cluster random sampling for given clusters, and for two-stage cluster random sampling for given primary sampling units (psu's) and number of secondary sampling units selected per psu draw. However, the model can also be used to optimise these sampling design parameters. For stratified random sampling the optimal allocation can be computed by predicting the population variances within strata and using the predicted population variances per stratum in Equation \@ref(eq:optallocation), and even the stratification can be optimised (Section \@ref(Ospats))). If we have a cost model, for cluster random sampling the size and shape of the clusters can be optimised, and for two-stage cluster random sampling the number of psu draws and number of ssu's per psu draw can be optimised.  

Model-based prediction of the sampling variance can also be useful to compare alternative types of sampling design at equal total costs or equal variances of the estimated population mean or total. For instance, to compare systematic random sampling, leading to good spatial coverage, and two-stage cluster random sampling, resulting in spatial clusters of observations.

Three approaches for model-based prediction of the sampling variance of a design-based estimator of the population mean (or total) are described, the analytical approach (Section \@ref(AnalyticalApproach)), the geostatistical simulation approach (Section \@ref(GeostatisticalSimulationApproach)) and the Bayesian approach (Section \@ref(MBpredSamplingVarBayes)). In the analytical approach we assume that the mean, $\mu(\mathbf{s})$ in Equation \@ref(eq:geostatmodel), is everywhere the same. This assumption is relaxed in the geostatistical simulation approach. This approach can also be used to predict the sampling variance using a model in which the mean is a linear combination of covariates and/or spatial coordinates, and to predict the sampling variance of the estimator of the mean of trans-Gaussian variables, i.e. random variables that can be transformed to a Gaussian variable. 

The predicted sampling variances of the estimated population mean obtained with the analytical and geostatistical simulation approach are conditional on the model of the spatial variation. Uncertainty about this model is not accounted for. On the contrary, in the Bayesian approach we do account for our uncertainty about the assumed model, and we analyse how this uncertainty propagates to the sampling variance of the estimator of the mean. 

### Analytical approach {#AnalyticalApproach}

In the analytical approach the sampling variance of the estimator of the mean is derived from mean semivariances within the study area\index{Mean semivariance!within a study area}  and mean semivariances within the sample\index{Mean semivariance!within a sample}. Assuming isotropy, these mean semivariances are a function of the separation distance between pairs of points. 

The sampling variance of a design-based estimator of the population mean can be predicted by (@dom94, @gru06)

\begin{equation}
E_{\xi}\{V_p(\hat{\bar{z}})\}=\bar{\gamma}-E_p(\pmb{\lambda}^{\prime}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda}) \;,
(\#eq:MBdesignvarAnydesign)
\end{equation}

where $E_{\xi}(\cdot)$ is the statistical expectation over realisations from the model $\xi$, $E_{p}(\cdot)$ is the statistical expectation over repeated sampling with sampling design $p$, $V_{p}(\hat{\bar{z}})$ is the variance of the estimator of the population mean over repeated sampling with sampling design $p$, $\bar{\gamma}$ is the mean semivariance of the random variable at two randomly selected locations in the study area, $\pmb{\lambda}$ is the vector of design-based weights of the units of a sample selected with design $p$, and $\pmb{\Gamma}_{\mathcal{S}}$ is the matrix of semivariances between the units of a sample $\mathcal{S}$ selected with design $p$.

The mean semivariance $\bar{\gamma}$ is a model-based prediction of the population variance (spatial variance), i.e. the model-expectation of the population variance:

\begin{equation}
\bar{\gamma} = E_{\xi}\{\sigma^2(z)\}\:.
(\#eq:meansemivariance)
\end{equation}

The mean semivariance $\bar{\gamma}$ can be calculated by discretising the study area by a fine square grid, and computing the matrix with geographical distances between the discretisation nodes, transforming this into a semivariance matrix, and computing the average of all elements of the semivariance matrix. The second term $E_p(\pmb{\lambda}^{\prime}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda})$ can be evaluated by Monte-Carlo simulation, repeatedly selecting a sample according to design $p$, calculating $\pmb{\lambda}^{\prime}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda}$, and averaging.

```{block2, type='rmdnote'}
The semivariance at zero distance (same location) is 0, so on the diagonal of a semivariance matrix we have zeroes. If a semivariogram with nugget is assumed, these zeroes on the diagonal must be replaced by the nugget to compute $\bar{\gamma}$. The same holds for the diagonal zeroes in  $\pmb{\Gamma}_{\mathcal{S}}$.  
```

This generic procedure is still computationally demanding, but it is the only option for complex spatial sampling designs. For basic sampling designs the general formula can be worked out. For simple random sampling, the sampling variance can be predicted by

\begin{equation}
E_{\xi}\{V_\mathrm{SI}(\hat{\bar{z}})\}=\bar{\gamma }/n \;,
(\#eq:MBdesignvarSI)
\end{equation}

and for stratified simple random sampling by

\begin{equation}
E_{\xi}\{V_\mathrm{STSI}(\hat{\bar{z}})\}=\sum_{h=1}^H w^2_h \bar{\gamma_h}/n_h \;,
(\#eq:MBdesignvarSTSI)
\end{equation}

with $H$ the number of strata, $w_h$ the stratum weight (relative size), $\bar{\gamma}_h$ the mean semivariance of stratum $h$, and $n_h$ the number of sampling units of stratum $h$.

```{block2, type='rmdnote'}
The model-based predictions of the variances within the strata, $\bar{\gamma}_h$, can also be used to compute the sample sizes for Neyman allocation, which are the optimal sample sizes  when the mean costs per unit are equal for the strata. To compute these sample sizes the standard deviations $S_h(z)$ in Equation \@ref(eq:Neymanallocation) are replaced by $\sqrt{\bar{\gamma}_h}$.
```

For systematic random sampling (sampling on a randomly placed grid), the variance can be predicted by

\begin{equation}
E_{\xi}\{V_\mathrm{SY}(\hat{\bar{z}})\}=\bar{\gamma} - E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}}) \;,
(\#eq:MBdesignvarSY)
\end{equation}

with $E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}})$ the design-expectation, i.e. the expectation over repeated systematic sampling, of the mean semivariance within the systematic sample (grid). With systematic random sampling the number of grid points within the study area can vary among samples, as well as the spatial pattern of the points (Chapter \@ref(SY)). Therefore multiple systematic random samples must be selected, and the average of the mean semivariance within the systematic sample must be computed.

The analytical approach is illustrated with the data of agricultural field Leest [@HofmanBrus2021]. Nitrate-N (NO3-N) in kg/ha in the layer 0 - 90 cm, using a standard soil density of 1500 kg/m$^3$, is measured at 30 points. These data are used to compute a sample semivariogram using the method-of-moments with function `variogram`, see Chapter \@ref(Introkriging). A spherical model without nugget is fitted to the sample semivariogram using function `fit.variogram`. The numbers in this plot are the numbers of pairs of points used to compute the semivariances.

```{r VariogramLeest, fig.asp=0.7, fig.cap="Sample semivariogram and fitted spherical model for NO3-N in agricultural field Leest. Numbers are numbers of pairs used in computing semivariances."}
library(gstat)
mydata <- read.csv("data/Leest05.csv")
coordinates(mydata) <- ~Easting+Northing
vg <- variogram(N~1, data=mydata)
vgm_MoM <- fit.variogram(vg, model=vgm(model="Sph", psill=2000, range=20))
plot(vg, vgm_MoM, plot.numbers=TRUE)
```

The few data makes that the sample semivariogram is very noisy. For the moment I ignore my uncertainty about the semivariogram parameters; in Section \@ref(MBpredSamplingVarBayes) I show how we can account for our uncertainty about the semivariogram parameters in model-based prediction of the sampling variance. A spherical semivariogram model\index{Semivariogram model} without nugget is fitted to the sample semivariogram, i.e. the intercept is 0. The fitted range of the model is `r round(vgm_MoM$range,0)` m, and the fitted sill equals `r round(vgm_MoM$psill,0)`. The fitted semivariogram is used to predict the sampling variance for three sampling designs: simple random sampling, stratified simple random sampling, and systematic random sampling. The costs for these three design types will be about equal, as the study area is small, so that the access time of the sampling points selected with the three designs is about equal. The sample size is 25 points. For systematic random sampling the number of points varies among the samples. For this sampling design the *expected* sample size is 25 points.

For simple random sampling we must compute the mean semivariance within the field (Equation \@ref(eq:MBdesignvarSI)). This mean semivariance is approximated by discretising the field by a square grid of 2000 points, computing the 2000 $\times$ 2000 matrix with distances between all pairs of discretisation nodes, transforming this distance matrix into a semivariance matrix using function `variogramLine` of package **gstat** [@peb04] , and finally averaging the semivariances. Note that in this case we do not need to replace the zeroes on the diagonal of the semivariance matrix by the nugget, as a model without nugget is fitted. The shape file is read with function `readOGR` of package **rgdal** [@rgdal], resulting in an object of class `SpatialPolygonsDataFrame`. The projection attributes of this object are removed with function `proj4string` to avoid an error message when running function `spsample`.

```{r ExiVarSILeest}
library(rgdal)
shpField <- readOGR(dsn="data", layer="Leest5", verbose=FALSE)
proj4string(shpField) <- NA_character_
mygrid <- spsample(shpField, type="regular", n=2000, offset=c(0.5, 0.5)) %>%
  as(., "data.frame")
H <- as.matrix(dist(mygrid))
G <- variogramLine(vgm_MoM, dist_vector=H)
m_semivar_field <- mean(G)
n <- 25
Exi_V_SI <- m_semivar_field/n
```

The model-based prediction of the sampling variance of the estimator of the mean with this design equals `r round(Exi_V_SI,1)`.

The strata of the stratified simple random sampling design are compact geographical strata\index{Compact geographical strata} of equal size (Section \@ref(geostrata)). The number of geostrata is equal to the sample size, 25 points, so that we have one point per stratum. With this design the sampling points are reasonably well spread out over the field, but not as good as with systematic random sampling. To predict the sampling variance we must compute the mean semivariances within the geostrata, see Equation \@ref(eq:MBdesignvarSTSI). Note that the stratum weights are constant as the strata have equal size: $w_h = 1/n$, and as $n_h=1$ Equation \@ref(eq:MBdesignvarSTSI) reduces to

\begin{equation}
E_{\xi}\{V_\mathrm{STSI}(\hat{\bar{z}})\}=\frac{1}{n^2}\sum_{h=1}^H \bar{\gamma_h} \;,
(\#eq:MBdesignvarSTSI2)
\end{equation}

```{r ExiVarSTSILeest}
library(spcosa)
gridded(mygrid) <- ~x1+x2
mygeostrata <- stratify(mygrid, nStrata=n, equalArea=TRUE, nTry=10) %>%
  as(., "data.frame")
m_semivar_geostrata <- numeric(length=n)
for (i in 1:n) {
 ids <- which(mygeostrata$stratumId==(i-1))
 mysubgrd <- mygeostrata[ids,]
 H_geostratum <- as.matrix(dist(mysubgrd[,c(2,3)]))
 G_geostratum <- variogramLine(vgm_MoM, dist_vector=H_geostratum)
 m_semivar_geostrata[i] <- mean(G_geostratum)
}
Exi_V_STSI <- sum(m_semivar_geostrata)/n^2
```

The model-based prediction of the sampling variance of the estimator of the mean with this design equals `r round(Exi_V_STSI,1)`, which is much smaller than with simple random sampling. The large stratification effect\index{Stratification effect} can be explained by the assumed strong spatial structure of NO3-N in the agricultural field and the improved geographical spreading of the sampling points, see Figure \@ref(fig:VariogramLeest).

To predict the  sampling variance for systematic random sampling with an expected sample size of 25 points, we must compute the design-expectation of the mean semivariance within the systematic sample (Equation \@ref(eq:MBdesignvarSY)). This expectation is approximated by selecting a large number of systematic random samples, computing the mean semivariance for each sample, and averaging. This average of mean semivariances within a systematic sample is subtracted from the mean semivariance within the field.

```{r}
set.seed(314)
m_semivar_SY <- numeric(length=100)
for (i in 1:100) {
  mySYsample <- spsample(x=mygrid, n=n, type="regular") %>%
    as(., "data.frame")
  H_SY <- as.matrix(dist(mySYsample))
  G_SY <- variogramLine(vgm_MoM, dist_vector=H_SY)
  m_semivar_SY[i] <- mean(G_SY)
}
Exi_V_SY <- m_semivar_field-mean(m_semivar_SY)
```

The model-based prediction of the sampling variance of the estimator of the mean with this design equals `r as.character(round(Exi_V_SY,1))`, which is smaller than that of stratified simple random sampling. This can be explained by the improved geographical spreading of the sampling points with systematic random sampling as compared to stratified simple random sampling with compact geographical strata.

#### Bulking soil aliquots into a composite sample

If the soil aliqouts collected at the points of the stratified random sample are bulked into a composite, as is usually done in soil testing of agricultural fields, the procedure for predicting the variance of the estimator of the mean is slightly different. Only the composite sample\index{Composite sampling} is analysed in a laboratory on NO3-N, not the individual soil aliquots\index{soil aliquot}. This implies that the contribution of the measurement error\index{Measurement error} to the total uncertainty about the population mean is larger. To predict the sampling variance in this situation, we need the semivariogram of errorless measurements of NO3-N, i.e. of the true NO3-N contents of soil aliquots collected at points. The sill of this semivariogram  will be smaller than the sill of the semivariogram of measured NO3-N data. A simple option is to subtract an estimate of the measurement error variance from the semivariogram of measured NO3-N data that contain a measurement error. So the measurement error variance is subtracted from the nugget. This may lead to negative nuggets, which is not allowed (a variance cannot be negative). The preferable alternative is to fit the model with maximum likelihood, and adding the measurement error variance to the diagonal of the covariance matrix of the data, see function `ll` in Section \@ref(MBpredSamplingVarBayes). 

#### Exercises {-}

1. Write an **R** script to predict the sampling variance of the estimator of the mean of NO3-N of agricultural field Leest, for simple random random sampling and a sample size of 25 points. Use in prediction a spherical semivariogram with a nugget of 483, a partial sill of 483 and a range of 44.6 m. The sum of the nugget and partial sill (966) is equal to the sill of the semivariogram used above in predicting sampling variances. Compare the predicted sampling variance with the predicted sampling variance for the same sampling design, obtained with the semivariogram without nugget. Explain the difference.  
2. Write an **R** script to compute the required sample size for simple random random sampling of agricultural field Leest, for a maximum length of a 95\% confidence interval of 20. Use the semivariogram without nugget in predicting the sampling variance. See Section \@ref(ReqSampleSizeLengthCI) (Equation \@ref(eq:nreqwidthCI)) for how to compute this required sample size given a prior estimate of the standard deviation of the study variable in the population.  
3. Do the same for systematic random sampling. Note that for this sampling design no such formula is available. Predict for a series of *expected* sample sizes, $n = 5,6,\dots , 40$, the sampling variance of the estimator of the mean, using Equation \@ref(eq:MBdesignvarSY). Approximate $E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}})$ from ten repeated selections. Compute the length of the confidence interval from the predicted sampling variances, and plot the interval length against the sample size. Finally determine the required sample size for a maximum length of 20. What is the design effect for an expected sample size of 34 points (the required sample size for simple random sampling), see Equation \@ref(eq:designeffect)? Also compute the design effect for expected sample sizes of $5,6,\dots , 40$. Explain why the design effect is not constant.  

### Geostatistical simulation approach {#GeostatisticalSimulationApproach}

The alternative to the analytical approach is to use a geostatistical simulation\index{Geostatistical simulation} approach. It is computationally more demanding, but an advantage of this approach is its flexibility. It can also be used to predict the sampling variance of the estimator of the mean using a geostatistical model with a non-constant mean. And besides, this approach can also handle trans-Gaussian variables\index{Trans-Gaussian variable}, i.e. of variables whose distribution can be transformed into a normal distribution. In Section \@ref(MBpredSamplingVarBayes) geostatistical simulation is used to predict the variance of the estimator of the mean of a lognormal variable. 

The geostatistical  simulation approach for predicting the sampling variance of a design-based estimator of the population mean involves the following steps:  

1. Select a large number $S$ of random samples with sampling design $p$.  
2. Use the model to simulate values of the study variable for all sampling points.  
3. Estimate for each sample the population mean, using the design-based estimator of the population mean for sampling design $p$. This results in $S$ estimated population means.  
4. Compute the variance of the $S$ estimated means.  
5. Repeat steps 1 to 4 $R$ times, and compute the mean of the $R$ variances.  

This approach is illustrated with the three administrative regions (woredas) in Ethiopia where a large sample is available with organic matter data in the topsoil (SOM) in mass percentages (wt\%) of dry soil. The soil samples are collected along roads (see Figure \@ref(fig:spatialinfillEthiopia)). It is a convenience sample\index{Convenience sample}, not a probability sample, so these sample data cannot be used in design-based or model-assisted estimation of the mean or total soil carbon stock in the study area. However, the data can be used to model the spatial variation of SOM, and this geostatistical model\index{Geostatistical model} can then be used to design a probability sample for design-based estimation of the total SOM stock. Apart from the point data of SOM, maps of covariates are available, such as a digital elevation model and remote sensing reflectance data. I selected four covariates to model the mean of SOM: elevation (dem), average near infrared reflectance (rfl-NIR), average red reflectance (rfl-red) and average land surface temperature (lst). I assume a normal distribution for the residuals of the linear model.  The model parameters are estimated by restricted maximum likelihood\index{Restricted maximum likelihood estimation} (REML), using package **geoR** [@geoR], see Section \@ref(REML) for details on REML estimation of a geostatistical model.

```{r}
library(geoR)
load(file="data/ThreeWoredasEthiopia.RData")
priordata <- as(priordataEthiopia, "data.frame")
dGeoR <- as.geodata(obj=priordata, header=TRUE,
  coords.col=13:14, data.col=1, covar.col=c(3,9,10,11))
vgm_REML <- likfit(geodata=dGeoR, 
  trend=~dem+rfl_NIR+rfl_red+lst, 
  cov.model="spherical", ini.cov.pars=c(1,5),nugget=0.2,
  lik.method="REML", messages=FALSE)
```

The estimated parameters of the residual semivariogram of SOM are shown in Table \@ref(tab:VariogramREMLEthiopia). The estimated regression coefficients are `r round(vgm_REML$beta[1],1)` for the intercept, `r round(vgm_REML$beta[2],3)` for elevation (dem), `r round(vgm_REML$beta[3],2)` for NIR reflectance, `r round(vgm_REML$beta[4],2)` for red reflectance and `r round(vgm_REML$beta[5],3)` for land surface temperature. 

Package **gstat** is used for geostatistical simulation, and therefore first the REML estimates of the semivariogram parameters are assigned to the arguments `nugget`, `psill` and `range` of the function `vgm` of this package. 

```{r}
vgm_REML_gstat <- vgm(model="Sph", nugget=vgm_REML$tausq,
  psill=vgm_REML$sigmasq, range=vgm_REML$phi)
```

The fitted model of the spatial variation of SOM is used to compare systematic random sampling and two-stage cluster random sampling at equal variances of the estimator of the mean. First the sampling variance with systematic random sampling is predicted. One hundred systematic random samples ($S=100$) with an expected sample size of 50 points ($E[n]=50$) are selected. The four covariates at the selected sampling points are extracted by overlaying the `SpatialPointsDataFrame`  `mySYsamples` and the `SpatialPixelsDataFrame` `grd` with function `over` of package **sp** [@Pebesma2005]. Values at the sampling points are simulated by sequential Gaussian simulation\index{Sequential Gaussian simulation} [@goo97], using function `krige`  with argument `nsim = 1` of package **gstat**. The argument `dummy` is set to `TRUE` to enforce unconditional simulation\index{Geostatistical simulation!unconditional}.

```{block2, type='rmdnote'}
The alternative is conditional simulation\index{Geostatistical simulation!conditional}, using the data of the convenience sample as conditioning data. Conditional simulation is only recommended if the quality of these legacy data is sufficient, and we may trust that the study variable at the legacy points is not changed since these legacy data are collected.
```

Note that by first drawing 100 samples, followed by simulating values of $z$ at the selected sampling points, instead of first simulating values of $z$ at the nodes of a discretisation  grid, followed by selecting samples and overlaying with the simulated field, the simulated values of points in the same discretisation cell differ, so that we account for the infinite number of points in the population.

With systematic random sampling the sample mean is an approximately unbiased estimator of the population mean (Chapter \@ref(SY)). Therefore, of each sample the mean of the simulated values is computed, using the function `tapply`. Finally, the variance of the 100 sample means is computed. This is a conditional variance, conditional on the simulated values. The whole procedure is repeated 100 times ($R=100$), leading to 100 conditional variances of sample means.

```{r MonteCarloEthiopia, eval=FALSE}
load(file="data/CovariatesThreeWoredasEthiopia.RData")
grd <- grdEthiopia
gridded(grd) <- ~s1+s2
S <- R <- 100
v_mzsim_SY <- numeric(length=R)
set.seed(314)
for (i in 1:R) {
  mySYsamples <- NULL
  for (j in 1:S) {
    xy <- spsample(x=grd, n=50, type="regular")
    mySY <- data.frame(
      s1=xy$x1, s2=xy$x2, sample=rep(j, length(xy)))
    mySYsamples <- rbind(mySYsamples, mySY)
  }
  coordinates(mySYsamples) <- ~s1+s2
  res <- over(mySYsamples, grd)
  mySYs <- data.frame(mySYsamples, res[,c(1,3,4,5)])
  coordinates(mySYs) <- ~s1+s2
  zsim <- krige(
    dummy~dem+rfl_NIR+rfl_red+lst, 
    locations=mySYs, newdata=mySYs, 
    model=vgm_REML_gstat, beta=vgm_REML$beta,
    nmax=20, nsim=1,
    dummy=TRUE,
    debug.level=0) %>% as(.,"data.frame")
  m_zsim <- tapply(zsim$sim1, INDEX=mySYs$sample, FUN=mean)
  v_mzsim_SY[i] <- var(m_zsim)
}
```

```{r, eval=FALSE, echo=FALSE}
save(v_mzsim_SY,file="results/MBpredictionDesignVariance_SY.RData")
```

```{r, echo=FALSE}
load(file="results/MBpredictionDesignVariance_SY.RData")
```

```{r, echo=FALSE}
Exi_vmz_SY <- mean(v_mzsim_SY)
```

The mean of the 100 conditional variances equals `r round(Exi_vmz_SY,3)`. This is a Monte Carlo approximation of the model-based prediction of the sampling variance of the ratio estimator of the mean for systematic random sampling with an expected sample size of 50.

Due to the geographical spreading of the sampling points with systematic random sampling, the accuracy of the estimated mean is expected to be high compared to that of other sampling designs of the same size. However, with large areas the time needed for travelling to the sampling points can become substantial, lowering the sampling efficiency. With large areas, sampling designs leading to spatial clusters of sampling points can be an attractive alternative. One option then is two-stage cluster random sampling, see Chapter \@ref(Twostage). The question is whether this alternative design is more efficient than systematic random sampling.

For the three woredas in Ethiopia 100 compact geostrata (see Section \@ref(geostrata)) are computed. Here these geostrata are not used as strata in stratified random sampling, but as primary sampling units (psu's) in two-stage cluster random sampling. The difference is that in stratified random sampling from each geostratum at least one sampling unit is selected, whereas in two-stage cluster random sampling only a randomly selected subset of the geostrata is sampled. The compact geostrata, used as psu's, are computed with function `kmeans`, and as a consequence the psu's do not have equal size. This is not needed in two-stage cluster random sampling, see Chapter \@ref(Twostage). If psu's of equal size are preferred, then these can be computed with function `stratify` of package **spcosa** with argument `equalArea=TRUE`, see Section \@ref(geostrata).

```{r}
load(file="data/CovariatesThreeWoredasEthiopia.RData")
grd <- grdEthiopia
set.seed(314)
res <- kmeans(grd[,c("s1","s2")], iter.max=1000, centers=100, nstart=100)
mypsus <- res$cluster
psusize <- as.numeric(table(mypsus))
summary(psusize)
```

To keep the estimation of the population mean simple, the psu's are selected with probabilities proportional to their size and with replacement (ppswr sampling), see Chapter \@ref(Twostage).

#### Optimisation of sample sizes for two-stage cluster random sampling

In Section \@ref(twostagesamplingestimators) formulas are presented for computing the optimal number of psu draws and ssu draws per psu draw. The optimal sample sizes are a function of the pooled variance of primary unit means, $S^2_{\mathrm{b}}$, and the pooled variance of secondary units (points) within the primary units, $S^2_{\mathrm{b}}$. In this section these variance components are predicted with the geostatistical model.

As a first step a large number of fields is simulated.

```{r}
grd$psu <- mypsus
coordinates(grd) <- ~s1+s2
set.seed(314)
zsim <- krige(
  dummy~dem+rfl_NIR+rfl_red+lst, 
  locations=grd, newdata=grd, 
  model=vgm_REML_gstat, beta=vgm_REML$beta, 
  nmax=20, nsim=1000, 
  dummy=TRUE, debug.level=0) %>% as(.,"data.frame")
zsim <- zsim[,-c(1,2)]
```

For each simulated field the means of the psu's and the variances within the psu's are computed using function `tapply` in function `apply`.

```{r}
m_zsim_psu <- apply(zsim, MARGIN=2, FUN=function(x)
  tapply(x, INDEX=grd$psu, FUN=mean))
v_zsim_psu <- apply(zsim, MARGIN=2, FUN=function(x)
  tapply(x, INDEX=grd$psu, FUN=var))
```

Next for each simulated field the pooled variance of psu means and pooled variance within psu's is computed, and finally these pooled variances are averaged over all simulated fields. These averages are approximations of the model-expectations of the pooled between unit and within unit variances, $E_{\xi}[S^2_{\mathrm{b}}]$ and $E_{\xi}[S^2_{\mathrm{w}}]$.

```{r}
p_psu <- psusize/sum(psusize)
S2b <- apply(m_zsim_psu, MARGIN=2, FUN=function(x)
  sum(p_psu*(x-sum(p_psu*x))^2))
S2w <- apply(v_zsim_psu, MARGIN=2, FUN=function(x)
  sum(p_psu*x))
Exi_S2b <- mean(S2b)
Exi_S2w <- mean(S2w)
```

The optimal sample sizes are computed for a simple linear costs model: $C = c_0 + c_1\;n + c_2n\;m$, with $c_0$ the fixed costs, $c_1$ the access costs per primary unit, including the access costs of the ssu's (points) within a given psu, and $c_2$ the observation costs per ssu. For the optimal sample sizes only the ratio of $c_1$ and $c_2$ is important, not their absolute values.

Given values for $c_1$ and $c_2$, the optimal number of psu draws $n$, and optimal number of ssu draws per psu draw $m$ is computed, required for a sampling variance of the estimator of the mean equal to the sampling variance with systematic random sampling of 50 points, see Equations \@ref(eq:nopt) and \@ref(eq:mopt). 

```{r}
c1 <- 2; c2 <- 1
nopt <- 1/Exi_vmz_SY*(sqrt(Exi_S2w*Exi_S2b)*sqrt(c2/c1)+Exi_S2b)
mopt <- sqrt(Exi_S2w/Exi_S2b)*sqrt(c1/c2)
```

The optimised number of psu draws is `r ceiling(nopt)`, and the optimal number of points per psu draw equals `r ceiling(mopt)`. The total number of sampling points is `r ceiling(nopt)` $\times$ `r ceiling(mopt)` $=96$. This is much larger than the sample size of 50 obtained with systematic random sampling. The total observation costs therefore are substantially larger. However, the access time can be substantially smaller due to the spatial clustering of sampling points. To answer the question whether the costs saved by this reduced access time outweighs the extra costs of observation, the model for the access costs and observation costs must be further developed.

### Bayesian approach {#MBpredSamplingVarBayes}

The model-based prediction of the variance of the design-based estimate of the population mean for a given sampling design is conditional on the model. If we change the model type or the model parameters, the predicted sampling variance also changes. In most situations we are quite uncertain about the model, even in situations where we have data that can be used to estimate the model parameters, as in the Ethiopia case study. Instead of using the best estimated model to predict the sampling variance as done in the previous sections, we may prefer to account for the uncertainty about the model parameters. This can be done through a Bayesian approach\index{Bayesian approach!to prediction of sampling variance}, in which the legacy data are used to update a prior distribution of the model parameters to a posterior distribution. For details about a Bayesian approach for estimating model parameters, see Section \@ref(BayesianGridSpacing). A sample from the posterior distribution of model parameters is used one-by-one to predict the sampling variance. This can be done either analytically, as described in Section \@ref(AnalyticalApproach), or through geostatistical simulation. Both approaches result in a *distribution* of sampling variances, reflecting our uncertainty about the sampling variance of the estimator of the population mean due to uncertainty about the semivariogram. The mean or median of the distribution of sampling variances can be used as the predicted sampling variance. 

The Bayesian approach is illustrated with a case study on predicting the sampling variance of NO3-N in an agricultural field in Belgium [@HofmanBrus2021]. Data of NO3-N are available at 30 points, forming approximately a square grid with a spacing of about 4.5 m. As a first step, I check whether we can safely assume that the data come from a normal distribution.

```{r qqplotMelle, fig.asp=0.7, fig.cap="Q-Q plot of Nitrate-N of field Melle."}
mydata <- read.csv("data/Melle17.csv", header=TRUE)
ggplot(mydata, aes(sample=N)) +
  geom_qq() +
  geom_qq_line()
pvalue <- shapiro.test(mydata$N)$p.value
```

The Q-Qplot\index{Q-Q plot} shows that a normal distribution is not very likely: there are too many large values, the distribution is skewed to the right. Also the $p$-value\index{Level of significance of a test}\index{\emph{p}-value of a test} of the Shapiro-Wilk test\index{Shapiro-Wilk test} shows that we should reject the null-hypothesis of a normal distribution for the data: *p*=`r as.character(round(pvalue,4))`. I therefore proceed with the natural logarithm of NO3-N, in short lnN.

```{r, echo=FALSE}
mydata$lnN <- log(mydata$N)
```

```{r, echo=FALSE}
min_Easting <- min(mydata$Easting)
min_Northing <- min(mydata$Northing)
mydata$Easting <- mydata$Easting - min_Easting
mydata$Northing <- mydata$Northing - min_Northing 
```

As a first step the semivariogram of lnN is estimated by maximum likelihood\index{Maximum likelihood estimation} (Section \@ref(MLestimationVariogram)). An exponential semivariogram model is assumed, see Equation \@ref(eq:exponential). 

```{block2, type='rmdnote'}
The parameters that are estimated are the reciprocal of the sill $\lambda$, the ratio of spatial dependence\index{Ratio of spatial dependence} $\xi$, defined as the partial sill divided by the sill, and the distance parameter $\phi$. This parameterisation of the semivariogram is chosen because hereafter in the Bayesian approach prior distributions are chosen for these parameters.
```

The likelihood function is defined, using a somewhat unusual parameterisation, tailored to the Markov chain Monte Carlo (MCMC) sampling\index{Markov chain Monte Carlo sampling} from the posterior distribution of the semivariogram parameters. In MCMC a Markov chain of sampling units (vectors with semivariogram parameters) is generated by using the previous sampling unit to randomly generate the next sampling unit (@Gelman2013, Chapter 11]. In MCMC sampling the probability of accepting a proposed sampling unit $\pmb{\theta}^*$  is a function of the ratio of the posterior density of the proposed sampling unit and that of the current sampling unit, $f(\pmb{\theta}^*|\mathbf{z})/f(\pmb{\theta}_{t-1}|\mathbf{z})$, so that the normalising constant, the denominator of Equation \@ref(eq:BayesTheorem), cancels. For a nice introduction to MCMC I refer to these [lecture notes](http://nitro.biosci.arizona.edu/courses/EEB596/handouts/Gibbs.pdf). `crossprod(X, Cinv)` is the same as `t(X) %*% Cinv`.

```{r}
library(mvtnorm)
ll <-function(thetas) {
  sill <- 1/thetas[1]
  psill <- thetas[2]*sill
  nugget <- sill-psill
  vgmodel <- vgm(model=model, psill=psill, range=thetas[3], nugget=nugget)
  C <- variogramLine(vgmodel, dist_vector=D, covariance=TRUE)
  Cinv <- solve(C)
  XCXinv <- solve(crossprod(X, Cinv) %*% X)
  XCz <- crossprod(X, Cinv) %*% z
  beta <- XCXinv %*% XCz
  mu <- as.numeric(X%*%beta)
  logLik <- dmvnorm(x=z, mean=mu, sigma=C, log=TRUE)
  logLik
}
```

Next, initial estimates of the semivariogram parameters are estimated by maximising the likelihood, using function `optim`. 

```{r}
lambda.ini <- 1/var(mydata$lnN)
xi.ini <- 0.5
phi.ini <- 20
pars <- c(lambda.ini, xi.ini, phi.ini)
D <- as.matrix(dist(mydata[,c(1,2)]))
X <- matrix(1, nrow(mydata), 1)
z <- mydata$lnN
model <- "Exp"
vgML <- optim(pars, ll, control=list(fnscale = -1),
  lower=c(1e-6,0,1e-6), upper=c(1000,1,150), method="L-BFGS-B")
```

The maximum likelihood (ML) estimates of the semivariogram parameters are used as initial values in MCMC sampling. A uniform prior is used for the inverse of the sill parameter, $\lambda=1/\sigma^2$, with a lower bound of $10^{-6}$ and an upper bound of 1. For the distance parameter $\phi$ of the exponential semivariogram a uniform prior is assumed, with a lower bound of $10^{-6}$ m. and an upper bound of 150 m. For the relative nugget, $\tau^2/\sigma^2$, a uniform prior is assumed with a lower bound of 0 and an upper bound of 1.

These priors can be defined by function `createUniformPrior` of package **BayesianTools** [@Hartig2018]. The function `createBayesianSetup` is then used to define the setup of the MCMC sampling, specifying the likelihood function, the prior, and the vector with best prior estimates of the model parameters, specified with argument `best`. Argument `sampler` of function `runMCMC` specifies the type of MCMC sampler. I used the differential evolution algorithm\index{Differential evolution algorithm} of @terBraak2008. Argument `start` of function `getSample` specifies the burn-in period\index{Burn-in period}, i.e. the number of first samples that are discarded to diminish the influence of the initial semivariogram parameter values. Argument `numSamples` specifies the sample size, i.e. the number of saved vectors with semivariogram parameter values, drawn from the posterior distribution.

```{r MCMCMelles, eval=FALSE}
library(BayesianTools)
priors <- createUniformPrior(lower=c(1e-6, 0, 1e-6),
                             upper=c(1000,1,150))
bestML <- c(vgML$par[1], vgML$par[2], vgML$par[3])
setup <- createBayesianSetup(likelihood=ll, prior=priors,
  best=bestML, names=c("lambda","xi","phi"))
set.seed(314)
res <- runMCMC(setup, sampler="DEzs")
MCMCsample <- getSample(res, start=1000, numSamples=1000) %>% data.frame(.)
```

```{r, eval=FALSE, echo=FALSE}
write.csv(file="results/MCMC_Melle17_logN.csv", MCMCsample, row.names=FALSE)
```

Figure \@ref(fig:MCMCsampleVariogramlnN) shows several semivariograms, sampled by MCMC from the posterior distribution of the estimated semivariogram parameters.

```{r, echo=FALSE}
MCMCsample <- read.csv(file="results/MCMC_Melle17_logN.csv", header=TRUE)
```

```{r MCMCsampleVariogramlnN, echo=FALSE, fig.asp=0.7, fig.cap="Semivariograms of lnN, obtained by MCMC sampling from posterior distribution of the estimated semivariogram parameters for field Melle." }
d <- 1:150
semivar <- matrix(nrow=length(d),ncol=20)
for (i in 1:20) {
  sill <- 1/MCMCsample$lambda[i]
  psill <- MCMCsample$xi[i]*sill
  nugget <- sill-psill
  phi <- MCMCsample$phi[i]
  g <- variogramLine(vgm(model="Exp",psill=psill,range=phi,nugget=nugget),dist_vector=d)
  semivar[,i] <- g$gamma
}
dfsemi <- data.frame(d=d,semivar)
df_lf <- dfsemi %>%
  pivot_longer(cols=names(dfsemi)[-1])

ggplot(df_lf, mapping=aes(x=d,y=value, group=name))+
  geom_line()+
  scale_x_continuous(name="Distance (m)",) +
  scale_y_continuous(name="Semivariance",limits=c(0,NA))
```

The evaluated sampling design is the same as used in Section \@ref(AnalyticalApproach) for field Leest: stratified simple random sampling, using compact geographical strata of equal size, a total sample size of 25 points, and one point per stratum. 

```{r, echo=FALSE}
shpField <- readOGR(dsn="data", layer="Melle17", verbose=FALSE)
proj4string(shpField) <- NA_character_
mygrid <- spsample(shpField,type="regular",n=2000,offset=c(0.5,0.5)) %>% as(.,"data.frame")
mygrid$x1 <- mygrid$x1-min_Easting
mygrid$x2 <- mygrid$x2-min_Northing
gridded(mygrid) <- ~x1+x2
n <- 25
mygeostrata <- stratify(mygrid,nStrata=n,equalArea=TRUE,nTry=10)
```

The next step is to simulate with each of the sampled semivariograms a large number of maps of lnN. This is done by sequential Gaussian simulation, conditional on the available data. The simulated values are backtransformed. Each simulated map is then used to compute the variance of the simulated values within the geostrata $S^2_h$. These stratum variances are used to compute the sampling variance of the estimator of the mean. Plugging $w_h = 1/n$ (all strata have equal size) and $n_h=1$ into Equation \@ref(eq:EstVarMeanSTSI), yields (compare with Equation \@ref(eq:MBdesignvarSTSI2))

\begin{equation}
    V(\hat{\bar{z}}) = \frac{1}{n^2}\sum_{h=1}^H S^2_h \;.
    (\#eq:VarSTSIMelles)
\end{equation}

I used the first 100 sampled semivariograms, and with each semivariogram I simulated 100 maps.

```{r, echo=FALSE}
mygeostrata <- as(mygeostrata, "data.frame")
```


```{r simulatevariances, eval=FALSE}
V <- matrix(data=NA, nrow=100, ncol=100)
coordinates(mydata) <- ~Easting+Northing
set.seed(314)
for (i in 1:100) {
  sill <- 1/MCMCsample$lambda[i]
  psill <- MCMCsample$xi[i]*sill
  nug <- sill - psill
  range <- MCMCsample$phi[i]
  vgmdl <- vgm(model="Exp", nugget=nug, psill=psill, range=range)
  ysim <- krige(
    lnN~1, locations=mydata, newdata=mygrid, 
    model=vgmdl, 
    nmax=20, nsim=100,
    debug.level=0) %>% as(., "data.frame")
  zsim <- exp(ysim[,-c(1,2)])
  S2h <- apply(zsim, MARGIN=2, FUN=function(x)
    tapply(x, INDEX=as.factor(mygeostrata$stratumId), FUN=var))
  V[i,] <- 1/n^2*apply(S2h, MARGIN=2, FUN=sum)
}
```

```{r, eval=FALSE, echo=FALSE}
save(V, file="results/SimulatedSamplingVariances_Melle17.RData")
```

Figure \@ref(fig:plotsimulatedmapsMelle) shows sixteen simulated maps, simulated with the first four semivariograms. The four maps in a row (a to d) are simulated with the same semivariogram. All maps show that the simulated data have positive skew, which is in agreement with the prior data. The data obtained by simulating from a lognormal distribution are always strictly positive. This is not guaranteed when simulating from a normal distribution.

```{r, echo=FALSE, eval=FALSE}
#coordinates(mydata) <- ~Easting+Northing
v <- matrix(data=NA, nrow=4, ncol=4)
Zsim <- NULL
set.seed(314)
for (i in 1:4) {
  sill <- 1/MCMCsample$lambda[i]
  psill <- MCMCsample$xi[i]*sill
  nugget <- sill - psill
  range <- MCMCsample$phi[i]
  for (j in 1:4) {
    ysim <- krige(
      lnN~1,
      locations=mydata,
      newdata=mygrid,
      model=vgm(model="Exp", nugget=nugget, psill=psill, range=range),
      nmax=20,
      nsim=1,
      debug.level=0) %>% as(.,"data.frame")
    zsim <- exp(ysim$sim1)
    S2h <- tapply(zsim, INDEX=as.factor(mygeostrata$stratumId), FUN=var)
    v[i,j] <- 1/n^2*sum(S2h)
    fld <- paste0(i,letters[j])
    zsimdf <- data.frame(coordinates(mygrid),zsim=zsim,fld=fld)
    Zsim <- rbind(Zsim,zsimdf)
  }
}
save(Zsim, v, file="results/SimulatedMaps_Melle17.RData")
```

```{r, plotsimulatedmapsMelle, echo=FALSE, out.width="100%", fig.cap="Maps of NO3-N simulated with four semivariograms (rows). Each semivariogram is used to simulate four maps (columns a-d)."}
load(file="results/SimulatedMaps_Melle17.RData")
ggplot(data=Zsim) +
  geom_raster(mapping=aes(x=x1, y=x2, fill=zsim)) +
  scale_x_continuous(name="") +
  scale_y_continuous(name="") +
  coord_fixed(ratio=1) +
  scale_fill_continuous(name="Nsim",type="viridis",limits=c(0,100)) +
  facet_wrap(~ fld,nrow=4,ncol=4)
```

The sampling variances of the estimated mean of NO3-N obtained with these sixteen maps are shown below. 

```{r, echo=FALSE}
colnames(v) <- c("a","b","c","d")
rownames(v) <- 1:4
round(v,3)
```

The sampling variance shows quite strong variation among the maps. The histogram shows the uncertainty distribution of the sampling variance, due to uncertainty about the semivariogram, as well as due to uncertainty about the spatial distribution of NO3-N within the agricultural field given the semivariogram and the available data from that field.

```{r, echo=FALSE}
load(file="results/SimulatedSamplingVariances_Melle17.RData")
```

```{r histogramNMelle, echo=FALSE, fig.asp=0.7, fig.cap="Histogram of simulated sampling variances of the estimator of the mean of NO3-N for stratified simple random sampling of field Melle."}
ggplot() +
  geom_histogram(aes(x=V), binwidth=0.2, fill="black", alpha=0.5, colour="black") +
  scale_y_continuous(name="Frequency") +
  scale_x_continuous(name="Variance of estimator of mean")
```

```{r, echo=FALSE}
Exi_V_STSI <- mean(V)
P50_V_STSI <- quantile(V, 0.5)
P90_V_STSI <- quantile(V, 0.9)
```

As a model-based prediction of the sampling variance we can take the mean or the median of the sampling variances over all $100 \times 100$ simulated maps, which are equal to `r round(Exi_V_STSI,3)` and `r round(P50_V_STSI,3)`, respectively.  If we want to be more safe, we can take a high quantile, e.g. the P90 of this distribution as the predicted sampling variance, which is equal to `r round(P90_V_STSI,3)`

I used the 30 data as conditioning data in geostatistical simulation. Unconditional simulation is recommended if we cannot rely on the quality of the legacy data, for instance due to a temporal change in lnN since the time the legacy data were observed. For NO3-N this might well be the case. I believe that, although the effect of 30 observations on the simulated fields and on the uncertainty distribution of the sampling variance will be very small, one still may prefer unconditional simulation. With unconditional simulation we must assign the model mean $\mu$ to the argument `beta` of function `krige`. The estimated model mean depends on the semivariogram parameters. The next code chunk shows how this model mean can be estimated (see also function `ll` above).

```{r, eval=FALSE}
C <- variogramLine(vgmodel, dist_vector=D, covariance=TRUE)
Cinv <- solve(C)
XCXinv <- solve(crossprod(X, Cinv) %*% X)
XCz <- crossprod(X, Cinv) %*% z
beta <- XCXinv %*% XCz
```

## Model-based optimisation of spatial strata {#Ospats}

@deGruijter2015 described a novel spatial stratification method that uses model predictions of the study variable as a stratification variable while accounting for errors in the predictions, as well as spatial correlation of the prediction errors.

The **Julia** package **Ospats** is an implementation of the stratification method. In **Ospats**\index{Optimal spatial stratification} the stratification is optimised through iterative reallocation of the raster cells to the strata. Recently, this stratification method was implemented in the package **SamplingStrata** (@Barcaroli2014, @Barcaroli2020). However, the algorithm used to optimise the strata differs from that in **Ospats**.  In `SamplingStrata` the stratification is optimised by optimising the breaks\index{Stratum breaks} (splitting points) on the stratification variable with a genetic algorithm\index{Genetic algorithm}. Optimisation of the strata through optimisation of the breaks on the stratification variable necessarily leads to non-overlapping strata, while with iterative reallocation\index{Iterative reallocation} the strata may overlap, i.e. when the strata are sorted on the mean of the stratification variable, the upper bound of a stratum can be larger than the lower bound of the next stratum. As argued by @deGruijter2015 optimisation of strata through optimisation of the stratum breaks can be suboptimal. On the other hand, optimisation through optimisation of the breaks needs fewer computations, and therefore is quicker.

The situation considered in this section is that prior data are available, either from the study area itself or from another similar area, that can be used to fit a linear regression model for the study variable, using one or more quantitative covariates and/or factors as predictors. These predictors must be available in the study area so that the fitted model can be used to map the study variable in the study area. We wish to collect (more) data by stratified simple random sampling, to be used in design-based estimation of the population mean or total of the study variable. The central research question then is how to construct these strata.

Recall the formula for the variance of the estimator of the mean for stratified simple random sampling (see Equations \@ref(eq:EstVarMeanSTSI) and \@ref(eq:EstVarstratummean)):

\begin{equation}
V\!\left(\hat{\bar{z}}\right)=\sum\limits_{h=1}^{H}w_{h}^{2} \frac{S^2_h(z)}{n_h}\;.
(\#eq:VarMeanSTSI2)
\end{equation}

Plugging the stratum sample sizes under optimal allocation (Equation \@ref(eq:optallocation)) into Equation \@ref(eq:VarMeanSTSI2), gives for the variance of the estimator of the mean

\begin{equation}
V\!\left(\hat{\bar{z}}\right)=\frac{1}{n}\left(\sum\limits_{h=1}^{H}w_h S_h(z) \sqrt{c_h} \sum_{h=1}^H \frac{w_h S_h(z)}{\sqrt{c_h}}\right)\;.
(\#eq:VSTSINeyman)
\end{equation}

So given the total sample size $n$ the variance of the estimator of the mean is minimal when the criterion 

\begin{equation}
O = \sum\limits_{h=1}^{H}w_h S_h(z) \sqrt{c_h} \sum_{h=1}^H \frac{w_h S_h(z)}{\sqrt{c_h}}
(\#eq:minicritospats)
\end{equation}

is minimised. 

Assuming that the costs are equal for all population units, so that the mean costs are the same for all strata, the minimisation criterion reduces to

\begin{equation}
O = \left(\sum\limits_{h=1}^H w_h S_h(z)\right)^2\;.
(\#eq:EOconstantch)
\end{equation}

In practice we do not know the values of the study variable $z$. @deGruijter2015 consider the situation where we have predictions of the study variable from a linear regression model: $\hat{z} = z + \epsilon$, with $\epsilon$ the prediction error. So this implies that we do not know the stratum standard deviations $S_h(z)$ of Equation \@ref(eq:VSTSINeyman). What we do have are the stratum standard deviations of the predictions of $z$: $S_h(\hat{z})$. With many statistical models, such as regression and kriging models, the standard deviation of the predictions are smaller than that of the study variable: $S_h(\hat{z}) < S_h(z)$. This is known as the smoothing or levelling effect. 

The stratum standard deviations in the minimisation criterion are replaced by model-expectations of these stratum standard deviations, i.e. by model-based predictions of the stratum standard deviations), $E[S_h(z)]$. This leads to the following minimisation criterion:

\begin{equation}
E_{\xi}[O] = \left(\sum\limits_{h=1}^H w_h E_{\xi}[S_h(z)]\right)^2\;.
(\#eq:EOconstantch2)
\end{equation}

The stratum variances are predicted by

\begin{equation}
E_{\xi}[S^2_h(z)]=\frac{1}{N^2_h}\sum_{i=1}^{N_h-1}\sum_{j=i+1}^{N_h}E_{\xi}[d^2_{ij}]\;,
\end{equation}

with $d^2_{ij} = (z_i-z_j)^2$ the squared difference of the study variable values at two nodes of a discretisation grid. The model-expectation of the squared differences are equal to

\begin{equation}
E_{\xi}[d^2_{ij}] = (\hat{z}_i-\hat{z}_j)^2+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j)
(\#eq:Exid2ij)
\;, 
\end{equation}

with $S^2(\epsilon_i)$ the variance of the prediction error at node $i$, and $S^2(\epsilon_i,\epsilon_j)$ the covariance of the prediction errors at nodes $i$ and $j$. The authors then argue that for smoothers, such as kriging and regression, the first term must be divided by the squared correlation coefficient $R^2$:

\begin{equation}
E_{\xi}[d^2_{ij}] = \frac{(\hat{z}_i-\hat{z}_j)^2}{R^2}+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j) \;.
(\#eq:Exid2ij2)
\end{equation}

The predicted stratum standard deviations are approximated by the square root of Equation \@ref(eq:Exid2ij2). Plugging these model-based predictions of the stratum standard deviations into the minimisation criterion, Equation \@ref(eq:EOconstantch), yields

\begin{equation}
E_{\xi}[O] = \frac{1}{N} \sum\limits_{h=1}^H \left( \sum_{i=1}^{N_h-1}\sum_{j=i+1}^{N_h}\frac{(\hat{z}_i-\hat{z}_j)^2}{R^2}+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j) \right)^{1/2}\;.
(\#eq:minicritospatsDeGruijter)
\end{equation}

Optimal spatial stratification with package **SamplingStrata** is illustrated with a survey of the soil organic matter (SOM) concentration (g/kg) in the topsoil (A horizon) of Xuancheng (China). Three samples are available. These three samples are merged. The total number of sampling points is 183. This sample is used to fit a simple linear regression model for SOM, using the elevation of the surface (dem) as a predictor. The function `lm` of the **stats** package is used to fit the simple linear regression model.

```{r}
sample_grid <- read.csv("data/Xuancheng_gridsample.csv")
sample_iPSM <- read.csv("data/Xuancheng_iPSMsample.csv")
sample_test <- read.csv("data/Xuancheng_Stratifiedrandomsample.csv")
mysample <- rbind(sample_grid, sample_iPSM, sample_test[,-c(13,14,15)])
lm_SOM <- lm(SOM_A_hori~dem, data=mysample)
```

In fitting a linear regression model we assume that the relation is linear, that the residual variance is constant (independent of the fitted value) and the residuals have a normal distribution. These assumptions are checked with a scatter plot of the residuals against the fitted value and a Q-Q plot\index{Q-Q plot}, respectively.

```{r checkassumptions, echo=FALSE, out.width='100%', fig.asp=0.5, fig.cap = "Scatter plot of residuals against fitted value, and Q-Q plot of residuals, for a simple linear regression model of soil organic matter concentration in Xuancheng, with elevation as a predictor."}
fit <- fitted(lm_SOM)
e <- residuals(lm_SOM)
df <- data.frame(fit=fit, resid=e)
plt1 <- ggplot(df) +
  geom_point(mapping=aes(x=fit, y=e)) +
  geom_hline(yintercept=0) +
  scale_x_continuous(name="Fitted value") +
  scale_y_continuous(name="Residuals")

plt2 <- ggplot(df, aes(sample=e)) +
  geom_qq() +
  geom_qq_line()

grid.arrange(plt1, plt2, nrow=1)
```

The scatter plot shows that the first assumption is realistic. No pattern can be seen: at all fitted values the residuals are scattered around the horizontal line. However, the second and thirds assumptions are questionable: the residual variance clearly increases with the fitted value, and the distribution of the residuals has positive skew, i.e. it has a long upper tail. There clearly is some evidence that these two assumptions are violated. Possibly these problems can be solved by fitting a model for the natural logarithm of SOM.

```{r checkassumptions2, echo=FALSE, out.width='100%', fig.asp=0.5, fig.cap = "Scatter plot of residuals against fitted value, and Q-Q plot of residuals, for a simple linear regression model of natural logarithm of soil organic matter concentration in Xuancheng, with elevation as a predictor."}
mysample$lnSOM <- log(mysample$SOM_A_hori)
lm_lnSOM <- lm(lnSOM~dem, data=mysample)
e <- residuals(lm_lnSOM)
fit <- fitted(lm_lnSOM)
df <- data.frame(fit, e)
plt1 <- ggplot(df) +
  geom_point(mapping=aes(x=fit, y=e)) +
  geom_hline(yintercept=0) +
  scale_x_continuous(name="Fitted value") +
  scale_y_continuous(name="Residuals")

plt2 <- ggplot(df, aes(sample=e)) +
  geom_qq() +
  geom_qq_line()

grid.arrange(plt1, plt2, nrow=1)
```

The variance of the residuals is more constant, and the Q-Q plot is improved, although we now have too many strong negative residuals for a normal distribution. I proceed with the model for natural log-transformed SOM (lnSOM). The fitted linear regression model is used to predict lnSOM at the nodes of a 200 m $\times$ 200 m discretisation grid.

```{r}
load("data/Xuancheng.RData")
res <- predict(lm_lnSOM, newdata=as(grd,"data.frame"), se.fit=TRUE)
grd <- within(as(grd,"data.frame"), 
              {lnSOMpred <- res$fit; varpred <- res$se.fit^2})
```

The predictions and their standard errors are shown in Figure \@ref(fig:predictedlnSOM).

```{r predictedlnSOM, echo=FALSE, out.width="100%", fig.cap = "Predicted natural logarithm of soil organic matter concentration (g/kg) in the topsoil, and its  standard error in Xuancheng, obtained with a linear regression model with elevation as predictor."}
plt1 <- ggplot(grd) +
  geom_raster(mapping=aes(x=x1, y=x2, fill=lnSOMpred)) +
  scale_fill_continuous(name="lnSOM",type="viridis") + 
  scale_x_continuous(name="Easting (km)") +
  scale_y_continuous(name="Northing (km)") +
  coord_fixed()

plt2 <- ggplot(grd) +
  geom_raster(mapping=aes(x=x1, y=x2, fill=sqrt(varpred))) +
  scale_fill_continuous(name="se",type="viridis") +
  scale_x_continuous(name="Easting (km)") +
  scale_y_continuous(name="Northing (km)") +
  coord_fixed()
grid.arrange(plt1, plt2, ncol=1)
```

Let us check now whether the spatial structure of the study variable lnSOM is fully captured by the mean, modelled as a linear function of the covariate elevation. This can be checked by estimating the semivariogram of the model residuals. If the semivariogram of the residuals is pure nugget (the semivariance does not increase with distance), then we can assume that the prediction errors are independent. In that case we do not need to account for a covariance of the prediction errors in optimisation of the spatial strata. However, if the semivariogram does show spatial structure, we must account for a covariance of the prediction errors. Figure \@ref(fig:residualvariogramSOM) shows the semivariogram of the residuals computed with function `variogram` of package **gstat**.

```{r residualvariogramSOM, echo=FALSE, fig.asp=0.7, fig.cap="Sample semivariogram of residuals of simple linear regression model for natural logarithm of soil organic matter concentration in Xuancheng."}
library(gstat)
mysample$X <- mysample$X/1000
mysample$Y <- mysample$Y/1000
coordinates(mysample) <- ~X+Y
vg <- variogram(lnSOM~dem, data=mysample)
plot(vg, plot.numbers=TRUE)
```

The sample semivariogram does not show much spatial structure, but the first two points in the semivariogram have somewhat smaller values. This indicates that the residuals at two close points, say $< \pm 5$ km are not independent, whereas if the distance between the two points $> \pm 5$ km, they are independent. This spatial dependency of the residuals can be modelled, e.g. by an exponential function. The exponential semivariogram has three parameters, the nugget\index{Nugget} variance $c_0$, the partial sill\index{Partial sill} $c_1$ and the distance parameter\index{Distance parameter} $\phi$. The total number of model parameters now is five: two regression coefficients (intercept and slope for elevation), and three semivariogram parameters. All five parameters can best be estimated by restricted maximum likelihood\index{Restricted maximum likelihood estimation}, see Section \@ref(REML). Table \@ref(tab:TableModelXuancheng) shows the estimated regression coefficients and semivariogram parameters. Up to a distance of about three times the estimated distance parameter $\phi$, which is about 8 km, the residuals are spatially correlated; beyond that distance, they are hardly correlated anymore.

```{r, echo=FALSE}
library(geoR)
mysample <- as(mysample,"data.frame")
dGeoR <- as.geodata(obj=mysample, header=TRUE, 
   coords.col=4:5, data.col=13, covar.col=12
 )
vgm_REML <- likfit(
  geodata=dGeoR, trend=~dem, cov.model="exponential",
  ini.cov.pars=c(0.05,3), nugget=0.1, lik.method="REML", messages=FALSE)
```

```{r TableModelXuancheng, echo=FALSE}
int <- round(vgm_REML$beta[1],3)
dem <- round(vgm_REML$beta[2],5)
nugget <- c(round(vgm_REML$nugget,3))
psill <- c(round(vgm_REML$sigmasq,3))
range <- c(round(vgm_REML$phi,3))

coefs <- data.frame(int,dem,nugget,psill,range)
rownames(coefs) <- c()

knitr::kable(
  coefs, caption = 'Estimated regression coefficients (intercept and slope for dem), and parameters of exponential semivariogram for natural logarithm of soil organic matter concentration in Xuancheng (China).',
  booktabs = TRUE,col.names=c("Int","dem","Nugget","Partial sill", "Distance parameter (km)")
) %>%
  kable_classic()
```

We conclude that the errors in the regression model predictions are not independent, although the correlation will be weak in this case, and that we must account for this correlation in optimising the spatial strata.

The discretisation grid with predicted lnSOM consists of 115,526 nodes. These are too many for function `optimStrata`. The grid is therefore thinned to a grid with a spacing of 800 m $\times$ 800 m, resulting in 7257 nodes.

```{r, echo=FALSE}
library(sp)
gridded(grd) <- c("x1","x2")
subgrd <- spsample(grd, type="regular", cellsize=0.8, offset=c(0.5,0.5))
subgrd <- data.frame(coordinates(subgrd), over(subgrd,grd))
```

The first step in optimisation of spatial strata with package **SamplingStrata** is to build the sampling frame with function `buildFrameSpatial`. The argument `X` specifies the stratification variables, and argument `Y` specifies the study variables. In our case we have only one stratification variable and one study variable, and these are the same variable. Argument `var` specifies the variance of the prediction error of the study variable. The variable `dom` is an identifier of the domain of interest of which we want to estimate the mean or total. I assigned the value 1 to all population units, which implies that the stratification is optimised for the entire population. If we have multiple domains of interest, the stratification is optimised for each domain separately.

Finally, as a preparatory step we must specify how precise the estimated mean should be. This precision must be specified in terms of the coefficient of variation (cv), i.e. the standard error of the estimated mean divided by the mean. In case of multiple domains of interest, and multiple study variables a cv must be specified per domain and per study variable. This precision requirement is used to compute the sample size for Neyman allocation (Equation \@ref(eq:Neymanallocation))^[For multivariate stratification, i.e. stratification with multiple study variables, Bethel allocation is used to compute the required sample size.]. The optimal stratification is independent of the precision requirement, although for a large cv, the optimal number of strata can be smaller than the value assigned to argument `nStrata` of function `optimStrata`, see hereafter.

```{r}
library(SamplingStrata)
subgrd$id <- c(1:nrow(subgrd))
subgrd$dom <- rep(1,nrow(subgrd))
frame <-buildFrameSpatial(df=subgrd, id="id",X=c("lnSOMpred"), Y=c("lnSOMpred"),
  variance=c("varpred"), lon="x1", lat="x2", domainvalue="dom")
cv <- as.data.frame(list(DOM="DOM1",CV1=0.005,domainvalue=1))
```

The optimal spatial stratification can be computed with function `optimStrata`, with argument `method="spatial"`. The $R^2$ value of the linear regression model, used in the minimisation criterion (Equation \@ref(eq:minicritospatsDeGruijter)), can be assigned to argument `fitting`.

```{block2, type= 'rmdnote'}
I am not sure that the correction factor $R^2$ in Equation \@ref(eq:Exid2ij) is really needed. I believe that the smoothing effect is already accounted for by the variance and covariance of the prediction errors. I used an $R^2$ value of 1.
```

Arguments `range` and `kappa` are parameters of an exponential semivariogram, needed for computing the covariance of the prediction errors. Function `optimiStrata` uses an extra parameter in the exponential semivariogram (Equation \@ref(eq:exponential)), $c_0+c_1\; \mathrm{exp}(-\kappa h/\phi)$, so for the usual exponential semivariogram `kappa` equals 1.

```{r, eval=FALSE}
res <- optimStrata(framesamp=frame, method="spatial", errors=cv, nStrata=5,
  fitting=1, range=c(vgm_REML$phi), kappa=1, showPlot=FALSE)
```

```{r, eval=FALSE, echo=FALSE}
save(res,file="results/OptimalStrataXuancheng_SamplingStrata_cv005.RData")
```

```{r, echo=FALSE}
load(file="results/OptimalStrataXuancheng_SamplingStrata_cv005.RData")
```

A summary of the optimised strata can be obtained with function `summaryStrata`.

```{r}
print(smr_strata <- summaryStrata(
  res$framenew, res$aggr_strata, progress=FALSE))
```

In the next code chunk it is checked whether the coefficient of variation is indeed equal to the desired value.

```{r}
strata <- res$aggr_strata
framenew <- res$framenew
N_h <- strata$N
w_h <- N_h/sum(N_h)
se <- sqrt(sum(w_h^2*strata$S1^2/strata$SOLUZ))
se/mean(framenew$Y1)
```

The coefficient of variation can also be computed with function `expected_CV`.

```{r}
expected_CV(strata)
```

Figure \@ref(fig:optimalstrataXuanchengSamplingStrata) shows the optimised strata. I used the stratum bounds in the data frame `smr_strata`, to compute the stratum for all raster cells of the original 200 m $\times$  200 m grid.

```{r optimalstrataXuanchengSamplingStrata, echo=FALSE, out.width="100%", fig.cap="Model-based optimal strata for estimating the population mean of natural logarithm of soil organic matter (lnSOM) concentration (g/kg)."}
grd <- as(grd,"data.frame")
preds <- predict(lm_lnSOM,grd)
strat <- findInterval(preds, smr_strata$Upper_X1[-5])

labels <- as.character(round(smr_strata$Upper_X1,2))
first <- paste("<",labels[1])
second <- paste(labels[1],"-",labels[2])
third <- paste(labels[2],"-",labels[3])
fourth <- paste(labels[3],"-",labels[4])
fifth <- paste(">",labels[4])
labs <- c(first,second,third,fourth,fifth)

ggplot(grd) +
  geom_raster(mapping=aes(x=x1, y=x2, fill=factor(strat))) +
  scale_fill_viridis_d(name="lnSOM", labels=labs) + 
  scale_x_continuous(name="Easting /km") +
  scale_y_continuous(name="Northing /km") +
  coord_fixed()
```

```{r, echo=FALSE}
rm(list=ls())
```


