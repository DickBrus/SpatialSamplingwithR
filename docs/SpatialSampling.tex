% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{krantz}
\title{Spatial sampling with R}
\author{Dick J. Brus}
\date{2022-01-05}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmonofont[Scale=0.7]{Source Code Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Spatial sampling with R},
  pdfauthor={Dick J. Brus},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}
\usepackage{tabu}
\usepackage{graphicx}
\usepackage{unicode-math}
\usepackage{qtree}

% \setmainfont[UprightFeatures={SmallCapsFont=AlegreyaSC-Regular}]{Alegreya}

\usepackage{framed,color}
%\definecolor{shadecolor}{RGB}{255,255,255}
\definecolor{shadecolor}{RGB}{245,245,245}

\newcommand{\Scal}{\mathcal{S}}
\newcommand{\xbf}{\mathbf{x}}
\newcommand{\bbf}{\mathbf{b}}
\newcommand{\sbf}{\mathbf{s}}
\newcommand{\hbf}{\mathbf{h}}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\makeatletter
\@ifundefined{Shaded}{
}{\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}}
\makeatother

\newenvironment{rmdblock}[1]
  {
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
    }
  }
  \setlength{\fboxsep}{1em}
  \begin{kframe}
  \item
  }
  {
  \end{kframe}
  \end{itemize}
  }
\newenvironment{rmdnote}
  {\begin{rmdblock}{note}}
  {\end{rmdblock}}
\newenvironment{rmdcaution}
  {\begin{rmdblock}{caution}}
  {\end{rmdblock}}
\newenvironment{rmdimportant}
  {\begin{rmdblock}{important}}
  {\end{rmdblock}}
\newenvironment{rmdtip}
  {\begin{rmdblock}{tip}}
  {\end{rmdblock}}
\newenvironment{rmdwarning}
  {\begin{rmdblock}{warning}}
  {\end{rmdblock}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\begin{document}
\maketitle

\includegraphics[width=1\paperwidth]{images/cover.pdf}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\frontmatter

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}


Since the start of The R Series of Chapman \& Hall/CRC in 2011 numerous books have been published on the statistical analysis and modelling of data using \textbf{R}. To date no book has been published in this series on how these data can best be collected. From my point of view this was an omission, as scientific research often starts with data collection. If the data collection is part of the project, it might be a good idea to start thinking right at project start instead of after the data have been collected, to make a well-founded decision on how many data are needed, and on the type of sampling design.

My experience as a statistical consultant is that many researchers pay insufficient attention to the method for data collection. Too many researchers start thinking when the data are there. Often I had to conclude that the way the data were collected by fellow researchers was suboptimal, or even unsuitable for their aim. I hope that this new book may help researchers, practitioners, and students to implement proper sampling designs, tailored to their problems at hand, so that valuable data are collected that can be used to answer the research questions.

Over the past decades numerous wall-to-wall data sets have been collected by remote sensing devices such as satellites and drones. These remote sensing images are valuable sources of information on the natural environment and resources. The question may arise how useful it still can be in this big data era to collect data in the field at a restricted number of sampling locations. Do we really need these data to estimate a population mean or total, for instance of the aboveground biomass or carbon stocks in the soil, or to map these study variables? In many cases the answer is that it is indeed still useful to collect sample data on the study variable, because the remote sensing images provide only proxies of the study variable. The variables derived from the remote sensing images can be related to the study variable, but we still need groundtruth data of the study variable to model this relation. By combining the wall-to-wall data of covariates and the sample data of the groundtruth we can increase the accuracy of the survey result compared to using only one of these data sources.

The handbook Sampling for Natural Resource Monitoring (SNRM) \citep{gru06} presents an overview of sampling strategies for the survey of natural resources at a given point in time, as well as for how these resources can be monitored through repeated surveys. The book presented here can be seen as a follow-up of SNRM. In SNRM spatial sampling designs for survey and space-time designs for monitoring are described and illustrated with notional and real-world examples. Estimators for global and local quantities in space and in space-time, and for the variance of these estimators are presented. However, neither the computer code for how a sample with a given design can be selected, nor the code for how the estimates can be computed is presented in SNRM. The publication at hand fills this gap.

This book describes and illustrates classical, basic sampling designs for spatial survey, as well as more recently developed, advanced sampling designs and estimators. Part I of the book is about random sampling designs for estimating a mean, total, or proportion of a population or of several subpopulations. Part II focuses on sampling designs for mapping.

The computer code is written in the popular programming language \textbf{R} \citep{R2020}. There are several good reasons for choosing \textbf{R} as a language. First of all, it is open-source, giving users the right to view the source code and modify it to their needs. Second, as a result of this open-source, numerous add-on packages have been developed, and this number is still increasing. Happily enough, also quite a few add-on packages have been published for sampling design and analysis. All these add-on packages make the writing of computer code much more simple. Even very advanced statistical methods for sampling design and statistical analysis are now within the reach of many scientists: only a few lines of \textbf{R} code are needed to do the work. A risk is that the appliers of the packages may not fully understand the implemented statistical method. This understanding is not needed to obtain a result. For this reason I decided not to jump to the add-on packages right after the theory, but to follow a more gradual approach. First I show in the simplest possible \textbf{R} code how a sample can be selected with a given sampling design, and how the (sub)population parameters can be estimated. After this I point out how the same result can be obtained with an add-on package.

The target group of this book are researchers and practitioners of sample surveys, as well as students in environmental, ecological, agricultural science or any other science in which knowledge about a population of interest is collected through spatial sampling. I have added exercises to most chapters, making this book suitable as a textbook for students. The answers to the exercises can be found in the appendix of this book. Large parts of the book are self-contained, requiring no prior knowledge of statistics. For the chapters in Part I on more advanced sampling designs, such as balanced sampling, and advanced estimators of (sub)population parameters (model-assisted estimators), knowledge of matrix algebra and regression analysis is required. For the final chapters of Part II basic knowledge of geostatistics is required. This knowledge is also needed for some chapters in Part I. For this reason I have added a chapter introducing the basics of geostatistics (Chapter \ref{Introkriging}).

A gitbook version of this book (html files) is available in the github repository \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master}{SpatialSamplingwithR}. Here you can also find the \textbf{R} scripts of the exercises. This is also the place where you can report errata and comment on text and/or \textbf{R} code. Updates of the book can also be found in the github repository.

Information about the version of \textbf{R} and the versions of the \textbf{R} packages used to compile this book can be found in the file \texttt{SessionInfo.rds} on github. My intention is to update the book as soon as a new version of an \textbf{R} package is available on CRAN which requires an update of the \textbf{R} code.

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}


In 2006 our handbook Sampling for Natural Resource Monitoring (SNRM) was published \citep{gru06}. Soon after this milestone Jaap retired from Wageningen University and Research (WUR). Now I arrived in the final stage of my career at WUR. For a couple of years I had been thinking of a revision of our handbook, to repair errors, and to include new developments in sampling design. Then I realised that to increase the impact of SNRM, it might be a better idea to write a new book, showing by means of computer code how the sampling designs can be implemented, and how the sample data can be used in statistical inference.

A nice side effect of the publication of SNRM was that I was asked to give sampling courses at many places in the world: China, Ethiopia, Uzbekistan, Australia, and various countries in the European Union. I have very pleasant memories of these courses, they made my life as a scientist very joyful. For these courses I wrote numerous scripts with computer code, using the popular programming language \textbf{R} \citep{R2020}. My naïve idea was that all I had to do was to bundle these \textbf{R} scripts into an Rmarkdown document \citep{Xie2020}, and add some text explaining the theory and the \textbf{R} code. As usual, it proved to be much more work than expected, but I am very happy that I was able to finish the job just before my retirement.

I could not have written this book without the help of many fellow researchers. First, I am very grateful for the support I received from the authors of various packages used in this book: Thomas Lumley for his support with package \textbf{survey}, Yves Tillé and Alina Gabriela Matei with package \textbf{sampling}, Anton Grafström with package \textbf{BalancedSampling}, Giulio Barcaroli and Marco Ballin with package \textbf{SamplingStrata}, Andreas Hill and Alex Massey with package \textbf{forestinventory}, and Martins Liberts with package \textbf{surveyplanning}. No need to say that I am responsible for all shortcomings of the \textbf{R} code.

Second, I would like to thank the following researchers for their valuable comments on (parts) of the book: Gerard Heuvelink (Wageningen University and ISRIC World Soil Information, Netherlands), Yuha Heikkinen (Luke, Natural Resources Institute, Finland), David Rossiter (Cornell University, USA and ISRIC World Soil Information, Netherlands), Steve Stehman (SUNY College of Environmental Science and Forestry, USA), Anton Grafström (Swedish University of Agricultural Sciences), Dennis Walvoort (Wageningen University and Research, Netherlands), and Ben Marchant (British Geological Survey, United Kingdom). Dennis Walvoort also was very supportive with the building of the \textbf{R} package \textbf{sswr} containing the data sets and some functions used in this book.

Finally, I would like to thank Alexandre Wadoux (University of Sydney) for preparing the data set of aboveground biomass and numerous environmental and climatological covariates of Eastern Amazonia (Brazil); Coen Bussink (United Nations Office on Drugs and Crime) for giving permission to use data on the occurrence of opium poppy fields in Kandahar (Afghanistan); Akmal Akramkhanov for providing the data set with measurements of the salinity of soil at a farm which is part of a regional Cotton Research Station in Khorezm (Uzbekistan), collected in the ZEF/UNESCO Landscape Restructuring project in the Khorezm province, with financial support by the German Ministry for Education and Research (BMBF; project number 0339970A); Lin Yang (Nanjing University) and A-Xing Zhu (Nanjing Normal University) for giving permission to use the data on soil organic matter concentration in Xuancheng (Anhui province, China) collected in a project supported by the National Natural Science Foundation of China (project numbers 41471178, 41971054, 41431177); the Ethiopian Agricultural Transformation Agency (my contact was Hailu Shiferaw) for allowing me to use the soil organic matter data of the western part of the Amhara region in Ethiopia which I used for training; Siegfried Hofman (Flemish Institute for Technological Research) for giving permission to use the nitrate-N data of several agricultural fields in Flanders (Belgium); and Budiman Minasny (University of Sydney) for giving permission to use the raster maps with terrain attributes in Hunter Valley (Australia).

Last but not least, I would like to thank my sister-in-law Marijke Compaijen who carefully read the entire manuscript. She identified and corrected all kinds of errors and mistakes and made several helpful suggestions. I am very grateful for her extremely precise work.

\mainmatter

\hypertarget{GeneralIntro}{%
\chapter{Introduction}\label{GeneralIntro}}

This book is about sampling for spatial \emph{surveys}. A survey\index{Survey} is an inventory of an object of study about which statistical statements will be made based on data collected from that object. The object of study is referred to as the population of interest or target population. Examples are a survey of the organic carbon stored in the soil of a country, the water quality of a lake, the wood volume in a forest, the yield of rice in a country, etc. In these examples soil organic carbon, water quality, wood volume, and rice yield are the study variables, i.e.~the variables of which we want to estimate the population mean or some other parameter, or which we want to map. So, this book is about \emph{observational research}, not about experiments. In experiments observations are done under controlled circumstances, think of an experiment on crop yields as a function of application rates of fertiliser. Several levels of fertiliser application rate are chosen and randomly assigned to experimental plots. In observational research factors that influence the study variable are not controlled. This implies that in observational research no conclusions can be drawn on causal relations.

If the whole population is observed, this is referred to as a \emph{census}\index{Census}. In general we cannot afford such a census. Only some parts of the population are selected and the study variable is observed (measured) for these selected parts (the population units in the sample) only. Such a survey is referred to as a \emph{sample survey}\index{Sample survey}. The observations are subsequently used to derive characteristics of the whole population. For instance, to estimate the wood volume in a forest, we cannot afford to measure the wood volume of every tree in the forest. Instead, some trees are selected, the wood volume of these trees is measured, and based on these measurements the total wood volume in the forest is estimated.

\hypertarget{BasicConcepts}{%
\section{Basic sampling concepts}\label{BasicConcepts}}

In this book the populations of interest have a spatial dimension. In selecting parts of such populations for observation we may account for the spatial coordinates of the parts, but this is not strictly needed. Examples of spatial sampling designs are designs selecting sampling units that are spread out throughout the study area, often leading to more precise estimates of the population mean or total as compared to sampling designs resulting in spatial clusters of units.

Two types of populations can be distinguished: discrete and continuous populations. \emph{Discrete populations} consist of discrete natural objects, think of trees, agricultural fields, lakes, etc. These objects are referred to as \emph{population units}\index{Population unit}. The total number of population units in a discrete population\index{Population!discrete population} is finite. A finite spatial population of discrete units can be denoted by \(\mathcal{U}=\{u(\mathbf{s}_1),u(\mathbf{s}_2), \dots , u(\mathbf{s}_N)\}\), with \(u(\mathbf{s}_k)\) the unit located at \(\mathbf{s}_k\), where \(\mathbf{s}\) is a vector with spatial coordinates. The population units naturally serve as the \emph{elementary sampling units}\index{Elementary sampling unit}. In this book the spatial populations are two-dimensional, so a vector \(\mathbf{s}\) has two coordinates, Easting and Northing.

Other populations may, for the purpose of sampling, be considered as a physical continuum, e.g.~the soil in a region, the water in a lake, the crop on a field.

\begin{rmdnote}
If interest lies in crop properties per areal unit of the field, the population is continuous. However, if interest lies in properties per plant, the population is discrete and finite.
\end{rmdnote}

Such continuous spatial populations can be denoted by \(\mathcal{U}=\{u(\mathbf{s}), \mathbf{s} \in \mathcal{A} \}\), with \(\mathcal{A}\) the study area. Discrete objects that can serve as elementary sampling units do not exist in \emph{continuous populations}\index{Population!continuous population}. Therefore, we must define the elementary sampling units. The elementary sampling units can be areal units, e.g.~10 m squares, or circular plots, e.g.~with a radius of 5 m, or ``points'', i.e.~units of such a small area, compared to the area of the population, that the area of the units can be ignored.

In this book a population unit and an elementary sampling unit can be an individual object of a discrete population as well as an areal sampling unit\index{Areal sampling unit} or a point of a continuous population.

The size and geometry of the elementary units used in sampling a continuous population is referred to as the sample support\index{Sample support}. The total number of elementary sampling units in a continuous population can be finite, e.g.~all 25 m \(\times\) 25 m (disjoint) raster cells in an area (raster cells in Figure \ref{fig:support}), or infinite, e.g.~all points in an area, or all squares or circular plots with a given radius that are allowed to overlap in an area (circles in Figure \ref{fig:support}).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/support-1} 

}

\caption{Three sample supports: points, squares, and circles. With disjoint squares the population is finite. With points, and squares or circles that are allowed to overlap the population is infinite.}\label{fig:support}
\end{figure}

Ideally, with areal elementary sampling units the selected elementary units are exhaustively observed, so that a measurement of the total or mean of the study variable within an areal unit is obtained, think for instance of the total aboveground biomass. In some cases this is not feasible, think for instance of measuring the mean of some soil property in 25 m squares. In this case a sample of points is selected from each selected square, and the measurement is done at the selected points. These measurements at points are used to estimate the mean of the squares. \citet{Stehman2018} introduced the concept of a response design\index{Response design} as ``the protocol used to determine the reference condition of an element of the population''. So, in the case just mentioned the response design is the sampling design and the estimator for the mean of the soil property of the 25 m squares.

Ideally, the sample support is constant, but in some situations a varying sample support cannot be avoided. Think, for instance, of square sampling units in an irregularly shaped study area. Near the border of the study area there are squares that cross the border. The part of a square that falls outside the study area is not observed. So, the support of the observations of squares crossing the border is smaller than that of the observations of squares in the interior of the study area. See also Section \ref{SIcircularplots}.

To sample a finite spatial population, the population units are listed in a data frame. This data frame contains the spatial coordinates of the population units and other information needed for selecting sampling units according to a specific design. Think, for instance, of the labels of more or less homogeneous subpopulations (used as strata in stratified random sampling, see Chapter \ref{STSI}) and the labels of clusters of population units, for instance, all units in a polygon of a map (used in cluster random sampling, see Chapter \ref{Cl}). Besides, if we have information about covariates possibly related to the study variable, which we would like to use in selecting the population units, these covariates are added to the list. The list used for selecting sampling units is referred to as the \emph{sampling frame}\index{Sampling frame}.

If the elementary sampling units are disjoint square grid cells (sample support is a square), the population is finite and the grid cells can be selected through selection of their centres (or any other point that uniquely identifies a grid cell) listed in the sampling frame.

In this book also continuous populations are sampled using a list as a sampling frame. The infinite population is discretised by the
cells of a fine discretisation grid. The grid cells are listed in the sampling frame by the spatial coordinates of the \emph{centres} of the grid cells. So, the infinite population is represented by a finite list of points. The advantage of this is that existing \textbf{R} packages for sampling of finite populations can also be used for sampling infinite populations.

If the elementary sampling units are points (sample support is a point), the population is infinite. In this case sampling of points can be implemented by a two-step approach. In the first step cells of the discretisation grid are selected with or without replacement, and in the second step one or more points are selected within the selected grid cells. Figure \ref{fig:SamplingFromInfinitePopulation} is an illustration of this two-step approach for simple random sampling of points from a discretised infinite population. Ten grid cells are selected by simple random sampling with replacement. Every time a grid cell is selected one point is randomly selected from that grid cell. Note that a grid cell can be selected more than once, so that more than one point will be selected from that grid cell. Note also that we may select a point that falls outside the boundary of the study area. This is actually the case with one grid cell in Figure \ref{fig:SamplingFromInfinitePopulation}. The points outside the study area are discarded and replaced by a randomly selected new point inside the study area. Finally, note that near the boundary there are small areas not covered by a grid cell, so that no points can be selected in these areas. It is important that the discretisation grid is fine enough to keep the discretisation error\index{Discretisation error} so small that it can be ignored. The alternative is to extend the discretisation grid beyond the boundaries of the study area so that the full study area is covered by grid cells.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingFromInfinitePopulation-1} 

}

\caption{Sampling of points from discretised infinite population. The grid cells are randomly selected with replacement. Each time a grid cell is selected a point is randomly selected from that grid cell.}\label{fig:SamplingFromInfinitePopulation}
\end{figure}

\hypertarget{PopulationParameters}{%
\subsection{Population parameters}\label{PopulationParameters}}

The sample data are used to estimate characteristics of the whole population\index{Population parameter}, e.g.~the population mean\index{Population mean} or total\index{Population total}, some quantile, e.g.~the median or the 90th percentile, or even the entire cumulative frequency distribution.

A finite population total is defined as

\begin{equation}
t(z) = \sum_{k \in \mathcal{U}} z_k = \sum_{k=1}^N z_k \;,
\label{eq:FinitePopTotal}
\end{equation}

with \(N\) the number of population units and \(z_k\) the study variable for population unit \(k\). A finite population mean is defined as a finite population total divided by \(N\).

An infinite population total is defined as an integral of the study variable over the study area:

\begin{equation}
t(z) = \int_{\mathbf{s} \in \mathcal{A}} z(\mathbf{s}) \;\mathrm{d}\mathbf{s} \;.
\label{eq:InfinitePopTotal}
\end{equation}

An infinite population mean is defined as a finite population total divided by the area, \(A\), covered by the population.

A finite population proportion\index{Population proportion} is defined as the population mean of an 0/1 indicator \(y\) with value 1 if the condition is satisfied, and 0 otherwise:

\begin{equation}
p=\frac{\sum_{k=1}^N y_k}{N} \;.
\label{eq:PopulationProportion}
\end{equation}

A cumulative distribution function\index{Cumulative distribution function} (CDF) is defined as

\begin{equation}
F(z)=\sum_{z^\prime \leq z} p(z^\prime) \;,
\label{eq:CDF}
\end{equation}

with \(p(z^\prime)\) the proportion of population units whose value for the study variable equals \(z^\prime\).

A population quantile\index{Population quantile}, for instance the population median or the population 90th percentile, is defined as

\begin{equation}
q_p= F^{-1}(p) \;,
\label{eq:PopQuantile}
\end{equation}

where \(p\) is a number between 0 and 1 (e.g.~0.5 for the median, 0.9 for the 90th percentile), and \(F^{-1}(p)\) is the smallest value of the study variable \(z\) satisfying \(F(z)\geq p\).

In surveys of spatial populations the aim can also be to make a map of the population.

\begin{rmdnote}
The parameters defined in this subsection are parameters of spatial populations, i.e.~populations observed in a relatively short period of time related to the dynamics of the study variable. We assume that the study variable does not change during the survey period. In Chapter \ref{RepeatedSurveys} parameters are defined for space-time populations.
\end{rmdnote}

\hypertarget{descriptive-statistics-versus-inference-about-a-population}{%
\subsection{Descriptive statistics versus inference about a population}\label{descriptive-statistics-versus-inference-about-a-population}}

When we observe only a (small) part of the population, we are uncertain about the population parameter estimates and the map of the population. By using statistical methods we can quantify how uncertain we are about these results. In decision making it can be important to take this uncertainty into account. An example is a survey of water quality. In Europe the concentration levels of nutrients are regulated in the European Water Framework Directive. To test whether the mean concentration of a nutrient complies with its standard, it is important to account for the uncertainty in the estimated mean. When the estimated mean is just below the standard, there is still a large probability that the population mean exceeds the standard. This example shows that it is important to distinguish computing descriptive statistics from characterising the population using the sample data. For instance, we can compute the sample mean (average of the sample data) without error, but if we use this sample mean as an \emph{estimate} of the population mean, there is certainly an error in this estimate.

\hypertarget{random-sampling-versus-probability-sampling}{%
\subsection{Random sampling versus probability sampling}\label{random-sampling-versus-probability-sampling}}

Many sampling methods are available. At the highest level one may distinguish random from non-random sampling methods. In random sampling a subset of population units is randomly selected from the population, using a (pseudo) random number generator. In non-random sampling no such random number generator is used. Examples of non-random sampling are (i) convenience sampling, i.e.~sampling at places that are easy to access, e.g.~along roads; (ii) arbitrary sampling, i.e.~sampling without a specific purpose in mind; and (iii) targeted sampling, e.g.~at sites suspected of soil pollution.

In the literature the term random sampling is often used for arbitrary sampling\index{Arbitrary sampling}, i.e.~sampling without a specific purpose in mind. To avoid confusion the term \emph{probability sampling}\index{Probability sampling} is used for random sampling using a (pseudo) random number generator, so that for any unit in the population the probability of selecting that unit is known. More precisely, a probability sample is a sample from a population such that every unit of the population has a positive probability of being included in the sample. Besides, these \emph{inclusion probabilities} must be known, at least for the selected units, as they are needed in estimation. This is explained in following chapters.

\hypertarget{DBvsMB}{%
\section{Design-based versus model-based approach}\label{DBvsMB}}

The choice between probability or non-probability sampling\index{Non-probability sampling} is closely connected with the choice between the design-based\index{Design-based approach} or the model-based approach\index{Model-based approach} for sampling and statistical inference (estimation, hypothesis testing). The difference between these two approaches is a rather technical subject, so, not to discourage you already in this very first chapter, I will keep it short. In Chapter \ref{Approaches} I elaborate on the fundamental difference of these two approaches and a third approach, the model-assisted approach, which can be seen as a compromise of the design-based and the model-based approach.

\begin{table}

\caption{\label{tab:approach}Statistical approaches for sampling and inference.}
\centering
\begin{tabular}[t]{lll}
\toprule
Approach & Sampling & Inference\\
\midrule
Design-based & Probability sampling required & Based on sampling distribution\\
 &  & (no model used)\\
Model-based & Probability sampling not required & Based on statistical model\\
\bottomrule
\end{tabular}
\end{table}

In the design-based approach units are selected by probability sampling (Table \ref{tab:approach}). Estimates are based on the inclusion probabilities of the sampling units as determined by the sampling design (design-based inference). No model is used in estimation. On the contrary, in the model-based approach a statistical model is used in prediction, i.e.~a model with a random error term, for instance a regression model. As the model already contains a random error term, probability sampling is not required in this approach.

Which statistical approach is best largely depends on the aim of the survey, see \citet{bru97} and \citet{gru06}. Broadly speaking the following aims can be distinguished:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  estimating parameters for the population;
\item
  estimating parameters for several subpopulations; and
\item
  mapping the study variable.
\end{enumerate}

\begin{rmdnote}
A map of the study variable is obtained by predicting the study variable at the points of a very fine grid that discretises the study area, or by predicting the means of the study variable for fine grid cells. Many mapping methods are available. In this book a statistical model is applied to predict the study variable, for instance a linear regression model, or a spatial linear mixed model as used in kriging.
\end{rmdnote}

When the aim is to map the study variable, a model-based approach is the most natural option. This implies that for this aim probability sampling is not necessarily required. In principle, both approaches are suitable for estimating (sub)population parameters\index{Population parameter}. The more subpopulations\index{Subpopulation} are distinguished, the more attractive a model-based approach becomes. Model-based estimates of the subpopulation means or totals are potentially more accurate (depending on how good the model is) than model-free design-based estimates. On the other hand, an advantage of design-based estimation is that an objective assessment of the uncertainty of the estimated mean or total is warranted, and that the coverage of confidence intervals is (almost) correct.

A probability sample can also be used in model-based inference. This flexibility can be attractive when we have a dual aim, mapping as well as estimation of parameters of (sub)populations. When units are not selected by probability sampling, model-free design-based estimation is impossible, and model-based prediction is the only option.

\hypertarget{Datasets}{%
\section{Populations used in sampling experiments}\label{Datasets}}

In this book various data sets are used to illustrate the sampling designs. Four data sets, Voorst, Kandahar, Eastern Amazonia, and the Iberian Peninsula (Spain and Portugal), are exhaustive, i.e.~for all population units data of the study variable and ancillary data are available. The first two exhaustive data sets\index{Exhaustive data set} are obtained through simulation\index{Simulation}, i.e.~by drawing numbers from a probability distribution. Sample data from these two study areas are used to calibrate a statistical model. This model is subsequently used to simulate values of the study variable for all population units. Voorst actually is an infinite population of points. However, this study area is discretised by the cells of a fine grid, and the study variable, the soil organic matter (SOM) concentration, is simulated for all centres of the grid cells. Kandahar is a finite population consisting of 965 squares of size 5 km \(\times\) 5 km. The study variable is the area cultivated with poppy. Eastern Amazonia is a map in raster format, with a resolution of 1 km \(\times\) 1 km. The study variable is the aboveground biomass as derived from remote sensing images. The aboveground biomass value of a raster cell is treated as the average biomass of that raster cell. Data set Iberian Peninsula is a time series of four maps in raster format with a resolution of 30 arc sec.~The study variable is the annual mean air temperature at two metres above the earth surface in \(^\circ\)C.

The exhaustive data sets are used in the first part of this book on probability sampling for estimating population parameters. By taking the population as the reality, we know the population parameters. Also, for any randomly selected sample from this population, the study variable values for the selected sampling units are known, so that we can \emph{estimate} the population parameters from this sample. An estimated population parameter can then be compared with the population parameter. The difference between these two is the \emph{sampling error}\index{Sampling error} in the estimated population parameter. This opens up the possibility of repeating the random selection of samples with a given sampling design a large number of times, estimating the population parameter for every sample, so that a frequency distribution of the estimated population parameter is obtained. Ideally, the mean of this frequency distribution, referred to as the \emph{sampling distribution}\index{Sampling distribution}, is equal to the population parameter (mean sampling error equals zero), and the variance of the estimated population parameters is small. Another advantage is that sampling designs can be compared on the basis of the sampling distribution, for instance the sampling distributions of the estimator of the population mean with stratified random sampling and simple random sampling, to evaluate whether the stratification leads to more accurate estimates of the population mean.

Furthermore, various data sets are used with data for a sample of population units only. These data sets are described at places where they are first used.

All data sets are available by installing the \textbf{R} package \textbf{sswr}. This package can be installed from github with function \texttt{install\_github} of package \textbf{devtools} \citep{devtools}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(devtools)}
\FunctionTok{install\_github}\NormalTok{(}\StringTok{"DickBrus/sswr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The package can then be loaded. You can see the contents of the package and of the data files by typing a question mark, followed by the name of the package or a data file.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sswr)}
\NormalTok{?sswr}
\NormalTok{?grdVoorst}
\end{Highlighting}
\end{Shaded}

\hypertarget{Voorst}{%
\subsection{Soil organic matter in Voorst (Netherlands)}\label{Voorst}}

The study area of Voorst is located in the eastern part of the Netherlands. The size of the study area is 6 km \(\times\) 1 km. At 132 points samples of the topsoil were collected by graduate students of Wageningen University, which were then analysed for SOM concentrations (in g kg\textsuperscript{-1} dry soil) in a laboratory. The map is created by conditional geostatistical simulation of natural logs of the SOM concentration on a 25 m \(\times\) 25 m grid, followed by backtransformation, using a linear mixed model with spatially correlated residuals and combinations of soil type and land use as a qualitative predictor (factor). Figure \ref{fig:mapVoorst} shows the simulated map of the SOM concentration.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/mapVoorst-1} 

}

\caption{Simulated map of the SOM concentration (g kg\textsuperscript{-1}) in Voorst.}\label{fig:mapVoorst}
\end{figure}

The frequency distribution of the simulated values at all 7,528 grid cells shows that the SOM concentration is skewed to the right (Figure \ref{fig:histogramVoorst}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histogramVoorst-1} 

}

\caption{Frequency distribution of the simulated SOM concentration (g kg\textsuperscript{-1}) in Voorst.}\label{fig:histogramVoorst}
\end{figure}

Summary statistics are:

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  10.75   49.45   68.15   81.13  100.63  394.45 
\end{verbatim}

The ancillary information consists of a map of soil classes and a land use map, which are combined to five soil-land use combinations (Figure \ref{fig:SoilLanduseCombinationsVoorst}). The first letter in the labels for the combinations stands for the soil type: B for \emph{beekeerdgrond} (sandy wetland soil with gleyic properties), E for \emph{enkeerdgrond} (sandy soil with thick anthropogenic humic topsoil), P for podzols (sandy soil with eluviated horizon below the topsoil), R for river clay soil, and X for other sandy soils. The second letter is for land use: A for agriculture (grassland, arable land) and F for forest.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SoilLanduseCombinationsVoorst-1} 

}

\caption{Soil-land use combinations in Voorst.}\label{fig:SoilLanduseCombinationsVoorst}
\end{figure}

\hypertarget{Poppy}{%
\subsection{Poppy fields in Kandahar (Afghanistan)}\label{Poppy}}

Cultivation of poppy for opium production is a serious problem in Afghanistan. The United Nations Office on Drugs and Crime (UNODC) monitors the area cultivated with poppy through detailed analysis of aerial photographs and satellite images. This is laborious, and therefore the analysis is restricted to a probability sample of 5 km squares. These sample data are then used to estimate the total poppy area \citep{UNODC2014}.

In 2014 the poppy area within 83 randomly selected squares in the province of Kandahar (Afghanistan) was determined, as well as the agricultural area within all 965 squares in this province. These data were used to simulate a map of poppy area per 5 km square. The map is simulated with an ordinary kriging model for the logit transform of the proportion of the agricultural area cultivated with poppy within a 5 km square. For privacy reasons the field was simulated \emph{unconditionally} on these sample data. Figure \ref{fig:mapsKandahar} shows the map with the agricultural area in hectares per 5 km square and the map with the simulated poppy area in hectares per square. The frequency distribution of the simulated poppy area per square shows very strong positive skew (Figure \ref{fig:histogramPoppyarea}). For 375 squares the simulated poppy area was smaller than 1 ha.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/mapsKandahar-1} 

}

\caption{Agricultural area and simulated poppy area, in ha per 5 km square, in Kandahar.}\label{fig:mapsKandahar}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histogramPoppyarea-1} 

}

\caption{Frequency distribution of simulated poppy area in ha  per 5 km square in Kandahar.}\label{fig:histogramPoppyarea}
\end{figure}

\hypertarget{Amazonia}{%
\subsection{Aboveground biomass in Eastern Amazonia (Brazil)}\label{Amazonia}}

This data set consists of data on the aboveground live woody biomass (AGB) in megatons per ha \citep{Baccini2012}. A rectangular area of 1,642 km \(\times\) 928 km in Eastern Amazonia (Brazil) was selected from this data set. The data were aggregated to a map with a resolution of 1 km \(\times\) 1 km. Besides, a stack of five ecologically relevant covariates of the same spatial extent was prepared, being long term mean of MODIS short-wave infrared radiation (SWIR2), primary production in kg C per m\textsuperscript{2} (Terra\_PP), average precipitation in driest month in mm (Prec\_dm), elevation in m, and clay content in g kg\textsuperscript{-1} soil. All covariates were either resampled by bilinear interpolation or aggregated to conform with the grid of the aboveground biomass map. Figure \ref{fig:mapsAmazonia} shows a map of AGB and SWIR2.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/mapsAmazonia-1} 

}

\caption{Aboveground biomass (AGB) in 10\textsuperscript{9} kg ha\textsuperscript{-1} and short-wave infrared radiation (SWIR2) of Eastern Amazonia.}\label{fig:mapsAmazonia}
\end{figure}

Figure \ref{fig:matrixscatter} shows a matrix of two-dimensional density plots of aboveground biomass and the five covariates, made with function \texttt{ggpairs} of \textbf{R} package \textbf{GGally} \citep{GGally}. The covariate with the strongest correlation with AGB is SWIR2. The Pearson correlation coefficient with AGB is -0.80. The relation does not look linear. The correlation of AGB with the covariates Terra\_PP and Prec\_dm is weakly positive. All correlations are significant, but this is not meaningful because of the very large number of data used in computing the correlation coefficients.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/matrixscatter-1} 

}

\caption{Matrix of two-dimensional density plots of AGB and five covariates of Eastern Amazonia.}\label{fig:matrixscatter}
\end{figure}

\hypertarget{TASIberia}{%
\subsection{Annual mean air temperature in Iberia}\label{TASIberia}}

The space-time designs of Chapter \ref{RepeatedSurveys} are illustrated with the annual mean air temperature at two metres above the earth surface (TAS) in \(^\circ\)C, in Iberia (Spain and Portugal, islands excluded) for the years 2004, 2009, 2014, and 2019 (Figure \ref{fig:TASofIberia}). These data are part of the data set \href{https://chelsa-climate.org/wp-admin/download-page/CHELSA_tech_specification_V2.pdf}{CHELSA} \citep{Karger2017}. The raster files are latitude-longitude grids with a resolution of 30 arc sec.~The data are projected using the Lambert azimuthal equal area (laea) projection. The resolution of the resulting laea raster file is about 780 m \(\times\) 780 m.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/TASofIberia-1} 

}

\caption{Annual mean air temperature in Iberia for the years 2004, 2009, 2014, and 2019.}\label{fig:TASofIberia}
\end{figure}

\begin{verbatim}
           used  (Mb) gc trigger   (Mb)  max used   (Mb)
Ncells  4922579 262.9    9368568  500.4   9368568  500.4
Vcells 38953872 297.2  141890558 1082.6 177363197 1353.2
\end{verbatim}

\hypertarget{part-probability-sampling-for-estimating-subpopulation-parameters}{%
\part{Probability sampling for estimating (sub)population parameters}\label{part-probability-sampling-for-estimating-subpopulation-parameters}}

\hypertarget{IntroProbabilitySampling}{%
\chapter{Introduction to probability sampling}\label{IntroProbabilitySampling}}

To estimate population parameters like the mean or the total, \emph{probability sampling} is most appropriate. Probability sampling is random sampling using a random number generator such that all population units have a probability larger than zero of being selected, and that these probabilities are known for at least the selected units.

The probability that a unit is included in the sample, in short the inclusion probability\index{Inclusion probability of a unit} of that unit, can be calculated as the sum of the selection probabilities over all samples that can be selected with a given sampling design and that contain this unit. In formula:

\begin{equation}
\pi_k = \sum_{\mathcal{S} \ni k} p(\mathcal{S}) \;,
\label{eq:InclusionProbability}
\end{equation}

where \(\mathcal{S} \ni k\) indicates that the sum is over all samples that contain unit \(k\), and \(p(\mathcal{S})\) is the selection probability\index{Selection probability of a sample} of sample \(\mathcal{S}\). \(p(\cdot)\) is called the \emph{sampling design}\index{Sampling design}. It is a function that assigns a probability to every possible sample (subset of population units) that can be selected with a given sample selection scheme\index{Sample selection scheme} (sampling algorithm\index{Sampling algorithm}). For instance, consider the following sample selection scheme from a finite population of \(N\) units:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select with equal probability \(1/N\) a first unit.\\
\item
  Select with equal probability \(1/(N-1)\) a second unit from the remaining \(N-1\) units.\\
\item
  Repeat this until an \(n\)th unit is selected with equal probability from the \(N-(n-1)\) units.
\end{enumerate}

This is a selection scheme for simple random sampling without replacement. With this scheme the selection probability of any sample of \(n\) units is \(1/\binom{N}{n}\) (there are \(\binom{N}{n}\) samples of size \(n\), and each sample has an equal selection probability), and zero for all other samples. There are \(\binom{N-1}{n-1}\) samples of size \(n\) in which unit \(k\) is included. The inclusion probability of each unit \(k\) therefore is \(\binom{N-1}{n-1}/\binom{N}{n}=\frac{n}{N}\). The sampling design plays a key role in the design-based approach as it determines the sampling distribution of random quantities computed from a sample such as the estimator of the population mean, see Section \ref{HTestimator}. The number of selected population units is referred to as the \emph{sample size}\index{Sample size}.

\begin{rmdnote}
In sampling with replacement each unit can be selected more than once. In this case the sample size refers to the number of draws, not to the number of unique population units in the sample.
\end{rmdnote}

A common misunderstanding is that with probability sampling the inclusion probabilities must be equal. Sampling with unequal inclusion probabilities can be more efficient than with equal probabilities. Unequal probability sampling is no problem as long as the inclusion probabilities are known and proper formulas are used for estimation, see Section \ref{HTestimator}.

There are many schemes for selecting a probability sample. The following sampling designs are described and illustrated in this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  simple random sampling;
\item
  stratified random sampling;
\item
  systematic random sampling;
\item
  cluster random sampling;
\item
  two-stage cluster random sampling;
\item
  sampling with probabilities proportional to size;
\item
  balanced and well-spread sampling; and
\item
  two-phase random sampling.
\end{enumerate}

The first five sampling designs are basic sampling designs. Implementation of these designs is rather straightforward, as well as the associated estimation of the population mean, total, or proportion, and their sampling variance. The final three sampling designs are more advanced. Appropriate use of these designs requires more knowledge of sampling theory and statistics, such as linear regression.

\hypertarget{exercises}{%
\subsubsection*{Exercises}\label{exercises}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Suppose a researcher selects a sample of points from a study area by throwing darts on a map depicting the study area. Is the resulting sample a probability sample? If not, why not?
\end{enumerate}

\hypertarget{HTestimator}{%
\section{Horvitz-Thompson estimator}\label{HTestimator}}

For any probability sampling design the population total can be estimated as a weighted sum of the observations (measurements) of the study variable on the selected population units:

\begin{equation}
\hat{t}_{\pi}(z)=\sum_{k \in \mathcal{S} } w_k z_k \;,
\label{eq:HTTotal}
\end{equation}

with \(\mathcal{S}\) the sample, \(z_k\) the observed study variable for unit \(k\), and \(w_k\) the \emph{design weight}\index{Design weight} attached to unit \(k\):

\begin{equation}
w_k = \frac{1}{\pi_k}\;,
\label{eq:designweight}
\end{equation}

with \(\pi_k\) the inclusion probability of unit \(k\). The estimator\index{Estimator} of Equation \eqref{eq:HTTotal} is referred to as the Horvitz-Thompson estimator\index{Horvitz-Thompson estimator|see {$\pi$ estimator}} or \(\pi\) estimator\index{$\pi$ estimator}. The \(z_k/\pi_k\)-values are referred to as the \(\pi\)-expanded values\index{$\pi$-expanded value}. The \(z\)-value of unit \(k\) in the sample is multiplied by the reciprocal of the inclusion probability of that unit, and the sample sum of these \(\pi\)-expanded values is used as an estimator of the population total\index{Population total}. The inclusion probabilities are determined by the type of sampling design and the sample size.

\begin{rmdnote}
An \emph{estimator} is not the same as an \emph{estimate}. Whereas an estimate is a particular value calculated from the sample data, an estimator is a formula for estimating a parameter. An estimator is a \emph{random variable} and therefore has a probability distribution. For this reason it is not correct, although very common, to say `the variance (standard error) of the estimated population mean equals \ldots{}'. It is (more) correct to say `the variance (standard error) of the estimator of the population mean equals \ldots{}'.
\end{rmdnote}

Also for infinite populations\index{Population!infinite population}, think of points in a continuous population, the above estimator for the population total can be used, but special attention must then be paid to the inclusion probabilities. Suppose the infinite population is discretised by \(N\) cells of a fine grid, and a simple random sample of \(n\) cells is selected. The inclusion probabilities of the grid cells is then \(n/N\). However, constraining the sampling points to the centres of the cells of the discretisation grid is not needed and even undesirable. To account for the infinite number of points in the population we may adopt a two-step approach, see Figure \ref{fig:SamplingFromInfinitePopulation}. In the first step \(n\) cells of the discretisation grid are selected by simple random sampling \emph{with replacement}. In the second step one point is selected fully randomly from the selected grid cells. If a grid cell is selected more than once, more points are selected in that grid cell. With this selection procedure the inclusion probability density\index{Inclusion probability density} is \(n/A\), with \(A\) the area of the study area. This inclusion probability density equals the expected number of sampling points per unit area, e.g.~the expected number of points per ha or per m\textsuperscript{2}. The inclusion probability density can be interpreted as the global sampling intensity\index{Sampling intensity}. Note that the local sampling intensity may strongly vary, think for instance of cluster random sampling.

The \(\pi\) estimator for the \emph{mean} of a finite population\index{Population!finite population}\index{Population mean}, \(\bar{z}\), is simply the \(\pi\) estimator for the total, divided by the total number of units in the population, \(N\):

\begin{equation}
\hat{\bar{z}}_{\pi}=\frac{1}{N} \sum_{k \in \mathcal{S}} \frac{1}{\pi_k}z_k \;.
\label{eq:HTMean}
\end{equation}

For infinite populations discretised by a finite set of points the same estimator can be used.

For infinite populations the population total can be estimated by multiplying the estimated population mean by the area of the population \(A\):

\begin{equation}
\hat{t}_{\pi}(z)=A \hat{\bar{z}}_{\pi} \;.
\label{eq:HTTotalinfinite}
\end{equation}

The \(\pi\) estimator can be worked out for the different types of sampling design listed above by inserting the inclusion probabilities as determined by the sampling design. For simple random sampling this leads to the unweighted sample mean (see Chapter \ref{SI}), and for stratified simple random sampling the \(\pi\) estimator is equal to the weighted sum of the sample means per stratum, with weights equal to the relative size of the strata (see Chapter \ref{STSI}).

\hypertarget{hansen-hurwitz-estimator}{%
\section{Hansen-Hurwitz estimator}\label{hansen-hurwitz-estimator}}

In sampling finite populations, units can be selected with or without replacement. In sampling with replacement after each draw the selected unit is replaced. As a consequence, a unit can be selected more than once. Sampling with replacement is less efficient than sampling without replacement. If a population unit is selected in a given draw, there is no additional information in this unit if it is selected again. One reason that sampling with replacement\index{Sampling with replacement} is still used is that it is more easy to implement.

The most common estimator used for sampling with replacement is the Hansen-Hurwitz estimator\index{Hansen-Hurwitz estimator|see {pwr estimator}}, referred to as the \(p\)-expanded with replacement (pwr) estimator\index{pwr estimator} by \citet{sar92}. With direct unit sampling, i.e.~sampling of individual population units, the pwr estimator is

\begin{equation}
\hat{t}_{\text{pwr}}(z)=\frac{1}{n}\sum_{k \in \mathcal{S} } \frac{z_k}{p_k} \;,
\label{eq:pwrTotal}
\end{equation}

with \(p_k\) the \emph{draw-by-draw selection probability} of population unit \(k\). For instance, in simple random sampling with replacement the draw-by-draw selection probability \(p\) of each unit is \(1/N\). If we select only one unit \(k\), the population total can be estimated by the observation of that unit divided by \(p\), \(\hat{t}(z) = z_k/p_k = N z_k\). If we repeat this \(n\) times, this results in \(n\) estimated population totals. The pwr estimator is the average of these \(n\) elementary estimates. If a unit occurs multiple times in the sample \(\mathcal{S}\), this unit provides multiple elementary estimates of the population total.

A sample obtained by sampling with replacement is referred to as an \emph{ordered sample}\index{Ordered sample} \citep{sar92}. Selecting the distinct units from this ordered sample results in the \emph{set-sample}\index{Set-sample}. Instead of using the ordered sample in the pwr estimator, we may use the set-sample in the \(\pi\) estimator. This requires computation of the inclusion probabilities for with replacement sampling. For instance, for simple random sampling with replacement the inclusion probability of each unit equals \(1-\left(1-\frac{1}{N}\right)^n\), with \(n\) the number of draws. This probability is smaller than \(n/N\), the inclusion probability for simple random sampling without replacement. There is no general rule which estimator is most accurate \citep{sar92}. In this book I only use the pwr estimator for sampling with replacement.

Sampling with replacement can also be applied at the level of clusters of population units as in cluster random sampling and two-stage cluster random sampling. If the clusters are selected with probabilities proportional to their size and with replacement, estimation of a population parameter is rather simple. This is a second reason why sampling with replacement can be attractive. With cluster sampling the Hansen-Hurwitz estimator is

\begin{equation}
\hat{t}_{\text{pwr}}(z)=\frac{1}{n}\sum_{j \in \mathcal{S} } \frac{t_j(z)}{p_j} \;,
\label{eq:pwrTotalcluster}
\end{equation}

with \(t_j(z)\) the total of the cluster selected in the \(j\)th draw. If not all population units of a selected cluster are observed, but only a sample of population units from a cluster, as in two-stage cluster random sampling, the cluster totals \(t_j(z)\) are replaced by the estimated cluster totals \(\hat{t}_j(z)\).

\hypertarget{exercises-1}{%
\subsubsection*{Exercises}\label{exercises-1}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Consider a population of four units (\(N=4\)). What is the inclusion probability of each population unit for simple random sampling without replacement and simple random sampling with replacement of two units (\(n=2\))?
\end{enumerate}

\hypertarget{using-models-in-design-based-approach}{%
\section{Using models in design-based approach}\label{using-models-in-design-based-approach}}

Design-based estimates of population parameters such as the mean, total, or proportion (areal fraction) are model-free: no use is made of a model for the spatial variation of the study variable. However, such a model can be used to optimise the probability sampling design. In Chapter \ref{MBpredictionofDesignVariance} I describe how a model can be used to compare alternative sampling designs at equal costs or equal precision to evaluate which sampling design performs best, to optimise the sample size(s) given a requirement on the precision of the estimated population parameter, or to optimise the spatial strata for stratified random sampling.

A model of the spatial variation can also be used at a later stage, after the data have been collected, in estimating the population parameter of interest. If one or more ancillary variables that are related to the study variable are available, these variables can be used in estimation to increase the accuracy. This leads to alternative estimators, such as the regression estimator, the ratio estimator, and the poststratified estimator (Chapter \ref{Modelassisted}). These estimators together are referred to as model-assisted estimators\index{Model-assisted approach}. In model-assisted estimation the inclusion probabilities, as determined by the random sampling design, play a key role, but besides, modelling assumptions about how the population might have been generated are used to work out an efficient estimator. The role of a model in the model-assisted approach is fundamentally different from its role in the model-based approach. This is explained in Chapter \ref{Approaches}.

For novices in geostatistics Chapters \ref{Modelassisted} and \ref{MBpredictionofDesignVariance} can be quite challenging, and I recommend to skip these chapters first and only return to them after having read the introductory chapter on geostatistics (Chapter \ref{Introkriging}).

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  4922598 262.9    9368568 500.4   9368568  500.4
Vcells 38954000 297.2  113512447 866.1 177363197 1353.2
\end{verbatim}

\hypertarget{SI}{%
\chapter{Simple random sampling}\label{SI}}

Simple random sampling\index{Simple random sampling} is the most basic form of probability sampling. There are two subtypes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  simple random sampling with replacement (SIR); and
\item
  simple random sampling without replacement (SI).
\end{enumerate}

This distinction is irrelevant for infinite populations. In with replacement sampling a population unit may be selected more than once.

In \textbf{R} a simple random sample can be selected with or without replacement by function \texttt{sample} from the \textbf{base} package. For instance, a simple random sample without replacement of 10 units from a population of 100 units labelled as \(1,2, \dots ,100\), can be selected by

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(}\DecValTok{100}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  21   7   5  16  58  76  44 100  71  84
\end{verbatim}

The number of units in the sample is referred to as the sample size (\(n = 10\) in the code chunk above). Use argument \texttt{replace\ =\ TRUE} to select a simple random sample with replacement.

When the spatial population is continuous and infinite, as in sampling points from an area, the infinite population is discretised by a very fine grid. Discretisation is not strictly needed (we could also select points directly), but it is used in this book for reasons explained in Chapter \ref{GeneralIntro}. The centres of the grid cells are then listed in a data frame, which serves as the sampling frame (Chapter \ref{GeneralIntro}). In the next code chunk a simple random sample without replacement of size 40 is selected from Voorst. The infinite population is represented by the centres of square grid cells with a side length of 25 m. These centres are listed in tibble (a data frame of class \texttt{tbl\_df}) \texttt{grdVoorst}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[units, ]}
\NormalTok{mysample}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 40 x 4
       s1      s2     z stratum
    <dbl>   <dbl> <dbl> <chr>  
 1 206992 464506.  23.5 EA     
 2 202567 464606. 321.  XF     
 3 205092 464530. 124.  XF     
 4 203367 464556.  53.6 EA     
 5 205592 465180.  38.4 PA     
 6 201842 464956. 159.  XF     
 7 201667 464930. 139.  XF     
 8 204317 465306.  59.4 PA     
 9 203042 464406.  90.5 BA     
10 204567 464530.  48.1 PA     
# ... with 30 more rows
\end{verbatim}

The result of function \texttt{sample} is a vector with the centres of the selected cells of the discretisation grid (discretisation points). The order of the elements of the vector is the order in which these are selected. Restricting the sampling points to the discretisation points can be avoided as follows. A simple random sample of points is selected in two stages. First, \emph{n} times a grid cell is selected by simple random sampling \emph{with replacement}. Second, every time a grid cell is selected, one point is selected fully randomly from that grid cell. This selection procedure accounts for the infinite number of points in the population. In the code chunk below the second step of this selection procedure is implemented with function \texttt{jitter}. It adds random noise to the spatial coordinates of the centres of the selected grid cells, by drawing from a continuous uniform distribution \(\text{unif}(-c,c)\), with \(c\) half the side length of the square grid cells. With this selection procedure we respect that the population actually is infinite.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[units, ]}
\NormalTok{cellsize }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{s1 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{s1, }\AttributeTok{amount =}\NormalTok{ cellsize }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{s2 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{s2, }\AttributeTok{amount =}\NormalTok{ cellsize }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysample}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 40 x 4
        s1      s2     z stratum
     <dbl>   <dbl> <dbl> <chr>  
 1 206986. 464493.  23.5 EA     
 2 202574. 464609. 321.  XF     
 3 205095. 464527. 124.  XF     
 4 203369. 464556.  53.6 EA     
 5 205598. 465181.  38.4 PA     
 6 201836. 464965. 159.  XF     
 7 201665. 464941. 139.  XF     
 8 204319. 465310.  59.4 PA     
 9 203052. 464402.  90.5 BA     
10 204564. 464529.  48.1 PA     
# ... with 30 more rows
\end{verbatim}

Variable \texttt{stratum} is not used in this chapter (but in the next chapter). The selected sample is shown in Figure \ref{fig:SampleSI}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SampleSI-1} 

}

\caption{Simple random sample of size 40 from Voorst.}\label{fig:SampleSI}
\end{figure}

\hypertarget{drop-outs}{%
\subsubsection*{Drop outs}\label{drop-outs}}


What to do with selected units that do not belong to the target population or cannot be observed for whatever reason (e.g.~no permission)\index{Drop outs}? In practice it may happen that inspection in the field shows that a selected sampling unit does not belong to the target population. For instance, in a soil survey the sampling unit may happen to fall on a road or in a built-up area. Shifting this unit to a nearby unit may lead to a biased estimator of the population mean, i.e.~a systematic error\index{Systematic error} in the estimated population mean. Besides, knowledge of the inclusion probabilities is lost. This can be avoided by discarding these units and to replace them by sampling units from a back-up list\index{Back-up list of sampling units}, selected in the same way, i.e.~by the same type of sampling design. The order of sampling units in this list must be the order in which they are selected. In summary, do not replace a deleted sampling unit by the nearest sampling unit from the back-up list, but by the first unit, not yet selected, from the back-up list.

\hypertarget{arbitrary-haphazard-sampling-versus-probability-sampling}{%
\subsubsection*{Arbitrary (haphazard) sampling versus probability sampling}\label{arbitrary-haphazard-sampling-versus-probability-sampling}}


In publications it is commonly stated that the sampling units were selected (more or less) at random (within strata), without further specification of how the sampling units were precisely selected. In statistical inference, the sampling units are subsequently treated as if they were selected by (stratified) simple random sampling. With probability sampling all units in the population have a positive probability of being selected, and the inclusion probabilities are known for all units. It is highly questionable whether this also holds for arbitrary\index{Arbitrary sampling} and haphazard sampling\index{Haphazard sampling}. In arbitrary and haphazard sampling the sampling units are not selected by a probability mechanism. So, the selection probabilities of the sampling units and of combinations of sampling units are unknown. Design-based estimation is therefore impossible, because it requires the inclusion probabilities of the population units as determined by the sampling design. The only option for statistical analysis using arbitrarily or haphazardly selected samples is model-based inference, i.e.~a model of the spatial variation must be assumed.

\hypertarget{HTestimatorSI}{%
\section{Estimation of population parameters}\label{HTestimatorSI}}

In simple random sampling without replacement of a finite population every possible sample of \(n\) units has an equal probability of being selected. There are \(\binom{N}{n}\) samples of size \(n\) and \(\binom{N-1}{n-1}\) samples that contain unit \(k\). From this it follows that the probability that unit \(k\) is included in the sample is \(\binom{N-1}{n-1}/\binom{N}{n}=\frac{n}{N}\) \citep{loh99}. Substituting this in the general \(\pi\) estimator for the total (Equation \eqref{eq:HTTotal}) gives for simple random sampling without replacement (from finite populations)

\begin{equation}
\hat{t}(z)=\frac{N}{n}\sum_{k \in \mathcal{S}} z_k = N \bar{z}_{\mathcal{S}} \;,
\label{eq:HTTotalSI}
\end{equation}

with \(\bar{z}_{\mathcal{S}}\) the (unweighted) \emph{sample mean}\index{Sample mean}. So, for simple random sampling without replacement the \(\pi\) estimator of the population mean is the \emph{unweighted} sample mean:

\begin{equation}
\hat{\bar{z}} = \bar{z}_{\mathcal{S}} = \frac{1}{n}\sum_{k \in \mathcal{S}} z_k \;.
\label{eq:HTMeanSI}
\end{equation}

In simple random sampling with replacement of finite populations a unit may occur multiple times in the sample \(\mathcal{S}\). In this case the population total can be estimated by the pwr estimator \citep{sar92}

\begin{equation}
\hat{t}(z)= \frac{1}{n} \sum_{k \in \mathcal{S}} \frac{z_{k}}{p_{k}} \;,
\label{eq:HHTotal}
\end{equation}

where \(n\) is the number of draws (sample size) and \(p_{k}\) is the draw-by-draw selection probability of unit \(k\). With simple random sampling \(p_{k}=1/N, k=1, \dots , N\). Inserting this in the pwr estimator yields

\begin{equation}
\hat{t}(z)= \frac{N}{n} \sum_{k \in \mathcal{S}} z_{k} \;,
\label{eq:HHTotalSIR}
\end{equation}

which is equal to the \(\pi\) estimator of the population total for simple random sampling \emph{without replacement}.

Alternatively, the population total can be estimated by the \(\pi\) estimator. With simple random sampling with replacement the inclusion probability of each unit \(k\) equals \(1-\left(1-\frac{1}{N}\right)^n\), which is smaller than the inclusion probability with simple random sampling without replacement of size \(n\) \citep{sar92}. Inserting these inclusion probabilities in the general \(\pi\) estimator of the population total (Equation \eqref{eq:HTTotal}), where the sample \(\mathcal{S}\) is reduced to the unique units in the sample, yields the \(\pi\) estimator of the total for simple random sampling with replacement.

With simple random sampling of \emph{infinite} populations the \(\pi\) estimator of the population mean equals the sample mean. Multiplying this estimator with the area of the region of interest \(A\) yields the \(\pi\) estimator of the population total:

\begin{equation}
\hat{t}(z)= \frac{A}{n}\sum_{k \in \mathcal{S}}z_{k} \;.
\label{eq:HTTotalSIInfinite}
\end{equation}

The simple random sample of size 40 selected above is used to estimate the total mass of soil organic matter (SOM) in the population. First, the population mean is estimated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z)}
\end{Highlighting}
\end{Shaded}

The estimated mean SOM concentration is 93.3 g kg\textsuperscript{-1}. Simply multiplying the estimated mean by the area \(A\) to obtain an estimate of the population total is not very useful, as the dimension of the total then is in g kg\textsuperscript{-1} m\textsuperscript{2}. To estimate the total mass of SOM in the soil layer \(0-30\) cm, first the soil volume in m\textsuperscript{3} is computed by the total number of grid cells, \(N\), multiplied by the size of the grid cells and by the thickness of the soil layer. The total is then estimated by the product of this volume, the bulk density of soil (1,500 kg m\textsuperscript{-3}), and the estimated population mean (g kg\textsuperscript{-1}). This is multiplied by 10\textsuperscript{-6} to obtain the total mass of SOM in Mg (1 Mg is 1,000 kg).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vol\_soil }\OtherTok{\textless{}{-}}\NormalTok{ N }\SpecialCharTok{*} \DecValTok{25}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*} \FloatTok{0.3}
\NormalTok{bd }\OtherTok{\textless{}{-}} \DecValTok{1500}
\NormalTok{tz }\OtherTok{\textless{}{-}}\NormalTok{ vol\_soil }\SpecialCharTok{*}\NormalTok{ bd }\SpecialCharTok{*}\NormalTok{ mz }\SpecialCharTok{*} \DecValTok{10}\SpecialCharTok{\^{}{-}}\DecValTok{6}
\end{Highlighting}
\end{Shaded}

The estimated total is 197,545 Mg (420 Mg ha\textsuperscript{-1}).

\begin{rmdnote}
Note that a constant bulk density is used. Ideally, this bulk density is also measured at the sampling points, by collecting soil aliquots of a constant volume. The measured SOM concentration and bulk density can then be used to compute the volumetric SOM concentration in kg m\(^{-3}\) at the sampling points. The estimated population mean of this volumetric SOM concentration can then be multiplied by the total volume of soil in the study area, to get an estimate of the total mass of SOM in the study area.\\
\end{rmdnote}

The simulated population is now sampled 10,000 times to see how sampling affects the estimates. For each sample the population mean is estimated by the sample mean. Figure \ref{fig:SamplingDistributionSI} shows the approximated sampling distribution of the \(\pi\) estimator of the mean SOM concentration. Note that the sampling distribution is nearly symmetric, whereas the histogram of the SOM concentrations in the population is far from symmetric, see Figure \ref{fig:histogramVoorst}. The increased symmetry is due to the averaging of 40 numbers.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionSI-1} 

}

\caption{Approximated sampling distribution of the \(\pi\) estimator of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst for simple random sampling of size 40.}\label{fig:SamplingDistributionSI}
\end{figure}

If we would repeat the sampling an infinite number of times and make the width of the bins in the histogram infinitely small, then we obtain, after scaling so that the sum of the area under the curve equals 1, the \emph{sampling distribution}\index{Sampling distribution} of the estimator of the population mean. Important summary statistics of this sampling distribution are the expectation (mean) and the variance.

When the expectation\index{Expectation of estimator} equals the population mean, there is no systematic error. The estimator is then said to be \emph{design-unbiased}\index{Unbiasedness!design-unbiasedness}. In Chapter \ref{Introkriging} another type of unbiasedness is introduced, model-unbiasedness. The difference between design-unbiasedness and model-unbiasedness is explained in Chapter \ref{Approaches}. In following chapters of Part I unbiased means design-unbiased. Actually, it is not the estimator which is unbiased, but the combination of a sampling design and an estimator. For instance, with an equal probability sampling design the sample mean is an unbiased estimator of the population mean, whereas it is a biased estimator in combination with an unequal probability sampling design.

The variance, referred to as the sampling variance\index{Sampling variance}, is a measure of the random error\index{Random error}. Ideally, this variance is as small as possible, so that there is a large probability that for an individual estimate the estimation error is small. The variance is a measure of the \emph{precision}\index{Precision} of an estimator. An estimator with a small variance but a strong bias is not a good estimator. To assess the quality of an estimator we should look at both. The variance and the bias are often combined in the \emph{mean squared error}\index{Mean squared error} (MSE), which is the sum of the variance and the \emph{squared} bias. An estimator with a small MSE is an \emph{accurate} estimator. So, contrary to precision, accuracy\index{Accuracy} also accounts for the bias\index{Bias}.

Do not confuse the \emph{population} variance and the \emph{sampling} variance. The population variance\index{Population variance} (spatial variance) is a \emph{population characteristic}, whereas the sampling variance is a \emph{characteristic of a sampling strategy},\index{Sampling strategy} i.e.~a combination of a sampling design and an estimator. The sampling variance quantifies our \emph{uncertainty} about the population mean. The sampling variance can be manipulated by changing the sample size \(n\), the type of sampling design, and the estimator. This has no effect on the population variance. The average of the 10,000 estimated population means equals 81.1 g kg\textsuperscript{-1}, so the difference with the true population mean equals -0.0 g kg\textsuperscript{-1}. The variance of the 10,000 estimated population means equals 55.8 (g kg\textsuperscript{-1})\textsuperscript{2}. The square root of this variance, referred to as the \emph{standard error}\index{Standard error}, equals 7.5 g kg\textsuperscript{-1}. Note that the standard error has the same units as the study variable, g kg\textsuperscript{-1}, whereas the units of the variance are the squared units of the study variable.

\hypertarget{PopProportion}{%
\subsection{Population proportion}\label{PopProportion}}

In some cases one is interested in the proportion of the population (study area) satisfying a given condition. Think, for instance, of the proportion of trees in a forest infected by some disease, the proportion of an area (areal fraction) in which a soil pollutant exceeds some critical threshold, or the proportion of an area where habitat conditions are suitable for some endangered species. Recall that a population proportion\index{Population proportion} is defined as the population mean of an 0/1 indicator \(y\) with value 1 if the condition is satisfied, and 0 otherwise (Subsection \ref{PopulationParameters}). For simple random sampling this population proportion can be estimated by the same formula as for the mean (Equation \eqref{eq:HTMeanSI}):

\begin{equation}
\hat{p} =  \frac{1}{n}\sum_{k \in \mathcal{S}} y_k \;.
\label{eq:HTProportionSI}
\end{equation}

\hypertarget{CDF}{%
\subsection{Cumulative distribution function and quantiles}\label{CDF}}

The population CDF is defined in Equation \eqref{eq:CDF}. A population CDF can be estimated by repeated application of the indicator technique described in the previous subsection on estimating a population proportion. A series of threshold values is chosen. Each threshold results in \(n\) indicator values having value 1 if the observed study variable \(z\) of unit \(k\) is smaller than or equal to the threshold, and 0 otherwise. These indicator values are then used to estimate the proportion of the population with a \(z\)-value smaller than or equal to that threshold. For simple random sampling these proportions can be estimated with Equation \eqref{eq:HTProportionSI}. Commonly the unique \(z\)-values in the sample are used as threshold values, leading to as many estimated population proportions as there are unique values in the sample.

Figure \ref{fig:CDFSIVoorst} shows the estimated CDF, estimated from the simple random sample of 40 units from Voorst. The steps are at the unique values of SOM in the sample.



\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mysample, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(z)) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{geom =} \StringTok{"step"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{name =} \StringTok{"SOM"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{name =} \StringTok{"F"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/CDFSIVoorst-1} 

}

\caption{Estimated cumulative distribution function of the SOM concentration (g kg\textsuperscript{-1}) in Voorst, estimated from the simple random sample of 40 units.}\label{fig:CDFSIVoorst}
\end{figure}

The estimated population proportions can be used to estimate a population quantile\index{Population quantile} for any population proportion (cumulative frequency, probability), for instance the median, first quartile\index{Quartile}, and third quartile, corresponding to a population proportion of 0.5, 0.25, and 0.75, respectively. A simple estimator is the smallest \(k\)th order statistic\index{\emph{k}th order statistic} with an estimated proportion larger than or equal to the desired cumulative frequency \citep{Hyndman1996}.

The estimated CDF shows jumps of size \(1/n\), so that the estimated population proportion can be larger than the desired proportion. The estimated population proportions therefore are often interpolated, for instance linearly. Function \texttt{quantile} of the \textbf{stats} package can be used to estimate a quantile. With argument \texttt{type\ =\ 4} linear interpolation is used to estimate the quantiles.

\begin{rmdnote}
Function \texttt{quantile} actually computes sample quantiles\index{Sample quantile}, i.e.~it assumes that the population units are selected with equal inclusion probabilities (as in simple random sampling), so that the estimators of the population proportions obtained with Equation \eqref{eq:HTProportionSI} are unbiased. With unequal inclusion probabilities these probabilities must be accounted for in estimating the population proportions, see following chapters.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{quantile}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{), }\AttributeTok{type =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  25%   50%   75% 
 50.4  65.6 138.7 
\end{verbatim}

Note the pipe operator \texttt{\%\textgreater{}\%} of package \textbf{magrittr} \citep{magrittr} forwarding the result of function \texttt{quantile} to function \texttt{round}.

Package \textbf{QuantileNPCI} \citep{QuantileNPCI} can be used to compute a non-parametric confidence interval estimate of a quantile, using fractional order statistics \citep{Hutson1999}. Parameter \texttt{q} specifies the proportion.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(QuantileNPCI)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{quantCI}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{q =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{method =} \StringTok{"exact"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The estimated median equals 66.2 g kg\textsuperscript{-1}, the lower bound of the 95\% confidence interval equals 54.0 g kg\textsuperscript{-1}, and the upper bound equals 98.1 g kg\textsuperscript{-1}.

\hypertarget{exercises-2}{%
\subsubsection*{Exercises}\label{exercises-2}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare the approximated sampling distribution of the \(\pi\) estimator of the mean SOM concentration of Voorst (Figure \ref{fig:SamplingDistributionSI}) with the histogram of the 7,528 simulated SOM values (Figure \ref{fig:histogramVoorst}). Explain the differences.\\
\item
  What happens with the spread in the approximated sampling distribution (variance of estimated population means) when the sample size \(n\) is increased?\\
\item
  Suppose we would repeat the sampling \(10^{12}\) number of times, what would happen with the difference between the average of the estimated population means and the true population mean?
\end{enumerate}

\hypertarget{VarMeanSI}{%
\section{Sampling variance of estimator of population parameters}\label{VarMeanSI}}

For simple random sampling of an infinite population and simple random sampling with replacement of a finite population the sampling variance of the estimator of the population mean equals

\begin{equation}
V\!\left(\hat{\bar{z}}\right)=\frac{S^{2}(z)}{n} \;,
\label{eq:VarMean}
\end{equation}

with \(S^{2}(z)\) the \emph{population} variance\index{Population variance}, also referred to as the spatial variance\index{Spatial variance}. For finite populations this population variance is defined as \citep{loh99}

\begin{equation}
S^{2}(z)=\frac{1}{N-1}\sum\limits_{k=1}^N\left(z_{k}-\bar{z}\right)^{2} \;,
\label{eq:PopulationVariance}
\end{equation}

and for infinite populations as

\begin{equation}
S^{2}(z) = \frac{1}{A} \int \limits_{\mathbf{s} \in \mathcal{A}} \left(z(\mathbf{s})-\bar{z}\right)^2\text{d}\mathbf{s} \;,
\label{eq:PopulationVarianceInfinite}
\end{equation}

with \(z(\mathbf{s})\) the value of the study variable \(z\) at a point with two-dimensional coordinates \(\mathbf{s}=(s_1,s_2)\), \(A\) the area of the study area, and \(\mathcal{A}\) the study area. In practice we select only one sample, i.e.~we do not repeat the sampling many times. Still it is possible to \emph{estimate} the variance of the estimator of the population mean if we would repeat the sampling. In other words, we can estimate the sampling variance of the estimator of the population mean from a single sample. We do so by estimating the population variance from the sample, and this estimate can then be used to estimate the \emph{sampling} variance of the estimator of the population mean. For simple random sampling \emph{with replacement} from finite populations the sampling variance of the estimator of the population mean can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}\right)=\frac{\widehat{S^2}(z)}{n}= \frac{1}{n\,(n-1)}\sum\limits_{k \in \mathcal{S}}\left(z_{k}-\bar{z}_{\mathcal{S}}\right)^{2} \;,
\label{eq:EstVarMeanSIR}
\end{equation}

with \(\widehat{S^2}(z)\) the \emph{estimated} population variance. With simple random sampling the \emph{sample} variance\index{Sample variance}, i.e.~the variance of the sample data, is an unbiased estimator of the population variance. The variance estimator of Equation \eqref{eq:EstVarMeanSIR} can also be used for \emph{infinite} populations. For simple random sampling \emph{without replacement} from finite populations the sampling variance of the estimator of the population mean can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}\right)=\left(1-\frac{n}{N}\right)\frac{\widehat{S^2}(z)}{n} \;.
\label{eq:EstVarMeanSI}
\end{equation}

The term \(1-\frac{n}{N}\) is referred to as the finite population correction\index{Finite population correction} (fpc).

In the sampling experiment\index{Sampling experiment} described above, the average of the 10,000 \emph{estimated} sampling variances equals 55.7 (g kg\textsuperscript{-1})\textsuperscript{2}. The true sampling variance equals 55.4 (g kg\textsuperscript{-1})\textsuperscript{2}. So, the difference is very small, indicating that the estimator of the sampling variance, Equation \eqref{eq:EstVarMeanSI}, is design-unbiased.

The sampling variance of the estimator of the total of a finite population can be estimated by multiplying the estimated variance of the estimator of the population mean by \(N^2\). For simple random sampling without replacement this estimator thus equals

\begin{equation}
\widehat{V}\!\left(\hat{t}(z)\right)=N^2 \left(1-\frac{n}{N}\right)\frac{\widehat{S^{2}}(z)}{n} \;.
\label{eq:EstVarTotalSI}
\end{equation}

For simple random sampling of infinite populations the sampling variance of the estimator of the total can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{t}(z)\right)=A^2\frac{\widehat{S^{2}}(z)}{n} \;.
\label{eq:EstVarTotalSIR}
\end{equation}

The sampling variance of the estimator of a proportion \(\hat{p}\) for simple random sampling without replacement of a finite population can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{p}\right)=\left( 1-\frac{n}{N}\right) \frac{\hat{p}(1-\hat{p})}{n-1} \;.
\label{eq:EstVarProportionSI}
\end{equation}

The numerator in this estimator is an estimate of the population variance of the indicator. Note that this estimated population variance is divided by \(n-1\), and not by \(n\) as in the estimator of the population mean \citep{loh99}.

Estimation of the standard error of the estimated population mean in \textbf{R} is very straightforward. To estimate the standard error of the estimated total in Mg the standard error of the estimated population mean must be multiplied by a constant equal to the product of the soil volume, the bulk density, and \(10^{-6}\), see second code chunk in Section \ref{HTestimatorSI}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se\_mz }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{se\_tz }\OtherTok{\textless{}{-}}\NormalTok{ se\_mz }\SpecialCharTok{*}\NormalTok{ vol\_soil }\SpecialCharTok{*}\NormalTok{ bd }\SpecialCharTok{*} \DecValTok{10}\SpecialCharTok{\^{}{-}}\DecValTok{6}
\end{Highlighting}
\end{Shaded}

The estimated standard error of the estimated total equals 20,334 Mg. This standard error does not account for spatial variation of bulk density.

Although there is no advantage in using package \textbf{survey} \citep{Lumley2020} to compute the \(\pi\) estimator and its standard error for this simple sampling design, I illustrate how this works. For more complex designs and alternative estimators, estimation of the population mean and its standard error with functions defined in this package is very convenient, as will be shown in the following chapters.

First, the sampling design that is used to select the sampling units is specified with function \texttt{svydesign}. The first argument specifies the sampling units. In this case the centres of the discretisation grid cells are used as sampling units, which is indicated by the formula \texttt{id\ =\ \textasciitilde{}\ 1}. In Chapter \ref{Cl} clusters of population units are used as sampling units, and in Chapter \ref{Twostage} both clusters and individual units are used as sampling units. Argument \texttt{probs} specifies the inclusion probabilities of the sampling units. Alternatively, we may specify the weights with argument \texttt{weights}, which are in this case equal to the inverse of the inclusion probabilities. Variable \texttt{pi} is a variable in \texttt{mysample}, which is indicated with the tilde in \texttt{probs\ =\ \textasciitilde{}\ pi}.

The population mean is then estimated with function \texttt{svymean}. The first argument is a formula specifying the study variable. Argument \texttt{design} specifies the sampling design.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{probs =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, }\AttributeTok{design =}\NormalTok{ design\_si)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 93.303 9.6041
\end{verbatim}

For simple random sampling of finite populations without replacement, argument \texttt{fpc} is used to correct the standard error.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{N }\OtherTok{\textless{}{-}}\NormalTok{ N}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{probs =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ N, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_si)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 93.303 9.5786
\end{verbatim}

The estimated standard error is smaller now due to the finite population correction, see Equation \eqref{eq:EstVarMeanSI}.

Population totals can be estimated with function \texttt{svytotal}, quantiles with function \texttt{svyquantile}, and ratios of population totals with \texttt{svyratio}, to mention a few functions that will be used in following chapters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{svyquantile}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_si, }\AttributeTok{quantile =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$z
     quantile    ci.2.5   ci.97.5       se
0.5  65.56675  53.67764  99.93484 11.43457
0.9 164.36975 153.86258 320.74887 41.25353

attr(,"hasci")
[1] TRUE
attr(,"class")
[1] "newsvyquantile"
\end{verbatim}

\hypertarget{exercises-3}{%
\subsubsection*{Exercises}\label{exercises-3}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Is the sampling variance for simple random sampling without replacement larger or smaller than for simple random sampling with replacement, given the sample size \(n\)? Explain your answer.\\
\item
  What is the effect of the population size \(N\) on this difference?\\
\item
  In Section \ref{VarMeanSI} the true sampling variance is reported, i.e.~the variance of the estimator of the population mean if we would repeat the sampling an infinite number of times. How can this true sampling variance be computed?\\
\item
  In reality we cannot compute the true sampling variance. Why not?
\end{enumerate}

\hypertarget{ConfidenceInterval}{%
\section{Confidence interval estimate}\label{ConfidenceInterval}}

A second way of expressing our uncertainty about the estimated total, mean, or proportion is to present not merely a single number, but an interval. The wider the interval, the more uncertain we are, and vice versa, the narrower the interval, the more confident we are about the estimate. To learn how to compute a confidence interval\index{Confidence interval}, I return to the sampling distribution of the estimator of the mean SOM concentration. Suppose we would like to compute the bounds of an interval \([a,b]\) such that 5\% of the estimated population means is smaller than \(a\), and 5\% is larger than \(b\). To compute the lower bound \(a\) and the upper bound \(b\) of this 90\%-interval, we must specify the distribution function. When the distribution of the study variable \(z\) is normal and we know the variance of \(z\) in the population, then the sampling distribution of the estimator of the population mean is also normal, regardless of the sample size. The larger the sample size, the smaller the effect of the distribution of \(z\) on the sampling distribution of the estimator of the population mean. For instance, even when the distribution of \(z\) is far from symmetric, then still the sampling distribution of the estimator of the population mean is approximately normal if the sample size is large, say \(n > 100\). This is the essence of the central limit theorem\index{Central limit theorem}. Above we already noticed that the sampling distribution is much less asymmetric than the histogram of the simulated values, and looks much more like a normal distribution. Assuming a normal distribution, the bounds of the 90\%-interval are given by

\begin{equation}
\hat{\bar{z}} \pm u_{(0.10/2)}\cdot \sqrt{V\!\left(\hat{\bar{z}}\right)} \;,
\label{eq:CIBounds}
\end{equation}

where \(u_{(0.10/2)}\) is the \(0.95\) quantile of the standard normal distribution\index{Standard normal distribution}, i.e.~the value of \(u\) having a tail area of 0.05 to its right. Note that in this equation the sampling variance of the estimator of the population mean \(V\!\left(\hat{\bar{z}}\right)\) is used. In practice this variance is unknown, because the population variance is unknown, and must be estimated from the sample (Equations \eqref{eq:EstVarMeanSIR} and \eqref{eq:EstVarMeanSI}). To account for the unknown sampling variance, the standard normal distribution is replaced by the Student's \emph{t} distribution\index{Student's \emph{t} distribution} (hereafter shortly referred to as the \emph{t} distribution), which has thicker tails than the standard normal distribution. This leads to the following bounds of the \(100(1-\alpha)\%\) confidence interval estimate of the mean:

\begin{equation}
\hat{\bar{z}} \pm t^{(n-1)}_{\alpha /2}\cdot
\sqrt{\widehat{V}\!\left(\hat{\bar{z}}\right)} \;,
\label{eq:CIBoundsStudent}
\end{equation}

where \(t^{(n-1)}_{\alpha /2}\) is the \((1-\alpha /2)\) quantile of the \emph{t} distribution with \((n-1)\) degrees of freedom. The quantity \((1-\alpha)\) is referred to as the confidence level\index{Confidence level}. The larger the number of degrees of freedom\index{Degrees of freedom} \((n-1)\), the closer the \emph{t} distribution is to the standard normal distribution. The quantity \(t^{(n-1)}_{1-\alpha /2}\cdot \sqrt{\widehat{V}\!\left(\hat{\bar{z}}\right)}\) is referred to as the margin of error\index{Margin of error}.

Function \texttt{qt} computes a quantile of a \emph{t} distribution, given the degrees of freedom and the cumulative probability. The bounds of the confidence interval can then be computed as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{margin }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_mz}
\NormalTok{lower }\OtherTok{\textless{}{-}}\NormalTok{ mz }\SpecialCharTok{{-}}\NormalTok{ margin}
\NormalTok{upper }\OtherTok{\textless{}{-}}\NormalTok{ mz }\SpecialCharTok{+}\NormalTok{ margin}
\end{Highlighting}
\end{Shaded}

More easily we can use method \texttt{confint} of package \textbf{survey} to compute the confidence interval.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confint}\NormalTok{(}\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_si), }\AttributeTok{df =} \FunctionTok{degf}\NormalTok{(design\_si), }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     2.5 %   97.5 %
z 73.92817 112.6771
\end{verbatim}

\begin{rmdnote}
The interpretation of a confidence interval is not straightforward. A common misinterpretation is that if the 0.90 confidence interval estimate of the population mean equals \([a,b]\), then the probability that the population mean is in this interval equals 0.90. In classical sampling theory\index{Classical sampling theory} this cannot be a correct interpretation, because the population mean is not a random variable, and consequently the probability that the population mean is in an interval does not exist. However, the estimated bounds of the confidence interval are random variables, because the estimated population mean and also the estimated sampling variance varies among samples drawn with a probability sampling design. Therefore it does make sense to attach a probability to this interval.
\end{rmdnote}

Figure \ref{fig:coverageconfinterval} shows the 90\% confidence interval estimates of the mean SOM concentration for the first 100 simple random samples drawn above. Note that both the location and the length of the intervals differ between samples. For each sample I determined whether this interval covers the population mean.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/coverageconfinterval-1} 

}

\caption{Estimated confidence intervals of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst, estimated from 100 simple random samples of size 40. The vertical red line is at the true population mean (81.1 g kg\textsuperscript{-1}).}\label{fig:coverageconfinterval}
\end{figure}

Out of the 10,000 samples, 1,132 samples do not cover the population mean, i.e.~close to the specified 10\%. So, a 90\% confidence interval is a random interval that contains in the long run the population mean 90\% of the time.

\hypertarget{ConfidenceIntervalProportion}{%
\subsection{Confidence interval for proportion}\label{ConfidenceIntervalProportion}}

Ideally, a confidence interval for a population proportion is based on the binomial distribution\index{Binomial distribution} of the number of sampling units satisfying a condition (the number of successes). The binomial distribution is a discrete distribution. There are various methods for computing coverage probabilities of confidence intervals for a binomial proportion\index{Binomial proportion}, see \citet{Brown2001} for a discussion. A common method for computing the confidence interval of a proportion is the Clopper-Pearson method\index{Clopper-Pearson method}. Function \texttt{BinomCI} of package \textbf{DescTools} can be used to compute confidence intervals for proportions \citep{DescTools}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(DescTools)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{5}
\FunctionTok{print}\NormalTok{(p.est }\OtherTok{\textless{}{-}} \FunctionTok{BinomCI}\NormalTok{(k, n, }\AttributeTok{conf.level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{method =} \StringTok{"clopper{-}pearson"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     est     lwr.ci    upr.ci
[1,] 0.1 0.03327509 0.2181354
\end{verbatim}

The confidence interval is not symmetric around the estimated proportion of 0.1. As can be seen below, the upper bound is the proportion at which the probability of 5 or less successes is 0.025,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\AttributeTok{q =}\NormalTok{ k, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p.est[}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.025
\end{verbatim}

and the lower bound of the confidence interval is the proportion at which the probability of 5 or more successes is also equal to 0.025. Note that to compute the upper tail probability\index{Upper tail probability} we must assign \(k-1 = 4\) to argument \texttt{q}, because with argument \texttt{lower.tail\ =\ FALSE} function \texttt{pbinom} computes the probability of \(X>x\), not of \(X \geq x\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\AttributeTok{q =}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p.est[}\DecValTok{2}\NormalTok{], }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.025
\end{verbatim}

For large sample sizes and for proportions close to 0.5 the confidence interval can be computed with a normal distribution as an approximation to the binomial distribution, using Equation \eqref{eq:EstVarProportionSI} for the variance estimator of the estimator of a proportion:

\begin{equation}
\hat{p} \pm u_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n-1}} \;.
\label{eq:Waldinterval}
\end{equation}

This interval is referred to as the Wald interval\index{Wald interval}. It is a fact that unless \(n\) is very large, the actual coverage probability of the Wald interval is poor for \(p\) near 0 or 1. A rule of thumb is that the Wald interval should be used only when \(n \cdot min\{p,(1−p)\}\) is at least 5 or 10. For small \(n\) \citet{Brown2001} recommend the Wilson interval and for larger \(n\) the Agresti-Coull interval. These intervals can be computed with function \texttt{BinomCI} of package \textbf{DescTools}.

\hypertarget{SIcircularplots}{%
\section{Simple random sampling of circular plots}\label{SIcircularplots}}

In forest inventory, vegetation surveys, and agricultural surveys circular sampling plots\index{Circular sampling plot} are quite common. Using circular plots as sampling units is not entirely straightforward because the study area cannot be partitioned into a finite number of circles that fully cover the study area. The use of circular plots as sampling units can be implemented in two ways \citep{DeVries1986}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  sampling from a finite set of fixed circles; and
\item
  sampling from an infinite set of floating circles.
\end{enumerate}

\hypertarget{sampling-from-a-finite-set-of-fixed-circles}{%
\subsection{Sampling from a finite set of fixed circles}\label{sampling-from-a-finite-set-of-fixed-circles}}

Sampling from a finite set of fixed circles\index{Circular sampling plot!fixed} is most simple, but as we will see this requires an assumption about the distribution of the study variable in the population. In this implementation the sampling units consist of a finite set of slightly overlapping or non-overlapping fixed circular plots (Figure \ref{fig:circularplotswithinsquares}). The circles can be constructed as follows. A grid with squares is superimposed on the study area, so that it fully covers the study area. These squares are then substituted by circles with an area equal to the area of the squares, or by non-overlapping tangent circles inscribed in the squares. The radius of the partly overlapping circles equals \(\sqrt{a/\pi}\), with \(a\) the area of the squares, the radius of the non-overlapping circles equals \(\sqrt{a}/2\). In both implementations the infinite population is replaced by a finite population of circles that does not fully tessellate the study area. When using the partly overlapping circles as sampling units we may avoid overlap by selecting a systematic sample (Chapter \ref{SY}) of circular plots. The population total can then be estimated by Equation \eqref{eq:HTTotalSI}, substituting \(A/a\) for \(N\), and where \(z_k\) is the total of the \(k\)th circle (sum of observations of all population units in \(k\)th circle). However, no unbiased estimator of the sampling variance of the estimator of the population total or mean is available for this sampling design, see Chapter \ref{SY}.

With simple random sampling without replacement of non-overlapping circular plots the finite population total can be estimated by Equation \eqref{eq:HTTotalSI} and its sampling variance by Equation \eqref{eq:EstVarTotalSI}. However, the circular plots do not cover the full study area, and as a consequence the total of the infinite population is underestimated. A corrected estimate can be obtained by estimating the mean of the finite population and multiplying this estimated population mean by \(A/a\) \citep{DeVries1986}:

\begin{equation}
\hat{t}(z)= \frac{A}{a} \hat{\bar{z}}\;,
\label{eq:correctedestimate}
\end{equation}

with \(\hat{\bar{z}}\) the estimated mean of the finite population. The variance can be estimated by the variance of the estimator of the mean of the finite population, multiplied by the square of \(A/a\). However, we still need to assume that the mean of the finite population is equal to the mean of the infinite population. This assumption can be avoided by sampling from an infinite set of floating circles.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/circularplotswithinsquares-1} 

}

\caption{Simple random sample of ten circular plots from a square discretised by a finite set of partly overlapping or non-overlapping circular plots.}\label{fig:circularplotswithinsquares}
\end{figure}

\hypertarget{sampling-from-an-infinite-set-of-floating-circles}{%
\subsection{Sampling from an infinite set of floating circles}\label{sampling-from-an-infinite-set-of-floating-circles}}

A simple random sample of floating circular plots\index{Circular sampling plot!floating} can be selected by simple random sampling of the centres of the plots. The circular plots overlap if two selected points are separated by a distance smaller than the diameter of the circular plots. Besides, when a plot is selected near the border of the study area, a part of the plot is outside the study area. This part is ignored in estimating the population mean or total. To select the centres the study area must be extended by a zone with a width equal to the radius of the circular plots. This is illustrated in Figure \ref{fig:circularplots}, showing a square study area of 100 m \(\times\) 100 m. To select ten circular plots with a radius of 5 m from this square, ten points are selected by simple random sampling, using function \texttt{runif}, with -5 as lower limit and 105 as upper limit of the uniform distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{129}\NormalTok{)}
\NormalTok{s1 }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{min =} \SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\AttributeTok{max =} \DecValTok{105}\NormalTok{)}
\NormalTok{s2 }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{min =} \SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\AttributeTok{max =} \DecValTok{105}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Two points are selected outside the study area, in the extended zone. For both points a small part of the circular plot is inside the square. To determine the study variable for these two sampling units, only the part of the plot inside the square is observed. In other words, these two observations have a smaller support than the observations of the other eight plots, see Chapter \ref{GeneralIntro}.

In the upper left corner two sampling units are selected that largely overlap. The intersection of the two circular plots is used twice, to determine the study variable of both sampling units.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/circularplots-1} 

}

\caption{Simple random sample of ten floating circular plots from a square.}\label{fig:circularplots}
\end{figure}

Given the observations of the selected circular plots, the population total can be estimated by \citep{DeVries1986}

\begin{equation}
\hat{t}(z)= \frac{A}{a}\frac{1}{n}\sum_{k \in \mathcal{S}} z_k\;,
\label{eq:EstimatorPopulationTotalCircles}
\end{equation}

with \(a\) the area of the circle and \(z_k\) the observed total of sampling unit \(k\) (circle). The same estimate of the total is obtained if we divide the observations by \(a\) to obtain a mean per sampling unit:

\begin{equation}
\hat{t}(z)= A\frac{1}{n}\sum_{k \in \mathcal{S}}\frac{z_k}{a}\;.
\label{eq:EstimatorPopulationTotalCircles2}
\end{equation}

The sampling variance of the estimator of the total can be estimated by

\begin{equation}
\widehat{V}(\hat{t}(z)) = \left(\frac{A}{a}\right)^2 \frac{\widehat{S^2}(z)}{n}\;,
\label{eq:VarEstimatorPopulationTotalCircles}
\end{equation}

with \(\widehat{S^2}(z)\) the estimated population variance of the totals per population unit (circle).

\hypertarget{exercises-4}{%
\subsubsection*{Exercises}\label{exercises-4}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write an \textbf{R} script to select a simple random sample of size 40 from Voorst.

  \begin{itemize}
  \tightlist
  \item
    Use the selected sample to estimate the population mean of the SOM concentration and its standard error (SOM is in the variable \(z\) of the data frame).
  \item
    Compute the lower and the upper bound of the 90\% confidence interval using the \emph{t} distribution, and check whether the population mean is covered by the interval.
  \item
    Compare the length of the 90\% confidence interval with the length of the 95\% interval. Explain the difference in width.
  \item
    Use the selected sample to estimate the total mass of SOM in Mg in the topsoil (\(0-30\) cm) of Voorst. Use as a bulk density 1,500 kg m\(^{-3}\). The size of the grid cells is 25 m \(\times\) 25 m.
  \item
    Estimate the standard error of the estimated total.
  \item
    Do you think this standard error is a realistic estimate of the uncertainty about the estimated total?
  \end{itemize}
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5019462 268.1    9368568 500.4   9368568  500.4
Vcells 23803786 181.7   90809958 692.9 177363197 1353.2
\end{verbatim}

\hypertarget{STSI}{%
\chapter{Stratified simple random sampling}\label{STSI}}

In stratified random sampling\index{Stratified random sampling} the population is divided into subpopulations, for instance soil mapping units, areas with the same land use or land cover, administrative units, etc. The subareas are mutually exclusive, i.e.~they do not overlap, and are jointly exhaustive, i.e.~their union equals the entire population (study area). Within each subpopulation, referred to as a stratum\index{Stratum}, a probability sample is selected by some sampling design. If these probability samples are selected by simple random sampling, as described in the previous chapter, the design is stratified \emph{simple} random sampling\index{Stratified random sampling!stratified simple random sampling}, the topic of this chapter. If sampling units are selected by cluster random sampling, then the design is stratified \emph{cluster} random sampling.

Stratified simple random sampling is illustrated with Voorst (Figure \ref{fig:SampleSTSI}). In the data frame with simulated data there is a variable \texttt{stratum}. The strata are combinations of soil class and land use, obtained by overlaying a soil map and a land use map. To select a stratified simple random sample, we set the total sample size \(n\). The sampling units must be apportioned to the strata. I chose to apportion the units proportionally to the size (area, number of grid cells) of the strata (for details, see Section \ref{STSIallocation}). The larger a stratum, the more units are selected from this stratum. The sizes of the strata (total number of grid cells) are computed with function \texttt{tapply}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{w\_h }\OtherTok{\textless{}{-}}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\FunctionTok{print}\NormalTok{(n\_h }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ w\_h))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
BA EA PA RA XF 
13  8  9  4  7 
\end{verbatim}

The sum of the stratum sample sizes is 41, we want 40, so we reduce the largest stratum sample size by 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_h[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ n\_h[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

The stratified simple random sample is selected with function \texttt{strata} of package \textbf{sampling} \citep{Tille2016}. Argument \texttt{size} specifies the stratum sample sizes.

\begin{rmdcaution}
The stratum sample sizes must be in the order in which the strata are encountered in tibble \texttt{grdVoorst}, which is determined first with function \texttt{unique}.
\end{rmdcaution}

Within the strata the grid cells are selected by simple random sampling \emph{with replacement} (\texttt{method\ =\ "srswr"}), so that in principle more than one point can be selected within a grid cell, see Chapter \ref{SI} for a motivation of this. Function \texttt{getdata} extracts the observations of the selected units from the sampling frame, as well as the spatial coordinates and the stratum of these units. The coordinates of the centres of the selected grid cells are jittered by an amount equal to half the side of the grid cells. In the next code chunk this is done with function \texttt{mutate} of package \textbf{dplyr} \citep{dplyr} which is part of package \textbf{tidyverse} \citep{Wickham2019}. We have seen the pipe operator \texttt{\%\textgreater{}\%} of package \textbf{magrittr} \citep{magrittr} before in Section \ref{CDF}. If you are not familiar with **tidyverse* I recommend to read the excellent book R for Data Science \citep{Wickham2017}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{ord }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{stratum)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(}
\NormalTok{  grdVoorst, }\AttributeTok{stratanames =} \StringTok{"stratum"}\NormalTok{, }\AttributeTok{size =}\NormalTok{ n\_h[ord], }\AttributeTok{method =} \StringTok{"srswr"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(grdVoorst, units) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =} \DecValTok{25} \SpecialCharTok{/} \DecValTok{2}\NormalTok{),}
         \AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =} \DecValTok{25} \SpecialCharTok{/} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{rmdnote}
The name of the package is added to function \texttt{strata} (\texttt{sampling::strata}), as \texttt{strata} is also a function of another package. Not adding the name of the package may result in an error message.
\end{rmdnote}

Figure \ref{fig:SampleSTSI} shows the selected sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SampleSTSI-1} 

}

\caption{Stratified simple random sample of size 40 from Voorst. Strata are combinations of soil class and land use.}\label{fig:SampleSTSI}
\end{figure}

\hypertarget{EstimatorsSTSI}{%
\section{Estimation of population parameters}\label{EstimatorsSTSI}}

With simple random sampling within strata, the estimator of the population mean for simple random sampling (Equation \eqref{eq:HTMeanSI}) is applied at the level of the strata. The estimated stratum means are then averaged, using the relative sizes (relative areas) of the strata as weights:

\begin{equation}
\hat{\bar{z}}= \sum\limits_{h=1}^{H} w_{h}\,\hat{\bar{z}}_{h} \;,
\label{eq:HTMeanSTSI}
\end{equation}

where \(H\) is the number of strata, \(w_{h}\) is the relative size (area) of stratum \(h\) (stratum weight)\index{Stratum weight}: \(w_h = N_h/N\), and \(\hat{\bar{z}}_{h}\) is the estimated mean of stratum \(h\), estimated by the sample mean for stratum \(h\):

\begin{equation}
\hat{\bar{z}}_{h}=\frac{1}{n_h}\sum_{k \in \mathcal{S}_h} z_k\;,
\label{eq:HTStratumMeanSI}
\end{equation}

with \(\mathcal{S}_h\) the sample selected from stratum \(h\).

The same estimator is found when the \(\pi\) estimator is worked out for stratified simple random sampling. With stratified simple random sampling without replacement and different sampling fractions for the strata the inclusion probabilities differ among the strata and equal \(\pi_{k} = n_h/N_h\) for all \(k\) in stratum \(h\), with \(n_h\) the sample size of stratum \(h\) and \(N_h\) the size of stratum \(h\). Inserting this in the \(\pi\) estimator of the population mean (Equation \eqref{eq:HTMean}) gives

\begin{equation}
\hat{\bar{z}}= \frac{1}{N}\sum\limits_{h=1}^{H}\sum\limits_{k \in \mathcal{S}_h} \frac{z_{k}}{\pi_{k}} = \frac{1}{N}\sum\limits_{h=1}^{H} \frac{N_h}{n_h}\sum\limits_{k \in \mathcal{S}_h} z_{k} = \sum\limits_{h=1}^{H} w_{h}\,\hat{\bar{z}}_{h} \;.
\label{eq:HTMeanSTSI2}
\end{equation}

\begin{rmdnote}
The sampling fractions are usually slightly different, even with proportional allocation (Section \ref{STSIallocation}), because \(n_h/N_h\) cannot be made exactly equal for all strata. Sample sizes necessarily are integers, so \(n_h/N_h\) must be rounded to integers.
\end{rmdnote}

The sampling variance of the estimator of the population mean is estimated by first estimating the sampling variances of the estimated stratum means, followed by computing the weighted average of the estimated sampling variances of the estimated stratum means. Note that we must square the stratum weights:

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}\right)=\sum\limits_{h=1}^{H}w_{h}^{2}\,\widehat{V}\!\left(\hat{\bar{z}}_{h}\right)\;,
\label{eq:EstVarMeanSTSI}
\end{equation}

where \(\widehat{V}\!\left(\hat{\bar{z}}_{h}\right)\) is the estimated sampling variance of \(\hat{\bar{z}}_{h}\):

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{h}\right)= (1-\frac{n_h}{N_h}) \frac{\widehat{S^2}_h(z)}{n_h}\;,
\label{eq:EstVarstratummean}
\end{equation}

with \(\widehat{S^2}_h(z)\) the estimated variance of \(z\) within stratum \(h\):

\begin{equation}
\widehat{S^2}_h(z)=\frac{1}{n_h-1}\sum\limits_{k \in \mathcal{S}_h}\left(z_{k}-\hat{\bar{z}}_{h}\right)^{2}\;.
\label{eq:EstStratumVar}
\end{equation}

For stratified simple random sampling with replacement of finite populations and stratified simple random sampling of infinite populations the fpcs \(1-(n_h/N_h)\) can be dropped.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mz\_h)}
\NormalTok{S2z\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ var)}
\NormalTok{v\_mz\_h }\OtherTok{\textless{}{-}}\NormalTok{ S2z\_h }\SpecialCharTok{/}\NormalTok{ n\_h}
\NormalTok{se\_mz }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_mz\_h))}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:stratummeans}Size (Nh), sample size (nh), estimated mean (Mean), estimated variance (Variance), and estimated standard error of estimator of mean (se) of the five strata in Voorst.}
\centering
\begin{tabular}[t]{llrrlr}
\toprule
Stratum & Nh & nh & Mean & Variance & se\\
\midrule
BA & 2,371 & 12 & 91.1 & 946.3 & 8.9\\
EA & 1,442 & 8 & 58.3 & 555.5 & 8.3\\
PA & 1,710 & 9 & 59.4 & 214.7 & 4.9\\
RA & 659 & 4 & 103.2 & 2,528.8 & 25.1\\
XF & 1,346 & 7 & 133.9 & 3,807.3 & 23.3\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:stratummeans} shows per stratum the estimated mean, the estimated variance, and the estimated sampling variance of the estimated mean of the soil organic matter (SOM) concentration. We can see large differences in the within-stratum variances\index{Within-stratum variance}. For the stratified sample of Figure \ref{fig:SampleSTSI} the estimated population mean equals 86.3 g kg\textsuperscript{-1} and the estimated standard error of this estimator equals 5.8 g kg\textsuperscript{-1}.

The population mean can also be estimated directly using the basic \(\pi\) estimator (Equation \eqref{eq:HTMean}). The inclusion probabilities are included in \texttt{data.frame} \texttt{mysample}, obtained with function \texttt{getdata} (see code chunk above), as variable \texttt{Prob}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(mysample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           s1       s2         z stratum ID_unit        Prob Stratum
1135 202554.8 464556.7 186.99296      XF    1135 0.005189017       1
2159 204305.5 464738.9  75.04809      XF    2159 0.005189017       1
4205 203038.3 465057.0 138.14617      XF    4205 0.005189017       1
4503 202381.1 465096.7  69.43803      XF    4503 0.005189017       1
5336 203610.4 465237.8  78.02003      XF    5336 0.005189017       1
5853 205147.1 465315.5 164.55224      XF    5853 0.005189017       1
\end{verbatim}

The population total is estimated first, and by dividing this estimated total by the total number of population units \(N\) an estimate of the population mean is obtained.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tz }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Prob)}
\FunctionTok{print}\NormalTok{(mz }\OtherTok{\textless{}{-}}\NormalTok{ tz }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 86.53333
\end{verbatim}

The two estimates of the population mean are not exactly equal. This is due to rounding errors in the inclusion probabilities. This can be shown by computing the sum of the inclusion probabilities over all population units. This sum should be equal to the sample size \(n=40\), but as we can see below, this sum is slightly smaller.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{Prob, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ unique)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{sum}\NormalTok{(pi\_h }\SpecialCharTok{*}\NormalTok{ N\_h))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 39.90711
\end{verbatim}

Now suppose we ignore that the sample data come from a stratified sampling design and we use the (unweighted) sample mean as an estimate of the population mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 86.11247
\end{verbatim}

The sample mean slightly differs from the proper estimate of the population mean (7.238). The sample mean is a \emph{biased} estimator, but the bias is small. The bias is only small because the stratum sample sizes are about proportional to the sizes of the strata, so that the inclusion probabilities (sampling intensities) are about equal for all strata: 0.0050494, 0.0055344, 0.0052509, 0.006056, 0.005189. The probabilities are not exactly equal because the stratum sample sizes are necessarily rounded to integers and because we reduced the largest sample size by one unit. The bias would have been substantially larger if an equal number of units would have been selected from each stratum, leading to much larger differences in the inclusion probabilities among the strata. Sampling intensity in stratum BA, for instance, then would be much smaller compared to the other strata, and so would be the inclusion probabilities of the units in this stratum as compared to the other strata. Stratum BA then would be underrepresented in the sample. This is not a problem as long as we account for the difference in inclusion probabilities of the units in the estimation of the population mean. The estimated mean of stratum BA then gets the largest weight, equal to the inverse of the inclusion probability. If we do not account for these differences in inclusion probabilities, the estimator of the mean will be seriously biased.

The next code chunk shows how the population mean and its standard error can be estimated with package \textbf{survey} \citep{Lumley2020}. Note that the stratum weights \(N_h/n_h\) must be passed to function \texttt{svydesign} using argument \texttt{weight}. These are first attached to \texttt{data.frame} \texttt{mysample} by creating a look-up table \texttt{lut}, which is then merged with function \texttt{merge} to \texttt{data.frame} \texttt{mysample}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{stratum))}
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{stratum =}\NormalTok{ labels, }\AttributeTok{weight =}\NormalTok{ N\_h }\SpecialCharTok{/}\NormalTok{ n\_h)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mysample, }\AttributeTok{y =}\NormalTok{ lut)}
\NormalTok{design\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ stratum, }\AttributeTok{weight =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_stsi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 86.334 5.8167
\end{verbatim}

\hypertarget{population-proportion-cumulative-distribution-function-and-quantiles}{%
\subsection{Population proportion, cumulative distribution function, and quantiles}\label{population-proportion-cumulative-distribution-function-and-quantiles}}

The proportion of a population satisfying some condition can be estimated by Equations \eqref{eq:HTMeanSTSI} and \eqref{eq:HTStratumMeanSI}, substituting for the study variable \(z_k\) an 0/1 indicator \(y_k\) with value 1 if for unit \(k\) the condition is satisfied, and 0 otherwise (Subsection \ref{PopProportion}). In general with stratified simple random sampling the inclusion probabilities are not exactly equal, so that the estimated population proportion is not equal to the sample proportion.

These unequal inclusion probabilities must also be accounted for when estimating the cumulative distribution function (CDF) and quantiles (Subsection \ref{CDF}), as shown in the next code chunk for the CDF.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{thresholds }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z))}
\NormalTok{cumfreq }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(thresholds))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thresholds))) \{}
\NormalTok{  ind }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{\textless{}=}\NormalTok{ thresholds[i]}
\NormalTok{  mh\_ind }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(ind, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{  cumfreq[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mh\_ind)}
\NormalTok{\}}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ thresholds, }\AttributeTok{y =}\NormalTok{ cumfreq)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:EstimatedCDFVoorstSTSI} shows the estimated CDF, estimated from the stratified simple random sample of 40 units from Voorst (Figure \ref{fig:SampleSTSI}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/EstimatedCDFVoorstSTSI-1} 

}

\caption{Estimated cumulative distribution function of the SOM concentration (g kg\textsuperscript{-1}) in Voorst, estimated from the stratified simple random sample of 40 units.}\label{fig:EstimatedCDFVoorstSTSI}
\end{figure}

The estimated proportions (cumulative frequencies) are used to estimate a quantile. These estimates are easily obtained with function \texttt{svyquantile} of package \textbf{survey}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{svyquantile}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_stsi, }\AttributeTok{quantile =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.8}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$z
     quantile    ci.2.5   ci.97.5        se
0.5  69.56081  65.70434  84.03993  4.515916
0.8 117.73877 102.75359 161.88611 14.563887

attr(,"hasci")
[1] TRUE
attr(,"class")
[1] "newsvyquantile"
\end{verbatim}

\hypertarget{WhyStratify}{%
\subsection{Why should we stratify?}\label{WhyStratify}}

There can be two reasons for stratifying the population:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  we are interested in the mean (total) per stratum; or
\item
  we want to increase the precision of the estimated mean (total) for the entire population.
\end{enumerate}

Figure \ref{fig:SamplingDistributionSTSI} shows the approximated sampling distributions (shown as boxplots) of the \(\pi\) estimator of the mean SOM concentration for stratified simple random sampling and simple random sampling, both of size 40, obtained by repeating the random sampling with each design and estimation 10,000 times.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionSTSI-1} 

}

\caption{Approximated sampling distribution of the \(\pi\) estimator of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst for stratified simple random sampling (STSI) and simple random sampling (SI) of size 40.}\label{fig:SamplingDistributionSTSI}
\end{figure}

The approximated sampling distributions of the estimators of the population mean with the two designs are not very different. With stratified random sampling the spread of the estimated means is somewhat smaller. The horizontal red line is the population mean (81.1 g kg\textsuperscript{-1}). The gain in precision due to the stratification, referred to as the stratification effect\index{Stratification effect}, can be quantified by the ratio of the variance with simple random sampling and the variance with stratified simple random sampling. So, when this variance ratio is larger than 1, stratified simple random sampling is more precise than simple random sampling. For Voorst the stratification effect with proportional allocation (Section \ref{STSIallocation}) equals 1.310. This means that with simple random sampling we need 1.310 more sampling units than with stratified simple random sampling to obtain an estimate of the same precision.

The stratification effect can be computed from the population variance \(S^2(z)\) (Equation \eqref{eq:PopulationVariance}) and the variances within the strata \(S^2_h(z)\). In the sampling experiment these variances are known without error because we know the \(z\)-values for all units in the population. In practice we only know the \(z\)-values for the sampled units. However, a design-unbiased estimator of the population variance is \citep{gru06}

\begin{equation}
\widehat{S^{2}}(z)= \widehat{\overline{z^{2}}}-\left(\hat{\bar{z}}\right)^{2}+
\widehat{V}\!\left(\hat{\bar{z}}\right) \;,
\label{eq:EstimatorPopulationVariancefromSTSI}
\end{equation}

where \(\widehat{\overline{z^{2}}}\) denotes the estimated population mean of the study variable squared (\(z^2\)), obtained in the same way as \(\hat{\bar{z}}\) (Equation \eqref{eq:HTMeanSTSI}), but using squared values, and \(\widehat{V}\!\left(\hat{\bar{z}}\right)\) denotes the estimated variance of the estimator of the population mean (Equation \eqref{eq:EstVarMeanSTSI}).

The estimated population variance is then divided by the sum of the stratum sample sizes to get an estimate of the sampling variance of the estimator of the mean with simple random sampling of an equal number of units:

\begin{equation}
\widehat{V}(\hat{\bar{z}}_{\text{SI}}) = \frac{\widehat{S^2}(z)}{\sum_{h=1}^{H}n_h}\;.
\label{eq:stratificationeffect}
\end{equation}

The population variance can be estimated with function \texttt{s2} of package \textbf{surveyplanning} \citep{surveyplanning}. However, this function is an implementation of an alternative, consistent estimator\index{Consistent estimator} of the population variance \citep{sar92}:

\begin{equation}
\widehat{S^2}(z) = \frac{N-1}{N} \frac{n}{n-1} \frac{1}{N-1} \sum_{k \in \mathcal{S}} \frac{(z_k - \hat{\bar{z}}_{\pi})^2}{\pi_k} \;.
\label{eq:EstimatorPopulationVariance4AnyDesign}
\end{equation}

\begin{rmdnote}
An estimator is consistent if it converges in probability to the true value of the parameter as the sample size tends to infinity \citep{sar92}.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(surveyplanning)}
\NormalTok{S2z }\OtherTok{\textless{}{-}} \FunctionTok{s2}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{w =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{weight)}
\end{Highlighting}
\end{Shaded}

The design effect\index{Design effect} is defined as the variance of an estimator of the population mean with the sampling design under study divided by the variance of the \(\pi\) estimator of the mean with simple random sampling of an equal number of units (Section \ref{DesignEffect}). So, the design effect of stratified random sampling is the reciprocal of the stratification effect. For the stratified simple random sample of Figure \ref{fig:SampleSTSI} the design effect can then be estimated as follows. Function \texttt{SE} extracts the estimated standard error of the estimator of the mean from the output of function \texttt{svymean}. The extracted standard error is then squared to obtain an estimate of the sampling variance of the estimator of the population with stratified simple random sampling. Finally, this variance is divided by the variance with simple random sampling of an equal number of units.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v\_mz\_SI }\OtherTok{\textless{}{-}}\NormalTok{ S2z }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_stsi)}
\FunctionTok{SE}\NormalTok{(res)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ v\_mz\_SI}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          z
z 0.6903965
\end{verbatim}

The same value is obtained with argument \texttt{deff} of function \texttt{svymean}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ stratum, }\AttributeTok{weight =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weight, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_stsi, }\AttributeTok{deff =} \StringTok{"replace"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     mean      SE   DEff
z 86.3340  5.8167 0.6904
\end{verbatim}

So, when using package \textbf{survey} estimation of the population variance is not needed to estimate the design effect. I only added this to make clear how the design effect is computed with functions in package \textbf{survey}. In following chapters I will skip the estimation of the population variance.

The estimated design effect as estimated from the stratified sample is smaller than 1, showing that stratified simple random sampling is more efficient than simple random sampling. The reciprocal of the estimated design effect (1.448) is somewhat larger than the stratification effect as computed in the sampling experiment, but this is an estimate of the design effect from one stratified sample only. The estimated population variance varies among stratified samples, and so does the estimated design effect.

Stratified simple random sampling with proportional allocation (Section \ref{STSIallocation}) is more precise than simple random sampling when the sum of squares of the stratum means is larger than the sum of squares within strata \citep{loh99}:

\begin{equation}
SSB > SSW\;,
\label{eq:STSImoreprecisewhen}
\end{equation}

with SSB the weighted sum-of-squares between the stratum means:

\begin{equation}
SSB = \sum_{h=1}^H N_h (\bar{z}_h-\bar{z})^2 \;,
\label{eq:SSB}
\end{equation}

and SSW the sum over the strata of the weighted variances within strata (weights equal to \(1-N_h/N\)):

\begin{equation}
SSW = \sum_{h=1}^H (1-\frac{N_h}{N})S^2_h\;.
\label{eq:SSW}
\end{equation}

In other words, the smaller the differences in the stratum means and the larger the variances within the strata, the smaller the stratification effect will be. Figure \ref{fig:boxplotsSOMstrata} shows a boxplot of the SOM concentration per stratum (soil-land use combination). The stratum means are equal to 83.0, 49.0, 68.8, 92.7, 122.3 g kg\textsuperscript{-1}. The stratum variances are 1799.2, 238.4, 1652.9, 1905.4, 2942.8 (g kg\textsuperscript{-1})\textsuperscript{2}. The large stratum variances explain the modest gain in precision realised by stratified simple random sampling compared to simple random sampling in this case.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/boxplotsSOMstrata-1} 

}

\caption{Boxplots of the SOM concentration (g kg\textsuperscript{-1}) for the five strata (soil-land use combinations) in Voorst.}\label{fig:boxplotsSOMstrata}
\end{figure}

\hypertarget{CISTSI}{%
\section{Confidence interval estimate}\label{CISTSI}}

The \(100(1-\alpha)\)\% confidence interval for \(\bar{z}\) is given by

\begin{equation}
\hat{\bar{z}} \pm t_{\alpha /2, df}\cdot
\sqrt{\widehat{V}\!\left(\hat{\bar{z}}\right)} \;,
\label{eq:CISTSI}
\end{equation}

where \(t_{\alpha /2,df}\) is the \((1-\alpha /2)\) quantile of a \emph{t} distribution with \(df\) degrees of freedom. The degrees of freedom \(df\) can be approximated by \(n-H\), as proposed by \citet{loh99}. This is the number of the degrees of freedom if the variances within the strata are equal. With unequal variances within strata \(df\) can be approximated by Sattherwaite's method\index{Sattherwaite's method} \citep{nan04}:

\begin{equation}
df \approx \frac {\left(\sum_{h=1}^H w_h^2
\frac{\widehat{S^2}_h(z)}{n_h}\right)^2} {\sum_{h=1}^H w_h^4
\left(\frac{\widehat{S^2}_h(z)}{n_h}\right)^2 \frac {1}{n_h-1}} \;.
\label{eq:dfSattherwaite}
\end{equation}

A confidence interval estimate of the population mean can be extracted with method \texttt{confint} of package \textbf{survey}. It uses \(n-H\) degrees of freedom.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_stsi)}
\NormalTok{df\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{degf}\NormalTok{(design\_stsi)}
\FunctionTok{confint}\NormalTok{(res, }\AttributeTok{df =}\NormalTok{ df\_stsi, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     2.5 %   97.5 %
z 74.52542 98.14252
\end{verbatim}

\hypertarget{STSIallocation}{%
\section{Allocation of sample size to strata}\label{STSIallocation}}

After we have decided on the total sample size \(n\), we must decide how to apportion the units to the strata. It is reasonable to allocate more sampling units to large strata and fewer to small strata. The simplest way to achieve this is proportional allocation\index{Allocation!proportional allocation}:

\begin{equation}
n_{h}=n \cdot \frac{N_{h}}{\sum N_{h}}\;,
\label{eq:propallocation}
\end{equation}

with \(N_h\) the total number of population units (size) of stratum \(h\). With infinite populations \(N_h\) is replaced by the area \(A_h\). The sample sizes computed with this equation are rounded to the nearest integers.

If we have prior information on the variance of the study variable within the strata, then it makes sense to account for differences in variance. Heterogeneous strata should receive more sampling units than homogeneous strata, leading to Neyman allocation\index{Allocation!Neyman allocation}:

\begin{equation}
n_{h}= n \cdot \frac{N_{h}\,S_{h}(z)}{\sum\limits_{h=1}^{H} N_{h}\,S_{h}(z)} \;,
\label{eq:Neymanallocation}
\end{equation}

with \(S_h(z)\) the standard deviation (square root of variance) of the study variable \(z\) in stratum \(h\).

Finally, the costs of sampling may differ among the strata. It can be relatively expensive to sample nearly inaccessible strata, and we do not want to sample many units there. This leads to optimal allocation\index{Allocation!optimal allocation}:

\begin{equation}
n_{h}= n \cdot \frac{\frac{N_{h}\,S_{h}(z)}{\sqrt{c_{h}}}}{\sum\limits_{h=1}^{H} \frac{N_{h}\,S_{h}(z)}{\sqrt{c_{h}}}} \;,
\label{eq:optallocation}
\end{equation}

with \(c_h\) the costs per sampling unit in stratum \(h\). Optimal means that given the total costs this allocation type leads to minimum sampling variance, assuming a linear costs model\index{Linear costs model}:

\begin{equation}
C = c_0 + \sum_{h=1}^H n_h c_h \;,
\label{eq:linearcostmodel}
\end{equation}

with \(c_0\) overhead costs. So, the more variable a stratum and the lower the costs, the more units will be selected from this stratum.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2z\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}\AttributeTok{X =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ var)}
\NormalTok{n\_h\_Neyman }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ N\_h }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(S2z\_h) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(S2z\_h)))}
\end{Highlighting}
\end{Shaded}

These optimal sample sizes can be computed with function \texttt{optsize} of package \textbf{surveyplanning}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{stratum))}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optsize}\NormalTok{(labels, n, N\_h, S2z\_h)}
\FunctionTok{round}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{nh, }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 14  3  9  4 10
\end{verbatim}

Table \ref{tab:tableallocation} shows the proportional and optimal sample sizes for the five strata of the study area Voorst, for a total sample size of 40. Stratum XF is the one-but-smallest stratum and therefore receives only seven sampling units. However, the standard deviation in this stratum is the largest, and as a consequence with optimal allocation the sample size in this stratum is increased by three points, at the cost of stratum EA which is relatively homogeneous.

\begin{table}

\caption{\label{tab:tableallocation}Proportional and Neyman sample sizes in stratified simple random sampling of Voorst with a total sample size of 40. Nh: stratum size; Sh: stratum standard deviation.}
\centering
\begin{tabular}[t]{llrrr}
\toprule
Stratum & Nh & Sh & nhprop & nhNeyman\\
\midrule
BA & 2,371 & 42.4 & 12 & 14\\
EA & 1,442 & 15.4 & 8 & 3\\
PA & 1,710 & 40.7 & 9 & 9\\
RA & 659 & 43.7 & 4 & 4\\
XF & 1,346 & 54.2 & 7 & 10\\
\bottomrule
\end{tabular}
\end{table}

Figure \ref{fig:plotsdmeanallocation} shows the standard error of the \(\pi\) estimator of the mean SOM concentration as a function of the total sample size, for simple random sampling and for stratified simple random sampling with proportional and Neyman allocation. A small extra gain in precision can be achieved using Neyman allocation instead of proportional allocation. However, in practice often Neyman allocation is not achievable because we do not know the standard deviations of the study variable within the strata. If a quantitative covariate \(x\) is used for stratification (see Sections \ref{cumrootf} and \ref{Ospats}), the standard deviations \(S_h(z)\) are approximated by \(S_h(x)\), resulting in approximately optimal stratum sample sizes. The gain in precision compared to proportional allocation is then partly or entirely lost.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/plotsdmeanallocation-1} 

}

\caption{Standard error of the \(\pi\) estimator of the mean SOM concentration (g kg\textsuperscript{-1}) as a function of the total sample size, for simple random sampling (SI) and for stratified simple random sampling with proportional (STSI(prop)) and Neyman allocation (STSI(Neyman)) for Voorst.}\label{fig:plotsdmeanallocation}
\end{figure}

Optimal allocation and Neyman allocation assume univariate stratification\index{Univariate stratification}, i.e.~the stratified simple random sample is used to estimate the mean of a single study variable. If we have multiple study variables, optimal allocation becomes more complicated. In Bethel allocation\index{Allocation!Bethel allocation} the total sampling costs, assuming a linear costs model (Equation \eqref{eq:linearcostmodel}), are minimised given a constraint on the precision of the estimated mean for each study variable \citep{Bethel1989}, see Section \ref{MultivariateStratification}. Bethel allocation can be computed with function \texttt{bethel} of package \textbf{SamplingStrata} \citep{Barcaroli2020}.

\hypertarget{exercises-5}{%
\subsubsection*{Exercises}\label{exercises-5}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use function \texttt{strata} of package \textbf{sampling} to select a stratified simple random sample with replacement of size 40 from Voorst, using proportional allocation. Check that the sum of the stratum sample sizes is 40.

  \begin{itemize}
  \tightlist
  \item
    Estimate the population mean and the standard error of the estimator.
  \item
    Compute the true standard error of the estimator. Hint: compute the population variances of the study variable \(z\) per stratum, and divide these by the stratum sample sizes.
  \item
    Compute a 95\% confidence interval estimate of the population mean, using function \texttt{confint} of package \textbf{survey}.\\
  \end{itemize}
\item
  Looking at Figure \ref{fig:boxplotsSOMstrata}, which strata do you expect can be merged without losing much precision of the estimated population mean?\\
\item
  Use function \texttt{fct\_collapse} of package \textbf{forcats} \citep{forcats} to merge the strata EA and PA.

  \begin{itemize}
  \tightlist
  \item
    Compute the true sampling variance of the estimator of the mean for this new stratification, for a total sample size of 40 and proportional allocation.
  \item
    Compare this true sampling variance with the true sampling variance using the original five strata (same sample size, proportional allocation). What is your conclusion about the new stratification?\\
  \end{itemize}
\item
  Proof that the sum of the inclusion probabilities over all population units with stratified simple random sampling equals the sample size \(n\).
\end{enumerate}

\hypertarget{cumrootf}{%
\section{\texorpdfstring{\emph{Cum-root-f} stratification}{Cum-root-f stratification}}\label{cumrootf}}

When we have a quantitative covariate \(x\) related to the study variable \(z\) and \(x\) is known for all units in the population, strata can be constructed with the \emph{cum-root-f} method using this covariate as a stratification variable, see \citet{Dalenius1959} and \citet{coc77}. Population units with similar values for the covariate (stratification variable) are grouped into a stratum. Strata are computed as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute a histogram of the stratification variable using a large number of bins.\\
\item
  Compute the square root of the histogram frequencies.\\
\item
  Cumulate the square root of the frequencies, i.e.~compute \(\sqrt{f_1}\), \(\sqrt{f_1} + \sqrt{f_2}\), \(\sqrt{f_1} + \sqrt{f_2} + \sqrt{f_3}\), etc.\\
\item
  Divide the cumulative sum of the last bin by the number of strata, multiply this value by \(1,2, \dots, H-1\), with \emph{H} the number of strata, and select the boundaries of the histogram bins closest to these values.
\end{enumerate}

In \emph{cum-root-f} stratification\index{\emph{Cum-root-f} stratification} it is assumed that (after linear transformation) the covariate values are nearly perfect predictions of the study variable, so that the prediction errors do not affect the stratification. Under this assumption the stratification is optimal.

\emph{Cum-root-f} stratification is illustrated with the data of Xuancheng (China). We wish to estimate the mean organic matter concentration in the topsoil (SOM, g kg\textsuperscript{-1}) of this area. Various covariates are available that are correlated with SOM, such as elevation, yearly average temperature, slope, and various other terrain attributes. Elevation (the name of this variable in the data frame is dem) is used as as a single stratification variable, see Figure \ref{fig:DEMXuancheng}. The correlation coefficient of SOM and elevation in a sample of 183 observations is 0.59. The positive correlation can be explained as follows. Temperature is decreasing with elevation, leading to a smaller decomposition rate of organic matter in the soil.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/DEMXuancheng-1} 

}

\caption{Elevation used as a stratification variable in \emph{cum-root-f} stratification of Xuancheng.}\label{fig:DEMXuancheng}
\end{figure}

The strata can be constructed with the package \textbf{stratification} \citep{Baillargeon2011}. Care should be taken that the data are sorted in ascending order by the variable used for stratification, see help of function \texttt{strata.cumrootf}. Argument \texttt{n} of this function is the total sample size, but this value has no effect on the stratification. Argument \texttt{Ls} is the number of strata. I arbitrarily chose to construct five strata. Argument \texttt{nclass} is the number of bins of the histogram. The output object of function \texttt{strata.cumrootf} is a list containing amongst others a numeric vector with the stratum bounds (\texttt{bh}) and a factor with the stratum levels of the grid cells (\texttt{stratumID}). Finally, note that the values of the stratification variable must be positive. The minimum elevation is -5 m, so we added the absolute value of this minimum to elevation.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(stratification)}
\NormalTok{grdXuancheng }\OtherTok{\textless{}{-}}\NormalTok{ grdXuancheng[}\FunctionTok{order}\NormalTok{(grdXuancheng}\SpecialCharTok{$}\NormalTok{dem), ]}
\NormalTok{dem\_new }\OtherTok{\textless{}{-}}\NormalTok{ grdXuancheng}\SpecialCharTok{$}\NormalTok{dem }\SpecialCharTok{+} \FunctionTok{abs}\NormalTok{(}\FunctionTok{min}\NormalTok{(grdXuancheng}\SpecialCharTok{$}\NormalTok{dem))}
\NormalTok{crfstrata }\OtherTok{\textless{}{-}} \FunctionTok{strata.cumrootf}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dem\_new, }\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{Ls =} \DecValTok{5}\NormalTok{, }\AttributeTok{nclass =} \DecValTok{500}\NormalTok{)}
\NormalTok{bh }\OtherTok{\textless{}{-}}\NormalTok{ crfstrata}\SpecialCharTok{$}\NormalTok{bh}
\NormalTok{grdXuancheng}\SpecialCharTok{$}\NormalTok{crfstrata }\OtherTok{\textless{}{-}}\NormalTok{ crfstrata}\SpecialCharTok{$}\NormalTok{stratumID}
\end{Highlighting}
\end{Shaded}

Stratum bounds are threshold values of the stratification variable elevation; these stratum bounds\index{Stratum bound} are equal to 46.7, 108.3, 214.5, 384.4. Note that the number of stratum bounds is one less than the number of strata. The resulting stratification is shown in Figure \ref{fig:optstrata}. Note that most strata are not single polygons, but are made up of many smaller polygons. This may be even more so if the stratification variable shows a noisy spatial pattern. This is not a problem at all, a stratum is just a collection of population units (raster cells) and need not be spatially contiguous.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/optstrata-1} 

}

\caption{Stratification of Xuancheng obtained with \emph{cum-root-f} method, using elevation as a stratification variable.}\label{fig:optstrata}
\end{figure}

\hypertarget{exercises-6}{%
\subsubsection*{Exercises}\label{exercises-6}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write an \textbf{R} script to compute five \emph{cum-root-f} strata for Eastern Amazonia (\texttt{grdAmazonia} in package \textbf{sswr}) to estimate the population mean of aboveground biomass (AGB), using log-transformed short-wave infrared (SWIR2) as a stratification variable.

  \begin{itemize}
  \tightlist
  \item
    Compute ten \emph{cum-root-f} strata, using function \texttt{strata} of package \textbf{sampling}. Sort the units first in ascending order on lnSWIR2. Use the stratum sample sizes as computed by function \texttt{strata.cumrootf}. What allocation is used for computing the stratum sample sizes?
  \item
    Select a stratified simple random sample of 100 units. First compute the stratum sample sizes for proportional allocation.
  \item
    Estimate the population mean of AGB and its sampling variance.
  \item
    Compute the true sampling variance of the estimator of the mean for this sampling design (see Exercise 1 for a hint).
  \item
    Compute the stratification effect (gain in precision). Hint: compute the sampling variance for simple random sampling by computing the population variance of AGB, and divide this by the total sample size.
  \end{itemize}
\end{enumerate}

\hypertarget{kmeansstratification}{%
\section{Stratification with multiple covariates}\label{kmeansstratification}}

If we have multiple variables that are possibly related to the study variable, we may want to use them all or a subset of them as stratification variables. Using the quantitative variables one-by-one in \emph{cum-root-f} stratification, followed by overlaying the maps with univariate strata, may lead to numerous cross-classification strata.

A simple solution is to construct homogeneous groups, referred to as clusters, of population units (raster cells). The units within a cluster are more similar to each other than to the units in other clusters. Various clustering techniques are available. Here I use hard k-means.

This is illustrated again with the Xuancheng case study. Five quantitative covariates are used for constructing the strata. Besides elevation, which was used as a single stratification variable in the previous section, now also temperature, slope, topographic wetness index (twi), and profile curvature are used to construct clusters that are used as strata in stratified simple random sampling. To speed up the computations a subgrid with a spacing of 0.4 km is selected, using function \texttt{spsample} of package \textbf{sp}, see Chapter \ref{SY} \citep{Bivand2013}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{gridded}\NormalTok{(grdXuancheng) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{subgrd }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}
\NormalTok{  grdXuancheng, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{cellsize =} \DecValTok{400}\NormalTok{, }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{subgrd }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{coordinates}\NormalTok{(subgrd), }\FunctionTok{over}\NormalTok{(subgrd, grdXuancheng))}
\end{Highlighting}
\end{Shaded}

Five clusters are computed with k-means using as clustering variables the five covariates mentioned above. The scale of these covariates is largely different, and for this reason they must be scaled before being used in clustering. The k-means algorithm is a deterministic algorithm, i.e.~the same initial clustering will end in the same final, optimised clustering. This final clustering can be suboptimal, and therefore it is recommended to repeat the clustering as many times as feasible, with different initial clusterings. Argument \texttt{nstart} is the number of initial clusterings. The best clustering, i.e.~the one with the smallest within-cluster sum-of-squares, is kept.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"dem"}\NormalTok{, }\StringTok{"temperature"}\NormalTok{, }\StringTok{"slope"}\NormalTok{, }\StringTok{"profile.curvature"}\NormalTok{, }\StringTok{"twi"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{myClusters }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(}
  \FunctionTok{scale}\NormalTok{(subgrd[, x]), }\AttributeTok{centers =} \DecValTok{5}\NormalTok{, }\AttributeTok{iter.max =} \DecValTok{1000}\NormalTok{, }\AttributeTok{nstart =} \DecValTok{100}\NormalTok{)}
\NormalTok{subgrd}\SpecialCharTok{$}\NormalTok{cluster }\OtherTok{\textless{}{-}}\NormalTok{ myClusters}\SpecialCharTok{$}\NormalTok{cluster}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:kmeansstrataXuancheng} shows the five clusters obtained by k-means clustering\index{\emph{k}-means clustering} of the raster cells. These clusters can be used as strata in random sampling.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/kmeansstrataXuancheng-1} 

}

\caption{Five clusters obtained by k-means clustering of the raster cells of Xuancheng, using five scaled covariates in clustering.}\label{fig:kmeansstrataXuancheng}
\end{figure}

The size of the clusters (strata) is largely different (Table \ref{tab:tablekmeansstrata}). This table also shows means of the unscaled covariates used in clustering.

\begin{table}

\caption{\label{tab:tablekmeansstrata}Size (Nh) and means of clustering variables of the five strata of Xuancheng obtained with k-means clustering of raster cells.}
\centering
\begin{tabular}[t]{rlrrrrr}
\toprule
Stratum & Nh & Elevation & Temperature & Slope & Profilecurv & Twi\\
\midrule
1 & 1,581 & 300 & 14.45 & 12.21 & -0.00147 & 6.34\\
2 & 15,987 & 54 & 15.44 & 2.11 & 0.00001 & 9.24\\
3 & 4,255 & 181 & 14.64 & 11.11 & 0.00068 & 7.75\\
4 & 4,955 & 20 & 15.59 & 0.47 & 0.00006 & 17.08\\
5 & 1,625 & 416 & 13.70 & 21.21 & 0.00012 & 6.45\\
\bottomrule
\end{tabular}
\end{table}

Categorical variables can be accommodated in clustering using the technique proposed by \citet{Huang1998}, implemented in package \textbf{clustMixType} \citep{clustMixType}.

In the situation that we already have some data of the study variable, an alternative solution is to calibrate a model for the study variable, for instance a multiple linear regression model, using the covariates as predictors, and to use the predictions of the study variable as a single stratification variable in \emph{cum-root-f} stratification or in optimal spatial stratification, see Section \ref{Ospats}.

\hypertarget{geostrata}{%
\section{Geographical stratification}\label{geostrata}}

When no covariate is available, we may still decide to apply a \emph{geographical stratification}\index{Geographical stratification}. For instance, a square study area can be divided into 4 \(\times\) 4 equal-sized subsquares that are used as strata. When we select one or two points per subsquare, we avoid strong spatial clustering of the sampling points. Geographical stratification improves the \emph{spatial coverage}\index{Spatial coverage}. When the study variable is spatially structured, think for instance of a spatial trend, then geographical stratification will lead to more precisely estimated means (smaller sampling variances).

A simple method for constructing geographical strata is k-means clustering \citep{bru99}. See Section \ref{SpatialCoverage} for a simple illustrative example of how geographical strata are computed with k-means clustering. In this approach the study area is discretised by a large number of grid cells. These grid cells are the objects that are clustered. The clustering variables are simply the spatial coordinates of the centres of the grid cells. This method leads to compact geographical strata\index{Compact geographical stratum}, shortly referred to as geostrata\index{Geostratum|see{Compact geographical stratum}}. Geostrata can be computed with function \texttt{kmeans}, as shown in Section \ref{kmeansstratification}. The two clustering variables have the same scale, so they should not be scaled because this would lead to an arbitrary distortion of geographical distances. The geostrata generally will not have the same size (number of grid cells). Geostrata of equal size can be attractive, as then the sample becomes selfweighting, i.e.~the sample mean is an unbiased estimator of the population mean.

Geostrata of the same size can be computed with function \texttt{stratify} of the package \textbf{spcosa} (\citet{spcosa}, \citet{walvoort2010}), with argument \texttt{equalArea\ =\ TRUE}.

If the total number of grid cells divided by the number of strata is an integer, the stratum sizes are exactly equal, otherwise the difference is one grid cell. \citet{walvoort2010} describe the k-means algorithms implemented in this package in detail. Argument \texttt{object} of function \texttt{stratify} specifies a spatial object of the population units. In the \textbf{R} code below \texttt{grdVoorst} is converted to a \texttt{SpatialPixelsDataFrame} with function \texttt{gridded} of the package \textbf{sp}. The spatial object can also be of class \texttt{SpatialPolygons}. In that case either argument \texttt{nGridCells} or argument \texttt{cellSize} must be set, so that the vector map in \texttt{object} can be discretised by a finite number of grid cells. Argument \texttt{nTry} specifies the number of initial stratifications in k-means clustering, and therefore is comparable with argument \texttt{nstart} of function \texttt{kmeans}. For more details on spatial stratification using k-means clustering, see Section \ref{SpatialCoverage}. The k-means algorithm used with \texttt{equalArea\ =\ TRUE} takes much more computing time than the one used with \texttt{equalArea\ =\ FALSE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\FunctionTok{gridded}\NormalTok{(subgrd) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{mygeostrata }\OtherTok{\textless{}{-}} \FunctionTok{stratify}\NormalTok{(}
  \AttributeTok{object =}\NormalTok{ subgrd, }\AttributeTok{nStrata =} \DecValTok{50}\NormalTok{, }\AttributeTok{nTry =} \DecValTok{1}\NormalTok{, }\AttributeTok{equalArea =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Function \texttt{spsample} of package \textbf{spcosa} is used to select from each geostratum a simple random sample of two points.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ spcosa}\SpecialCharTok{::}\FunctionTok{spsample}\NormalTok{(mygeostrata, }\AttributeTok{n =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:GeoStrata} shows fifty compact geostrata of equal size for Xuancheng with the selected sampling points. Note that the sampling points are reasonably well spread throughout the study area.\footnote{The compact geostrata and the sample are plotted with package \textbf{ggplot2}. A simple alternative is to use method \texttt{plot} of \textbf{spcosa}: \texttt{plot(mygeostrata,\ mysample)}.}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/GeoStrata-1} 

}

\caption{Compact geostrata of equal size for Xuancheng and stratified simple random sample of two points per stratum.}\label{fig:GeoStrata}
\end{figure}

Once the observations are done, the population mean can be estimated with function \texttt{estimate}. For Xuancheng I simulated data from a normal distribution, just to illustrate estimation with function \texttt{estimate}. Various statistics can be estimated, among which the population mean (spatial mean), the standard error, and the cumulative distribution function (CDF). The CDF is estimated by transforming the data to indicators (Subsection \ref{CDF}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ spcosa}\SpecialCharTok{::}\FunctionTok{spsample}\NormalTok{(mygeostrata, }\AttributeTok{n =} \DecValTok{2}\NormalTok{)}
\NormalTok{mydata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{z =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{))}
\NormalTok{mean }\OtherTok{\textless{}{-}} \FunctionTok{estimate}\NormalTok{(}\StringTok{"spatial mean"}\NormalTok{, mygeostrata, mysample, }\AttributeTok{data =}\NormalTok{ mydata)}
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{estimate}\NormalTok{(}\StringTok{"standard error"}\NormalTok{, mygeostrata, mysample, }\AttributeTok{data =}\NormalTok{ mydata)}
\NormalTok{cdf }\OtherTok{\textless{}{-}} \FunctionTok{estimate}\NormalTok{(}\StringTok{"scdf"}\NormalTok{, mygeostrata, mysample, }\AttributeTok{data =}\NormalTok{ mydata)}
\end{Highlighting}
\end{Shaded}

The estimated population mean equals 9.8 with an estimated standard error of 0.2.

\hypertarget{exercises-7}{%
\subsubsection*{Exercises}\label{exercises-7}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Why is it attractive to select at least two points per geostratum?\\
\item
  The alternative to 50 geostrata and two points per geostratum is 100 geostrata and one point per geostratum. Which sampling strategy will be more precise?\\
\item
  The geostrata in Figure \ref{fig:GeoStrata} have equal size (area), which can be enforced by argument \texttt{equalArea\ =\ TRUE}. Why are equal sizes attractive? Work out the estimator of the population mean for strata of equal size.\\
\item
  Write an \textbf{R} script to construct 20 compact geographical strata of equal size for agricultural field Leest. The geopackage file of this field can be read with \textbf{sf} function \texttt{read\_sf(system.file("extdata/leest.gpkg",\ package\ =\ "sswr"))}. Remove the projection attributes with \texttt{st\_set\_crs(NA\_crs\_)}, and convert the simple feature object to a spatial object with method \texttt{as\_Spatial}. Select two points per geostratum, using function \texttt{spsample} of package \textbf{spcosa}. Repeat this with 40 strata of equal size, and randomly select one point per stratum.

  \begin{itemize}
  \tightlist
  \item
    If only one point per stratum is selected, the sampling variance can be approximated by the collapsed strata\index{Collapsed strata} estimator. In this method pairs of strata are formed, and the two strata of a pair are joined. In each new stratum we now have two points. With an odd number of strata there will be one group of three strata and three points. The sample is then analysed as if it were a random sample from the new collapsed strata. Suppose we group the strata on the basis of the measurements of the study variable. Do you think this is a proper way of grouping?
  \item
    In case you think this is not a proper way of grouping the strata, how would you group the strata?
  \item
    Is the sampling variance estimator unbiased? If not, is the sampling variance overestimated or underestimated?\\
  \end{itemize}
\item
  Laboratory costs for measuring the study variable can be saved by bulking the soil aliquots\index{Soil aliquot} (composite sampling\index{Composite sampling}). There are two options: bulking all soil aliquots from the same stratum (bulking within strata) or bulking by selecting one aliquot from each stratum (bulking across strata). In \textbf{spcosa} bulking across strata is implemented. Write an \textbf{R} script to construct 20 compact geographical strata for study area Voorst. Use argument \texttt{equalArea\ =\ TRUE}. Select four points per stratum using argument \texttt{type\ =\ "composite"}, and convert the resulting object to \texttt{SpatialPoints}. Extract the \(z\)-values in \texttt{grdVoorst} at the selected sampling points using function \texttt{over}. Add a variable to the resulting data frame indicating the composite (points 1 to 4 are from the first stratum, points 5 to 8 from the second stratum, etc.), and estimate the means for the four composites using function \texttt{tapply}. Finally, estimate the population mean and its standard error.

  \begin{itemize}
  \tightlist
  \item
    Can the sampling variance of the estimator of the mean be estimated for bulking within the strata?
  \item
    The alternative to analysing the concentration of four composite samples obtained by bulking across strata is to analyse all 20 \(\times\) 4 aliquots separately. The strata have equal size, so the inclusion probabilities are equal. As a consequence, the sample mean is an unbiased estimator of the population mean. Is the precision of this estimated population mean equal to that of the estimated population mean with composite sampling? If not, is it smaller or larger, and why?
  \item
    If you use argument \texttt{equalArea\ =\ FALSE} in combination with argument \texttt{type\ =\ "composite"}, you get an error message. Why does this combination of arguments not work?
  \end{itemize}
\end{enumerate}

\hypertarget{multi-way-stratification}{%
\section{Multi-way stratification}\label{multi-way-stratification}}

In Section \ref{kmeansstratification} multiple continuous covariates are used to construct clusters of raster cells using k-means. These clusters are then used as strata. This section considers the case where we have multiple categorical and/or continuous variables that we would like to use as stratification variables. The continuous stratification variables are first used to compute strata based on that stratification variable, e.g.~using the \emph{cum-root-f} method. What could be done then is to compute the cross-classification of each unit and use these cross-classifications as strata in random sampling. However, this may lead to numerous strata, maybe even more than the intended sample size. To reduce the total number of strata, we may aggregate cross-classification strata\index{Cross-classification stratum} with similar means of the study variable, based on our prior knowledge.

An alternative to aggregation of cross-classification strata is to use the separate strata, i.e.~the strata based on an individual stratification variable, as \emph{marginal} strata in random sampling. How this works is explained in Subsection \ref{Multiwaystratification}.

\hypertarget{MultivariateStratification}{%
\section{Multivariate stratification}\label{MultivariateStratification}}

Another situation is where we have multiple study variables and would like to optimise the stratification and allocation for estimating the population means of all study variables. Optimal stratification for multiple study variables is only relevant if we would like to use different stratification variables for the study variables\index{Multivariate stratification}. In many cases we do not have reliable prior information about the different study variables justifying the use of multiple stratification variables. We are already happy to have one stratification variable that may serve to increase the precision of the estimated means of all study variables.

However in case we do have multiple stratification variables, tailored to different study variables, the objective is to partition the population in strata, so that for a given allocation the total sampling costs, assuming a linear costs model (Equation \eqref{eq:linearcostmodel}), are minimised, given a constraint on the precision of the estimated mean for each study variable.

Package \textbf{SamplingStrata} \citep{Barcaroli2020} can be used to optimise multivariate strata. \citet{Barcaroli2014} gives details about the objective function and the algorithm used for optimising the strata. Sampling units are allocated to the strata by Bethel allocation\index{Allocation!Bethel allocation} \citep{Bethel1989}. The required precision is specified in terms of a coefficient of variation\index{Coefficient of variation}, one per study variable.

Multivariate stratification is illustrated with the Meuse data set of package \textbf{gstat} \citep{peb04}. The prior data of heavy metal concentrations of Cd and Zn are used in spatial prediction to create maps of these two study variables.

The maps of natural logs of the two metal concentrations are created by kriging with an external drift, using the square root of the distance to the Meuse river as a predictor for the mean, see Section \ref{IntroKED} for how this spatial prediction method works.

Figure \ref{fig:PredictedCd} shows the map with the predicted log Cd and log Zn concentrations.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/PredictedCd-1} 

}

\caption{Kriging predictions of natural logs of Cd and Zn concentrations in study area Meuse, used as stratification variables in bivariate stratification.}\label{fig:PredictedCd}
\end{figure}

The predicted log concentrations of the two heavy metals are used as stratification variables in designing a new sample for design-based estimation of the population means of Cd and Zn. For the log of Cd there are negative predicted concentrations (Figure \ref{fig:PredictedCd}). This leads to an error when running function \texttt{optimStrata}. The minimum predicted log Cd concentration is -1.7, so I added 2 to the predictions. A variable indicating the domains of interest is added to the data frame. The value of this variable is 1 for all grid cells, so that a sample is designed for estimating the mean of the entire population. As a first step function \texttt{buildFrameDF} is used to create a data frame that can be handled by function \texttt{optimStrata}. Argument \texttt{X} specifies the stratification variables, and argument \texttt{Y} the study variables. In our case the stratification variables and the study variables are the same. This is typical for the situation where the stratification variables are obtained by mapping the study variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SamplingStrata)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{cd =}\NormalTok{ lcd\_kriged}\SpecialCharTok{$}\NormalTok{var1.pred }\SpecialCharTok{+} \DecValTok{2}\NormalTok{,}
                 \AttributeTok{zn =}\NormalTok{ lzn\_kriged}\SpecialCharTok{$}\NormalTok{var1.pred,}
                 \AttributeTok{dom =} \DecValTok{1}\NormalTok{,}
                 \AttributeTok{id =} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(lcd\_kriged)))}
\NormalTok{frame }\OtherTok{\textless{}{-}} \FunctionTok{buildFrameDF}\NormalTok{(}
  \AttributeTok{df =}\NormalTok{ df, }\AttributeTok{id =} \StringTok{"id"}\NormalTok{,}
  \AttributeTok{X =} \FunctionTok{c}\NormalTok{(}\StringTok{"cd"}\NormalTok{, }\StringTok{"zn"}\NormalTok{), }\AttributeTok{Y =} \FunctionTok{c}\NormalTok{(}\StringTok{"cd"}\NormalTok{, }\StringTok{"zn"}\NormalTok{),}
  \AttributeTok{domainvalue =} \StringTok{"dom"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next, a data frame with the precision requirements for the estimated means is created. The precision requirement is given as a coefficient of variation, i.e.~the standard error of the estimated population mean, divided by the estimated mean. The study variables as specified in \texttt{Y} are used to compute the estimated means and the standard errors for a given stratification and allocation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{DOM =} \StringTok{"DOM1"}\NormalTok{, }\AttributeTok{CV1 =} \FloatTok{0.02}\NormalTok{, }\AttributeTok{CV2 =} \FloatTok{0.02}\NormalTok{, }\AttributeTok{domainvalue =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Finally, the multivariate stratification is optimised by searching for the optimal stratum bounds using a genetic algorithm \citep{ger99}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimStrata}\NormalTok{(}
  \AttributeTok{method =} \StringTok{"continuous"}\NormalTok{,  }\AttributeTok{errors =}\NormalTok{ cv, }\AttributeTok{framesamp =}\NormalTok{ frame, }\AttributeTok{nStrata =} \DecValTok{5}\NormalTok{,}
  \AttributeTok{iter =} \DecValTok{50}\NormalTok{, }\AttributeTok{pops =} \DecValTok{20}\NormalTok{, }\AttributeTok{showPlot =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A summary of the strata can be obtained with function \texttt{summaryStrata}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{smrstrata }\OtherTok{\textless{}{-}} \FunctionTok{summaryStrata}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{framenew, res}\SpecialCharTok{$}\NormalTok{aggr\_strata, }\AttributeTok{progress =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Stratum Population Allocation Lower_X1 Upper_X1 Lower_X2 Upper_X2
1       1        717          7    0.266    1.421    4.502    5.576
2       2        694          5    1.421    2.090    4.950    6.010
3       3        597          3    2.091    2.630    5.163    6.358
4       4        704          6    2.630    3.476    5.472    6.802
5       5        391          5    3.480    4.781    6.234    7.527
\end{verbatim}

Column \texttt{Population} contains the sizes of the strata (number of grid cells). The total sample size equals 26. The sample size per stratum is computed with Bethel allocation, see Section \ref{STSIallocation}. The last four columns contain the lower and upper bounds of the orthogonal intervals.

Figure \ref{fig:2dplotbivariatestrata} shows a 2D-plot of the bivariate strata. The strata can be plotted as a series of nested rectangles. All population units in the smallest rectangle belong to stratum 1; all units in the one-but-smallest rectangle that are not in the smallest rectangle belong to stratum 2, etc. If we have more than two stratification variables the strata form a series of nested hyperrectangles or boxes. The strata are obtained as the Cartesian product of orthogonal intervals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt }\OtherTok{\textless{}{-}} \FunctionTok{plotStrata2d}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{framenew, res}\SpecialCharTok{$}\NormalTok{aggr\_strata,}
  \AttributeTok{domain =} \DecValTok{1}\NormalTok{, }\AttributeTok{vars =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Cd"}\NormalTok{, }\StringTok{"Zn"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/2dplotbivariatestrata-1} 

}

\caption{2D-plot of optimised bivariate strata of study area Meuse.}\label{fig:2dplotbivariatestrata}
\end{figure}

\begin{rmdnote}
It may happen that after the optimisation of the stratum bounds in some resulting strata no units are contained. If the stratification with a smaller number of strata requires fewer sampling units so that the sampling costs are lower (and still the precision requirement is met), then this is retained as the optimal stratification (personal communication Giulio Barcaroli).
\end{rmdnote}

Figure \ref{fig:OptimisedstrataMeuse} shows a map of the optimised strata.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/OptimisedstrataMeuse-1} 

}

\caption{Map of optimised bivariate strata of study area Meuse.}\label{fig:OptimisedstrataMeuse}
\end{figure}

The expected coefficient of variation can be extracted with function \texttt{expected\_CV}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{expected\_CV}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{aggr\_strata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     cv(Y1) cv(Y2)
DOM1   0.02  0.009
\end{verbatim}

The coefficient of variation of Cd is indeed equal to the desired level of 0.02, for Zn it is smaller. So, in this case Cd is the study variable that determines the total sample size of 26 units.

Note that these coefficients of variation are computed from the stratification variables, which are predictions of the study variable. Errors in these predictions are not accounted for. It is well-known that kriging is a smoother, so that the variance of the predicted values within a stratum is smaller than the variance of the true values. As a consequence, the coefficients of variation of the predictions underestimate the coefficients of variation of the study variables. See Section \ref{Ospats} for how prediction errors and spatial correlation of prediction errors can be accounted for in optimal stratification. An additional problem is that I added a value of 2 to the log Cd concentrations. This does not affect the standard error of the estimated mean, but does effect the estimated mean, so that also for this reason the coefficient of variation of the study variable Cd is underestimated.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5214331 278.5    9368568 500.4   9368568  500.4
Vcells 25514128 194.7   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{SY}{%
\chapter{Systematic random sampling}\label{SY}}

A simple way of drawing probability samples whose units are spread uniformly over the study area, is systematic random sampling\index{Systematic random sampling} (SY). Systematic random sampling from a two-dimensional spatial population entails the selection of a regular grid randomly placed on the area\index{Regular grid}. A systematic sample can be selected with function \texttt{spsample} of package \textbf{sp} with argument \texttt{type\ =\ "regular"} \citep{Bivand2013}. Argument \texttt{offset} is not used, so that the grid is randomly placed on the study area. This is illustrated with Voorst. First \texttt{data.frame} \texttt{grdVoorst} is converted to \texttt{SpatialPixelsDataFrame} with function \texttt{gridded}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{gridded}\NormalTok{(grdVoorst) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{777}\NormalTok{)}
\NormalTok{mySYsample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdVoorst, }\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:sampleSY} shows the randomly selected systematic sample. The shape of the grid is square\index{Square grid}, and the orientation is East-West (E-W), North-South (N-S). There is no strict need for random selection of the orientation of the grid. Random placement of the grid on the study area suffices for design-based estimation.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleSY-1} 

}

\caption{Systematic random sample (square grid) from Voorst.}\label{fig:sampleSY}
\end{figure}

Argument \texttt{n} in function \texttt{spsample} is used to set the sample size. Note that this is the \emph{expected} sample size\index{Expected sample size}, i.e.~on average over repeated sampling the sample size is 40. In Figure \ref{fig:sampleSY} the number of selected sampling points equals 38. Given the expected sample size, the spacing\index{Grid spacing} of the square grid can be computed with \(\sqrt{A/n}\), with \(A\) the area of the study area. This area \(A\) can be computed by the total number of cells of the discretisation grid multiplied by the area of a grid cell. Note that the area of the study area is smaller than the number of grid cells in the horizontal direction multiplied by the number of grid cells in the vertical direction multiplied by the grid cell area, as we have non-availables (built-up areas, roads, etc.).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cell\_size }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst) }\SpecialCharTok{*}\NormalTok{ cell\_size}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{(spacing }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(A }\SpecialCharTok{/}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 342.965
\end{verbatim}

Instead of argument \texttt{n} we may use argument \texttt{cell\_size} to select a grid with a specified spacing. The expected sample size of a square grid can then be computed with \(A/spacing^2\).

The spatial coverage\index{Spatial coverage} with random grid sampling is better than that with stratified random sampling using compact geographical strata (Section \ref{geostrata}), even with one sampling unit per geostratum. Consequently, in general systematic random sampling results in more precise estimates of the mean or total.

However, there are also two disadvantages of systematic random sampling compared to geographically stratified random sampling. First, for systematic random sampling no design-unbiased estimator of the sampling variance exists. Second, the number of sampling units with random grid sampling is not fixed, but varies among randomly drawn samples. We may choose the grid spacing such that \emph{on average} the number of sampling units equals the required (allowed) number of sampling units, but for the actually drawn sample, this number can be smaller or larger. In Voorst the variation of the sample size is quite large. The approximated sampling distribution, obtained by repeating the sampling 10,000 times, is bimodal (Figure \ref{fig:samplesizeSY}). The smaller sample sizes are of square grids with only two E-W oriented rows of points instead of three rows.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/samplesizeSY-1} 

}

\caption{Approximated sampling distribution of the sample size of systematic random samples from Voorst. The expected sample size is 40.}\label{fig:samplesizeSY}
\end{figure}

A large variation in sample size over repeated selection with the sampling design under study is undesirable and should be avoided when possible. In the case of Voorst a simple solution is to select a rectangular grid\index{Rectangular grid} instead of a square grid, with a spacing in the N-S direction that results in a fixed number of E-W oriented rows of sampling points over repeated selection of grids. This is achieved with a N-S spacing equal to the dimension of the study area in N-S direction divided by an integer. The spacing in E-W direction is then adapted so that on average a given number of sampling points is selected. As the N-S dimension of Voorst is 1,000 m, a N-S spacing of 1,000/3 m is chosen, so that the number of E-W oriented rows of sampling points in the systematic sample equals three for any randomly selected rectangular grid.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dy }\OtherTok{\textless{}{-}} \DecValTok{1000} \SpecialCharTok{/} \DecValTok{3}
\NormalTok{dx }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*}\NormalTok{ dy)}
\NormalTok{mySYsample\_rect }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ grdVoorst, }\AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(dx, dy), }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The E-W spacing is somewhat larger than the N-S spacing: 352.875 m versus 333.333 m. The variation in sample size with the random rectangular grid is much smaller than that of the square grid. The sample size now ranges from 33 to 46, whereas with the square grid the range varies from 20 to 48.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(sampleSizes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  33.00   38.00   40.00   39.99   42.00   46.00 
\end{verbatim}

An alternative shape for the sampling grid is triangular\index{Triangular grid}. Triangular grids can be selected with argument \texttt{type\ =\ "hexagonal"}. The centres of hexagonal sampling grid cells form a triangular grid. The triangular grid was shown to yield most precise estimates of the population mean given the expected sample size \citep{mat86}. Given the spacing of a triangular grid, the expected sample size can be computed by the area \(A\) of the study area divided by the area of hexagonal grid cells with the sampling points at their centres. The area of a hexagon equals \(6\sqrt{3}/4\;r^2\), with \(r\) the radius of the circle circumscribing the hexagon (distance from centre to a corner of the hexagon). So, by choosing a radius of \(\sqrt{A/(6\sqrt{3}/4)\;n}\) the expected sample equals \(n\). The distance between neighbouring points of the triangular grid in the E-W direction, \(dx\), then equals \(r \sqrt{3}\). The N-S distance equals \(\sqrt{3}/2 \; dx\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cnst }\OtherTok{\textless{}{-}} \DecValTok{6} \SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \DecValTok{4}
\NormalTok{r }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(A }\SpecialCharTok{/}\NormalTok{ (cnst }\SpecialCharTok{*}\NormalTok{ n))}
\NormalTok{dx }\OtherTok{\textless{}{-}}\NormalTok{ r }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{dy }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ dx}
\end{Highlighting}
\end{Shaded}

Function \texttt{spsample} does not work properly in combination with argument \texttt{type\ =\ "hexagonal"}. Over repeated sampling the average sample size is not equal to the chosen sample size passed to function \texttt{spsample} with argument \texttt{n}. The same problem remains when using argument \texttt{cellsize}.

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  18.00   23.00   26.00   28.39   35.00   41.00 
\end{verbatim}

The following code can be used for random selection of triangular grids.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SY\_triangular }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(dx, grd) \{}
\NormalTok{  dy }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ dx}
  \CommentTok{\#randomly select offset}
\NormalTok{  offset\_x }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =}\NormalTok{ dx)}
\NormalTok{  offset\_y }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =}\NormalTok{ dy)}
  \CommentTok{\#compute x{-}coordinates of 1 row and y{-}coordinates of 1 column}
\NormalTok{  bbox }\OtherTok{\textless{}{-}} \FunctionTok{bbox}\NormalTok{(grd)}
\NormalTok{  nx }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{((bbox[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ bbox[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ dx)}
\NormalTok{  ny }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{((bbox[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ bbox[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ dy)}
\NormalTok{  x }\OtherTok{\textless{}{-}}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nx) }\SpecialCharTok{*}\NormalTok{ dx }\SpecialCharTok{+}\NormalTok{ offset\_x}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{0}\SpecialCharTok{:}\NormalTok{ny) }\SpecialCharTok{*}\NormalTok{ dy }\SpecialCharTok{+}\NormalTok{ offset\_y}
  \CommentTok{\#compute coordinates of rectangular grid}
\NormalTok{  xy }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(x, y)}
  \FunctionTok{names}\NormalTok{(xy) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)}
  \CommentTok{\#shift points of even rows in horizontal direction}
\NormalTok{  units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(xy}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{\%in\%}\NormalTok{ y[}\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{2}\NormalTok{, }\AttributeTok{to =}\NormalTok{ ny, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)])}
\NormalTok{  xy}\SpecialCharTok{$}\NormalTok{x[units] }\OtherTok{\textless{}{-}}\NormalTok{ xy}\SpecialCharTok{$}\NormalTok{x[units] }\SpecialCharTok{+}\NormalTok{ dx }\SpecialCharTok{/} \DecValTok{2}
  \CommentTok{\#add coordinates of origin}
\NormalTok{  xy}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ xy}\SpecialCharTok{$}\NormalTok{x }\SpecialCharTok{+}\NormalTok{ bbox[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\NormalTok{  xy}\SpecialCharTok{$}\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ xy}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{+}\NormalTok{ bbox[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{]}
  \CommentTok{\#overlay with grid}
  \FunctionTok{coordinates}\NormalTok{(xy) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ y}
\NormalTok{  mysample }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{coordinates}\NormalTok{(xy), }\FunctionTok{over}\NormalTok{(xy, grd))}
  \CommentTok{\#delete points with NA}
\NormalTok{  mysample }\OtherTok{\textless{}{-}}\NormalTok{ mysample[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(mysample[, }\DecValTok{3}\NormalTok{]), ]}
\NormalTok{\}}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mySYsample\_tri }\OtherTok{\textless{}{-}} \FunctionTok{SY\_triangular}\NormalTok{(}\AttributeTok{dx =}\NormalTok{ dx, }\AttributeTok{grd =}\NormalTok{ grdVoorst)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:Triangulargrid} shows a triangular grid, selected randomly from Voorst with an expected sample size of 40. The selected triangular grid has 42 points.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/Triangulargrid-1} 

}

\caption{Systematic random sample (triangular grid) from Voorst.}\label{fig:Triangulargrid}
\end{figure}

\hypertarget{EstVarSY}{%
\section{Estimation of population parameters}\label{EstVarSY}}

With systematic random sampling all units have the same inclusion probability, equal to \(E[n]/N\), with \(E[n]\) the expected sample size. Consequently, the population total can be estimated by

\begin{equation}
\hat{t}(z)=\sum_{k \in \mathcal{S}}\frac{z_k}{\pi_k} = N \sum_{k \in \mathcal{S}}\frac{z_k}{E[n]} \;.
\label{eq:HTTotalSY}
\end{equation}

The population mean can be estimated by dividing this \(\pi\) estimator of the population total by the population size:

\begin{equation}
\hat{\bar{z}}=\sum_{k \in \mathcal{S}}\frac{z_k}{E[n]} \;.
\label{eq:HTMeanSY}
\end{equation}

In this \(\pi\) estimator of the population mean the sample sum of the observations is not divided by the number of selected units, but by the expected number of units.

An alternative estimator is obtained by dividing the \(\pi\) estimator of the population total by the \(\pi\) estimator of the population size:

\begin{equation}
\hat{N}=\sum_{k \in \mathcal{S}}\frac{1}{\pi_k} = n \frac{N}{E[n]} \;.
\label{eq:EstimatorNSY}
\end{equation}

This yields the ratio estimator\index{Ratio estimator} of the population mean:

\begin{equation}
\hat{\bar{z}}_{\text{ratio}}=\frac{\hat{t}(z)}{\hat{N}} = \frac{1}{n}\sum_{k \in \mathcal{S}}z_k \;.
\label{eq:RatioMeanSY}
\end{equation}

So, the ratio estimator of the population total is equal to the unweighted sample mean. In general the variance of this ratio estimator is smaller than that of the \(\pi\) estimator. On the other side the \(\pi\) estimator is design-unbiased, whereas the ratio estimator is not, although its bias can be negligibly small. Only in the very special case where the sample size with systematic random sampling is fixed, the two estimators are equivalent.

Recall that for Voorst we have exhaustive knowledge of the study variable \(z\): values of the soil orgaic matter concentration (SOM) were simulated for all grid cells. To determine the \(z\)-values at the selected sampling points an overlay of the systematic random sample and the \texttt{SpatialPixelsDataFrame} is made, using function \texttt{over} of package \textbf{sp}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(mySYsample, grdVoorst)}
\NormalTok{mySYsample }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(mySYsample, }\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{mySYsample}\SpecialCharTok{$}\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{z}
\NormalTok{mz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mySYsample}\SpecialCharTok{$}\NormalTok{z) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{mz\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mySYsample}\SpecialCharTok{$}\NormalTok{z)}
\end{Highlighting}
\end{Shaded}

Using the systematic random sample of Figure \ref{fig:sampleSY} the \(\pi\) estimated mean SOM concentration equals 69.8 g kg\textsuperscript{-1}, the ratio estimate equals 73.5 g kg\textsuperscript{-1}. The ratio estimate is larger than the \(\pi\) estimate because the size of the selected sample is two units smaller (38) than the expected sample size (40).

\hypertarget{approximating-the-sampling-variance-of-the-estimator-of-the-mean}{%
\section{Approximating the sampling variance of the estimator of the mean}\label{approximating-the-sampling-variance-of-the-estimator-of-the-mean}}

An unbiased estimator of the sampling variance of the estimator of the mean is not available. A simple, often applied procedure is to calculate the sampling variance as if the sample were a simple random sample (Equation \eqref{eq:EstVarMeanSIR} or \eqref{eq:EstVarMeanSI}). In general this procedure overestimates the sampling variance, so that we are on the safe side.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{av\_SI\_mz }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mySYsample}\SpecialCharTok{$}\NormalTok{z) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(mySYsample)}
\end{Highlighting}
\end{Shaded}

The approximated variance equals 50.3 (g kg\textsuperscript{-1})\textsuperscript{2}.

Alternatively, the sampling variance can be estimated by treating the systematic random sample as if it were a stratified simple random sample (Equation \eqref{eq:EstVarMeanSTSI}). The sampling units are clustered on the basis of their spatial coordinates into \(H=n/2\) clusters (\(n\) even) or \(H=(n-1)/2\) clusters (\(n\) odd). In the next code chunk a simple k-means function is defined to cluster the sampling units of the grid into equal-sized clusters\index{\emph{k}-means clustering}. Arguments \texttt{s1} and \texttt{s2} are the spatial coordinates of the sampling units, \texttt{k} is the number of clusters. First, in this function the ids of equal-sized clusters are randomly assigned to the sampling units on the nodes of the sampling grid (initial clustering). Next, the centres of the clusters, i.e.~the means of the spatial coordinates of the clusters (initial cluster centres), are computed. There are two for-loops. In the inner-loop it is determined whether the cluster id of the unit selected in the outer-loop should be swopped with the cluster id of the next unit. If both units have the same cluster id the next unit is selected, until a unit of a different cluster is found. The cluster ids of the two units are swopped when the sum of the squared distances of the two units to their corresponding cluster centres is reduced. When the cluster ids are swopped, the centres are recomputed. The two loops are repeated until no swops are made anymore.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.kmeans\_equal\_size }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(s1, s2, k) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(s1)}
\NormalTok{  cluster\_id }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{k, }\AttributeTok{times =} \FunctionTok{ceiling}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ k))}
\NormalTok{  cluster\_id }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_id[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n]}
\NormalTok{  cluster\_id }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_id[}\FunctionTok{sample}\NormalTok{(n, }\AttributeTok{size =}\NormalTok{ n)]}
\NormalTok{  s1\_c }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(s1, }\AttributeTok{INDEX =}\NormalTok{ cluster\_id, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{  s2\_c }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(s2, }\AttributeTok{INDEX =}\NormalTok{ cluster\_id, }\AttributeTok{FUN =}\NormalTok{ mean)}
  \ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{    n\_swop }\OtherTok{\textless{}{-}} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) \{}
\NormalTok{      ci }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_id[i]}
      \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in}\NormalTok{ (i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{n) \{}
\NormalTok{        cj }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_id[j]}
        \ControlFlowTok{if}\NormalTok{ (ci }\SpecialCharTok{==}\NormalTok{ cj) \{}
          \ControlFlowTok{next}
\NormalTok{          \}}
\NormalTok{        d1 }\OtherTok{\textless{}{-}}\NormalTok{ (s1[i] }\SpecialCharTok{{-}}\NormalTok{ s1\_c[ci])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (s2[i] }\SpecialCharTok{{-}}\NormalTok{ s2\_c[ci])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}
\NormalTok{          (s1[j] }\SpecialCharTok{{-}}\NormalTok{ s1\_c[cj])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (s2[j] }\SpecialCharTok{{-}}\NormalTok{ s2\_c[cj])}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{        d2 }\OtherTok{\textless{}{-}}\NormalTok{ (s1[i] }\SpecialCharTok{{-}}\NormalTok{ s1\_c[cj])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (s2[i] }\SpecialCharTok{{-}}\NormalTok{ s2\_c[cj])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}
\NormalTok{          (s1[j] }\SpecialCharTok{{-}}\NormalTok{ s1\_c[ci])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (s2[j] }\SpecialCharTok{{-}}\NormalTok{ s2\_c[ci])}\SpecialCharTok{\^{}}\DecValTok{2}
        \ControlFlowTok{if}\NormalTok{ (d1 }\SpecialCharTok{\textgreater{}}\NormalTok{ d2) \{}
          \CommentTok{\#swop cluster ids and recompute cluster centres}
\NormalTok{          cluster\_id[i] }\OtherTok{\textless{}{-}}\NormalTok{ cj; cluster\_id[j] }\OtherTok{\textless{}{-}}\NormalTok{ ci}
\NormalTok{          s1\_c }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(s1, cluster\_id, mean)}
\NormalTok{          s2\_c }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(s2, cluster\_id, mean)}
\NormalTok{          n\_swop }\OtherTok{\textless{}{-}}\NormalTok{ n\_swop }\SpecialCharTok{+} \DecValTok{1}
          \ControlFlowTok{break}
\NormalTok{        \}}
\NormalTok{      \}}
\NormalTok{    \}}
    \ControlFlowTok{if}\NormalTok{ (n\_swop }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
      \ControlFlowTok{break}
\NormalTok{      \}}
\NormalTok{  \}}
\NormalTok{  D }\OtherTok{\textless{}{-}}\NormalTok{ fields}\SpecialCharTok{::}\FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =} \FunctionTok{cbind}\NormalTok{(s1\_c, s2\_c), }\AttributeTok{x2 =} \FunctionTok{cbind}\NormalTok{(s1, s2))}
\NormalTok{  dmin }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(D, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ min)}
\NormalTok{  MSSD }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dmin}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
  \FunctionTok{list}\NormalTok{(}\AttributeTok{clusters =}\NormalTok{ cluster\_id, }\AttributeTok{MSSD =}\NormalTok{ MSSD)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The clustering is repeated 100 times (\texttt{ntry\ =\ 100}). The clustering with the smallest mean of the squared distances of the sampling units to their cluster centres (mean of squared shortest distances, MSSD) is selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_equal\_size }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(s1, s2, k, ntry) \{}
\NormalTok{  res\_opt }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{  MSSD\_min }\OtherTok{\textless{}{-}} \ConstantTok{Inf}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{ntry) \{}
\NormalTok{      res }\OtherTok{\textless{}{-}} \FunctionTok{.kmeans\_equal\_size}\NormalTok{(s1, s2, k)}
      \ControlFlowTok{if}\NormalTok{ (res}\SpecialCharTok{$}\NormalTok{MSSD }\SpecialCharTok{\textless{}}\NormalTok{ MSSD\_min) \{}
\NormalTok{        MSSD\_min }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{MSSD}
\NormalTok{        res\_opt }\OtherTok{\textless{}{-}}\NormalTok{ res}
\NormalTok{      \}}
\NormalTok{  \}}
\NormalTok{  res\_opt}
\NormalTok{\}}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(mySYsample); k }\OtherTok{\textless{}{-}} \FunctionTok{floor}\NormalTok{(n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{kmeans\_equal\_size}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ mySYsample}\SpecialCharTok{$}\NormalTok{x1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ mySYsample}\SpecialCharTok{$}\NormalTok{x2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{,}
  \AttributeTok{k =}\NormalTok{ k, }\AttributeTok{ntry =} \DecValTok{100}\NormalTok{)}
\NormalTok{mySYsample}\SpecialCharTok{$}\NormalTok{cluster }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{clusters}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:varapproxSY} shows the clustering of the systematic random sample of Figure \ref{fig:sampleSY}. The two (or three) sampling units of a cluster are treated as a simple random sample from a stratum, and the variance estimator for stratified random sampling is used. The weights are computed by \(w_h=n_h/n\). With \(n\) even the stratum weight is \(1/H\) for all strata. For more details on variance estimation with stratified simple random sampling, I refer to Section \ref{EstimatorsSTSI}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2z\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mySYsample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mySYsample}\SpecialCharTok{$}\NormalTok{cluster, }\AttributeTok{FUN =}\NormalTok{ var)}
\NormalTok{nh }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mySYsample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mySYsample}\SpecialCharTok{$}\NormalTok{cluster, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{v\_mz\_h }\OtherTok{\textless{}{-}}\NormalTok{ S2z\_h }\SpecialCharTok{/}\NormalTok{ nh}
\NormalTok{w\_h }\OtherTok{\textless{}{-}}\NormalTok{ nh }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(nh)}
\NormalTok{av\_STSI\_mz }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_mz\_h)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/varapproxSY-1} 

}

\caption{Clustering of grid points for approximating the variance of the ratio estimator of the mean SOM concentration in Voorst.}\label{fig:varapproxSY}
\end{figure}

This method yields an approximated variance of 51.2 (g kg\textsuperscript{-1})\textsuperscript{2}, which is for the selected triangular grid slightly larger than the simple random sample approximation. Hereafter we will see that on average the stratified simple random sample approximation of the variance is smaller than the simple random sample approximation. For an individual sample the reverse can be true.

A similar approach for approximating the variance was proposed by Matérn \citep{Matern1947} a long time ago. In this approach the variance is approximated by computing the squared difference of two local means. A local mean is computed by linear interpolation of the observations at the two nodes on the diagonal of a square sampling grid cell. The four corners of a sampling grid cell serve as a group. Every sampling grid node belongs to four groups, and so the observation at a sampling grid node is used four times in computing a local mean. Near the edges of the study area we have incomplete groups: one, two, or even three observations are missing. To compute a squared difference these missing values are replaced by the sample mean. This results in as many squared differences as we have groups. Note that the number of groups is larger than the sample size. The squared differences are computed by

\begin{equation}
\begin{split}
d^2_{r,s} & = \left(\frac{z_{r,s}+z_{r+1,s+1}}{2}-\frac{z_{r+1,s}+z_{r,s+1}}{2}\right)^2 \\
& =\frac{(z_{r,s}-z_{r+1,s}-z_{r,s+1}+z_{r+1,s+1})^2}{4}\;,
\end{split}
\label{eq:sqdiflocalmean}
\end{equation}

with \(r = 0,1, \dots ,R\) an index for the column number and \(s=0,1, \dots, S\) an index for the row number of the extended grid. The variance of the estimator of the mean (sample mean) is then approximated by the sum of the squared differences divided by the squared sample size:

\begin{equation}
\widehat{V}(\bar{z}_{\mathcal{S}}) = \frac{\sum_{g=1}^G d^2_g}{n^2}\;,
\label{eq:VarMatern}
\end{equation}

with \(d^2_g\) the squared difference of group unit \(g\) and \(G\) the total number of groups.

To approximate the variance with Matérn's method\index{Mat$\text{{\'e}}$rn's variance approximation method} a function is defined.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{matern }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(s) \{}
\NormalTok{  g\_11 }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(s, \{gr }\OtherTok{\textless{}{-}}\NormalTok{ i; gs }\OtherTok{\textless{}{-}}\NormalTok{ j; z11 }\OtherTok{\textless{}{-}}\NormalTok{ z\})[, }\FunctionTok{c}\NormalTok{(}\StringTok{"gr"}\NormalTok{, }\StringTok{"gs"}\NormalTok{, }\StringTok{"z11"}\NormalTok{)]}
\NormalTok{  g\_12 }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(s, \{gr }\OtherTok{\textless{}{-}}\NormalTok{ i; gs }\OtherTok{\textless{}{-}}\NormalTok{ j }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{; z12 }\OtherTok{\textless{}{-}}\NormalTok{ z\})[, }\FunctionTok{c}\NormalTok{(}\StringTok{"gr"}\NormalTok{, }\StringTok{"gs"}\NormalTok{, }\StringTok{"z12"}\NormalTok{)]}
\NormalTok{  g\_21 }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(s, \{gr }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{; gs }\OtherTok{\textless{}{-}}\NormalTok{ j; z21 }\OtherTok{\textless{}{-}}\NormalTok{ z\})[, }\FunctionTok{c}\NormalTok{(}\StringTok{"gr"}\NormalTok{, }\StringTok{"gs"}\NormalTok{, }\StringTok{"z21"}\NormalTok{)]}
\NormalTok{  g\_22 }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(s, \{gr }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{; gs }\OtherTok{\textless{}{-}}\NormalTok{ j }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{; z22 }\OtherTok{\textless{}{-}}\NormalTok{ z\})[, }\FunctionTok{c}\NormalTok{(}\StringTok{"gr"}\NormalTok{, }\StringTok{"gs"}\NormalTok{, }\StringTok{"z22"}\NormalTok{)]}
\NormalTok{  g }\OtherTok{\textless{}{-}} \FunctionTok{Reduce}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x, y) }\FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"gr"}\NormalTok{, }\StringTok{"gs"}\NormalTok{), }\AttributeTok{all =} \ConstantTok{TRUE}\NormalTok{),}
              \FunctionTok{list}\NormalTok{(g\_11, g\_12, g\_21, g\_22))}
\NormalTok{  g[}\FunctionTok{is.na}\NormalTok{(g)] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(s}\SpecialCharTok{$}\NormalTok{z)}
\NormalTok{  g }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(g, T }\OtherTok{\textless{}{-}}\NormalTok{ (z11 }\SpecialCharTok{{-}}\NormalTok{ z12 }\SpecialCharTok{{-}}\NormalTok{ z21 }\SpecialCharTok{+}\NormalTok{ z22)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/} \DecValTok{4}\NormalTok{)}
  \FunctionTok{sum}\NormalTok{(g}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{/}\NormalTok{ ((}\FunctionTok{nrow}\NormalTok{(s))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Before using this function the data frame with the sample data must be extended with two variables: an index \(i\) for the column number and an index \(j\) for the row number of the square grid.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mySYsample }\OtherTok{\textless{}{-}}\NormalTok{ mySYsample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{i =} \FunctionTok{round}\NormalTok{((x1 }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x1)) }\SpecialCharTok{/}\NormalTok{ spacing),}
    \AttributeTok{j =} \FunctionTok{round}\NormalTok{((x2 }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x2)) }\SpecialCharTok{/}\NormalTok{ spacing))}
\FunctionTok{matern}\NormalTok{(mySYsample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 41.63163
\end{verbatim}

Figure \ref{fig:SamplingDistributionSY} shows the approximated sampling distributions of estimators of the mean SOM concentration for systematic random sampling, using a randomly placed square grid (with fixed orientation) and an expected sample size of 40, and for simple random sampling, obtained by repeating the random sampling with each design and estimation 10,000 times. To estimate the population mean from the systematic random samples both the \(\pi\) estimator and the ratio estimator are used.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionSY-1} 

}

\caption{Approximated sampling distribution of estimators of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst, for systematic random sampling (square grid) and simple random sampling and an (expected) sample size of 40. With systematic random sampling both the \(\pi\) estimator (SY.HT) and the ratio estimator (SY.ratio) are used in estimation.}\label{fig:SamplingDistributionSY}
\end{figure}

The boxplots of the estimated means indicate that systematic random sampling in combination with the ratio estimator is more precise than simple random sampling. The variance of the 10,000 ratio estimates equals 49.0 (g kg\textsuperscript{-1})\textsuperscript{2}, whereas for simple random sampling this variance equals 55.4 (g kg\textsuperscript{-1})\textsuperscript{2}. Systematic random sampling in combination with the \(\pi\) estimator performs very poor: the variance equals 142.6 (g kg\textsuperscript{-1})\textsuperscript{2}. This can be explained by the strong variation in sample size (Figure \ref{fig:samplesizeSY}), which is not accounted for in the \(\pi\) estimator.

The mean of the 10,000 ratio estimates is 81.2 g kg\textsuperscript{-1}, which is about equal to the population mean 81.1 g kg\textsuperscript{-1}, showing that in this case the design-bias of the ratio estimator is negligibly small indeed.

The average of the 10,000 approximated variances treating the systematic sample as a simple random sample equals 56.4 (g kg\textsuperscript{-1})\textsuperscript{2}. This is larger than the variance of the ratio estimator (49.0 (g kg\textsuperscript{-1})\textsuperscript{2}). The stratified simple random sample approximation of the variance somewhat underestimates the variance: the mean of this variance approximation equals 47.1 (g kg\textsuperscript{-1})\textsuperscript{2}. Also with Matérn's method the variance is underestimated in this case: the mean of the 10,000 variances equals 45.6 (g kg\textsuperscript{-1})\textsuperscript{2}. Figure \ref{fig:SamplingDistributionApproxVarSY} shows boxplots of the approximated standard error of the ratio estimator of the population mean. The horizontal red line is at the standard deviation of the 10,000 ratio estimates of the population mean. Differences between the three approximation methods are small in this case.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionApproxVarSY-1} 

}

\caption{Sampling distribution of the approximated standard error of the ratio estimator of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst, with systematic random sampling (square grid) and an expected sample size of 40. Approximations are obtained by treating the systematic sample as a simple random sample (SI) or a stratified simple random sample (STSI), and with Matérn's method (Mat).}\label{fig:SamplingDistributionApproxVarSY}
\end{figure}

The variance of the 10,000 ratio estimates of the population mean with the triangular grid and an expected sample size of 40 equals 46.9 (g kg\textsuperscript{-1})\textsuperscript{2}. Treating the triangular grid as a simple random sample strongly overestimates the variance: the average approximated variance equals 60.1 (g kg\textsuperscript{-1})\textsuperscript{2}. The stratified simple random sample approximation performs much better in this case: the average of the 10,000 approximated variances equals 46.8 (g kg\textsuperscript{-1})\textsuperscript{2}. Matérn's method cannot be used to approximate the variance with a triangular grid.

The approximated variance for this clustering equals \texttt{round(av\_STSI\_mz\_SYtri,1)}.

\citet{Brus2016c} compared various variance approximations for systematic random sampling, among which model-based prediction of the variance, using a semivariogram that is estimated from the systematic sample, see Chapter \ref{MBpredictionofDesignVariance}.

\hypertarget{exercises-8}{%
\subsubsection*{Exercises}\label{exercises-8}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  One solution to the problem of variance estimation with systematic random sampling is to select multiple systematic random samples independently from each other. So, for instance, instead of one systematic random sample with an expected sample size of 40, we may select two systematic random samples with an expected size of 20.

  \begin{itemize}
  \tightlist
  \item
    Write an \textbf{R} script to select two systematic random samples (random square grids) both with an expected size of 20 from Voorst.
  \item
    Use each sample to estimate the population mean, so that you obtain two estimated means. Overlay the points of each sample with \texttt{grdVoorst}, using function \texttt{over} and extract the \(z\)-values.
  \item
    Use the two estimated means to estimate the sampling variance of the estimator of the mean for systematic random sampling \emph{with an expected sample size of 20}.
  \item
    Use the two estimated means to compute a single, final estimate of the population mean, as estimated from \emph{two systematic random samples, each with an expected sample size of 20}.
  \item
    Estimate the sampling variance of the final estimate of the population mean.\\
  \end{itemize}
\item
  Do you like this solution? What about the variance of the estimator of the mean, obtained by selecting two systematic random samples of half the expected size, as compared with the variance of the estimator of the mean, obtained with a single systematic random sample? Hint: plot the two random square grids. What do you think of the spatial coverage of the two samples?
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5216567 278.6    9368568 500.4   9368568  500.4
Vcells 25547290 195.0   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{Cl}{%
\chapter{Cluster random sampling}\label{Cl}}

With stratified random sampling using geographical strata and systematic random sampling the sampling units are well spread throughout the study area. In general this leads to an increase of the precision of the estimated mean (total). This is because many spatial populations show spatial structure, so that the values of the study variable at two close units are more similar than those at two distant units. With large study areas the price to be paid for this is long travel times, so that fewer sampling units can be observed in a given survey time. In this situation it can be more efficient to select \emph{spatial clusters}\index{Spatial cluster} of population units. In cluster random sampling\index{Cluster random sampling}, once a cluster is selected, \emph{all} units in this cluster are observed. Therefore this design is also referred to as \emph{single-stage} cluster random sampling. The clusters are not subsampled as in two-stage cluster random sampling (see Chapter \ref{Twostage}).

In spatial sampling a popular cluster shape is a transect\index{Transect}. This is because the individual sampling units of a transect can easily be located in the field, which was in particular an advantage in the pre-GPS era.

The implementation of cluster random sampling is not straightforward. Frequently this sampling design is improperly implemented. A proper selection technique is as follows \citep{gru06}. In the first step a starting unit is selected, for instance by simple random sampling. Then the remaining units of the cluster to which the starting unit belongs are identified by making use of the definition of the cluster. For instance, with clusters defined as E-W oriented transects with a spacing of 100 m between the units of a cluster, all units E and W of the starting unit at a distance of 100 m, 200 m, etc. that fall inside the study area are selected. These two steps are repeated until the required number of \emph{clusters} (not the number of units) is selected.

A requirement of a valid selection method is that the same cluster is selected, regardless of which of its units is used as a starting unit. In the example above this is the case: regardless of which of the units of the transect is selected first, the final set of units selected is the same because, as stated above, all units E and W of the starting unit are selected.

\begin{rmdnote}
An example of an improper implementation of cluster random sampling is the following selection procedure. A cluster is defined as an E-W oriented transect of four units with a mutual spacing of 100 m. A cluster is selected by randomly selecting a starting unit. The remaining three units of the cluster are selected E of this starting unit. Units outside the study area are ignored. With this selection method the set of selected units is \emph{not} independent of the starting unit, and therefore this selection method is invalid.
\end{rmdnote}

Note that the size, i.e.~the number of units, of a cluster need not be constant. With the proper selection method described above the selection probability of a cluster is proportional to its size. With irregularly shaped study areas the size of the clusters can vary strongly. The size of the clusters can be controlled by subdividing the study area into blocks, for instance stripes perpendicular to the direction of the transects, or square blocks in case the clusters are grids. In this case, the remaining units are identified by extending the transect or grid until the boundary of the block. With irregularly shaped areas blocking will not entirely eliminate the variation in cluster sizes\index{Cluster size}.

Cluster random sampling is illustrated with the selection of E-W oriented transects in Voorst. In order to delimit the length of the transects the study area is split into six 1 km \(\times\) 1 km zones. In this case the zones have an equal size, but this is not needed. Note that these zones do not serve as strata. When used as strata, from each zone one or more clusters would be selected, see Section \ref{StratifiedCl}.

In the code chunk below the function \texttt{findInterval} of the \textbf{base} package is used to determine for all discretisation points in which zone they fall.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cell\_size }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{w }\OtherTok{\textless{}{-}} \DecValTok{1000} \CommentTok{\#width of zones}
\NormalTok{grdVoorst }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{zone =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{findInterval}\NormalTok{(}\FunctionTok{min}\NormalTok{(s1) }\SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ w }\SpecialCharTok{+} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ cell\_size))}
\end{Highlighting}
\end{Shaded}

As a first step in the \textbf{R} code below the variable \texttt{cluster} is added to \texttt{grdVoorst} indicating to which cluster a unit belongs. Note that each unit belongs exactly to one cluster. The operator \%\% computes the modulus of the s1-coordinates and the spacing of units within a transect (cluster). Function \texttt{stringr} of package \textbf{stringr} \citep{stringr} joins the resulting vector, the vector with the s2-coordinate, and the vector with the zone into a single character vector. The sizes of the clusters are computed with function \texttt{tapply}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spacing }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{grdVoorst }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
        \AttributeTok{cluster =} \FunctionTok{str\_c}\NormalTok{(}
\NormalTok{            (s1 }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(s1)) }\SpecialCharTok{\%\%}\NormalTok{ spacing,}
\NormalTok{            s2 }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(s2),}
\NormalTok{            zone, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{),}
        \AttributeTok{unit =} \FunctionTok{row\_number}\NormalTok{())}
\NormalTok{M\_cl }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{cluster, }\AttributeTok{FUN =}\NormalTok{ length)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/clustersize-1} 

}

\caption{Frequency distribution of the size of clusters in Voorst. Clusters are E-W oriented transects within zones, with a spacing of 100 m between units.}\label{fig:clustersize}
\end{figure}

In total there are 960 clusters in the population. Figure \ref{fig:clustersize} shows the frequency distribution of the size of the clusters.

Clusters are selected with probabilities proportional to their size and with replacement (ppswr). So, the sizes of all clusters must be known, which explains that all clusters must be enumerated. Selection of clusters by ppswr can be done by simple random sampling with replacement of elementary units (centres of grid cells) and identifying the clusters to which these units belong. Finally, all units of the selected clusters are included in the sample. In the code chunk below a function is defined for selecting clusters by ppswr. Note variable \texttt{cldraw}, that has value 1 for all units selected in the first draw, value 2 for all units selected in the second draw, etc. This variable is needed in estimating the population mean, as explained in Section \ref{clustersamplingestimators}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cl\_ppswr }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(sframe, n) \{}
\NormalTok{  units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(sframe), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  units\_cl }\OtherTok{\textless{}{-}}\NormalTok{ sframe}\SpecialCharTok{$}\NormalTok{cluster[units]}
\NormalTok{  mysamples }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(units\_cl))) \{}
\NormalTok{    mysample }\OtherTok{\textless{}{-}}\NormalTok{ sframe[sframe}\SpecialCharTok{$}\NormalTok{cluster }\SpecialCharTok{\%in\%}\NormalTok{ units\_cl[i], ]}
\NormalTok{    mysample}\SpecialCharTok{$}\NormalTok{start }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{    mysample}\SpecialCharTok{$}\NormalTok{start[mysample}\SpecialCharTok{$}\NormalTok{unit }\SpecialCharTok{\%in\%}\NormalTok{ units[i]] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{    mysample}\SpecialCharTok{$}\NormalTok{cldraw }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(i, }\FunctionTok{nrow}\NormalTok{(mysample))}
\NormalTok{    mysamples }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysamples, mysample)}
\NormalTok{  \}}
\NormalTok{  mysamples}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Function \texttt{cl\_ppswr} is now used to select six times a cluster by ppswr.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{6}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{cl\_ppswr}\NormalTok{(}\AttributeTok{sframe =}\NormalTok{ grdVoorst, }\AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

As our population actually is infinite, the centres of the selected grid cells are jittered to a random point within the selected grid cells. Note that the same noise is added to all units of a given cluster.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(cldraw) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{+} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \SpecialCharTok{{-}}\FloatTok{12.5}\NormalTok{, }\AttributeTok{max =} \FloatTok{12.5}\NormalTok{),}
         \AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{+} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \SpecialCharTok{{-}}\FloatTok{12.5}\NormalTok{, }\AttributeTok{max =} \FloatTok{12.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:ClVoorst} shows the selected sample. Note that in this case the second west-most zone has two transects (clusters) whereas one zone has none, showing that the zones are not used as strata. The total number of selected points equals 50. Similar to systematic random sampling, with cluster random sampling the total sample size is random, so that we do not have perfect control of the total sample size. This is because in this case the size (number of points) of the clusters is not constant but varies.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ClVoorst-1} 

}

\caption{Cluster random sample from Voorst selected by ppswr.}\label{fig:ClVoorst}
\end{figure}

The output data frame of function \texttt{cl} has a variable named \texttt{start}. This is an indicator with value 1 if this point of the cluster is selected first, and 0 otherwise. When in the field it appears that the first selected point of a cluster does not belong to the target population, all other points of that cluster are also discarded. This is to keep the selection probabilities of the clusters exactly proportional to their size. Column \texttt{cldraw} is needed in estimation because clusters are selected with replacement. In case a cluster is selected more than once, multiple means of that cluster are used in estimation, see next section.

\hypertarget{clustersamplingestimators}{%
\section{Estimation of population parameters}\label{clustersamplingestimators}}

With ppswr sampling\index{pps sampling!with replacement (ppswr)} of clusters, the population total can be estimated by the pwr estimator:

\begin{equation}
\hat{t}(z) = \frac{1}{n}\sum_{j \in \mathcal{S}} \frac{t_{j}(z)}{p_{j}} \;,
\label{eq:EstTotalCl1}
\end{equation}

with \(n\) the number of cluster draws, \(p_j\) the draw-by-draw selection probability of cluster \(j\), and \(t_j(z)\) the total of cluster \(j\):

\begin{equation}
t_j(z) = \sum_{k=1}^{M_j} z_{kj} \;,
\label{eq:clustertotal}
\end{equation}

with \(M_j\) the size (number of units) of cluster \(j\) and \(z_{kj}\) the study variable value of unit \(k\) in cluster \(j\).

The draw-by-draw selection probability of a cluster\index{Draw-by-draw selection probability!of a cluster} equals

\begin{equation}
p_{j} = \frac{M_j}{M} \;,
\label{eq:drawbydraw}
\end{equation}

with \(M\) the total number of population units (for Voorst \(M\) equals 7,528). Inserting this in Equation \eqref{eq:EstTotalCl1} yields

\begin{equation}
\hat{t}(z) = \frac{M}{n} \sum_{j \in \mathcal{S}} \frac{t_{j}(z)}{M_{j}} = \frac{M}{n} \sum_{j \in \mathcal{S}} \bar{z}_{j} \;,
\label{eq:EstTotalCl}
\end{equation}

with \(\bar{z}_{j}\) the mean of cluster \(j\). Note that if a cluster is selected more than once, multiple means of that cluster are used in the estimator.

Dividing this estimator by the total number of population units \(M\), yields the estimator of the population mean:

\begin{equation}
\hat{\bar{\bar{z}}}=\frac{1}{n}\sum\limits_{j \in \mathcal{S}} \bar{z}_{j} \;.
\label{eq:EstMeanCl}
\end{equation}

Note the two bars in \(\hat{\bar{\bar{z}}}\), indicating that the observations are averaged twice.

For an infinite population of points discretised by the centres of a finite number of grid cells, \(z_{kj}\) in Equation \eqref{eq:clustertotal} is the study variable value at a randomly selected point within the grid cell multiplied by the area of the grid cell. The estimated population total thus obtained is equal to the estimated population mean (Equation \eqref{eq:EstMeanCl}) multiplied by the area of the study area.

The sampling variance of the estimator of the mean with ppswr sampling of clusters is equal to (\citet{coc77}, Equation (9A.6))

\begin{equation}
V(\hat{\bar{\bar{z}}})= \frac{1}{n}\sum_{j=1}^N \frac{M_j}{M} (\bar{z}_j-\bar{z})^2  \;,
\label{eq:TrueVarEstMeanCl}
\end{equation}

with \(N\) the total number of clusters (for Voorst, \(N=960\)), \(\bar{z}_j\) the mean of cluster \(j\), and \(\bar{z}\) the population mean. Note that \(M_j/M\) is the selection probability of cluster \(j\).

This sampling variance can be estimated by (\citet{coc77}, Equation (9A.22))

\begin{equation}
\widehat{V}\!\left(\hat{\bar{\bar{z}}}\right)=\frac{\widehat{S^2}(\bar{z})}{n} \;,
\label{eq:VarEstMeanCl}
\end{equation}

where \(\widehat{S^2}(\bar{z})\) is the estimated variance of cluster means (the between-cluster variance):

\begin{equation}
\widehat{S^2}(\bar{z}) = \frac{1}{n-1}\sum_{j \in \mathcal{S}}(\bar{z}_{j}-\hat{\bar{\bar{z}}})^2 \;.
\label{eq:S2EstMeanCl}
\end{equation}

In \textbf{R} the population mean and the sampling variance of the estimator of the population means can be estimated as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{est }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(cldraw) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz\_cl =} \FunctionTok{mean}\NormalTok{(z)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz =} \FunctionTok{mean}\NormalTok{(mz\_cl),}
            \AttributeTok{se\_mz =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(mz\_cl) }\SpecialCharTok{/} \FunctionTok{n}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

The estimated mean equals 87.1 g kg\textsuperscript{-1}, and the estimated standard error equals 17.4 g kg\textsuperscript{-1}. Note that the size of the clusters (number of units) does not appear in these formulas. This simplicity is due to the fact that the clusters are selected with probabilities proportional to size. The effect of the cluster size on the variance is implicitly accounted for. To understand this, consider that larger clusters result in smaller variance among their means.

The same estimates are obtained with functions \texttt{svydesign} and \texttt{svymean} of package \textbf{survey} \citep{Lumley2020}. Argument \texttt{weights} specifies the weights of the sampled clusters equal to \(M/(M_j\; n)\) (Equation \eqref{eq:EstTotalCl}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ M }\SpecialCharTok{/}\NormalTok{ (M\_cl[mysample}\SpecialCharTok{$}\NormalTok{cluster] }\SpecialCharTok{*}\NormalTok{ n)}
\NormalTok{design\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cldraw, }\AttributeTok{weights =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weights, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_cluster, }\AttributeTok{deff =} \StringTok{"replace"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE   DEff
z 87.077 17.428 4.0767
\end{verbatim}

The design effect\index{Design effect} \texttt{DEff} as estimated from the selected cluster sample is considerably larger than 1. About 4 times more sampling points are needed with cluster random sampling compared to simple random sampling to estimate the population mean with the same precision.

A confidence interval estimate of the population mean can be computed with method \texttt{confint}. The number of degrees of freedom equals the number of cluster draws minus 1.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confint}\NormalTok{(}\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_cluster, }\AttributeTok{df =} \FunctionTok{degf}\NormalTok{(design\_cluster), }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     2.5 %   97.5 %
z 52.91908 121.2347
\end{verbatim}

Figure \ref{fig:SamplingDistributionCl} shows the approximated sampling distribution of the pwr estimator of the mean soil organic matter (SOM) concentration with cluster random sampling and of the \(\pi\) estimator with simple random sampling, obtained by repeating the random sampling with each design and estimation 10,000 times. The size of the simple random samples is equal to the expected sample size of the cluster random sampling design (rounded to nearest integer).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionCl-1} 

}

\caption{Approximated sampling distribution of the pwr estimator of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst with cluster random sampling (Cl) and of the \(\pi\) estimator with simple random sampling (SI). In Cl six clusters are selected by ppswr. The (expected) sample size is 49 units.}\label{fig:SamplingDistributionCl}
\end{figure}

The variance of the 10,000 estimated population means with cluster random sampling equals 126.2 (g kg\textsuperscript{-1})\textsuperscript{2}. This is considerably larger than with simple random sampling: 44.8 (g kg\textsuperscript{-1})\textsuperscript{2}. The large variance is caused by the strong spatial clustering of points. This may save travel time in large study areas, but in Voorst the saved travel time will be very limited, and therefore cluster random sampling in Voorst is not a good idea. The average of the estimated variances with cluster random sampling equals 125.9 (g kg\textsuperscript{-1})\textsuperscript{2}. The difference with the variance of the 10,000 estimated means is small because the estimator of the variance, Equation \eqref{eq:VarEstMeanCl}, is unbiased. Figure \ref{fig:histsamplesizeCl} shows the approximated sampling distribution of the sample size. The expected sample size can be computed as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ M\_cl }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(M\_cl)}
\FunctionTok{print}\NormalTok{(m\_n }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(p }\SpecialCharTok{*}\NormalTok{ M\_cl))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 49.16844
\end{verbatim}

So, the unequal draw-by-draw selection probabilities of the clusters are accounted for in computing the expected sample size\index{Expected sample size}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histsamplesizeCl-1} 

}

\caption{Approximated sampling distribution of the sample size with cluster random sampling from Voorst, for six clusters selected by ppswr.}\label{fig:histsamplesizeCl}
\end{figure}

\hypertarget{exercises-9}{%
\subsubsection*{Exercises}\label{exercises-9}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to compute the true sampling variance of the estimator of the mean SOM concentration in Voorst for cluster random sampling and clusters selected with ppswr, \(n = 6\), see Equation \eqref{eq:TrueVarEstMeanCl}. Compare the sampling variance for cluster random sampling with the sampling variance for simple random sampling with a sample size equal to the expected sample size of cluster random sampling.\\
\item
  As an alternative we may select three times a transect, using three 2 km \(\times\) 1 km zones obtained by joining two neighbouring 1 km \(\times\) 1 km zones of Figure \ref{fig:ClVoorst}. Do you expect that the sampling variance of the estimator of the population mean is equal to, larger or smaller than that of the sampling design with six transects of half the length?
\end{enumerate}

\hypertarget{clusters-selected-with-probabilities-proportional-to-size-without-replacement}{%
\section{Clusters selected with probabilities proportional to size, without replacement}\label{clusters-selected-with-probabilities-proportional-to-size-without-replacement}}

In the previous section the clusters were selected with replacement (ppswr). The advantage of with replacement sampling is that this keeps the statistical inference simple, more specifically the estimation of the standard error of the estimator of the population mean. However, in sampling from finite populations, cluster sampling with replacement is less efficient than cluster sampling without replacement, especially with large sampling fractions of clusters, i.e.~if \(1-n/N\) is small, with \(N\) being the total number of clusters and \(n\) the sample size, i.e.~the number of cluster draws. If a cluster is selected more than once, there is less information about the population mean in this sample than in a sample with all clusters different. Selection of clusters with probabilities proportional to size without replacement (ppswor) is not straightforward\index{pps sampling!without replacement (ppswor)}.

\begin{rmdnote}
The problem is the computation of the inclusion probabilities of the clusters. After we have selected a first cluster, we must adapt the sum of the sizes of the \(N-1\) remaining clusters and recompute the selection probabilities of the remaining clusters in the second draw, etc. Section 6.4 of \citet{loh99} nicely describes how the inclusion probabilities of the \(N\) clusters in a cluster random sample of size two, selected by ppswor, can be computed.
\end{rmdnote}

Many algorithms have been developed for ppswor sampling, see \citet{Tille2006} for an overview, and quite a few of them are implemented in package \textbf{sampling} \citep{Tille2016}. In the next code chunk function \texttt{UPpivotal} is used to select a cluster random sample with ppswor. For an explanation of this algorithm, see Subsection \ref{pivotalmethod}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{6}
\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ M\_cl }\SpecialCharTok{/}\NormalTok{ M}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{eps }\OtherTok{\textless{}{-}} \FloatTok{1e{-}6}
\NormalTok{sampleind }\OtherTok{\textless{}{-}} \FunctionTok{UPpivotal}\NormalTok{(}\AttributeTok{pik =}\NormalTok{ pi, }\AttributeTok{eps =}\NormalTok{ eps)}
\NormalTok{clusters }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{cluster))}
\NormalTok{clusters\_sampled }\OtherTok{\textless{}{-}}\NormalTok{ clusters[sampleind }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{cluster }\SpecialCharTok{\%in\%}\NormalTok{ clusters\_sampled, ]}
\end{Highlighting}
\end{Shaded}

The population mean can be estimated by the \(\pi\) estimator by writing a few lines of \textbf{R} code yourself or by using function \texttt{svymean} of package \textbf{survey} as shown hereafter. Estimation of the sampling variance in pps sampling of clusters without replacement is difficult\footnote{The problem is the computation of the joint inclusion probabilities of pairs of points.}. A simple solution is to treat the cluster sample as a ppswr sample and to estimate the variance with Equation \eqref{eq:VarEstMeanCl}. With small sampling fractions this variance approximation is fine: the overestimation of the variance is negligible. For larger sampling fractions various alternative variance approximations are developed, see \citet{Berger2004} for details. One of the methods is Brewer's method\index{Brewer's variance estimator}, which is implemented in function \texttt{svydesign}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ M\_cl[mysample}\SpecialCharTok{$}\NormalTok{cluster] }\SpecialCharTok{/}\NormalTok{ M}
\NormalTok{design\_clppswor }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cluster, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{pps =} \StringTok{"brewer"}\NormalTok{, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_clppswor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   mean     SE
z 96.83 13.454
\end{verbatim}

Another variance estimator implemented in function \texttt{svydesign} is the Hartley-Rao estimator\index{Hartley-Rao's variance estimator}. The two estimated standard errors are nearly equal.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2sum }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((n }\SpecialCharTok{*}\NormalTok{ M\_cl[mysample}\SpecialCharTok{$}\NormalTok{cluster] }\SpecialCharTok{/}\NormalTok{ M)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{design\_hr }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cluster,  }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{pps =} \FunctionTok{HR}\NormalTok{(p2sum), }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_hr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   mean     SE
z 96.83 13.436
\end{verbatim}

\hypertarget{SIC}{%
\section{Simple random sampling of clusters}\label{SIC}}

Suppose the clusters have unequal size, but we do not know the size of the clusters, so that we cannot select the clusters with probabilities proportional to their size. In this case we may select the clusters by simple random sampling without replacement. The inclusion probability of a cluster equals \(n/N\) with \(n\) the number of selected clusters and \(N\) the total number of clusters in the population. This yields the following \(\pi\) estimator of the population total:

\begin{equation}
\hat{t}(z) = \frac{N}{n} \sum_{j \in \mathcal{S}} t_{j}(z)\;.
\label{eq:EstTotalClEqual}
\end{equation}

The population mean can be estimated by dividing this estimator of the population total by the total number of units in the population \(M\):

\begin{equation}
\hat{\bar{\bar{z}}}_{\pi}(z) = \frac{\hat{t}(z)}{M}\;.
\label{eq:EstMeanHTClEqual}
\end{equation}

Alternatively, we may estimate the population mean by dividing the estimate of the population total by the \emph{estimated} population size:

\begin{equation}
\widehat{M} = \sum_{j \in \mathcal{S}} \frac{M_{j}}{\pi_{j}} = \frac{N}{n} \sum_{j \in \mathcal{S}} M_{j} \;.
\label{eq:EstPopulatonSizeClEqual}
\end{equation}

This leads to the ratio estimator\index{Ratio estimator} of the population mean:

\begin{equation}
\hat{\bar{\bar{z}}}_{\text{ratio}}(z) = \frac{\hat{t}(z)}{\widehat{M}} \;.
\label{eq:EstMeanRatioClEqual}
\end{equation}

The \(\pi\) estimator and the ratio estimator are equal when the clusters are selected with probabilities proportional to size. This is because the estimated population size is equal to the true population size.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(M\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7528
\end{verbatim}

However, when clusters of different size are selected with equal probabilities, the two estimators are different. This is shown below. Six clusters are selected by simple random sampling without replacement.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{clusters }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{cluster))}
\NormalTok{units\_cl }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{length}\NormalTok{(clusters), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{clusters\_sampled }\OtherTok{\textless{}{-}}\NormalTok{ clusters[units\_cl]}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{cluster }\SpecialCharTok{\%in\%}\NormalTok{ clusters\_sampled, ]}
\end{Highlighting}
\end{Shaded}

The \(\pi\) estimate and the ratio estimate of the population mean are computed for the selected sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(clusters)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi)}
\NormalTok{mz\_HT }\OtherTok{\textless{}{-}}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M}
\NormalTok{M\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi)}
\NormalTok{mz\_ratio }\OtherTok{\textless{}{-}}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M\_HT}
\end{Highlighting}
\end{Shaded}

The \(\pi\) estimate equals 68.750 g kg\textsuperscript{-1}, and the ratio estimate equals 70.319 g kg\textsuperscript{-1}. The \(\pi\) estimate of the population mean can also be computed by first computing totals of clusters, see Equations \eqref{eq:EstTotalClEqual} and \eqref{eq:EstMeanHTClEqual}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tz\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{cluster, }\AttributeTok{FUN =}\NormalTok{ sum)}
\NormalTok{pi\_cluster }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(tz\_cluster }\SpecialCharTok{/}\NormalTok{ pi\_cluster)}
\FunctionTok{print}\NormalTok{(mz\_HT }\OtherTok{\textless{}{-}}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 68.74994
\end{verbatim}

The variance of the \(\pi\) estimator of the population mean can be estimated by first estimating the variance of the estimator of the total:

\begin{equation}
\widehat{V}(\hat{t}(z)) = N^2\left(1-\frac{n}{N}\right)\frac{\widehat{S^2}(t(z))}{n}
\label{eq:EstVarTotalHTClequal}
\;,
\end{equation}

and dividing this variance by the squared number of population units:

\begin{equation}
\widehat{V}(\hat{\bar{\bar{z}}}) = \frac{1}{M^2} \widehat{V}(\hat{t}(z)) \;.
\label{eq:EstVarMeanHTClequal}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fpc }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{v\_tz }\OtherTok{\textless{}{-}}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ fpc }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(tz\_cluster) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{se\_mz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(v\_tz }\SpecialCharTok{/}\NormalTok{ M}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The estimated standard error equals 11.5 g kg\textsuperscript{-1}.

To compute the variance of the ratio estimator of the population mean we first compute residuals of cluster totals:

\begin{equation}
e_j = t_j(z)-\hat{b}M_j \;,
\label{eq:residualsclustertotals}
\end{equation}

with \(\hat{b}\) the ratio of the estimated population mean of the cluster totals to the estimated population mean of the cluster sizes:

\begin{equation}
\hat{b}=\frac{\frac{1}{n}\sum_{j \in \mathcal{S}} t_{j}}{\frac{1}{n}\sum_{j \in \mathcal{S}} M_{j}} \;.
\label{eq:ratioclustertotalclustersize}
\end{equation}

The variance of the ratio estimator of the population mean can be estimated by

\begin{equation}
\hat{V}(\hat{\bar{\bar{z}}}_{\text{ratio}})=\left(1-\frac{n}{N}\right)\frac{1}{(\frac{1}{n}\sum_{j \in \mathcal{S}} M_{j})^2}\frac{\widehat{S^2}_e}{n} \;,
\label{eq:varratioestimatormeanCl}
\end{equation}

with \(\widehat{S^2}_e\) the estimated variance of the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m\_M\_cl }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(M\_cl[}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{cluster)])}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(tz\_cluster) }\SpecialCharTok{/}\NormalTok{ m\_M\_cl}
\NormalTok{e\_cl }\OtherTok{\textless{}{-}}\NormalTok{ tz\_cluster }\SpecialCharTok{{-}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ M\_cl[}\FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{cluster))]}
\NormalTok{S2e }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(e\_cl)}
\FunctionTok{print}\NormalTok{(se\_mz\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(fpc }\SpecialCharTok{*} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ m\_M\_cl}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ S2e }\SpecialCharTok{/}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 12.39371
\end{verbatim}

The ratio estimate can also be computed with function \texttt{svymean} of package \textbf{survey}, which also provides an estimate of the standard error of the estimated mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_SIC }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cluster, }\AttributeTok{probs =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_SIC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 70.319 12.394
\end{verbatim}

\hypertarget{StratifiedCl}{%
\section{Stratified cluster random sampling}\label{StratifiedCl}}

The basic sampling designs stratified random sampling (Chapter \ref{STSI}) and cluster random sampling can be combined into stratified cluster random sampling\index{Stratified random sampling!stratified cluster random sampling}. So, instead of selecting simple random samples from the strata, within each stratum clusters are randomly selected. Figure \ref{fig:STCl} shows a stratified cluster random sample from Voorst. The strata consist of three 2 km \(\times\) 1 km zones, obtained by joining two neighbouring 1 km \(\times\) 1 km zones (Figure \ref{fig:ClVoorst}). The clusters are the same as before, i.e.~E-W oriented transects within 1 km \(\times\) 1 km zones, with an inter-unit spacing of 100 m. Within each stratum two times a cluster is selected by ppswr. The stratification avoids the clustering of the selected transects in one part of the study area. Compared to (unstratified) cluster random sampling, the geographical spreading of the clusters is improved, which may lead to an increase of the precision of the estimated population mean. In Figure \ref{fig:STCl} in the most western stratum the two selected transects are in the same 1 km \(\times\) 1 km zone. The alternative would be to use the six zones as strata, leading to an improved spreading of the clusters, but there is also a downside with this design, see Exercise 3. Note that the selection probabilities are now equal to

\begin{equation}
p_{jh}= M_j/M_h \;,
\label{eq:drawbySTSICl}
\end{equation}
with \(M_h\) the total number of population units of stratum \(h\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdVoorst}\SpecialCharTok{$}\NormalTok{zone\_stratum }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{zone)}
\FunctionTok{levels}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{zone\_stratum) }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{), }\AttributeTok{each =} \DecValTok{2}\NormalTok{)}
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{324}\NormalTok{)}
\NormalTok{stratumlabels }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{zone\_stratum)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) \{}
\NormalTok{  grd\_h }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{zone\_stratum }\SpecialCharTok{==}\NormalTok{ stratumlabels[i], ]}
\NormalTok{  mysample\_h }\OtherTok{\textless{}{-}} \FunctionTok{cl\_ppswr}\NormalTok{(}\AttributeTok{sframe =}\NormalTok{ grd\_h, }\AttributeTok{n =}\NormalTok{ n\_h[i])}
\NormalTok{  mysample }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysample, mysample\_h)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/STCl-1} 

}

\caption{Stratified cluster random sample from Voorst, with three strata. From each stratum two times a cluster is selected by ppswr.}\label{fig:STCl}
\end{figure}

The population mean is estimated by first estimating the stratum means using Equation \eqref{eq:EstMeanCl} at the level of the strata, followed by computing the weighted average of the estimated stratum means using Equation \eqref{eq:HTMeanSTSI2}. The variance of the estimator of the population mean is estimated in the same way, by first estimating the variance of the estimator of the stratum means using Equations \eqref{eq:VarEstMeanCl} and \eqref{eq:S2EstMeanCl} at the level of the strata, followed by computing the weighted average of the estimated variances of the estimated stratum means (Equation \eqref{eq:EstVarMeanSTSI}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{strata\_size }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(zone\_stratum) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{M\_h =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{w\_h =}\NormalTok{ M\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(M\_h))}
\NormalTok{est }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(zone\_stratum, cldraw) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz\_cl =} \FunctionTok{mean}\NormalTok{(z), }\AttributeTok{.groups =} \StringTok{"drop\_last"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz\_h =} \FunctionTok{mean}\NormalTok{(mz\_cl),}
            \AttributeTok{v\_mz\_h =} \FunctionTok{var}\NormalTok{(mz\_cl) }\SpecialCharTok{/} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(strata\_size, }\AttributeTok{by =} \StringTok{"zone\_stratum"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mz\_h),}
            \AttributeTok{se\_mz =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_mz\_h)))}
\end{Highlighting}
\end{Shaded}

The estimated mean equals 82.8 g kg\textsuperscript{-1}, and the estimated standard error equals 4.7 g kg\textsuperscript{-1}. The same estimates are obtained with function \texttt{svymean}. Weights for the clusters are computed as before, but now at the level of the strata. Note argument \texttt{nest\ =\ TRUE}, which means that the clusters are nested within the strata.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ strata\_size}\SpecialCharTok{$}\NormalTok{M\_h[mysample}\SpecialCharTok{$}\NormalTok{zone\_stratum] }\SpecialCharTok{/}
\NormalTok{  (M\_cl[mysample}\SpecialCharTok{$}\NormalTok{cluster] }\SpecialCharTok{*}\NormalTok{ n\_h[mysample}\SpecialCharTok{$}\NormalTok{zone\_stratum])}
\NormalTok{design\_strcluster }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ cldraw, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ zone\_stratum,}
  \AttributeTok{weights =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weights, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{nest =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_strcluster)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 82.796 4.6737
\end{verbatim}

\hypertarget{exercises-10}{%
\subsubsection*{Exercises}\label{exercises-10}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Why is it attractive in stratified random cluster sampling to select at least two clusters per stratum?
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5231600 279.4    9368568 500.4   9368568  500.4
Vcells 25554775 195.0   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{Twostage}{%
\chapter{Two-stage cluster random sampling}\label{Twostage}}

As opposed to cluster random sampling in which all population units of a cluster are observed (Chapter \ref{Cl}), in two-stage cluster random sampling\index{Two-stage cluster random sampling} not all units of the selected clusters are observed, but only some of them. In two-stage cluster random sampling the clusters will generally be contiguous groups of units, for instance all points in a map polygon (the polygons on the map are the clusters), whereas in single-stage cluster random sampling the clusters generally are non-contiguous. The units to be observed are selected by random subsampling of the randomly selected clusters. In two-stage cluster sampling the clusters are commonly referred to as primary sampling units\index{Primary sampling unit} (PSUs) and the units selected in the second stage as the secondary sampling units\index{Secondary sampling unit} (SSUs).

As with cluster random sampling, two-stage cluster random sampling may lead to a strong spatial clustering of the selected population units in the study area. This may save considerable time for fieldwork, and more population units can be observed for the same budget. However, due to the spatial clustering the estimates will generally be less precise compared to samples of the same size selected by a design that leads to a much better spreading of the sampling units throughout the study area, such as systematic random sampling.

In two-stage cluster random sampling in principle any type of sampling design can be used at the two stages, leading to numerous combinations. An example is (SI,SI), in which both PSUs and SSUs are selected by simple random sampling.

Commonly the PSUs have unequal size, i.e.~the number of SSUs (finite population) or the area (infinite population) are not equal for all PSUs. Think for instance of the agricultural fields, forest stands, lakes, river sections, etc. in an area. If the PSUs are of unequal size, then PSUs can best be selected with probabilities proportional to their size (pps). Recall that in (one-stage) cluster random sampling I also recommended to select the clusters with probabilities proportional to their size, see Chapter \ref{Cl}. If the total of the study variable of a PSU is proportional to its size, then pps sampling leads to more precise estimates compared to simple random sampling of PSUs. Also, with pps sampling of PSUs the estimation of means or totals and of their sampling variances is much simpler compared to selection with equal probabilities. Implementation of selection with probabilities proportional to size is easiest when units are replaced (pps with replacement, ppswr)\index{pps sampling!with replacement (ppswr)}. This implies that a PSU might be selected more than once, especially if the total number of PSUs in the population is small compared to the number of PSU draws (large sampling fraction in first stage).

Using a list as a sampling frame, the following algorithm can be used to select \(n\) times a PSU by ppswr from a total of \(N\) PSUs in the population:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select randomly one SSU from the list with \(M=\sum_{j=1}^N M_j\) SSUs (\(M_j\) is the number of SSUs of PSU \(j\)), and determine the PSU of the selected SSU.\\
\item
  Repeat step 1 until \(n\) selections have been made.
\end{enumerate}

In the first stage a SSU is selected in order to select a PSU. This may seem unnecessarily complicated. The reason for this is that this procedure automatically adjusts for the size of the PSUs (number of SSUs within a PSU), i.e.~a PSU is selected with probability proportional to its size. In the second stage, a pre-determined number of SSUs, \(m_{j}\), is selected every time PSU \(j\) is selected.

Note that the SSU selected in the first step of the two algorithms primarily serves to identify the PSU, but these SSUs can also be used as selected SSUs.

The selection of a two-stage cluster random sample is illustrated again with Voorst. Twenty-four 0.5 km squares are constructed that serve as PSUs.

\begin{rmdnote}
Due to built-up areas, roads, etc., the PSUs in Voorst have unequal size, i.e.~the number of SSUs (points in our case) within the PSUs varies among the PSUs.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cell\_size }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{w }\OtherTok{\textless{}{-}} \DecValTok{500} \CommentTok{\#width of zones}
\NormalTok{grdVoorst }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{zone\_s1 =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{findInterval}\NormalTok{(}\FunctionTok{min}\NormalTok{(s1) }\SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{:}\DecValTok{11} \SpecialCharTok{*}\NormalTok{ w }\SpecialCharTok{+} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ cell\_size),}
           \AttributeTok{zone\_s2  =}\NormalTok{ s2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{findInterval}\NormalTok{(}\FunctionTok{min}\NormalTok{(s2) }\SpecialCharTok{+}\NormalTok{ w }\SpecialCharTok{+} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ cell\_size),}
           \AttributeTok{psu =} \FunctionTok{str\_c}\NormalTok{(zone\_s1, zone\_s2, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In the next code chunk a function is defined to select a two-stage cluster random sample from an infinite population, discretised by finite number of points (centres of grid cells).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{twostage }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(sframe, psu, n, m) \{}
\NormalTok{  units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(sframe), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  mypsusample }\OtherTok{\textless{}{-}}\NormalTok{ sframe[units, psu]}
\NormalTok{  ssunits }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (psunit }\ControlFlowTok{in}\NormalTok{ mypsusample) \{}
\NormalTok{    ssunit }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}
      \AttributeTok{x =} \FunctionTok{which}\NormalTok{(sframe[, psu] }\SpecialCharTok{==}\NormalTok{ psunit), }\AttributeTok{size =}\NormalTok{ m, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    ssunits }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(ssunits, ssunit)}
\NormalTok{  \}}
\NormalTok{  psudraw }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n), }\AttributeTok{each =}\NormalTok{ m)}
\NormalTok{  mysample }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(ssunits, sframe[ssunits, ], psudraw)}
\NormalTok{  mysample}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note that both the PSUs and the SSUs are selected with replacement. If a grid cell centre is selected, one point is selected fully randomly from that grid cell. This is done by shifting the centre of the grid cell to a random point within the selected grid cell with function \texttt{jitter}, see code chunk hereafter. In every grid cell there is an infinite number of points, so we must select the grid cell centres with replacement. If a grid cell is selected more than once, more than one point is selected from the associated grid cell. Column \texttt{psudraw} in the output data frame of function \texttt{twostage} is needed in estimation because PSUs are selected with replacement. In case a PSU is selected more than once, multiple estimates of the mean of that PSU are used in estimation, see next section.

In the next code chunk function \texttt{twostage} is used to select four times a PSU (\(n=4\)), with probabilities proportional to size and with replacement (ppswr). The second stage sample size equals 10 for all PSUs (\(m_j=10,\; j = 1, \dots, N\)). These SSUs are selected by simple random sampling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{m }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{cell\_size }\OtherTok{\textless{}{-}} \DecValTok{25}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{twostage}\NormalTok{(}\AttributeTok{psu =} \StringTok{"psu"}\NormalTok{, }\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{m =}\NormalTok{ m) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{),}
         \AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:TwostageVoorst} shows the selected sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/TwostageVoorst-1} 

}

\caption{Two-stage cluster random sample from Voorst. PSUs are 0.5 km squares, built-up areas, roads, etc. excluded. Four times a PSU is selected by ppswr. Each time a PSU is selected, ten SSUs (points) are selected from that PSU by simple random sampling.}\label{fig:TwostageVoorst}
\end{figure}

\hypertarget{twostagesamplingestimators}{%
\section{Estimation of population parameters}\label{twostagesamplingestimators}}

The population total can be estimated by substituting the estimated cluster (PSU) totals in Equation \eqref{eq:EstTotalCl}. This yields the following estimator for the population total:

\begin{equation}
\hat{t}(z) = \frac{M}{n} \sum_{j \in \mathcal{S}} \frac{\hat{t}_{j}(z)}{M_{j}} = \frac{M}{n} \sum_{j \in \mathcal{S}} \hat{\bar{z}}_{j} \;,
\label{eq:EstTotalTwostage}
\end{equation}

where \(n\) is the number of PSU selections and \(M_{j}\) is the total number of SSUs in PSU \(j\). This shows that the mean of cluster \(j\), \(\bar{z}_j\), is replaced by the estimated mean of PSU \(j\), \(\hat{\bar{z}}_j\). Dividing this estimator by the total number of population units \(M\) gives the pwr estimator of the population mean:

\begin{equation}
\hat{\bar{\bar{z}}}=
\frac{1}{n}\sum\limits_{j \in \mathcal{S}}\hat{\bar{z}}_{j} \;,
\label{eq:EstMeanTwostage}
\end{equation}

with \(\hat{\bar{z}}_{j}\) the estimated mean of the PSU \(j\). With simple random sampling of SSUs this mean can be estimated by the sample mean of this PSU. Note the two bars in \(\hat{\bar{\bar{z}}}\), indicating that the population mean is estimated as the mean of estimated PSU means. When \(m_j\) is equal for all PSUs the sampling design is self-weighting\index{Self-weighting sampling design}, i.e.~the average of \(z\) over all selected SSUs is an unbiased estimator of the population mean.

For an infinite population of points the population total is estimated by multiplying the estimated population mean (Equation \eqref{eq:EstMeanTwostage}) by the area of the study area.

The sampling variance of the estimator of the mean with two-stage cluster random sampling (PSUs selected with probabilities proportional to size with replacement, SSUs selected by simple random sampling (with replacement in case of finite populations), and \(m_j = m, \; j = 1, \dots, N\)) is equal to (\citet{coc77}, Equation (11.33)\footnote{Equation (11.33) in \citet{coc77} is the variance estimator for the estimator of the population total. In Exercise 5 you are asked to derive the variance estimator for the estimator of the population mean from this variance estimator.})

\begin{equation}
V(\hat{\bar{\bar{z}}}) = \frac{S^2_{\mathrm{b}}}{n} + \frac{S^2_{\mathrm{w}}}{n\;m} \;,
\label{eq:TrueVarEstMeanTwostage}
\end{equation}

with

\begin{equation}
S^2_{\mathrm{b}}=\sum_{j=1}^N p_j\left(\bar{z}_j-\bar{z}\right)^2
\label{eq:PooledBetweenClusterVariance}
\end{equation}

and

\begin{equation}
S^2_{\mathrm{w}}=\sum_{j=1}^N p_j S^2_j \;,
\label{eq:PooledWithinClusterVariance}
\end{equation}

with \(N\) the total number of PSUs in the population, \(p_j=M_j/M\) the draw-by-draw selection probability of PSU \(j\)\index{Draw-by-draw selection probability!of a primary sampling unit}, \(\bar{z}_j\) the mean of PSU \(j\), \(\bar{z}\) the population mean of \(z\), and \(S^2_j\) the variance of \(z\) within PSU \(j\):

\begin{equation}
S^2_j = \frac{1}{M_j} \sum_{k=1}^{M_j} (z_{kj}-\bar{z}_j)^2 \;.
\label{eq:WithinClusterVariance}
\end{equation}

\begin{rmdnote}
The first term of Equation \eqref{eq:TrueVarEstMeanTwostage} is equal to the variance of Equation \eqref{eq:TrueVarEstMeanCl}. This variance component accounts for the variance of the true PSU means within the population. The second variance component quantifies our additional uncertainty about the population mean, as we do not observe all SSUs of the selected PSUs, but only a subset (sample) of these units.
\end{rmdnote}

The sampling variance of the estimator of the population mean can simply be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{\bar{z}}}\right)=\frac{\widehat{S^2}(\hat{\bar{z}})}{n}  \;,
\label{eq:VarEstMeanTwostage}
\end{equation}

with \(\widehat{S^2}(\hat{\bar{z}})\) the estimated variance of the \emph{estimated} PSU means:

\begin{equation}
\widehat{S^2}(\hat{\bar{z}}) = \frac{1}{n-1}\sum_{j \in \mathcal{S}}(\hat{\bar{z}}_{j}-\hat{\bar{\bar{z}}})^2 \;,
\label{eq:S2psuMeans}
\end{equation}

with \(\hat{\bar{z}}_{j}\) the estimated mean of PSU \(j\) and \(\hat{\bar{\bar{z}}}\) the estimated population mean (Equation \eqref{eq:EstMeanTwostage}).

\begin{rmdnote}
Neither the sizes of the PSUs, \(M_j\), nor the secondary sample sizes \(m_{j}\) occur in Equations \eqref{eq:VarEstMeanTwostage} and \eqref{eq:S2psuMeans}. This simplicity is due to the fact that the PSUs are selected with replacement and with probabilities proportional to their size. The effect of the secondary sample sizes on the variance is implicitly accounted for. To understand this, note that the larger \(m_{j}\), the less variable \(\hat{\bar{z}}_{j}\), and the smaller its contribution to the variance.
\end{rmdnote}

Let us assume a linear model for the total costs: \(C = c_0 + c_1n + c_2nm\), with \(c_0\) the fixed costs, \(c_1\) the costs per PSU, and \(c_2\) the costs per SSU. We want to minimise the total costs, under the constraint that the variance of the estimator of the population mean may not exceed \(V_{\mathrm{max}}\). The total costs can then be minimised by selecting \citep{gru06}

\begin{equation}
n=\frac{1}{V_{\mathrm{max}}}\left(S_{\mathrm{w}}S_{\mathrm{b}}\sqrt{\frac{c_2}{c_1}}+S^2_{\mathrm{b}}\right)
\label{eq:nopt}
\end{equation}

PSUs and

\begin{equation}
m=\frac{S_{\mathrm{w}}}{S_{\mathrm{b}}}\sqrt{\frac{c_1}{c_2}}
\label{eq:mopt}
\end{equation}

SSUs per PSU.

Conversely, given a budget \(C_{\mathrm{max}}\), the optimal number of PSU selections\index{Optimal sample size in two-stage cluster random sampling} can be computed with \citep{gru06}

\begin{equation}
n=\frac{C_{\mathrm{max}}S_{\mathrm{b}}}{S_{\mathrm{w}}\sqrt{c_1c_2}+S_{\mathrm{b}}c_1}\;,
\label{eq:nopt2}
\end{equation}

and \(m\) as above.

In \textbf{R} the population mean and the sampling variance of the estimator of the mean can be estimated as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{est }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(psudraw) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz\_psu =} \FunctionTok{mean}\NormalTok{(z)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mz =} \FunctionTok{mean}\NormalTok{(mz\_psu),}
            \AttributeTok{se\_mz =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(mz\_psu) }\SpecialCharTok{/} \FunctionTok{n}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

The estimated mean equals 48.6 g kg\textsuperscript{-1}, and the estimated standard error equals 0.0 g kg\textsuperscript{-1}. The sampling design is self-weighting, and so the estimated mean is equal to the sample mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 48.55792
\end{verbatim}

The same estimate is obtained with functions \texttt{svydesign} and \texttt{svymean} of package \textbf{survey} \citep{Lumley2020}. The estimator of the population total can be written as a weighted sum of the observations with all weights equal to \(M/(n\;m)\). These weights are passed to function \texttt{svydesign} with argument \texttt{weight}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ M }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*}\NormalTok{ m)}
\NormalTok{design\_2stage }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ psudraw }\SpecialCharTok{+}\NormalTok{ ssunits, }\AttributeTok{weight =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weights, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_2stage, }\AttributeTok{deff =} \StringTok{"replace"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE DEff
z 48.558  0.000    0
\end{verbatim}

Similar to (one-stage) cluster random sampling the estimated design effect\index{Design effect} is much larger than 1.

A confidence interval estimate of the population mean can be computed with method \texttt{confint}. The number of degrees of freedom equals the number of PSU draws minus 1.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confint}\NormalTok{(}\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_2stage, }\AttributeTok{df =} \FunctionTok{degf}\NormalTok{(design\_2stage), }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     2.5 %   97.5 %
z 48.55792 48.55792
\end{verbatim}

Figure \ref{fig:SamplingDistributionTwostage} shows the approximated sampling distribution of the pwr estimator of the mean soil organic matter (SOM) concentration with two-stage cluster random sampling and of the \(\pi\) estimator with simple random sampling from Voorst, obtained by repeating the random sampling with each design and estimation 10,000 times. For simple random sampling the sample size is equal to \(n \times m\).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionTwostage-1} 

}

\caption{Approximated sampling distribution of the pwr estimator of the mean SOM concentration (g kg\textsuperscript{-1}) in Voorst with two-stage cluster random sampling (Twostage) and of the \(\pi\) estimator with simple random sampling (SI). The sample size with both sampling designs is 40. In two-stage sampling four PSUs are selected by ppswr and ten SSUs (points) are selected per PSU draw by simple random sampling.}\label{fig:SamplingDistributionTwostage}
\end{figure}

The variance of the 10,000 means with two-stage cluster random sampling equals 179.6 (g kg\textsuperscript{-1})\textsuperscript{2}. This is considerably larger than with simple random sampling: 56.3 (g kg\textsuperscript{-1})\textsuperscript{2}. The average of the estimated variances with two-stage cluster random sampling equals 182.5 (g kg\textsuperscript{-1})\textsuperscript{2}.

Optimal sample sizes for two-stage cluster random sampling (ppswr in first stage, simple random sampling without replacement in second stage) can be computed with function \texttt{clusOpt2} of \textbf{R} package \textbf{PracTools} (\citet{PracTools}, \citet{Vaillant2018}). This function requires as input various variance measures, which can be computed with function \texttt{BW2stagePPS}, in case the study variable is known for the whole population, or estimated from a sample with function \texttt{BW2stagePPSe}. This is left as an exercise (Exercise 5).

\hypertarget{exercises-11}{%
\subsubsection*{Exercises}\label{exercises-11}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to compute for Voorst the true sampling variance of the estimator of the mean SOM concentration for two-stage cluster random sampling, PSUs selected by ppswr, \(n=4\), and \(m=10\), see Equation \eqref{eq:TrueVarEstMeanTwostage}.\\
\item
  Do you expect that the standard error of the estimator of the population mean with ten PSU draws (\(n=10\)) and four SSUs per PSU draw (\(m=4\)) is larger or smaller than with four PSU draws (\(n=4\)) and ten SSUs per PSU draw (\(m=10\))?\\
\item
  Compute the optimal sample sizes \(n\) and \(m\) for a maximum variance of the estimator of the mean SOM concentration of 1, \(c_1=2\) monetary units, and \(c_2=1\) monetary unit, see Equations \eqref{eq:nopt} and \eqref{eq:mopt}.\\
\item
  Compute the optimal sample sizes \(n\) and \(m\) for a budget of 100 monetary units, \(c_1=2\) monetary units, and \(c_2=1\) monetary unit, see Equations \eqref{eq:nopt2} and \eqref{eq:mopt}.\\
\item
  Use function \texttt{clusOpt2} of \textbf{R} package \textbf{PracTools} to compute optimal sample sizes given the precision requirement for the estimated population mean of Exercise 3 and given the budget of Exercise 4. First use function \texttt{BW2stagePPS} to compute the variance measures needed as input for function \texttt{clusOpt2}. Note that the precision requirement of function \texttt{clusOpt2} is the coefficient of variation of the estimated population total, i.e.~the standard deviation of the estimated population total divided by the population total. Compute this coefficient of variation from the maximum variance of the estimator of the population mean used in Exercise 3.\\
\item
  The variance of the estimator for the population total is \citep{coc77}:
  \begin{equation}
  V(\hat{t}(z)) = \frac{1}{n} \sum_{j=1}^N p_j\left(\frac{t_j(z)}{p_j}-t(z)\right)^2 + \frac{1}{n} \sum_{j=1}^N \frac{M_j^2 (1-f_{2j})S^2_j}{m_j p_j}  \;,
  \label{eq:EstVarTotalTwostageCochran}
  \end{equation}
  with \(\hat{t}(z)\) and \(t(z)\) the estimated and the true population total of \(z\), respectively, \(t_j(z)\) the total of PSU \(j\), and \(p_j = M_j/M\). Use \(m_j = m, \;j = 1, \dots, N\), and \(f_{2j}=0\), i.e.~sampling from infinite population, or sampling of SSUs within PSUs by simple random sampling \emph{with} replacement from finite population. Derive the variance of the estimator for the population mean, Equation \eqref{eq:TrueVarEstMeanTwostage}, from Equation \eqref{eq:EstVarTotalTwostageCochran}.
\end{enumerate}

\hypertarget{primary-sampling-units-selected-without-replacement}{%
\section{Primary sampling units selected without replacement}\label{primary-sampling-units-selected-without-replacement}}

Similar to cluster random sampling, we may prefer to select the PSUs without replacement\index{pps sampling!without replacement (ppswor)}. This leads to less strong spatial clustering of the sampling points, especially with large sampling fractions of PSUs. Sampling without replacement of PSUs can be done with function \texttt{UPpivotal} of package \textbf{sampling} \citep{Tille2016}, see Subsection \ref{pivotalmethod}. The second stage sample of SSUs is selected with function \texttt{strata} of the same package, using the PSUs as strata.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{M\_psu }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{6}
\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ M\_psu }\SpecialCharTok{/}\NormalTok{ M}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{sampleind }\OtherTok{\textless{}{-}} \FunctionTok{UPpivotal}\NormalTok{(}\AttributeTok{pik =}\NormalTok{ pi, }\AttributeTok{eps =} \FloatTok{1e{-}6}\NormalTok{)}
\NormalTok{psus }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{psu))}
\NormalTok{sampledpsus }\OtherTok{\textless{}{-}}\NormalTok{ psus[sampleind }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{mysample\_stage1 }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{psu }\SpecialCharTok{\%in\%}\NormalTok{ sampledpsus, ]}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(mysample\_stage1, }\AttributeTok{stratanames =} \StringTok{"psu"}\NormalTok{,}
  \AttributeTok{size =} \FunctionTok{rep}\NormalTok{(m, n), }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(mysample\_stage1, units)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{ssunits }\OtherTok{\textless{}{-}}\NormalTok{ units}\SpecialCharTok{$}\NormalTok{ID\_unit}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ m }\SpecialCharTok{/}\NormalTok{ M}
\FunctionTok{print}\NormalTok{(mean\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi) }\SpecialCharTok{/}\NormalTok{ M)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 100.039
\end{verbatim}

The population mean can be estimated with function \texttt{svymean} of package \textbf{survey}. To estimate the variance, a simple solution is to treat the two-stage cluster random sample as a pps sample \emph{with replacement}, so that variance can be estimated with Equation \eqref{eq:VarEstMeanTwostage}. With small sampling fractions of PSUs the overestimation of the variance is negligible. With larger sampling fractions Brewer's method is recommended, see \citet{Berger2004} (option 2)\index{Brewer's variance estimator}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc1 }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ M\_psu[mysample}\SpecialCharTok{$}\NormalTok{psu] }\SpecialCharTok{/}\NormalTok{ M}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc2 }\OtherTok{\textless{}{-}}\NormalTok{ m }\SpecialCharTok{/}\NormalTok{ M\_psu[mysample}\SpecialCharTok{$}\NormalTok{psu]}
\NormalTok{design\_2stageppswor }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ psu }\SpecialCharTok{+}\NormalTok{ ssunits, }\AttributeTok{data =}\NormalTok{ mysample,}
  \AttributeTok{pps =} \StringTok{"brewer"}\NormalTok{, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc1 }\SpecialCharTok{+}\NormalTok{ fpc2)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_2stageppswor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 100.04 19.883
\end{verbatim}

\hypertarget{TwostageSISI}{%
\section{Simple random sampling of primary sampling units}\label{TwostageSISI}}

Suppose the PSUs are for some reason not selected with probabilities proportional to their size, but by simple random sampling without replacement. The inclusion probabilities of the PSUs then equal \(\pi_j=n/N,\; j = 1, \dots, N\), and the population total can be estimated by (compare with Equation \eqref{eq:EstTotalClEqual})

\begin{equation}
\hat{t}(z) =  \sum_{j=1}^n \frac{\hat{t}_j(z)}{\pi_j} = \frac{N}{n} \sum_{j=1}^n \hat{t}_j(z)\;,
\label{eq:EstTotalTwostageEqual}
\end{equation}

with \(\hat{t}_j(z)\) an estimator of the total of PSU \(j\). The population mean can be estimated by dividing this estimator by the population size \(M\).

Alternatively, we may estimate the population mean by dividing the estimate of the population total by the \emph{estimated} population size. The population size can be estimated by the \(\pi\) estimator, see Equation \eqref{eq:EstPopulatonSizeClEqual}. The \(\pi\) estimator and the ratio estimator are equal when the PSUs are selected by ppswr, but not so when the PSUs of different size are selected with equal probabilities. This is shown below. First, a sample is selected by selecting both PSUs and SSUs by simple random sampling without replacement.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{psus }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{psu))}
\NormalTok{ids\_psu }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{length}\NormalTok{(psus), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{sampledpsus }\OtherTok{\textless{}{-}}\NormalTok{ psus[ids\_psu]}
\NormalTok{mysample\_stage1 }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{psu }\SpecialCharTok{\%in\%}\NormalTok{ sampledpsus, ]}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(mysample\_stage1, }\AttributeTok{stratanames =} \StringTok{"psu"}\NormalTok{,}
  \AttributeTok{size =} \FunctionTok{rep}\NormalTok{(m, n), }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(mysample\_stage1, units)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{ssunits }\OtherTok{\textless{}{-}}\NormalTok{ units}\SpecialCharTok{$}\NormalTok{ID\_unit}
\end{Highlighting}
\end{Shaded}

The population mean is estimated by the \(\pi\) estimator and the ratio estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{psu))}
\NormalTok{M\_psu }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{pi\_psu }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{pi\_ssu }\OtherTok{\textless{}{-}}\NormalTok{ m }\SpecialCharTok{/}\NormalTok{ M\_psu[mysample}\SpecialCharTok{$}\NormalTok{psu]}
\NormalTok{est }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pi =}\NormalTok{ pi\_psu }\SpecialCharTok{*}\NormalTok{ pi\_ssu,}
         \AttributeTok{z\_piexpanded =}\NormalTok{ z }\SpecialCharTok{/}\NormalTok{ pi) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{tz\_HT =} \FunctionTok{sum}\NormalTok{(z\_piexpanded),}
            \AttributeTok{mz\_HT =}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M,}
            \AttributeTok{M\_HT =} \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi),}
            \AttributeTok{mz\_ratio =}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M\_HT)}
\end{Highlighting}
\end{Shaded}

The \(\pi\) estimate equals 79.0 g kg\textsuperscript{-1}, and the ratio estimate equals Inf g kg\textsuperscript{-1}. The \(\pi\) estimate of the population mean can also be computed by first estimating totals of PSUs, see Equation \eqref{eq:EstTotalTwostageEqual}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tz\_psu }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ pi\_ssu, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{FUN =}\NormalTok{ sum)}
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(tz\_psu }\SpecialCharTok{/}\NormalTok{ pi\_psu)}
\NormalTok{(mz\_HT }\OtherTok{\textless{}{-}}\NormalTok{ tz\_HT }\SpecialCharTok{/}\NormalTok{ M)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 78.99646
\end{verbatim}

The variance of the \(\pi\) estimator of the population mean can be estimated by first estimating the variance of the estimator of the PSU totals:

\begin{equation}
\widehat{V}(\hat{t}(z)) = N^2\left(1-\frac{n}{N}\right)\frac{\widehat{S^2}(\hat{t}_i(z))}{n} \;,
\label{eq:EstVarTotalHTTwostageSI}
\end{equation}

and dividing this variance by the squared number of population units:

\begin{equation}
\widehat{V}(\hat{\bar{\bar{z}}}) = \frac{1}{M^2} \widehat{V}(\hat{t}(z)) \;,
\label{eq:EstVarMeanHTTwostageSI}
\end{equation}

as shown in the code chunk below (the final line computes the standard error).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fpc }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{v\_tz }\OtherTok{\textless{}{-}}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ fpc }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(tz\_psu) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{(se\_mz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(v\_tz }\SpecialCharTok{/}\NormalTok{ M}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9.467406
\end{verbatim}

The ratio estimator of the population mean and its standard error can be computed with function \texttt{svymean} of package \textbf{survey}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc1 }\OtherTok{\textless{}{-}}\NormalTok{ N}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc2 }\OtherTok{\textless{}{-}}\NormalTok{ M\_psu[mysample}\SpecialCharTok{$}\NormalTok{psu]}
\NormalTok{design\_2stage }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ psu }\SpecialCharTok{+}\NormalTok{ ssunits, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc1 }\SpecialCharTok{+}\NormalTok{ fpc2, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_2stage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean     SE
z 79.845 7.7341
\end{verbatim}

The estimated standard error of the ratio estimator is slightly smaller than the standard error of the \(\pi\) estimator.

\hypertarget{StratifiedTwostage}{%
\section{Stratified two-stage cluster random sampling}\label{StratifiedTwostage}}

The basic sampling designs stratified random sampling (Chapter \ref{STSI}) and two-stage cluster random sampling can be combined into stratified two-stage cluster random sampling\index{Stratified random sampling!stratified two-stage cluster random sampling}. Figure \ref{fig:STtwostage} shows a stratified two-stage cluster random sample from Voorst. The strata are groups of eight PSUs within 2 km \(\times\) 1 km blocks, as before in stratified cluster random sampling (Figure \ref{fig:ClVoorst}). The PSUs are 0.5 km squares (built-up areas, roads, etc. excluded), as before in (unstratified) two-stage cluster random sampling (Figure \ref{fig:TwostageVoorst}). Within each stratum two times a PSU is selected by ppswr, and every time a PSU is selected, six SSUs (points) are selected by simple random sampling. The stratification avoids the clustering of the selected PSUs in one part of the study area. Compared to (unstratified) two-stage cluster random sampling, the geographical spreading of the PSUs is somewhat improved, which may lead to an increase of the precision of the estimated population mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{m }\OtherTok{\textless{}{-}} \DecValTok{6}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{stratumlabels }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{zonestratum)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) \{}
\NormalTok{  grd\_h }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[grdVoorst}\SpecialCharTok{$}\NormalTok{zonestratum }\SpecialCharTok{==}\NormalTok{ stratumlabels[i], ]}
\NormalTok{  mysample\_h }\OtherTok{\textless{}{-}} \FunctionTok{twostage}\NormalTok{(}\AttributeTok{sframe =}\NormalTok{ grd\_h, }\AttributeTok{psu =} \StringTok{"psu"}\NormalTok{, }\AttributeTok{n =}\NormalTok{ n\_h[i], }\AttributeTok{m =}\NormalTok{ m)}
\NormalTok{  mysample }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysample, mysample\_h)}
\NormalTok{\}}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{s1 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{s1, }\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{s2 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{s2, }\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/STtwostage-1} 

}

\caption{Stratified two-stage random sample from Voorst. Strata are groups of eight PSUs (0.5 km squares) within 2 km $\times$ 1 km blocks. From each stratum two times a PSU is selected by ppswr, and six SSUs (points) are selected per PSU draw by simple random sampling.}\label{fig:STtwostage}
\end{figure}

The population mean can be estimated in much the same way as with stratified cluster random sampling. With function \texttt{svymean} this is an easy task.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{zonestratum,}
  \AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x) \{}
    \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(x))}
\NormalTok{    \})}
\NormalTok{M\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{zonestratum, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{w1 }\OtherTok{\textless{}{-}}\NormalTok{ N\_h[mysample}\SpecialCharTok{$}\NormalTok{zonestratum]}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{w2 }\OtherTok{\textless{}{-}}\NormalTok{ M\_h[mysample}\SpecialCharTok{$}\NormalTok{zonestratum]}
\NormalTok{design\_str2stage }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ psudraw }\SpecialCharTok{+}\NormalTok{ ssunits, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ zonestratum,}
  \AttributeTok{weights =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ w1 }\SpecialCharTok{+}\NormalTok{ w2, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{nest =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_str2stage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean SE
z 73.654  0
\end{verbatim}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5231189 279.4    9368568 500.4   9368568  500.4
Vcells 25557211 195.0   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{pps}{%
\chapter{Sampling with probabilities proportional to size}\label{pps}}

In simple random sampling the inclusion probabilities are equal for all population units. The advantage of this is simple and straightforward statistical inference. With equal inclusion probabilities the unweighted sample mean is an unbiased estimator of the spatial mean, i.e.~the sampling design is \emph{self-weighting}. However, in some situations equal probability sampling is not very efficient, i.e.~given the sample size the precision of the estimated mean or total will be relatively low. An example is the following. In order to estimate the total area of a given crop in a country, a raster of square cells of, for instance, 1 km \(\times\) 1 km is constructed and projected on the country. The square cells are the population units, and these units serve as the sampling units. Note that near the country border cells cross the border. Some of them may contain only a few hectares of the target population, the country under study. We do not want to select many of these squares with only a few hectares of the study area, as intuitively it is clear that this will result in a low precision of the estimated crop area. In such situation it can be more efficient to select units with probabilities proportional to the area of the target population within the squares, so that small units near the border have a smaller probability of being selected than interior units. Actually, the sampling units are not the square cells, but the pieces of land obtained by overlaying the cells and the GIS map of the country under study. As a consequence, the sampling units have unequal size. The sampling units of unequal size are selected by probabilities proportional to their size (pps).

\begin{rmdnote}
In Chapters \ref{Cl} and \ref{Twostage} pps sampling was already used to select clusters (primary sampling units) of population units. In this chapter the \emph{individual} population units (elementary sampling units) are selected with probabilities proportional to size.
\end{rmdnote}

If we have a GIS map of land use categories such as agriculture, built-up areas, water bodies, forests, etc., we may use this file to further adapt the selection probabilities. The crop will be grown in agricultural areas only, so we expect small crop areas in cells largely covered by non-agricultural land. As a size measure in computing the selection probabilities we may use the agricultural area (as represented in the GIS map) in the country under study within the cells. Note that size now has a different meaning. It does not refer to the area of the sampling units anymore, but to an ancillary variable that we expect to be related to the study variable, i.e.~the crop area. When the crop area per cell is proportional to the agricultural area per cell, then the precision of the estimated total area of the crop can be increased by selecting the cells with probabilities proportional to the agricultural area.

In this example the sampling units have an area. However, sampling with probabilities proportional to size is not restricted to areal sampling units\index{Areal sampling unit}, but can also be used for selecting points. If we have a map of an ancillary variable that is expected to be (linearly) related to the study variable, this ancillary variable can be used as a size measure. For instance, in areas where soil organic matter shows a positive (linear) relation with elevation, it can be efficient to select sampling points with a selection probability proportional to this environmental variable. The ancillary variable must be strictly positive for all points.

Sampling units can be selected with probabilities proportional to their size \emph{with} or \emph{without} replacement. This distinction is immaterial for infinite populations, as in sampling points from an area. pps sampling with replacement (ppswr) is much easier to implement than pps sampling without replacement (ppswor). The problem with ppswor is that after each draw the selected unit is removed from the sampling frame, so that the sum of the size variable over all remaining units changes and as a result the draw-by-draw selection probabilities of the units.

pps sampling is illustrated with the simulated map of poppy area per 5 km square in the province of Kandahar (Figure \ref{fig:mapsKandahar}). The first six rows of the data frame are shown below. Variable \texttt{poppy} is the study variable, variable \texttt{agri} is the agricultural area within the 5 km squares, used as a size variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdKandahar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 965 x 4
        s1       s2    poppy   agri
     <dbl>    <dbl>    <dbl>  <dbl>
 1 809232. 3407627.  0.905    65.7 
 2 814232. 3412627.  0.00453  15.6 
 3 794232. 3417627. 11.3      17.6 
 4 809232. 3417627.  0.110    14.0 
 5 814232. 3417627.  0.0344   22.2 
 6 819232. 3417627.  0.143    13.3 
 7 794232. 3422627.  3.66     34.1 
 8 799232. 3422627.  3.66      6.12
 9 809232. 3422627.  0.688    10.6 
10 814232. 3422627.  4.79    130.  
# ... with 955 more rows
\end{verbatim}

\hypertarget{ppswr}{%
\section{Probability-proportional-to-size sampling with replacement}\label{ppswr}}

In the first draw a sampling unit is selected with probability \(p_k = x_k/t(x)\), with \(x_k\) the size variable for unit \(k\) and \(t(x) = \sum_{k=1}^N x_k\) the population total of the size variable\index{pps sampling!with replacement (ppswr)}. The selected unit is then replaced, and these two steps are repeated \(n\) times. Note that with this sampling design population units can be selected more than once, especially with large sampling fractions\index{Sampling fraction} \(n/N\).

The population total can be estimated by the pwr estimator:

\begin{equation}
\hat{t}(z)=\frac{1}{n}\sum_{k \in \mathcal{S}}\frac{z_{k}}{p_{k}} \;,
\label{eq:HHTotalppswr}
\end{equation}

where \(n\) is the sample size (number of draws). The population mean can be estimated by the estimated population total divided by the population size \(N\). With independent draws the sampling variance of the estimator of the population total can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{t}(z)\right)=
\frac{1}{\,n\,(n-1)}\sum_{k \in \mathcal{S}}\left( \frac{z_{k}}{p_{k}}-\hat{t}(z)\right)^{2} \;.
\label{eq:VarHHTotalppswr}
\end{equation}

The sampling variance of the estimator of the mean can be estimated by the variance of the estimator of the total divided by \(N^2\).

As a first step I check whether the size variable is strictly positive in our case study of Kandahar. The minimum equals 0.307 m\textsuperscript{2}, so this is the case. If there are values equal to or smaller than 0, these values must be replaced by a small number, so that all units have a positive probability of being selected. Then the draw-by-draw selection probabilities are computed, and the sample is selected using function \texttt{sample}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdKandahar}\SpecialCharTok{$}\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ grdKandahar}\SpecialCharTok{$}\NormalTok{agri }\SpecialCharTok{/}  \FunctionTok{sum}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdKandahar)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ grdKandahar}\SpecialCharTok{$}\NormalTok{p)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdKandahar[units, ]}
\end{Highlighting}
\end{Shaded}

\begin{rmdnote}
To select the units, computing the selection probabilities is not strictly needed. Exactly the same units are selected when the agricultural area within the units (variable \texttt{agri} in the data frame) is used in argument \texttt{prob} of \texttt{sample}.
\end{rmdnote}

Four units are selected twice.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_frq }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(units) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{data.frame}\NormalTok{()}
\FunctionTok{print}\NormalTok{(table\_frq[table\_frq}\SpecialCharTok{$}\NormalTok{Freq }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   units Freq
9    278    2
13   334    2
14   336    2
24   439    2
\end{verbatim}

Figure \ref{fig:ppswrKandahar} shows the selected sampling units, plotted on a map of the agricultural area within the units which is used as a size variable.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ppswrKandahar-1} 

}

\caption{Sample of size 40 from Kandahar, selected with probabilities proportional to agricultural area with replacement. Four units are selected twice, so that the number of distinct units is 36.}\label{fig:ppswrKandahar}
\end{figure}

The next code chunk shows how the population total of the poppy area can be estimated, using Equation \eqref{eq:HHTotalppswr}, as well as the standard error of the estimator of the population total (square root of estimator of Equation \eqref{eq:VarHHTotalppswr}). As a first step the observations are inflated (expanded) through division of the observations by the selection probabilities of the corresponding units.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_pexpanded }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{p}
\NormalTok{tz }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(z\_pexpanded)}
\NormalTok{se\_tz }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(z\_pexpanded) }\SpecialCharTok{/}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

The estimated total equals 65,735 ha, with a standard error of 12,944. The same estimates are obtained with package \textbf{survey} \citep{Lumley2020}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{weight }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ (mysample}\SpecialCharTok{$}\NormalTok{p }\SpecialCharTok{*}\NormalTok{ n)}
\NormalTok{design\_ppswr }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{weights =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weight)}
\FunctionTok{svytotal}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, design\_ppswr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      total    SE
poppy 65735 12944
\end{verbatim}

In ppswr sampling a sampling unit can be selected more than once, especially with large sampling fractions \(n/N\). This may decrease the sampling efficiency. With large sampling fractions the alternative is pps sampling without replacement (ppswor), see next section.

The estimators of Equations \eqref{eq:HHTotalppswr} and \eqref{eq:VarHHTotalppswr} can also be used for infinite populations. For infinite populations the probability that a unit is selected more than once is zero.

\hypertarget{exercises-12}{%
\subsubsection*{Exercises}\label{exercises-12}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select a pps with replacement sample from Eastern Amazonia (\texttt{grdAmazonia} in package \textbf{sswr}) to estimate the population mean of aboveground biomass (AGB), using log-transformed short-wave infrared (SWIR2) as a size variable.

  \begin{itemize}
  \tightlist
  \item
    The correlation of AGB and lnSWIR2 is negative. The first step is to compute an appropriate size variable, so that the larger the size variable, the larger the selection probability is. Multiply the lnSWIR2 values by -1. Then add a small value, so that the size variable becomes strictly positive.
  \item
    Select in a for-loop 1,000 times a ppswr sample of size 100 (\(n=100\)), and estimate from each sample the population mean of AGB with the pwr estimator (Hansen-Hurwitz estimator) and its sampling variance. Compute the variance of the 1,000 estimated population means and the mean of the 1,000 estimated variances. Make a histogram of the 1,000 estimated means.
  \item
    Compute the true sampling variance of the \(\pi\) estimator with simple random sampling with replacement and the same sample size.
  \item
    Compute the gain in precision by the ratio of the variance of the estimator of the mean with simple random sampling to the variance with ppswr.
  \end{itemize}
\end{enumerate}

\hypertarget{ppswor}{%
\section{Probability-proportional-to-size sampling without replacement}\label{ppswor}}

The alternative to pps sampling with replacement (ppswr) is pps sampling without replacement (ppswor)\index{pps sampling!without replacement (ppswor)}. In ppswor sampling the \emph{inclusion} probabilities are proportional to a size variable, not the draw-by-draw selection probabilities as in ppswr. For this reason ppswor sampling is referred to as \(\pi\)ps sampling by \citet{sar92}. ppswor sampling starts with assigning target inclusion probabilities to all units in the population. With inclusion probabilities proportional to a size variable \(x\) the target inclusion probabilities are computed by \(\pi_k= n\;x_k/\sum_{j=1}^Nx_j,\; k = 1, \dots , N\).

\hypertarget{Systematicpps}{%
\subsection{Systematic pps sampling without replacement}\label{Systematicpps}}

Many algorithms are available for ppswor sampling, see \citet{Tille2006} for an overview. A simple, straightforward method is systematic ppswor sampling\index{Systematic ppswor sampling}. Two subtypes can be distinguished, systematic ppswor sampling with fixed frame order and systematic ppswor sampling with random frame order \citep{Rosen1997b}. Given some order of the units, the cumulative sum of the inclusion probabilities is computed. Each population unit is then associated with an interval of cumulative inclusion probabilities. The larger the inclusion probability of a unit, the wider the interval. Then a random number from the uniform distribution is drawn, which serves as the start of a 1-dimensional systematic sample of size \(n\) with an interval of 1. Finally, the units are determined for which the systematic random values are in the interval of cumulative inclusion probabilities, see Figure \ref{fig:sysppswor} for ten population units and a sample size of four. The units selected are 2, 5, 7, and 9. Note that the sum of the interval lengths equals the sample size. Further note that a unit cannot be selected more than once because the inclusion probabilities are \(<1\) and the sampling interval equals 1.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{20}\NormalTok{, }\AttributeTok{sd =} \DecValTok{5}\NormalTok{)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{inclusionprobabilities}\NormalTok{(x, n)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{id =} \FunctionTok{seq\_len}\NormalTok{(N), x, pi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   id        x        pi
1   1 13.55882 0.3027383
2   2 23.63731 0.5277684
3   3 15.83538 0.3535687
4   4 16.48162 0.3679978
5   5 20.63624 0.4607613
6   6 18.32529 0.4091630
7   7 16.50655 0.3685545
8   8 20.06336 0.4479702
9   9 22.94495 0.5123095
10 10 11.15957 0.2491684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cumsumpi }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{cumsum}\NormalTok{(pi))}
\NormalTok{start }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{1}\NormalTok{)}
\NormalTok{sys }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}\NormalTok{  start}
\FunctionTok{print}\NormalTok{(units }\OtherTok{\textless{}{-}} \FunctionTok{findInterval}\NormalTok{(sys, cumsumpi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2 5 7 9
\end{verbatim}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sysppswor-1} 

}

\caption{Systematic random sample along a line with unequal inclusion probabilities.}\label{fig:sysppswor}
\end{figure}

Sampling efficiency can be increased by ordering the units by the size variable (Figure \ref{fig:sysppsworsort}). With this design the third, fourth, fifth, and second unit in the original frame are selected, with sizes 15.8, 16.5, 20.6, and 23.6, respectively. Ordering the units by size leads to a large within-sample and a small between-sample variance of the size variable \(x\). If the study variable is proportional to the size variable, this results in a smaller sampling variance of the estimator of the mean of the study variable. A drawback of systematic ppswor sampling with fixed order is that no unbiased estimator of the sampling variance exists.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sysppsworsort-1} 

}

\caption{Systematic random sample along a line with unequal inclusion probabilities. Units are ordered by size.}\label{fig:sysppsworsort}
\end{figure}

A small simulation study is done next to see how much gain in precision can be achieved by ordering the units by size. A size variable \(x\) and a study variable \(z\) are simulated by drawing 1,000 values from a bivariate normal distribution with a correlation coefficient of 0.8. Function \texttt{mvrnorm} of package \textbf{MASS} \citep{VenablesRipley2002} is used for the simulation.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS)}
\NormalTok{rho }\OtherTok{\textless{}{-}} \FloatTok{0.8}
\NormalTok{mu1 }\OtherTok{\textless{}{-}} \DecValTok{10}\NormalTok{; sd1 }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{mu2 }\OtherTok{\textless{}{-}} \DecValTok{15}\NormalTok{; sd2 }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(mu1, mu2)}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \AttributeTok{data =} \FunctionTok{c}\NormalTok{(sd1}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\FunctionTok{rep}\NormalTok{(sd1 }\SpecialCharTok{*}\NormalTok{  sd2 }\SpecialCharTok{*}\NormalTok{  rho, }\DecValTok{2}\NormalTok{), sd2}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
  \AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{1000}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{mvrnorm}\NormalTok{(N, }\AttributeTok{mu =}\NormalTok{ mu, }\AttributeTok{Sigma =}\NormalTok{ sigma))}
\FunctionTok{names}\NormalTok{(dat) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"z"}\NormalTok{, }\StringTok{"x"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(dat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          z         x
1  9.462930  9.149784
2 12.605847 17.306046
3  7.892686 11.979986
4  7.945021 12.567608
5 11.004325 15.165744
6 10.369943 13.258177
\end{verbatim}

Twenty units are selected by systematic ppswor sampling with random order and ordered by size. This is repeated 10,000 times.

The standard deviation of the 10,000 estimated means with systematic ppswor sampling with random order is 0.336, and when ordered by size 0.321. So, a small gain in precision is achieved through ordering the units by size. For comparison I also computed the standard error for simple random sampling without replacement (SI) of the same size. The standard error with this basic sampling design is 0.424.

\hypertarget{pivotalmethod}{%
\subsection{The pivotal method}\label{pivotalmethod}}

Another interesting algorithm for ppswor sampling is the pivotal method\index{Pivotal method for ppswor sampling} \citep{Deville1998}. A nice adaptation of this algorithm, the local pivotal method, leading to samples with improved (geographical) spreading, is described in Section \ref{Spreaded}. In the pivotal method the \(N\)-vector with inclusion probabilities is successively updated to a vector with indicators. If the indicator value for sampling unit \(k\) becomes 1, then this sampling unit is selected, if it becomes 0, then it is not selected. The updating algorithm can be described as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select randomly two units \(k\) and \(l\) with \(0<\pi_k<1\) and \(0<\pi_l<1\).\\
\item
  If \(\pi_k + \pi_l < 1\) then update the probabilities by
\end{enumerate}

\begin{equation}
(\pi^{\prime}_k,\pi^{\prime}_l)=\left\{
\begin{array}{cc}
(0,\pi_k+\pi_l) & \;\;\;\text{with probability}\frac{\pi_l}{\pi_k+\pi_l} \\
(\pi_k+\pi_l,0) & \;\;\;\text{with probability}\frac{\pi_k}{\pi_k+\pi_l}
\end{array}
\right. \;,
\label{eq:algppswor1}
\end{equation}

and if \(\pi_k + \pi_l \geq 1\) update the probabilities by

\begin{equation}
(\pi^{\prime}_k,\pi^{\prime}_l)=\left\{
\begin{array}{cc}
(1,\pi_k+\pi_l-1) & \;\;\;\text{with probability}\frac{1-\pi_l}{2-(\pi_k+\pi_l)} \\
(\pi_k+\pi_l-1,1) & \;\;\;\text{with probability}\frac{1-\pi_k}{2-(\pi_k+\pi_l)}
\end{array}
\right.\;.
\label{eq:algppswor2}
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Replace (\(\pi_k,\pi_l\)) by (\(\pi^{\prime}_k,\pi^{\prime}_l\)), and repeat the first two steps until each population unit is either selected (inclusion probability equals 1) or not selected (inclusion probability equals 0).
\end{enumerate}

In words, when the sum of the inclusion probabilities is smaller than 1, the updated inclusion probability of one of the units will become 0, which means that this unit will not be sampled. The inclusion probability of the other unit will become the sum of the two inclusion probabilities, which means that the probability increases that this unit will be selected in one of the subsequent iterations. The probability of a unit of being excluded from the sample is proportional to the inclusion probability of the other unit, so that the larger the inclusion probability of the other unit, the larger the probability that it will not be selected.

When the sum of the inclusion probabilities of the two units is larger than or equal to 1, then one of the units is selected (updated inclusion probability is one), while the inclusion probability of the other unit is lowered by 1 minus the inclusion probability of the selected unit. The probability of being selected is proportional to the complement of the inclusion probability of the other unit. After the inclusion probability of a unit has been updated to either 0 or 1, this unit cannot be selected anymore in the next iteration.

With this ppswor design the population total can be estimated by the \(\pi\) estimator, Equation \eqref{eq:HTTotal}. The \(\pi\) estimator of the mean is simply obtained by dividing the estimator for the total by the population size \(N\).

\begin{rmdnote}
The inclusion probabilities \(\pi_k\) used in the \(\pi\) estimator are not the final probabilities obtained with the local pivotal method, which are either 0 or 1, but the initial inclusion probabilities.
\end{rmdnote}

An alternative estimator of the population mean is the ratio estimator, also known as the Hájek estimator\index{H$\text{{\'a}}$jek estimator}:

\begin{equation}
\hat{\bar{z}}_{\text{Hajek}}=\frac{\sum_{k \in \mathcal{S}} w_k z_k}{\sum_{k \in \mathcal{S}} w_k} \;,
\label{eq:HTTotalppsworHajek}
\end{equation}

with \(w_k = 1/\pi_k\). The denominator is an estimator of the population size \(N\). The Hájek estimator of the population total is obtained by multiplying the Hájek estimator of the mean with the population size \(N\). Recall that the ratio estimator of the population mean was presented before in the chapters on systematic random sampling (Equation \eqref{eq:RatioMeanSY}), cluster random sampling with simple random sampling of clusters (Equation \eqref{eq:EstMeanRatioClEqual}), and two-stage cluster random sampling with simple random sampling of PSUs. These sampling designs have in common that the sample size (for cluster random sampling the number of SSUs) is random.

Various functions in package \textbf{sampling} \citep{Tille2016} can be used to select a ppswor sample. In the code chunk below I use function \texttt{UPrandompivotal}. With this function the order of the population units is randomised before function \texttt{UPpivotal} is used. Argument \texttt{pi} is a numeric with the inclusion probabilities. These are computed with function \texttt{inclusionprobabilities}. Recall that \(\pi_k= n\;x_k/t(x)\). The sum of the inclusion probabilities should be equal to the sample size \(n\). Function \texttt{UPpivotal} returns a numeric of length \(N\) with elements 1 and 0, 1 if the unit is selected, 0 if it is not selected.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{size }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri }\SpecialCharTok{\textless{}} \FloatTok{1E{-}12}\NormalTok{, }\FloatTok{0.1}\NormalTok{, grdKandahar}\SpecialCharTok{$}\NormalTok{agri)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{inclusionprobabilities}\NormalTok{(size, n)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{sampleind }\OtherTok{\textless{}{-}} \FunctionTok{UPrandompivotal}\NormalTok{(}\AttributeTok{pik =}\NormalTok{ pi)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(grdKandahar[sampleind }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, ], }\AttributeTok{pi =}\NormalTok{ pi[sampleind }\SpecialCharTok{==} \DecValTok{1}\NormalTok{])}
\FunctionTok{nrow}\NormalTok{(mysample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 39
\end{verbatim}

As can be seen not 40 but only 39 units are selected. The reason is that function \texttt{UPrandompivotal} uses a very small number that can be set with argument \texttt{eps}. If the updated inclusion probability of a unit is larger than the complement of this small number \texttt{eps}, the unit is treated as being selected. The default value of \texttt{eps} is \(10^{-6}\). If we replace \texttt{sampleind\ ==\ 1} by \texttt{sampleind\ \textgreater{}\ 1\ -\ eps}, 40 units are selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eps }\OtherTok{\textless{}{-}} \FloatTok{1e{-}6}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
\NormalTok{  grdKandahar[sampleind }\SpecialCharTok{\textgreater{}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps, ], }\AttributeTok{pi =}\NormalTok{ pi[sampleind }\SpecialCharTok{\textgreater{}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps])}
\FunctionTok{nrow}\NormalTok{(mysample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40
\end{verbatim}

The total poppy area can be estimated from the ppswor sample by

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi)}
\NormalTok{tz\_Hajek }\OtherTok{\textless{}{-}}\NormalTok{ N }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pi)}
\end{Highlighting}
\end{Shaded}

The total poppy area as estimated with the \(\pi\) estimator equals 88,501 ha. The Hájek estimator results in a much smaller estimated total: 62,169 ha.

The \(\pi\) estimate can also be computed with function \texttt{svytotal} of package \textbf{survey}, which also provides an approximate estimate of the standard error. Various methods are implemented in function \texttt{svydesign} for approximating the standard error. These methods differ in the way the pairwise inclusion probabilities are approximated from the unit-wise inclusion probabilities. These approximated pairwise inclusion probabilities are then used in the \(\pi\) variance estimator or the Yates-Grundy variance estimator\index{Yates-Grundy variance estimator}. In the next code chunks Brewer's method\index{Brewer's variance estimator} is used, see option 2 of Brewer's method in \citet{Berger2004}, as well as Hartley-Rao's method\index{Hartley-Rao's variance estimator} for approximating the variance.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{design\_ppsworbrewer }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{pps =} \StringTok{"brewer"}\NormalTok{, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi)}
\FunctionTok{svytotal}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, design\_ppsworbrewer)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      total    SE
poppy 88501 14046
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2sum }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{pi}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{design\_ppsworhr }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{pps =} \FunctionTok{HR}\NormalTok{(p2sum), }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ pi)}
\FunctionTok{svytotal}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, design\_ppsworhr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      total    SE
poppy 88501 14900
\end{verbatim}

In package \textbf{samplingVarEst} \citep{samplingVarEst} also various functions are available for approximating the variance: \texttt{VE.Hajek.Total.NHT}, \texttt{VE.HT.Total.NHT}, and \texttt{VE.SYG.Total.NHT}. The first variance approximation is the Hájek-Rosén variance estimator\index{H$\text{{\'a}}$jek-Ros$\text{{\'e}}$n variance estimator}, see Equation (4.3) in \citet{Rosen1997b}. The latter two functions require the pairwise inclusion probabilities\index{Pairwise inclusion probability}, which can be estimated by function \texttt{Pkl.Hajek.s}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(samplingVarEst)}
\NormalTok{se\_tz\_Hajek }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{VE.Hajek.Total.NHT}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy, mysample}\SpecialCharTok{$}\NormalTok{pi))}
\NormalTok{pikl }\OtherTok{\textless{}{-}} \FunctionTok{Pkl.Hajek.s}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{pi)}
\NormalTok{se\_tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{VE.HT.Total.NHT}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy, mysample}\SpecialCharTok{$}\NormalTok{pi, pikl))}
\NormalTok{se\_tz\_SYG }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{VE.SYG.Total.NHT}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy, mysample}\SpecialCharTok{$}\NormalTok{pi, pikl))}
\end{Highlighting}
\end{Shaded}

The three approximated standard errors are 14,045,14,068, and 14,017 ha. The differences are small when related to the estimated total.

Figure \ref{fig:SamplingDistributionPps} shows the approximated sampling distribution of estimators of the total poppy area with ppswor sampling and simple random sampling without replacement of size 40, obtained by repeating the random sampling with each design and estimation 10,000 times. With the ppswor samples the total poppy area is estimated by the \(\pi\) estimator and the Hájek estimator. For each ppswor sample the variance of the \(\pi\) estimator is approximated by the Hájek-Rosén variance estimator (using function \texttt{VE.Hajek.Total.NHT} of package \textbf{samplingVarEst}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionPps-1} 

}

\caption{Approximated sampling distribution of the \(\pi\) estimator (ppswor.HT) and the Hájek estimator (ppswor.Hajek) of the total poppy area (ha) in Kandahar with ppswor sampling of size 40, and of the \(\pi\) estimator with simple random sampling without replacement (SI) of size 40.}\label{fig:SamplingDistributionPps}
\end{figure}

Sampling design ppswor in combination with the \(\pi\) estimator is clearly much more precise than simple random sampling. The standard deviation of the 10,000 \(\pi\) estimates of the total poppy area with ppswor equals 11,684 ha. The average of the square root of the Hájek-Rosén approximated variances equals 12,332 ha.

Interestingly, with ppswor sampling the variance of the 10,000 Hájek estimates is much larger than that of the \(\pi\) estimates. The standard deviation of the 10,000 Hájek estimates with ppswor sampling is about equal to that of the \(\pi\) estimates with simple random sampling: 31,234 and 33,178, respectively.

\hypertarget{exercises-13}{%
\subsubsection*{Exercises}\label{exercises-13}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A field with poppy was found outside Kandahar in a selected sampling unit crossing the boundary. Should this field be included in the sum of the poppy area of that sampling unit?\\
\item
  In another sampling unit a poppy field was encountered in Kandahar but in the area represented as non-agriculture in the GIS map. Should this field be included in the sum of that sampling unit?
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5238112 279.8    9368568 500.4   9368568  500.4
Vcells 25629263 195.6   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{BalancedSpreaded}{%
\chapter{Balanced and well-spread sampling}\label{BalancedSpreaded}}

In this chapter two related but fundamentally different sampling designs are described and illustrated. The similarity and difference are shortly outlined below, but hopefully will become more clear in following sections.

Roughly speaking, for a balanced sample the sample means of covariates are equal to the population means of these covariates. When the covariates are linearly related to the study variable, this may yield a more precise estimate of the population mean or total of the study variable.

A well-spread sample\index{Well-spread sample} is a sample with a large range of values for the covariates, from small to large values, but also including intermediate values. In more technical terms: the sampling units are well-spread along the axes spanned by the covariates. If the spatial coordinates are used as covariates (spreading variables), this results in samples that are well-spread in geographical space. Such samples are commonly referred to as spatially balanced samples, which is somewhat confusing, as the geographical spreading is not implemented through balancing on the geographical coordinates. On the other hand, the averages of the spatial coordinates of a sample well-spread in geographical space will be close to the population means of the coordinates. Therefore, the sample will be approximately balanced on the spatial coordinates \citep{Grafstrom2014}. The reverse is not true: with balanced sampling\index{Balanced sampling} the spreading of the sampling units in the space spanned by the balancing variables can be poor. A sample with all values of a covariate used in balancing near the population mean of that variable has a poor spreading along the covariate axis, but can still be perfectly balanced.

\hypertarget{Balanced}{%
\section{Balanced sampling}\label{Balanced}}

Balanced sampling is a sampling method that exploits one or more quantitative covariates that are related to the study variable. The idea behind balanced sampling is that, if we know the mean of the covariates, then the sampling efficiency can be increased by selecting a sample whose averages of the covariates must be equal to the population means of the covariates.

Let me illustrate balanced sampling with a small simulation study. The simulated population shown in Figure \ref{fig:simpleexample} shows a linear trend from West to East and besides a trend from South to North. Due to the West-East trend the simulated study variable \(z\) is correlated with the covariate Easting and, due to the South-North trend, also with the covariate Northing. To estimate the population mean of the simulated study variable, intuitively it is attractive to select a sample with an average of the Easting coordinate that is equal to the population mean of Easting (which is 10). Figure \ref{fig:simpleexample} (subfigure on the left) shows such a sample of size four; we say that the sample is `balanced' on the covariate Easting. The sample in the subfigure on the right is balanced on Easting as well as on Northing.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/simpleexample-1} 

}

\caption{Sample balanced on Easting (E) and on Easting and Northing (E and N).}\label{fig:simpleexample}
\end{figure}

\hypertarget{balanced-sample-versus-balanced-sampling-design}{%
\subsection{Balanced sample versus balanced sampling design}\label{balanced-sample-versus-balanced-sampling-design}}

We must distinguish a balanced \emph{sample} from a balanced sampling \emph{design}. A sampling design is balanced on a covariate \(x\) when \emph{all possible} samples that can be generated by the design are balanced on \(x\).

\begin{rmdnote}
Simple random sampling is not a balanced sampling design, because for many simple random samples the sample mean of the balancing variable \(x\) is not equal to the population mean of \(x\). Only the \emph{expectation} of the sample mean of \(x\), i.e.~the mean of the sample means obtained by selecting an infinite number of simple random samples, equals the population mean of \(x\).
\end{rmdnote}

Figure \ref{fig:scatterplotsqerror} shows for 1,000 simple random samples the squared error of the estimated population mean of the study variable \(z\) against the difference between the sample mean of balancing variable Easting and the population mean of Easting. Clearly, the larger the absolute value of the difference, the larger on average the squared error. So, to obtain a precise and accurate estimate of the population mean of \(z\), we better select samples with a difference close to 0.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/scatterplotsqerror-1} 

}

\caption{Squared error in the estimated population mean of \(z\) against the difference between the sample mean and the population mean of Easting, for 1,000 simple random samples of size four selected from the population shown in Figure \ref{fig:simpleexample}.}\label{fig:scatterplotsqerror}
\end{figure}

Using only Easting as a balancing variable reduces the sampling variance of the estimator of the mean substantially. Using Easting and Northing as balancing variables further reduces the sampling variance. See Table \ref{tab:tablebalanced}.

\begin{table}

\caption{\label{tab:tablebalanced}Sampling variance of the $\pi$ estimator of the mean for simple random sampling (SI) and balanced sampling of four units.}
\centering
\begin{tabular}[t]{llr}
\toprule
Sampling design & Balancing variables & Sampling variance\\
\midrule
SI & - & 39.70\\
Balanced & Easting & 14.40\\
Balanced & Easting and Northing & 9.77\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{unequal-inclusion-probabilities}{%
\subsection{Unequal inclusion probabilities}\label{unequal-inclusion-probabilities}}

Until now we have assumed that the inclusion probabilities of the population units are equal, but this is not a requirement for balanced sampling designs. A more general definition of a balanced sampling design is as follows. A sampling design is balanced on variable \(x\) when for all samples generated by the design the \(\pi\) estimate of the population total of \(x\) equals the population total of \(x\):

\begin{equation}
\sum_{k \in \mathcal{S}} \frac{x_k}{\pi_k}= \sum_{k=1}^{N} x_k \;.
\label{eq:generaldefinitionbalanced}
\end{equation}

Similar to the regression estimator\index{Regression estimator} explained in the next chapter (Subsection \ref{RegressionEstimator}), balanced sampling exploits the linear relation between the study variable and one or more covariates. When using the regression estimator this is done at the estimation stage. Balanced sampling does so at the sampling stage. For a single covariate the regression estimator of the population total equals (see Equation \eqref{eq:SimpleRegressionEstimatorSI})

\begin{equation}
\hat{t}_{\mathrm{regr}}(z) = \hat{t}_{\pi}(z) + \hat{b}\left(t(x) - \hat{t}_{\pi}(x)\right) \;,
\label{eq:RegressionEstimatoranydesign}
\end{equation}

with \(\hat{t}_{\pi}(z)\) and \(\hat{t}_{\pi}(x)\) the \(\pi\) estimators of the population total of the study variable \(z\) and the covariate \(x\), respectively, \(t(x)\) the population total of the covariate, and \(\hat{b}\) the estimated slope parameter (see hereafter). With a perfectly balanced sample the second term in the regression estimator, which adjusts the \(\pi\) estimator, equals zero.

Balanced samples can be selected with the cube algorithm\index{Cube algorithm for balanced sampling} of \citet{Deville2004}. The population total and mean can be estimated by the \(\pi\) estimator. The approximated variance of the \(\pi\) estimator of the population mean can be estimated by (\citet{Deville2005}, \citet{Grafstrom2013})

\begin{equation}
\widehat{V}(\hat{\bar{z}}) = \frac{1}{N^2}\frac{n}{n-p} \sum_{k \in \mathcal{S}} c_k \left(\frac{e_k}{\pi_k}\right)^2 \;,
\label{eq:approxvarianceBalanced}
\end{equation}

with \(p\) the number of balancing variables, \(c_k\) a weight for unit \(k\) (see hereafter), and \(e_k\) the residual of unit \(k\) given by

\begin{equation}
e_k = z_k - \mathbf{x}_k^{\text{T}}\hat{\mathbf{b}} \;,
\label{eq:residualsBalanced}
\end{equation}

with \(\mathbf{x}_k\) a vector of length \(p\) with the balancing variables for unit \(k\), and \(\hat{\mathbf{b}}\) the estimated population regression coefficients\index{Population regression coefficient}, given by

\begin{equation}
\hat{\mathbf{b}} = \left(\sum_{k \in \mathcal{S}} c_k \frac{\mathbf{x}_k}{\pi_k} \frac{\mathbf{x}_k}{\pi_k}^{\text{T}} \right)^{-1} \sum_{k \in \mathcal{S}} c_k \frac{\mathbf{x}_k}{\pi_k} \frac{z_k}{\pi_k} \;.
\label{eq:betasbalanced}
\end{equation}

Working this out for balanced sampling without replacement with equal inclusion probabilities, \(\pi_k = n/N,\; k = 1, \dots , N\), yields

\begin{equation}
\widehat{V}(\hat{\bar{z}}) = \frac{1}{n(n-p)} \sum_{k \in \mathcal{S}} c_k e_k^2 \;.
\label{eq:approxvarianceBalancedSI}
\end{equation}

\citet{Deville2005} give several formulas for computing the weights \(c_k\), one of which is \(c_k = (1-\pi_k)\).

Balanced sampling is now illustrated with aboveground biomass (AGB) data of Eastern Amazonia, see Figure \ref{fig:mapsAmazonia}. Log-transformed short-wave infrared radiation (lnSWIR2) is used as a balancing variable. The \texttt{samplecube} function of the \textbf{sampling} package \citep{Tille2016} implements the cube algorithm. Argument \texttt{X} of this function specifies the matrix of ancillary variables on which the sample must be balanced. The first column of this matrix is filled with ones, so that the sample size is fixed. To speed up the computations a 5 km \(\times\) 5 km subgrid of \texttt{grdAmazonia} is used.

\begin{rmdnote}
Recall that a sample is balanced on a covariate \(x\) if the \(\pi\) estimate of the population total of \(x\) is equal to the known true population total of \(x\) (Equation \eqref{eq:generaldefinitionbalanced}). If we know the total number of units in a population, \(N\), we can balance the sample on this known total using a constant with value 1 as a balancing variable. Only for samples of size \(n\) the \(\pi\) estimate of the total number of population units equals \(N\): \(\sum_{k \in \mathcal{S}} 1/\pi_k = N\) for \(|\mathcal{S}| = n\).
\end{rmdnote}

Equal inclusion probabilities are used, i.e.~for all population units the inclusion probability equals \(n/N\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{lnSWIR2 =} \FunctionTok{log}\NormalTok{(SWIR2))}
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{times =}\NormalTok{ N), grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, }\AttributeTok{times =}\NormalTok{ N)}
\NormalTok{sample\_ind }\OtherTok{\textless{}{-}} \FunctionTok{samplecube}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{pik =}\NormalTok{ pi, }\AttributeTok{comment =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{method =} \DecValTok{1}\NormalTok{)}
\NormalTok{eps }\OtherTok{\textless{}{-}} \FloatTok{1e{-}6}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(sample\_ind }\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps))}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units, ]}
\end{Highlighting}
\end{Shaded}

The population mean can be estimated by the sample mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB)}
\end{Highlighting}
\end{Shaded}

To estimate the variance a function is defined for estimating the population regression coefficients.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estimate\_b }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(z, X, c) \{}
\NormalTok{  cXX }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{data =} \DecValTok{0}\NormalTok{)}
\NormalTok{  cXz }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \DecValTok{1}\NormalTok{, }\AttributeTok{ncol =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{data =} \DecValTok{0}\NormalTok{)}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(z))) \{}
\NormalTok{    x }\OtherTok{\textless{}{-}}\NormalTok{ X[i, ]}
\NormalTok{    cXX\_i }\OtherTok{\textless{}{-}}\NormalTok{ c[i] }\SpecialCharTok{*}\NormalTok{ (x }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(x))}
\NormalTok{    cXX }\OtherTok{\textless{}{-}}\NormalTok{ cXX }\SpecialCharTok{+}\NormalTok{ cXX\_i}
\NormalTok{    cXz\_i }\OtherTok{\textless{}{-}}\NormalTok{ c[i] }\SpecialCharTok{*} \FunctionTok{t}\NormalTok{(x) }\SpecialCharTok{*}\NormalTok{ z[i]}
\NormalTok{    cXz }\OtherTok{\textless{}{-}}\NormalTok{ cXz }\SpecialCharTok{+}\NormalTok{ cXz\_i}
\NormalTok{  \}}
\NormalTok{  b }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(cXX, }\FunctionTok{t}\NormalTok{(cXz))}
  \FunctionTok{return}\NormalTok{(b)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The next code chunk shows how the estimated variance of the \(\pi\) estimator of the population mean can be computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, n)}
\NormalTok{c }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pi)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_b}\NormalTok{(}\AttributeTok{z =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{/}\NormalTok{ pi, }\AttributeTok{X =}\NormalTok{ X[units, ] }\SpecialCharTok{/}\NormalTok{ pi, }\AttributeTok{c =}\NormalTok{ c)}
\NormalTok{zpred }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ b}
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ zpred[units]}
\NormalTok{v\_tz }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \FunctionTok{ncol}\NormalTok{(X)) }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(c }\SpecialCharTok{*}\NormalTok{ (e }\SpecialCharTok{/}\NormalTok{ pi)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{v\_mz }\OtherTok{\textless{}{-}}\NormalTok{ v\_tz }\SpecialCharTok{/}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:BalancedSampleAmazonia} shows the selected balanced sample. Note the spatial clustering of some units. The estimated population mean (as estimated by the sample mean) of AGB equals 224.5 10\textsuperscript{9} kg ha\textsuperscript{-1}. The population mean of AGB equals 225.3 10\textsuperscript{9} kg ha\textsuperscript{-1}. The standard error of the estimated mean equals 6.1 10\textsuperscript{9} kg ha\textsuperscript{-1}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/BalancedSampleAmazonia-1} 

}

\caption{Sample balanced on lnSWIR2 from Eastern Amazonia.}\label{fig:BalancedSampleAmazonia}
\end{figure}

Figure \ref{fig:SamplingDistributionBalanced} shows the approximated sampling distribution of the \(\pi\) estimator of the mean AGB with balanced sampling and simple random sampling, obtained by repeating the random sampling with both designs and estimation 1,000 times.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionBalanced-1} 

}

\caption{Approximated sampling distribution of the \(\pi\) estimator of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) in Eastern Amazonia, with balanced sampling, balanced on lnSWIR2 and using equal inclusion probabilities, and simple random sampling without replacement (SI) of 100 units.}\label{fig:SamplingDistributionBalanced}
\end{figure}

The variance of the 1,000 estimates of the population mean of the study variable AGB equals 28.8 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}. The gain in precision compared to simple random sampling, equals 2.984 (design effect is 0.335), so with simple random sampling about three times more sampling units are needed to estimate the population mean with the same precision. The mean of the 1,000 estimated variances equals 26.4 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, indicating that the approximated variance estimator somewhat underestimates the true variance in this case. The population mean of the balancing variable lnSWIR2 equals 6.414. The sample mean of lnSWIR2 varies a bit among the samples. Figure \ref{fig:histSampleMeanSWIR} shows the approximated sampling distribution of the sample mean of lnSWIR2. In other words, many samples are not perfectly balanced on lnSWIR2. This is not exceptional, in most cases perfect balance is impossible.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histSampleMeanSWIR-1} 

}

\caption{Approximated sampling distribution of the sample mean of balancing variable lnSWIR2 in Eastern Amazonia with balanced sampling of size 100 and equal inclusion probabilities.}\label{fig:histSampleMeanSWIR}
\end{figure}

\hypertarget{exercises-14}{%
\subsubsection*{Exercises}\label{exercises-14}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select a sample of size 100 balanced on lnSWIR2 and Terra\_PP from Eastern Amazonia, using equal inclusion probabilities for all units.

  \begin{itemize}
  \tightlist
  \item
    First select a subgrid of 5 km \(\times\) 5 km using function \texttt{spsample}, see Chapter \ref{SY}.
  \item
    Estimate the population mean.
  \item
    Estimate the standard error of the \(\pi\) estimator. First estimate the regression coefficients, using function \texttt{estimate\_b} defined above, then compute the residuals, and finally compute the variance.\\
  \end{itemize}
\item
  Spatial clustering of sampling units is not avoided in balanced sampling. What effect do you expect of this spatial clustering on the precision of the estimated mean? Can you think of a situation where this effect does not occur?
\end{enumerate}

\hypertarget{StratifiedsamplingasBalancedsampling}{%
\subsection{Stratified random sampling}\label{StratifiedsamplingasBalancedsampling}}

Much in the same way as we controlled in the previous subsection the sample size \(n\) by balancing the sample on the known total number of population units \(N\), we can balance a sample on the known total number of units in subpopulations. A sample balanced on the sizes of subpopulations is a stratified random sample. Figure \ref{fig:BalancedSampleCategorical} shows four subpopulations or strata. These four strata can be used in balanced sampling by constructing the following design matrix\index{Design matrix} \(\mathbf{X}\) with as many columns as there are strata and as many rows as there are population units:

\begin{equation}
\mathbf{X}=
\begin{bmatrix}
1 &0 &0 &0 \\
1 &0 &0 &0 \\
1 &0 &0 &0 \\
1 &0 &0 &0 \\
0 &1 &0 &0 \\
0 &1 &0 &0 \\
0 &0 &1 &0 \\
\vdots &\vdots &\vdots &\vdots\\
0 & 0 & 0 & 1 \\
\end{bmatrix}  \;.
\end{equation}

The first four rows refer to the four leftmost bottom row population units in Figure \ref{fig:BalancedSampleCategorical}. These units belong to class A, which explains that the first column for these units contain ones. The other three columns for these rows contain all zeroes. The fifth and sixth unit belong to stratum B, so that the second column for these rows contain ones, and so on. The final row is the upper-right sampling unit in stratum D, so the first three columns contain zeroes, and the fourth column is filled with a one. The sum of the indicators in the columns is the total number of population units in the strata.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/BalancedSampleCategorical-1} 

}

\caption{Sample balanced on a categorical variable with four classes.}\label{fig:BalancedSampleCategorical}
\end{figure}

In the next code chunk the inclusion probabilities are computed by \(\pi_{hk}=n_h/N_h,\; k=1, \dots , N_h\), with \(n_h=5\) for all four strata. The stratum sample sizes are equal, but the number of population units of a stratum differ among the strata, so the inclusion probabilities also differ among the strata.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mypop}\SpecialCharTok{$}\NormalTok{s1, }\AttributeTok{INDEX =}\NormalTok{ mypop}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{times =} \DecValTok{4}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(n\_h)}
\FunctionTok{print}\NormalTok{(pi\_h }\OtherTok{\textless{}{-}}\NormalTok{ n\_h }\SpecialCharTok{/}\NormalTok{ N\_h)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         A          B          C          D 
0.06250000 0.12500000 0.03125000 0.04166667 
\end{verbatim}

The inclusion probabilities are added to \texttt{data.frame} \texttt{mypop} with the 400 population units, using a lookup table \texttt{lut} and function \texttt{merge}. The seven leftmost units on the bottom row are shown below. Variables s1 and s2 are the spatial coordinates of the centres of the units.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{stratum =} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mypop}\SpecialCharTok{$}\NormalTok{stratum)),}
                  \AttributeTok{pi =}\NormalTok{ n\_h }\SpecialCharTok{/}\NormalTok{ N\_h)}
\NormalTok{mypop }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mypop, }\AttributeTok{y =}\NormalTok{ lut, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{)}
\NormalTok{ord }\OtherTok{\textless{}{-}} \FunctionTok{order}\NormalTok{(mypop}\SpecialCharTok{$}\NormalTok{s2, mypop}\SpecialCharTok{$}\NormalTok{s1)}
\FunctionTok{head}\NormalTok{(mypop[ord, ], }\DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    stratum  s1  s2      pi
1         A 0.5 0.5 0.06250
2         A 1.5 0.5 0.06250
3         A 2.5 0.5 0.06250
4         A 3.5 0.5 0.06250
96        B 4.5 0.5 0.12500
84        B 5.5 0.5 0.12500
150       C 6.5 0.5 0.03125
\end{verbatim}

Next, the design matrix \(\mathbf{X}\) is computed with function \texttt{model.matrix}, expanding the factor \texttt{stratum} to a set of dummy variables, see code chunk below. By adding \texttt{-\ 1} to the formula, we avoid that the first column in the design matrix has all ones. The design matrix has four columns with dummy variables (indicators), indicating to which stratum a unit belongs.

The columns in the design matrix with dummy variables are multiplied by the vector with inclusion probabilities, using function \texttt{sweep}, resulting in the following design matrix:

\begin{equation}
\mathbf{X}=
\begin{bmatrix}
0.0625 &0 &0 &0 \\
0.0625 &0 &0 &0 \\
0.0625 &0 &0 &0 \\
0.0625 &0 &0 &0 \\
0 &0.125 &0 &0 \\
0 &0.125 &0 &0 \\
0 &0 &0.03125 &0 \\
\vdots &\vdots &\vdots &\vdots\\
0 & 0 & 0 &0.04167 \\
\end{bmatrix}  \;.
\end{equation}

The multiplication by the inclusion probabilities is not strictly needed. Using the design matrix with dummy variables implies that we balance the sample on the known total number of population units in the strata, \(N_h\). For samples with stratum sample sizes equal to \(n_h\), the sample sums of the dummy variables used in balancing, divided by the inclusion probability, are equal to \(N_h\).

Multiplication of the dummy variables by the vector with inclusion probabilities implies that we balance the sample on the population totals of the inclusion probabilities, which are equal to the targeted stratum sample sizes. For samples with stratum sample sizes \(n_h\) equal to these targeted sample sizes, the sample sums of the balancing variables, divided by the inclusion probability (having value \(\pi_{hk}/\pi_{hk}=1\) or 0), are equal to the targeted sample sizes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ stratum }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mypop)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(X, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, mypop}\SpecialCharTok{$}\NormalTok{pi, }\StringTok{\textasciigrave{}}\AttributeTok{*}\StringTok{\textasciigrave{}}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{sample\_ind }\OtherTok{\textless{}{-}} \FunctionTok{samplecube}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{pik =}\NormalTok{ mypop}\SpecialCharTok{$}\NormalTok{pi, }\AttributeTok{comment =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{method =} \DecValTok{1}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mypop[sample\_ind }\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps), ]}
\end{Highlighting}
\end{Shaded}

In the above example all units in a stratum have the same inclusion probability, yielding a stratified simple random sample. We may also use variable inclusion probabilities, for instance proportional to a size measure of the units, yielding a stratified ppswor random sample (Section \ref{ppswor}).

The advantage of selecting a stratified random sample by balancing the sample on a categorical variable becomes clear in case we have multiple classifications that we would like to use in stratification, and we cannot afford to use all cross-classifications as strata. This is the topic of the next subsection.

\hypertarget{Multiwaystratification}{%
\subsection{Multi-way stratification}\label{Multiwaystratification}}

\citet{Falorsi2008} describe how a multi-way stratified sample\index{Multi-way stratification} can be selected as a balanced sample. Multi-way stratification is of interest when one has multiple stratification variables, each stratification variable leading to several strata, so that the total number of cross-classification strata\index{Cross-classification stratum} becomes so large that the stratum sample sizes are strongly disproportional to their size or even exceed the total sample size. For instance, suppose we have three maps with 4, 3, and 5 map units. Further, suppose that all combinations of map units are non-empty, so that we have 4 \(\times\) 3 \(\times\) 5 = 60 combinations. We may not like to use all combinations (cross-classifications) as strata. The alternative is then to use the \(4+3+5=12\) map units as strata.

The sample sizes of the marginal strata can be controlled using a design matrix with as many columns as there are strata. The units of an individual map used for stratification are referred to as marginal strata\index{Marginal stratum}. Each row \(k = 1, \dots, N\) in the design matrix \(\mathbf{X}\) has as many non-zero values as we have maps, in entries corresponding to the cross-classification map unit of population unit \(k\), and zeroes in the remaining entries. The non-zero value is the inclusion probability of that unit. Each column of the design matrix has non-zero values in entries corresponding to the population units in that marginal stratum and zeroes in all other entries.

Two-way stratified random sampling is illustrated with a simulated population of 400 units (Figure \ref{fig:TwowaystratifiedPopulation}). Figure \ref{fig:Twowaystratifiedsample} shows two classifications of the population units. Classification A consists of four classes (map units), classification B of three classes. Instead of using \(4 \times 3 = 12\) cross-classifications as strata in random sampling, only \(4+3=7\) marginal strata are used in two-way stratified random sampling.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/TwowaystratifiedPopulation-1} 

}

\caption{Simulated population, used for illustration of two-way stratified random sampling.}\label{fig:TwowaystratifiedPopulation}
\end{figure}

As a first step the inclusion probabilities are added to \texttt{data.frame} \texttt{mypop} with the spatial coordinates and simulated values. To keep it simple I computed inclusion probabilities equal to 2 divided by the number of population units in a cross-classification stratum. Note that this does not imply that a sample is selected with two units per cross-classification stratum. As we will see later it is possible that in some cross-classification strata no units are selected at all, while in other cross-classification strata more than two units are selected. In multi-way stratified sampling the marginal stratum sample sizes are controlled. The inclusion probabilities should result in six selected units for all four units of map A and eight selected units for all three units of map B.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mypop }\OtherTok{\textless{}{-}}\NormalTok{ mypop }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(A, B) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}\AttributeTok{N\_h =} \FunctionTok{n}\NormalTok{(), }\AttributeTok{.groups =} \StringTok{"drop"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pih =} \FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{12}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ N\_h) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{right\_join}\NormalTok{(mypop, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The next step is to create the design matrix. Two submatrices are computed, one per stratification. The two submatrices are joined column-wise, using function \texttt{cbind}. The columns are multiplied by the vector with inclusion probabilities.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XA }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ A }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, mypop)}
\NormalTok{XB }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ B }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, mypop)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(XA, XB)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(X, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, mypop}\SpecialCharTok{$}\NormalTok{pih, }\StringTok{\textasciigrave{}}\AttributeTok{*}\StringTok{\textasciigrave{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Matrix \(\mathbf{X}\) can be reduced by one column if in the first column the inclusion probabilities of \emph{all} population units are inserted. This first column contains no zeroes. Balancing on this variable implies that the total sample size is controlled. Now there is no need anymore to control the sample sizes of all marginal strata. It is sufficient to control the sample sizes of three marginal strata of map A (A2, A3, and A4) and two marginal strata of map B (B2 and B3). Given the total sample size, the sample sizes of map units A1 and B1 then cannot be chosen freely anymore.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ A }\SpecialCharTok{+}\NormalTok{ B, mypop)}
\FunctionTok{colnames}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "(Intercept)" "AA2"         "AA3"         "AA4"         "BB2"        
[6] "BB3"        
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(X, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, mypop}\SpecialCharTok{$}\NormalTok{pih, }\StringTok{\textasciigrave{}}\AttributeTok{*}\StringTok{\textasciigrave{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This reduced design matrix is not strictly needed for selecting a multi-way stratified sample, but must be used in estimation. If in estimation as many balancing variables are used as we have marginal strata, the matrix with the sum of squares of the balancing variables (first sum in Equation \eqref{eq:betasbalanced}) cannot be inverted (the matrix is singular), and as a consequence the population regression coefficients cannot be estimated.

Finally, the two-way stratified random sample is selected with function \texttt{samplecube} of package \textbf{sampling}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_ind }\OtherTok{\textless{}{-}} \FunctionTok{samplecube}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{pik =}\NormalTok{ mypop}\SpecialCharTok{$}\NormalTok{pih, }\AttributeTok{method =} \DecValTok{1}\NormalTok{, }\AttributeTok{comment =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(sample\_ind }\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps))}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mypop[units, ]}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:Twowaystratifiedsample} shows the selected sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/Twowaystratifiedsample-1} 

}

\caption{Two-way stratified sample.}\label{fig:Twowaystratifiedsample}
\end{figure}

All marginal stratum sample sizes of map A are six and all marginal stratum sample sizes of map B are eight, as expected. The sample sizes of the cross-classification strata vary from zero to four.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{addmargins}\NormalTok{(}\FunctionTok{table}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{A, mysample}\SpecialCharTok{$}\NormalTok{B))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     
      B1 B2 B3 Sum
  A1   2  0  4   6
  A2   2  3  1   6
  A3   3  1  2   6
  A4   1  4  1   6
  Sum  8  8  8  24
\end{verbatim}

The population mean can be estimated by the \(\pi\) estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(mypop)}
\FunctionTok{print}\NormalTok{(mean }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pih) }\SpecialCharTok{/}\NormalTok{ N)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8.688435
\end{verbatim}

The variance is estimated as before (Equation \eqref{eq:approxvarianceBalanced}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pih)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_b}\NormalTok{(}
  \AttributeTok{z =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pih, }\AttributeTok{X =}\NormalTok{ X[units, ] }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pih, }\AttributeTok{c =}\NormalTok{ c)}
\NormalTok{zpred }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ b}
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{z }\SpecialCharTok{{-}}\NormalTok{ zpred[units]}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(mysample)}
\NormalTok{v\_tz }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \FunctionTok{ncol}\NormalTok{(X)) }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(c }\SpecialCharTok{*}\NormalTok{ (e }\SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{pih)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\FunctionTok{print}\NormalTok{(v\_mz }\OtherTok{\textless{}{-}}\NormalTok{ v\_tz }\SpecialCharTok{/}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1723688
\end{verbatim}

\hypertarget{Spreaded}{%
\section{Well-spread sampling}\label{Spreaded}}

With balanced sampling the spreading of the sampling units in the space spanned by the balancing variables can be poor. For instance, in Figure \ref{fig:simpleexample} the Easting coordinates of all units of a sample balanced on Easting can be equal or close to the population mean of 10. So, in this example balancing does not guarantee a good geographical spreading. Stated more generally, a balanced sample can be selected that shows strong clustering in the space spanned by the balancing variables. This clustering may inflate the standard error of the estimated population total and mean. The clustering in geographical or covariate space can be avoided by the local pivotal method \citep{Grafstrom2012} and the spatially correlated Poisson sampling method\index{Spatially correlated Poisson sampling} \citep{Grafstrom2012b}.

\begin{rmdnote}
For spreading in \emph{geographical} space various other designs are available. A simple design is stratified random sampling from compact geographical strata, see Section \ref{geostrata}. Alternative designs are generalised random-tessellation stratified sampling \citep{stevens2004}, see Subsection \ref{GRTS}, and balanced acceptance sampling\index{Balanced acceptance sampling} \citep{Robertson2013}.
\end{rmdnote}

\hypertarget{LPM}{%
\subsection{Local pivotal method}\label{LPM}}

The local pivotal method (LPM) is a modification of the pivotal method explained in Subsection \ref{pivotalmethod}\index{Local pivotal method}. The only difference with the pivotal method is the selection of the pairs of units. In the pivotal method at each step two units are selected, for instance, the first two units in the vector with inclusion probabilities after randomising the order of the units. In the local pivotal method the first unit is selected fully randomly and the nearest neighbour of this unit is used as its counterpart. Recall that when one unit of a pair is included in the sample, the inclusion probability of its counterpart is decreased. This leads to a better spreading of the sampling units in the space spanned by the spreading variables.

LPM can be used for arbitrary inclusion probabilities. The inclusion probabilities can be equal, but as with the pivotal method these probabilities may also differ among the population units.

Selecting samples with LPM can be done with functions \texttt{lpm}, \texttt{lpm1}, or \texttt{lpm2} of package \textbf{BalancedSampling} \citep{Grafstrom2016}. Functions \texttt{lpm1} and \texttt{lpm2} only differ in the selection of neighbours that are allowed to compete, for details see \citet{Grafstrom2012}. For most populations the two algorithms perform similarly (personal communication Anton Grafström). The algorithm implemented in function \texttt{lpm} is only recommended when the population size is too large for \texttt{lpm1} or \texttt{lpm2}. It only uses a subset of the population in search for nearest neighbours and is thus not as good. Another function \texttt{lpm2\_kdtree} of package \textbf{SamplingBigData} \citep{samplingBigData} is developed for big data sets.

Inclusion probabilities are computed with function \texttt{inclusionprobabilities} of package \textbf{sampling}. A matrix \(\mathbf{X}\) must be defined with the values of the spreading variables of the population units. Figure \ref{fig:LPMKandahar} shows a ppswor sample of 40 units selected from the sampling frame of Kandahar, using the spatial coordinates of the population units as spreading variables. Inclusion probabilities are proportional to the agricultural area within the population units. The geographical spreading is improved compared with the sample shown in Figure \ref{fig:ppswrKandahar}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BalancedSampling)}
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{inclusionprobabilities}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri, n)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{s1, grdKandahar}\SpecialCharTok{$}\NormalTok{s2)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{lpm1}\NormalTok{(pi, X)}
\NormalTok{myLPMsample }\OtherTok{\textless{}{-}}\NormalTok{ grdKandahar[units, ]}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/LPMKandahar-1} 

}

\caption{Spatial ppswor sample of size 40 from Kandahar, selected by the local pivotal method, using agricultural area as a size variable.}\label{fig:LPMKandahar}
\end{figure}

The total poppy area can be estimated with the \(\pi\) estimator (Equation \eqref{eq:HTTotal}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myLPMsample}\SpecialCharTok{$}\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ pi[units]}
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(myLPMsample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ myLPMsample}\SpecialCharTok{$}\NormalTok{pi)}
\end{Highlighting}
\end{Shaded}

The estimated total poppy area equals 62,232 ha. The sampling variance of the estimator of the population total with the local pivotal method can be estimated by \citep{Grafstrom2014}

\begin{equation}
\widehat{V}(\hat{t}(z)) = \frac{1}{2} \sum_{k \in \mathcal{S}} \left( \frac{z_k}{\pi_k} - \frac{z_{k_j}}{\pi_{k_j}} \right)^2 \;,
\label{eq:VartotalLPM}
\end{equation}

with \({k_j}\) the nearest neighbour of unit \(k\) in the sample. This variance estimator is for the case where we have only one nearest neighbour.

Function \texttt{vsb} of package \textbf{BalancedSampling} is an implementation of a more general variance estimator that accounts for more than one nearest neighbour (Equation (6) in \citet{Grafstrom2014}). We expect a somewhat smaller variance compared to pps sampling, so we may use the variance of the pwr estimator (Equation \eqref{eq:VarHHTotalppswr}) as a conservative variance estimator\index{Conservative variance estimator}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Xsample }\OtherTok{\textless{}{-}}\NormalTok{ X[units, ]}
\NormalTok{se\_tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{vsb}\NormalTok{(pi[units], myLPMsample}\SpecialCharTok{$}\NormalTok{poppy, Xsample))}
\NormalTok{pk }\OtherTok{\textless{}{-}}\NormalTok{ myLPMsample}\SpecialCharTok{$}\NormalTok{pi }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{se\_tz\_pwr }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(myLPMsample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ pk) }\SpecialCharTok{/}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

The standard error obtained with function \texttt{vsb} equals 12,850 ha, the standard error of the pwr estimator equals 14,094 ha.

As explained above, the LPM design can also be used to select a probability sample well-spread in the space spanned by one or more quantitative covariates. Matrix \(\mathbf{X}\) then should contain the values of the \emph{scaled} (standardised) covariates instead of the spatial coordinates.

\hypertarget{exercises-15}{%
\subsubsection*{Exercises}\label{exercises-15}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Geographical spreading of the sampling units can also be achieved by random sampling from compact geographical strata (geostrata) (Section \ref{geostrata}). Can you think of one or more advantages of LPM sampling over random sampling from geostrata?
\end{enumerate}

\hypertarget{GRTS}{%
\subsection{Generalised random-tessellation stratified sampling}\label{GRTS}}

Generalised random-tessellation stratified (GRTS) sampling\index{Generalised random-tessellation stratified sampling} is designed for sampling discrete objects scattered throughout space, think for instance of the lakes in Finland, segments of hedgerows in England, etc. Each object is represented by a point in 2D-space. It is a complicated design, and for sampling points from a continuous universe or raster cells from a finite population, I recommend more simple designs such as the local pivotal method (Subsection \ref{LPM}), balanced sampling with geographical spreading (Section \ref{BalancedandSpreaded}), or sampling from compact geographical strata (Section \ref{geostrata}). Let me try to explain the GRTS design with a simple example of a finite population of point objects in a circular study area (Figure \ref{fig:GRTSNumbering}). For a more detailed description of this design I refer to \citet{Hankin2019}. As a first step a square bounding box of the study area is constructed. This bounding box is recursively partitioned into square grid cells. First, 2 \(\times\) 2 grid cells are constructed. These grid cells are numbered in a predefined order. In Figure \ref{fig:GRTSNumbering} this numbering is from lower left, lower right, upper left to upper right. Each grid cell is then subdivided into four subcells; the subcells are numbered using the same order. This is repeated until at most one population unit occurs in each subcell. For our population only two iterations were needed, leading to 4 \(\times\) 4 subcells. Note that two subcells are empty. Each address of a subcell consists of two digits, the first digit refers to the grid cell, the second digit to the subcell.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/GRTSNumbering-1} 

}

\caption{Numbering of grid cells and subcells for GRTS sampling.}\label{fig:GRTSNumbering}
\end{figure}

The next step is to place the sixteen subcells on a line in a random order. The randomisation is done hierarchically. First, the four grid cells at the highest level are randomised. In our example the randomised order is 1, 2, 3, 0 (Figure \ref{fig:GRTS}). Next, within each grid cell the order of the subcells is randomised. This is done independently for the grid cells. In our example for grid cell 1 the randomised order of the subcells is 2, 1, 3, 0 (Figure \ref{fig:GRTS}). Note that the empty subcells, subcells (0,0) and (3,3), are removed from the line.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{ord }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{myfinpop\_rand }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ ord) \{}
\NormalTok{  units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(myfinpop}\SpecialCharTok{$}\NormalTok{partit1 }\SpecialCharTok{==}\NormalTok{ i)}
\NormalTok{  units\_rand }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(units, }\AttributeTok{size =} \FunctionTok{length}\NormalTok{(units))}
\NormalTok{  myfinpop\_rand }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(myfinpop\_rand, myfinpop[units\_rand, ])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

After the subcells have been placed on a line, a one-dimensional systematic random sample is selected (Figure \ref{fig:GRTS}), see also Subsection \ref{Systematicpps}. This can be done either with equal or unequal inclusion probabilities. With equal inclusion probabilities the length of the intervals representing the population units is constant. With unequal inclusion probabilities the interval lengths are proportional to a size variable. For a sample size of \(n\), the total line is divided into \(n\) segments of equal length. A random point is selected in the first segment, and the other points of the systematic sample are determined. Finally, the population units corresponding to the selected systematic sample are identified. With equal probabilities the five selected units are the units in subcells 11, 23, 22, 32, and 03 (Figure \ref{fig:GRTS}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{size }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{interval }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(size) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{start }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ interval, }\DecValTok{2}\NormalTok{)}
\NormalTok{mysys }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(start, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ interval }\SpecialCharTok{+}\NormalTok{ start)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/GRTS-1} 

}

\caption{Systematic random sample along a line with equal inclusion probabilities.}\label{fig:GRTS}
\end{figure}

Figure \ref{fig:GRTSpps} shows a systematic random sample along a line with unequal inclusion probabilities. The inclusion probabilities are proportional to a size variable, with values 1, 2, 3, or 4. The selected population units are the units in subcells 10, 20, 31, 01, and 02.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/GRTSpps-1} 

}

\caption{Systematic random sample along a line with inclusion probabilities proportional to size.}\label{fig:GRTSpps}
\end{figure}

GRTS samples can be selected with function \texttt{grts} of package \textbf{spsurvey} \citep{spsurvey}. The next code chunk shows the selection of a GRTS sample of 40 units from Kandahar. Tibble \texttt{grdKandahar} is first converted to an \texttt{sf} object with function \texttt{st\_as\_sf} of package \textbf{sf} \citep{sf}. The data set is using a UTM projection (zone 41N) with WGS84 datum. This projection is passed to function \texttt{st\_as\_df} with argument \texttt{crs} (\texttt{crs\ =\ 32641}). Argument \texttt{sframe} of function \texttt{grts} specifies the sampling frame. The sample size is passed to function \texttt{grts} with argument \texttt{n\_base}. Argument \texttt{seltype} is set to \texttt{proportional} to select units with probabilities proportional to an ancillary variable which is passed to function \texttt{grts} with argument \texttt{aux\_var}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spsurvey)}
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{sframe\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(grdKandahar, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{), }\AttributeTok{crs =} \DecValTok{32641}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{grts}\NormalTok{(}
  \AttributeTok{sframe =}\NormalTok{ sframe\_sf, }\AttributeTok{n\_base =} \DecValTok{40}\NormalTok{, }\AttributeTok{seltype =} \StringTok{"proportional"}\NormalTok{, }\AttributeTok{aux\_var =} \StringTok{"agri"}\NormalTok{)}
\NormalTok{myGRTSsample }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{sites\_base}
\end{Highlighting}
\end{Shaded}

Function \texttt{cont\_analysis} computes the ratio estimator of the population mean and its standard error. The estimated mean is multiplied by the total number of population units to obtain a ratio estimate of the population total.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myGRTSsample}\SpecialCharTok{$}\NormalTok{siteID }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"siteID"}\NormalTok{, }\FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(myGRTSsample)))}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{cont\_analysis}\NormalTok{(myGRTSsample,}
       \AttributeTok{vars =} \StringTok{"poppy"}\NormalTok{, }\AttributeTok{siteID =} \StringTok{"siteID"}\NormalTok{, }\AttributeTok{weight =} \StringTok{"wgt"}\NormalTok{, }\AttributeTok{statistics =} \StringTok{"Mean"}\NormalTok{)}
\NormalTok{tz\_ratio }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{Mean}\SpecialCharTok{$}\NormalTok{Estimate }\SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(grdKandahar)}
\NormalTok{se\_tz\_ratio }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{Mean}\SpecialCharTok{$}\NormalTok{StdError }\SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(grdKandahar)}
\end{Highlighting}
\end{Shaded}

The estimated total poppy area is 109,809 ha, and the estimated standard error is 24,327 ha.

The alternative is to estimate the total poppy area by the \(\pi\) estimator. Function \texttt{vsb} of package \textbf{BalancedSampling} can be used to estimate the standard error of the \(\pi\) estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(myGRTSsample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{/}\NormalTok{ myGRTSsample}\SpecialCharTok{$}\NormalTok{ip)}
\NormalTok{Xsample }\OtherTok{\textless{}{-}} \FunctionTok{st\_coordinates}\NormalTok{(myGRTSsample)}
\NormalTok{se\_tz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{vsb}\NormalTok{(myGRTSsample}\SpecialCharTok{$}\NormalTok{ip, myGRTSsample}\SpecialCharTok{$}\NormalTok{poppy, Xsample))}
\end{Highlighting}
\end{Shaded}

The estimated total is 71,634 ha, and the estimated standard error is 12,593 ha.

\hypertarget{BalancedandSpreaded}{%
\section{Balanced sampling with spreading}\label{BalancedandSpreaded}}

As mentioned in the introduction to this chapter a sample balanced on a covariate still may have a poor spreading along the axis spanned by the covariate. \citet{Grafstrom2013} presented a method for selecting balanced samples that are also well-spread in the space spanned by the covariates, which they refer to as doubly-balanced sampling\index{Doubly-balanced sampling}. If we take one or more covariates as balancing variables and, besides, Easting and Northing as spreading variables, this leads to balanced samples with good \emph{geographical} spreading. When the residuals of the regression model show spatial structure (are spatially correlated), the estimated population mean of the study variable becomes more precise thanks to the improved geographical spreading. Balanced samples with spreading can be selected with function \texttt{lcube} of package \textbf{BalancedSampling}. This is illustrated with Eastern Amazonia, using as before lnSWIR2 for balancing the sample.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BalancedSampling)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{Xbal }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{times =}\NormalTok{ N), grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{Xspread }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{x1, grdAmazonia}\SpecialCharTok{$}\NormalTok{x2)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, }\AttributeTok{times =}\NormalTok{ N)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{lcube}\NormalTok{(}\AttributeTok{Xbal =}\NormalTok{ Xbal, }\AttributeTok{Xspread =}\NormalTok{ Xspread, }\AttributeTok{prob =}\NormalTok{ pi)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units, ]}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/DoublyBalancedSampleAmazonia-1} 

}

\caption{Sample balanced on lnSWIR2 with geographical spreading from Eastern Amazonia.}\label{fig:DoublyBalancedSampleAmazonia}
\end{figure}

The selected sample is shown in Figure \ref{fig:DoublyBalancedSampleAmazonia}. Comparing this sample with the balanced sample of Figure \ref{fig:BalancedSampleAmazonia} shows that the geographical spreading of the sample is improved, although there still are some close points. I used equal inclusion probabilities, so the \(\pi\) estimate of the mean is equal to the sample mean, which is equal to 225.6 10\textsuperscript{9} kg ha\textsuperscript{-1}.

The variance of the \(\pi\) estimator of the mean can be estimated by (Equation (7) of \citet{Grafstrom2013})

\begin{equation}
\widehat{V}(\hat{\bar{z}}) = \frac{n}{n-p}\frac{p}{p+1} \sum_{k \in \mathcal{S}}(1-\pi_k) \left(\frac{e_k}{\pi_k}-\bar{e}_k \right)^2 \;,
\label{eq:VarmeanDoublyBalanced}
\end{equation}

with \(p\) the number of balancing variables, \(e_k\) the regression model residual of unit \(k\) (Equation \eqref{eq:residualsBalanced}), and \(\bar{e}_k\) the local mean of the residuals of this unit, computed by

\begin{equation}
\bar{e}_k = \frac{\sum_{j=1}^{p+1}(1-\pi_j)\frac{e_j}{\pi_j}}{\sum_{j=1}^{p+1}(1-\pi_j)}\;.
\label{eq:localmeanresdual}
\end{equation}

The variance estimator can be computed with functions \texttt{localmean\_weight} and \texttt{localmean\_var} of package \textbf{spsurvey} \citep{spsurvey}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spsurvey)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, n)}
\NormalTok{c }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pi)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_b}\NormalTok{(}\AttributeTok{z =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{/}\NormalTok{ pi, }\AttributeTok{X =}\NormalTok{ Xbal[units, ] }\SpecialCharTok{/}\NormalTok{ pi, }\AttributeTok{c =}\NormalTok{ c)}
\NormalTok{zpred }\OtherTok{\textless{}{-}}\NormalTok{ Xbal }\SpecialCharTok{\%*\%}\NormalTok{ b}
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ zpred[units]}
\NormalTok{weights }\OtherTok{\textless{}{-}} \FunctionTok{localmean\_weight}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{x1, }\AttributeTok{y =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{x2, }\AttributeTok{prb =}\NormalTok{ pi, }\AttributeTok{nbh =} \DecValTok{3}\NormalTok{)}
\NormalTok{v\_mz }\OtherTok{\textless{}{-}} \FunctionTok{localmean\_var}\NormalTok{(}\AttributeTok{z =}\NormalTok{ e }\SpecialCharTok{/}\NormalTok{ pi, }\AttributeTok{weight\_1st =}\NormalTok{ weights) }\SpecialCharTok{/}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

The estimated standard error is 2.8 10\textsuperscript{9} kg ha\textsuperscript{-1}, which is considerably smaller than the estimated standard error of the balanced sample without geographical spreading.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5284453 282.3    9368568 500.4   9368568  500.4
Vcells 26128066 199.4   72647967 554.3 177363197 1353.2
\end{verbatim}

\hypertarget{Modelassisted}{%
\chapter{Model-assisted estimation}\label{Modelassisted}}

In many cases ancillary information is available that could be useful to increase the accuracy of the estimated mean or total of the study variable. The ancillary variable(s) can be qualitative (i.e.~classifications) or quantitative. As we have seen before, both types of ancillary variable can be used at the design stage, i.e.~in selecting the sampling units, to improve the performance of the sampling strategy, for instance by stratification (Chapter \ref{STSI}), selecting sampling units with probabilities proportional to size (Chapter \ref{pps}), or through balancing and/or spreading the sample on the covariates (Chapter \ref{BalancedSpreaded}). In this chapter I explain how these covariates can be used at the stage of \emph{estimation}, once the data are collected.

In the design-based approach for sampling various estimators are developed that exploit one or more covariates. These estimators are derived from different superpopulation models\index{Superpopulation model} of the study variable. A superpopulation model is a statistical model that can be used to generate an infinite number of populations, a superpopulation, through simulation. An example is the simulation of spatial populations using a geostatistical model, see Chapter \ref{MBpredictionofDesignVariance}. A superpopulation is a construct, it does not exist in reality. We assume that the population of interest is one of the populations that can be generated with the chosen model. The combination of probability sampling and estimators that are built on a superpopulation model is referred to as the model-assisted approach\index{Model-assisted approach}. Also in the model-based approach a superpopulation model is used, however, its role is fundamentally different from that in the model-assisted approach, see Chapter \ref{Approaches}. To stress the different use of the superpopulation model in the model-assisted approach this model is referred to as the ``working model''\index{Working model}, i.e.~the superpopulation model that is used to derive a model-assisted estimator.

\citet{Breidt2017} present an overview of model-assisted estimators derived from a general working model:

\begin{equation}
Z_k = \mu(\mathbf{x}_k)+\epsilon_k\;,
\label{eq:workingmodel}
\end{equation}

with \(\mu(\mathbf{x}_k)\) the model-mean\index{Model-mean} for population unit \(k\) which is a function of the covariate values of that unit collected in vector \(\mathbf{x}_k = (1, x_{1,k}, \dots , x_{J,k})^{\mathrm{T}}\) and \(\epsilon_k\) a random variable with zero mean. Note that I use uppercase \(Z\) to distinguish the random variable \(Z_k\) of unit \(k\) from one realisation of this random variable for unit \(k\) in the population of interest, \(z_k\). The model-mean \(\mu(\mathbf{x}_k)\) can be a linear or a non-linear combination of the covariates. If the study variable and the covariate values were observed for all population units, all these data could be used to compute a so-called hypothetical population fit\index{Population fit of model parameters} of the model parameters. These model parameters can then be used to compute \emph{estimates} of the model-means \(\mu(\mathbf{x}_k)\), denoted by \(m(\mathbf{x}_k)\), for all population units. For instance, with a (multiple) regression model \(m(\mathbf{x}_k)=\mathbf{x}_k^{\text{T}} \mathbf{b}\), with \(\mathbf{b}\) the vector with regression coefficients estimated from observations of the study variable \(z\) and the covariates on \emph{all} population units. In practice we have a sample only, which is used to estimate \(m(\mathbf{x}_k)\) by \(\hat{m}(\mathbf{x}_k)\). For the multiple regression model \(\hat{m}(\mathbf{x}_k)= \mathbf{x}_k^{\text{T}} \hat{\mathbf{b}}\), with \(\hat{\mathbf{b}}\) the vector with regression coefficients estimated from the sample data. This leads to the generalised difference estimator\index{Generalised difference estimator} \citep{Wu2001}:

\begin{equation}
\hat{\bar{z}}_{\mathrm{dif}}=\frac{1}{N} \sum_{k=1}^N \hat{m}(\mathbf{x}_k) + \frac{1}{N} \sum_{k \in \mathcal{S}} \frac{z_k-\hat{m}(\mathbf{x}_k)}{\pi_k}\;,
\label{eq:GeneralizedDifferenceEstimator}
\end{equation}

with \(\pi_k\) the inclusion probability of unit \(k\). The first term is the population mean of model predictions of the study variable, the second term is the \(\pi\) estimator of the population mean of the residuals.

A wide variety of model-assisted estimators have been developed and tested over the past decades. They differ in the working model used to obtain the estimates \(\hat{m}(\mathbf{x}_k)\) in Equation \eqref{eq:GeneralizedDifferenceEstimator}. The best known class of model-assisted estimators is the generalised regression estimator\index{Regression estimator!generalised regression estimator} that uses a linear model in prediction \citep{sar92}. Alternative model-assisted estimators are the estimators using machine learning techniques for prediction. In the era of big data with a vastly increasing number of exhaustive data sets and a rapid development of machine learning techniques, these estimators have great potentials for spatial sample survey.

\hypertarget{GREG}{%
\section{Generalised regression estimator}\label{GREG}}

The working model of the generalised regression estimator is the heteroscedastic multiple linear regression model\index{Linear regression model!heteroscedastic}:

\begin{equation}
Z_k = \mathbf{x}^{\mathrm{T}}_k \pmb{\beta}+\epsilon_k \;,
\label{eq:GREGmodel}
\end{equation}

with \(\epsilon_k\) uncorrelated residuals, with zero mean and variance \(\sigma^2(\epsilon_k)\). Note that the variance of the residuals \(\sigma^2(\epsilon_k)\) need not be constant but may differ among the population units. If \(\{z_k,x_{1,k}, \dots , x_{J,k}\}\) were observed for all units \(k= 1, \dots , N\) in the population, the regression coefficients \(\pmb{\beta}\) would be estimated by

\begin{equation}
\mathbf{b} = \left(\sum_{k=1}^N \frac{\mathbf{x}_k\mathbf{x}_k^{\mathrm{T}}}{\sigma^2(\epsilon_k)}  \right)^{-1} \sum_{k=1}^N \frac{\mathbf{x}_k z_k}{\sigma^2(\epsilon_k)}\;,
\label{eq:populationfitGREG}
\end{equation}

with \(\mathbf{x}_k\) the vector \((1, x_{1,k}, \dots , x_{J,k})^{\mathrm{T}}\) and \(\sigma^2(\epsilon_k)\) the variance of the residual of unit \(k\). Similar to the distinction between model-mean and population mean (see Chapter \ref{Approaches}), here the model regression coefficients\index{Model regression coefficient} \(\pmb{\beta}\) are distinguished from the population regression coefficients\index{Population regression coefficient} \(\mathbf{b}\). The means \(m(\mathbf{x}_k)\) would then be computed by

\begin{equation}
m(\mathbf{x}_k) = \mathbf{x}_k^{\mathrm{T}} \mathbf{b}\;.
\label{eq:mxi}
\end{equation}

If we have a probability sample from the population of interest, \(\mathbf{b}\) is estimated by replacing the population totals in Equation \eqref{eq:populationfitGREG} by their \(\pi\) estimators:

\begin{equation}
\hat{\mathbf{b}} = \left(\sum_{k \in \mathcal{S}} \frac{\mathbf{x}_k\mathbf{x}_k^{\mathrm{T}}}{\sigma^2(\epsilon_k) \pi_k}  \right)^{-1} \sum_{k \in \mathcal{S}} \frac{\mathbf{x}_k z_k}{\sigma^2(\epsilon_k) \pi_k} \;.
\label{eq:EstimatorGREGCoefficients}
\end{equation}

\begin{rmdcaution}
With unequal inclusion probabilities, the design-based estimators of the population regression coefficients differ from the usual ordinary least squares\index{Ordinary least squares} (OLS) estimators of the regression coefficients defined as model parameters. The values \(\hat{b}_j\) are estimates of the \emph{population parameters} \(b_j\).
\end{rmdcaution}

The mean values \(m(\mathbf{x}_k)\) are now estimated by

\begin{equation}
\hat{m}(\mathbf{x}_k) = \mathbf{x}_k^{\mathrm{T}} \hat{\mathbf{b}}\;.
\label{eq:estmxi}
\end{equation}

Plugging Equation \eqref{eq:estmxi} into the generalised difference estimator, Equation \eqref{eq:GeneralizedDifferenceEstimator}, leads to the generalised regression estimator\index{Regression estimator!generalised regression estimator} for the population mean:

\begin{equation}
\hat{\bar{z}}_{\mathrm{regr}} = \frac{1}{N} \sum_{k=1}^N \mathbf{x}_k^{\mathrm{T}} \hat{\mathbf{b}} + \frac{1}{N} \sum_{k \in \mathcal{S}} \frac{z_k-\mathbf{x}^{\mathrm{T}}_k\hat{\mathbf{b}}} {\pi_k}
  \;.
\label{eq:GREG}
\end{equation}

This estimator can also be written as

\begin{equation}
\hat{\bar{z}}_{\text{regr}}= \hat{\bar{z}}_{\pi}+\sum_{j=1}^J \hat{b}_j(\bar{x}_j-\hat{\bar{x}}_{j,\pi})  \;,
\label{eq:GREG2}
\end{equation}

with \(\hat{\bar{z}}_{\pi}\) and \(\hat{\bar{x}}_{j,\pi}\) the \(\pi\) estimator of the study variable and the \(j\)th covariate, respectively, \(\bar{x}_j\) the population mean of the \(j\)th covariate, and \(\hat{b}_j\) the estimated slope coefficient associated with the \(j\)th covariate. So, the generalised regression estimate is equal to the \(\pi\) estimate when the estimated means of the covariates are equal to the population means. This is the rationale of balanced sampling (Chapter \ref{BalancedSpreaded}).

The alternative formulation of the regression estimator (Equation \eqref{eq:GREG2}) shows that we do not need to know the covariate values for all population units. Knowledge of the population means of the covariates is sufficient. This is because a linear relation is assumed between the study variable and the covariates. On the contrary, for non-linear working models such as a random forest model, exhaustive knowledge of the covariates is needed so that the estimated mean \(\hat{m}(\mathbf{x}_k)\) in Equation \eqref{eq:GeneralizedDifferenceEstimator} can be computed for every unit in the population.

\citet{sar92} worked out the generalised regression estimator for various superpopulation models, such as the simple and multiple linear regression model, the ratio model, and the analysis of variance (ANOVA) model.

\hypertarget{RegressionEstimator}{%
\subsection{Simple and multiple regression estimators}\label{RegressionEstimator}}

The working model of the simple and the multiple regression estimator is the homoscedastic linear regression model\index{Linear regression model!homoscedastic}. The only difference with the heteroscedastic model is that the variance of the residuals is assumed constant: \(\sigma^2(\epsilon_k) = \sigma^2(\epsilon), k = 1 , \dots , N\).

In the simple linear regression model the mean is a linear function of a single covariate, \(\mu(x_k)= \alpha + \beta\;x_k\). The simple linear regression model\index{Simple linear regression model} leads to the simple regression estimator\index{Regression estimator!simple regression estimator}. With simple random sampling this estimator for the population mean is

\begin{equation}
\hat{\bar{z}}_{\text{regr}}= \bar{z}_{\mathcal{S}}+\hat{b}\left( \bar{x}-\bar{x}_{\mathcal{S}}\right) \;,
\label{eq:SimpleRegressionEstimatorSI}
\end{equation}

where \(\bar{z}_{\mathcal{S}}\) and \(\bar{x}_{\mathcal{S}}\) are the sample means of the study variable and the covariate, respectively, \(\bar{x}\) is the population mean of the covariate, and \(\hat{b}\) is the estimated slope coefficient:

\begin{equation}
\hat{b}=\frac{\sum_{k \in \mathcal{S}} (x_k-\bar{x}_{\mathcal{S}})(z_k-\bar{z}_{\mathcal{S}})}{\sum_{k \in \mathcal{S}}(x_k-\bar{x}_{\mathcal{S}})^2} \;.
\label{eq:OLSSlope}
\end{equation}

The rationale of the regression estimator is that when the estimated mean of the covariate is, for instance, smaller than the population mean of the covariate, then with a positive correlation between study variable and covariate, also the estimated mean of the study variable is expected to be smaller than the population mean of the study variable. The difference between the population mean and the estimated mean of the covariate can be used to improve the \(\pi\) estimate of the mean of \(z\) (which is for simple random sampling equal to the sample mean \(\bar{z}_{\mathcal{S}}\)), by adding a term proportional to the difference between the estimated mean and the population mean of the covariate. As a scaling factor the estimated slope of the fitted regression line is used.

The sampling variance of this regression estimator can be estimated by computing first the regression residuals \(e_k= z_k - \hat{z}_k,\;k = 1, \dots , n\) at the sampling units, with \(\hat{z}_k = \hat{a} + \hat{b} x_k\) the predicted value for unit \(k\). Note that I use symbol \(\epsilon\) (Equation \eqref{eq:GREGmodel}) for the residuals from the model with the model regression coefficients \(\pmb{\beta}\), whereas for the residuals from the model with the estimated population regression coefficients \(\hat{\mathbf{b}}\) I use symbol \(e\). To compute the residuals \(e\) also an estimate of the intercept \(a\) is needed. With simple random sampling this intercept can be estimated by

\begin{equation}
\hat{a} = \bar{z}_{\mathcal{S}} - \hat{b}\; \bar{x}_{\mathcal{S}}\;.
\label{eq:OLSIntercept}
\end{equation}

The sampling variance of the regression estimator of the population mean is \emph{approximately} equal to the sampling variance of the \(\pi\) estimator of the mean of the model residuals:

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\mathrm{regr}}\right)=\left(1-\frac{n}{N}\right)\frac{\widehat{S^{2}}(e)}{n} \;,
\label{eq:VarianceRegressionEstimatorSI}
\end{equation}

with \(\widehat{S^{2}}(e)\) the estimated population variance of the regression residuals:

\begin{equation}
\widehat{S^{2}}(e)=\frac{1}{n-1}\sum_{k \in \mathcal{S}} e_k^2 \;.
\label{eq:VarianceResiduals}
\end{equation}

\begin{rmdnote}
The variance estimator is an approximation because the regression coefficients are also estimated from the sample, which makes the regression estimator non-linear. The approximation of the variance is based on a Taylor linearisation\index{Taylor linearisation of regression estimator} of the regression estimator (\citet{sar92}, p.~235).
\end{rmdnote}

For simple random sampling with replacement from finite populations and simple random sampling of infinite populations, the finite population correction factor \(1-n/N\) must be dropped, see Chapter \ref{SI}.

In the multiple linear regression model\index{Multiple linear regression model} the mean is a linear function of multiple covariates. This model leads to the multiple regression estimator\index{Regression estimator!multiple regression estimator}. With simple random sampling the population regression coefficients of this estimator can be estimated by

\begin{equation}
\hat{\mathbf{b}} = \left(\sum_{k \in \mathcal{S}} \mathbf{x}_k\mathbf{x}_k^{\mathrm{T}} \right)^{-1} \sum_{k \in \mathcal{S}} \mathbf{x}_k z_k \;.
\label{eq:EstimatorMultipleRegressionCoefficients}
\end{equation}

Comparison with the general estimator of the population regression coefficients (Equation \eqref{eq:EstimatorGREGCoefficients}) shows that the variance of the residuals, \(\sigma^2(\epsilon_k)\), is missing as they are assumed constant. Besides, the inclusion probabilities \(\pi_k\) are missing because they are equal for all population units with simple random sampling.

The simple regression estimator is illustrated with Eastern Amazonia. The population mean of the aboveground biomass (AGB) is estimated by the simple regression estimator, using natural logs of MODIS short-wave infrared radiation (SWIR2) as a covariate.

A simple random sample without replacement of 100 units is selected using \texttt{slice\_sample} of package \textbf{dplyr}, and the two population regression coefficients are estimated with Equation \eqref{eq:EstimatorMultipleRegressionCoefficients}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{lnSWIR2 =} \FunctionTok{log}\NormalTok{(SWIR2))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{321}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(AGB,lnSWIR2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =}\NormalTok{ n, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{data =} \DecValTok{1}\NormalTok{)}
\NormalTok{X[, }\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2}
\NormalTok{XXinv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X)}
\NormalTok{Xz }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB}
\FunctionTok{print}\NormalTok{(ab }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(XXinv }\SpecialCharTok{\%*\%}\NormalTok{ Xz))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         [,1]      [,2]
[1,] 1751.636 -237.1379
\end{verbatim}

The same estimates are obtained by ordinary least squares (OLS) fitting of the model with function \texttt{lm}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_sample }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{print}\NormalTok{(ab\_mb }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(lm\_sample))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)     lnSWIR2 
  1751.6363   -237.1379 
\end{verbatim}

As already stressed above, the design-based estimates of the population regression coefficients are only equal to the model-based OLS estimates of the regression coefficients for equal probability sampling designs. Also be aware that the variance of the design-based estimates of the population regression coefficients is not equal to the model-based variance of the model regression coefficients. See Section (11.2.2.1) in \citet{loh99} for how to estimate the variance of the design-based estimates of the population regression coefficients.

Figure \ref{fig:ScatterAGBvsSWIR2} shows the scatter plot for the simple random sample and the fitted simple linear regression model.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/ScatterAGBvsSWIR2-1} 

}

\caption{Scatter plot of AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) against lnSWIR2 of a simple random sample of size 100 from Eastern Amazonia and the fitted simple linear regression model for AGB.}\label{fig:ScatterAGBvsSWIR2}
\end{figure}

The simple random sample is used to estimate the population mean of the study variable AGB by the simple regression estimator and to approximate the sampling variance of the regression estimator. The residuals of the fitted model can be extracted with function \texttt{residuals} because in this case the OLS estimates of the regression coefficients are equal to the design-based estimates. With unequal inclusion probabilities the residuals must be computed by predicting the study variable for the selected units, using the design-based estimates of the regression coefficients, and subtracting the observations of the study variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mx\_pop }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{mx\_sam }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{mz\_sam }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB)}
\NormalTok{mz\_regr }\OtherTok{\textless{}{-}}\NormalTok{ mz\_sam }\SpecialCharTok{+}\NormalTok{ ab[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ (mx\_pop }\SpecialCharTok{{-}}\NormalTok{ mx\_sam)}
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(lm\_sample)}
\NormalTok{S2e }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(e)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{se\_mz\_regr }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*}\NormalTok{ S2e }\SpecialCharTok{/}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

The difference \(\delta(x)\) between the population mean of the covariate lnSWIR2 (6.415) and its estimated mean (6.347) equals 0.068. We may expect the difference between the unknown population mean of the study variable AGB and its sample mean (246.510) to be equal to \(\delta(x)\), multiplied by the estimated slope of the line, which equals -237.1. The result, -16.1039, is added to the simple random sample estimate, so that the ultimate regression estimate is adjusted downward to 230.4 10\textsuperscript{9} kg ha\textsuperscript{-1}.

The estimated approximate standard error of the regression estimator equals 4.458 10\textsuperscript{9} kg ha\textsuperscript{-1}. The approximated variance is a simplification of a more complicated approximation derived from writing the regression estimator of the population total as a weighted sum of the \(\pi\)-expanded observations (\citet{sar92}, Equation (6.5.9)):

\begin{equation}
\hat{\bar{z}}_{\mathrm{regr}}=\frac{1}{N}\sum_{k \in \mathcal{S}} g_k \frac{z_k}{\pi_k}\;,
\label{eq:AlternativeRegressionEstimator}
\end{equation}

with \(g_k\) the weight for unit \(k\). For simple random sampling the weights are equal to (\citet{sar92}, Equation (6.5.12))

\begin{equation}
g_k = 1+\frac{(\bar{x}-\bar{x}_{\mathcal{S}})(x_k-\bar{x}_{\mathcal{S}})}{\widehat{S^2}(x)}\;.
\label{eq:RegressionWeights}
\end{equation}

These weights are now computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2x }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{g }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ ((mx\_pop }\SpecialCharTok{{-}}\NormalTok{ mx\_sam) }\SpecialCharTok{*}\NormalTok{ (mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2 }\SpecialCharTok{{-}}\NormalTok{ mx\_sam)) }\SpecialCharTok{/}\NormalTok{ S2x}
\end{Highlighting}
\end{Shaded}

The sample mean of the weights equals 1,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

and the sample mean of the product of the weights and the covariate \(x\) equals the population mean of the covariate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all.equal}\NormalTok{(}\FunctionTok{mean}\NormalTok{(g }\SpecialCharTok{*}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2), }\FunctionTok{mean}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

In other words, the sample is calibrated on the known population means. The variance of the regression estimator of the population mean can be approximated by (\citet{sar92}, Section 6.6)

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\mathrm{regr}}\right)=\left(1-\frac{n}{N}\right)\frac{\sum_{k \in \mathcal{S}} g_k^2e_k^2}{n(n-1)} \;.
\label{eq:AlternativeVarianceRegressionEstimator}
\end{equation}

Comparing this with Equation \eqref{eq:VarianceRegressionEstimatorSI} shows that in the first approximation we assumed that all weights are equal to 1.

The alternative approximate standard error is computed in the next code chunk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2ge }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(g}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ e}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\FunctionTok{print}\NormalTok{(se\_mz\_regr }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*}\NormalTok{ S2ge }\SpecialCharTok{/}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.546553
\end{verbatim}

The regression estimator and its standard error can be computed with package \textbf{survey} \citep{Lumley2020}. After specifying the sampling design with function \texttt{svydesign}, function \texttt{calibrate} is used to calibrate the sample on the known population totals \(N\) and \(t(x) = \sum_{k=1}^N x_k\), with \(x_k\) the value of covariate lnSWIR2 for unit \(k\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc }\OtherTok{\textless{}{-}}\NormalTok{ N}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample,  }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc)}
\NormalTok{populationtotals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(N, }\FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(design\_si, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{population =}\NormalTok{ populationtotals, }\AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The calibrated weights\index{Calibrated weights} can be extracted with function \texttt{weights}.

\begin{rmdcaution}
The calibrated weights are divided by the inclusion probabilities \(\pi=n/N\), so that the sample sum of the weights equals \(N\) and not the sample size \(n\) (as in the code chunk above).
\end{rmdcaution}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{weights}\NormalTok{(mysample\_cal)}
\FunctionTok{all.equal}\NormalTok{(}\FunctionTok{sum}\NormalTok{(g), N)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

The sample sum of the product of the weights and the covariate equals the population total of the covariate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all.equal}\NormalTok{(}\FunctionTok{sum}\NormalTok{(g }\SpecialCharTok{*}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2), }\FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

Finally, the population mean can be estimated with function \texttt{svymean}. This is simply the sample sum of the product of the weights and the study variable AGB, divided by \(N\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 230.41 4.5466
\end{verbatim}

The standard error is computed with Equation \eqref{eq:AlternativeVarianceRegressionEstimator}. Figure \ref{fig:SamplingDistributionRegression} shows the sampling distribution of the simple regression estimator along with the distribution of the \(\pi\) estimator, obtained by repeating simple random sampling of 100 units and estimation 10,000 times.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionRegression-1} 

}

\caption{Approximated sampling distribution of the simple regression estimator (Regression) and the \(\pi\) estimator (HT) of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) in Eastern Amazonia, for simple random sampling without replacement of size 100.}\label{fig:SamplingDistributionRegression}
\end{figure}

The average of the 10,000 regression estimates equals 224.9 10\textsuperscript{9} kg ha\textsuperscript{-1}. The population mean of the study variable AGB equals 225.0 10\textsuperscript{9} kg ha\textsuperscript{-1}, so the estimated bias of the regression estimator equals -0.1 10\textsuperscript{9} kg ha\textsuperscript{-1}, which is negligibly small related to the estimated population mean. The variance of the 10,000 regression estimates equals 26.70 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, and the average of the 10,000 estimated approximate variances using Equation \eqref{eq:AlternativeVarianceRegressionEstimator} equals 26.86 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}. The gain in precision due to the regression estimator, quantified by the ratio of the variance of the \(\pi\) estimator to the variance of the regression estimator equals 3.192.

For simple random sampling the ratio of the variances of the simple regression estimator and the \(\pi\) estimator
is independent of the sample size and equals \(1-r^2\), with \(r\) the correlation coefficient of the study variable and the covariate (\citet{sar92}, p.~274).

Using multiple covariates in the regression estimator is straightforward with function \texttt{calibrate} of package \textbf{survey}. As a first step the best model is selected with function \texttt{regsubsets} of package \textbf{leaps} \citep{leaps}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(leaps)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{321}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(AGB, lnSWIR2, Terra\_PP, Prec\_dm, Elevation, Clay) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n) }
\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{regsubsets}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{nvmax =} \DecValTok{4}\NormalTok{)}
\NormalTok{res\_sum }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(models)}
\NormalTok{res\_sum}\SpecialCharTok{$}\NormalTok{outmat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         lnSWIR2 Terra_PP Prec_dm Elevation Clay
1  ( 1 ) "*"     " "      " "     " "       " " 
2  ( 1 ) "*"     "*"      " "     " "       " " 
3  ( 1 ) "*"     "*"      " "     "*"       " " 
4  ( 1 ) "*"     "*"      "*"     "*"       " " 
\end{verbatim}

The best model with one predictor is the model with lnSWIR2, the best model with two predictors is the one with lnSWIR2 and Terra\_PP, etc. Of these models the third model, i.e.~the model with lnSWIR2, Terra\_PP, and Elevation, is the best when using adjusted \(R^2\) as a selection criterion.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{which.max}\NormalTok{(res\_sum}\SpecialCharTok{$}\NormalTok{adjr2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

The standard error of the estimated mean AGB is somewhat reduced by adding the covariates Terra\_PP and Elevation to the regression estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{fpc }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc)}
\NormalTok{totals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2),}
  \FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Terra\_PP), }\FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Elevation))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(design\_si, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2 }\SpecialCharTok{+}\NormalTok{ Terra\_PP }\SpecialCharTok{+}\NormalTok{ Elevation,}
  \AttributeTok{population =}\NormalTok{ totals, }\AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 230.54 4.2224
\end{verbatim}

Another interesting package for model-assisted estimation is package \textbf{mase} \citep{mase2018}. The regression estimate can be computed with function \texttt{greg}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mase)}
\NormalTok{covars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"lnSWIR2"}\NormalTok{, }\StringTok{"Terra\_PP"}\NormalTok{, }\StringTok{"Elevation"}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{greg}\NormalTok{(}\AttributeTok{y =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{xsample =}\NormalTok{ mysample[covars],}
  \AttributeTok{xpop =}\NormalTok{ grdAmazonia[covars], }\AttributeTok{pi =} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, n),}
  \AttributeTok{var\_est =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{var\_method =} \StringTok{"LinHTSRS"}\NormalTok{, }\AttributeTok{model =} \StringTok{"linear"}\NormalTok{)}
\NormalTok{res}\SpecialCharTok{$}\NormalTok{pop\_mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 230.5407
\end{verbatim}

The multiple regression estimate is equal to the estimate obtained with function \texttt{calibrate} of package \textbf{survey}. The estimated standard error equals

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{pop\_mean\_var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         [,1]
[1,] 4.207809
\end{verbatim}

which is slightly smaller than the standard error computed with package \textbf{survey}. The standard error obtained with function \texttt{greg} is computed by ignoring the g-weights \citep{McConville2020}. In an exercise the two approximate standard errors are compared in a sampling experiment.

\hypertarget{penalised-least-squares-estimation}{%
\subsection{Penalised least squares estimation}\label{penalised-least-squares-estimation}}

In the previous subsection I first selected a best subset of covariates before using these covariates in estimating the population regression coefficients. The alternative is to skip the selection of the best model and to estimate the population regression coefficients of \emph{all} covariates by penalised least squares (PLS) estimation\index{Penalised least squares}. In PLS estimation a penalty equal to the sum of the absolute or squared values of the population regression coefficients is added to the minimisation criterion, see \citet{McConville2020} for details. PLS estimation is implemented in function \texttt{gregElasticNet} of package \textbf{mase}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"lnSWIR2"}\NormalTok{, }\StringTok{"Terra\_PP"}\NormalTok{, }\StringTok{"Prec\_dm"}\NormalTok{, }\StringTok{"Elevation"}\NormalTok{, }\StringTok{"Clay"}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{gregElasticNet}\NormalTok{(}
  \AttributeTok{y =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{xsample =}\NormalTok{ mysample[covars],}
  \AttributeTok{xpop =}\NormalTok{ grdAmazonia[covars], }\AttributeTok{pi =} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, n),}
  \AttributeTok{var\_est =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{var\_method =} \StringTok{"LinHTSRS"}\NormalTok{, }\AttributeTok{model =} \StringTok{"linear"}\NormalTok{,}
  \AttributeTok{lambda =} \StringTok{"lambda.min"}\NormalTok{, }\AttributeTok{cvfolds =} \DecValTok{100}\NormalTok{)}
\FunctionTok{signif}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{coefficients, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)     lnSWIR2    Terra_PP     Prec_dm   Elevation        Clay 
  -71.07000    -2.83800     0.02204     0.52710    -0.03507     0.13630 
\end{verbatim}

All five covariates are used in prediction, but the coefficients associated with these predictors are small except for lnSWIR2.

As shown below, the estimated standard error is considerably larger than the standard error obtained with lnSWIR2, Terra\_PP, and Elevation as predictors. In this case the elastic net regression estimator\index{Regression estimator!elastic net regression estimator} works not as well as the multiple regression estimator using the best subset of the covariates.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{pop\_mean\_var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         s1
s1 6.207637
\end{verbatim}

\hypertarget{exercises-16}{%
\subsubsection*{Exercises}\label{exercises-16}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select a simple random sample without replacement of size 50 from Eastern Amazonia. Compute the regression estimator of the population mean of AGB and its standard error ``by hand'', i.e.~without using package \textbf{survey}, using lnSWIR2 as a covariate. Use Equation \eqref{eq:VarianceRegressionEstimatorSI} to estimate the standard error.

  \begin{itemize}
  \tightlist
  \item
    Use the same sample to compute the regression estimator with functions \texttt{calibrate} and \texttt{svymean} of package \textbf{survey}. The regression estimate and its standard error can be extracted from the output object of \texttt{svymean} with methods \texttt{coef} and \texttt{SE}, respectively.
  \item
    Repeat both estimation procedures 1,000 times (for-loop). Check that the 2 \(\times\) 1,000 estimated population means obtained with both estimators are all equal (use function \texttt{all.equal}), and compute summary statistics of the two approximated standard errors. Which approximate standard error estimator has the largest mean value?\\
  \end{itemize}
\item
  Write an \textbf{R} script to compute the sampling variance of the simple regression estimator of the mean AGB, using lnSWIR2 as a covariate, for simple random sampling and sample sizes 10, 25, and 100, assuming that the population regression coefficients are perfectly known. Hint: fit a simple linear regression model on all data, and compute the population variance of the residuals.

  \begin{itemize}
  \tightlist
  \item
    Next, select 10,000 times a simple random sample with replacement of size 10 (for-loop). Use each sample to estimate the population mean of AGB with the simple regression estimator (using sample estimates of the population regression coefficients), and estimate the approximate variance of the estimator of the mean. Compute the variance of the 10,000 regression estimates and the average of the 10,000 approximate variance estimates. Repeat this for sample sizes 25 and 100.
  \item
    Compute for each sample size the difference between the experimental variance (variance of the 10,000 regression estimates) and the variance obtained with the population fit of the regression model as a proportion of the experimental variance. Explain what you see.
  \item
    Compute for each sample size the difference between the average of the 10,000 approximated variances and the experimental variance as a proportion of the experimental variance. Explain what you see.
  \end{itemize}
\end{enumerate}

\hypertarget{RegressionEstimatorSTSI}{%
\subsection{Regression estimator with stratified simple random sampling}\label{RegressionEstimatorSTSI}}

With stratified simple random sampling there are two regression estimators, the \emph{separate} and the \emph{combined} regression estimator. In the first estimator the regression estimator for simple random sampling is applied at the level of the strata\index{Regression estimator!separate regression estimator}. This implies that for each stratum separately a vector with population regression coefficients \(\mathbf{b}_h\) is estimated. The regression estimates of the stratum means are then combined by computing the weighted average, using the relative sizes of the strata as weights:

\begin{equation}
\hat{\bar{z}}_{\mathrm{sregr}}=\sum_{h=1}^H w_h \hat{\bar{z}}_{\text{regr,}h} \;,
\label{eq:SeparateRegressionEstimator}
\end{equation}

with, for the simple linear estimator

\begin{equation}
\hat{\bar{z}}_{\text{regr,}h} = \bar{z}_{\mathcal{S}h}+\hat{b}_h\left( \bar{x}_h-\bar{x}_{\mathcal{S}h}\right) \;,
\label{eq:RegressionEstimatorStratumMean}
\end{equation}

with \(\bar{z}_{\mathcal{S}h}\) and \(\bar{x}_{\mathcal{S}h}\) the stratum sample means of the study variable and the covariate, respectively, \(\bar{x}_h\) the mean of the covariate in stratum \(h\), and \(\hat{b}_h\) the estimated slope coefficient for stratum \(h\).

The variance of this separate regression estimator of the population mean can be estimated by first estimating the variances of the regression estimators of the stratum means using Equation \eqref{eq:VarianceRegressionEstimatorSI}, and then combining these variances using Equation \eqref{eq:EstVarMeanSTSI}.

The separate regression estimator is illustrated with Eastern Amazonia. Biomes are used as strata. There are four biomes, the levels of which are given short names using function \texttt{levels}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Mangroves"                                               
[2] "Tropical & Subtropical Dry Broadleaf Forests"            
[3] "Tropical & Subtropical Grasslands, Savannas & Shrublands"
[4] "Tropical & Subtropical Moist Broadleaf Forests"          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{biomes }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Mangrove"}\NormalTok{, }\StringTok{"Forest\_dry"}\NormalTok{, }\StringTok{"Grassland"}\NormalTok{, }\StringTok{"Forest\_moist"}\NormalTok{)}
\FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome) }\OtherTok{\textless{}{-}}\NormalTok{ biomes}
\end{Highlighting}
\end{Shaded}

Moist forest is by far the largest stratum, it covers 92\% of the area. Mangrove, Forest\_dry, and Grassland cover 0.4\%, 2.3\%, and 5.5\% of the area, respectively. A stratified simple random sample of size 100 is selected using function \texttt{strata} of package \textbf{sampling}, see Chapter \ref{STSI}. I chose five units as a minimum sample size. Note that the stratum sample sizes are not proportional to their size.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{N\_h }\OtherTok{\textless{}{-}}  \FunctionTok{table}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{85}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(grdAmazonia, }\AttributeTok{stratanames =} \StringTok{"Biome"}\NormalTok{,}
  \AttributeTok{size =}\NormalTok{ n\_h[}\FunctionTok{unique}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)], }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(grdAmazonia, units)}
\end{Highlighting}
\end{Shaded}

As a first step in estimation, for each stratum the mean of the covariate over all units in a stratum (population mean per stratum) and the sample means of the study variable and the covariate are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mx\_h\_pop }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2, }\AttributeTok{INDEX =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mzh\_sam }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mx\_h\_sam }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean)}
\end{Highlighting}
\end{Shaded}

The next step is to estimate the regression coefficients (intercept and slope) per stratum. This is done in a for-loop. The estimated slope coefficient is used to compute the regression estimator per stratum. The residuals are extracted to approximate the variance of the regression estimator per stratum.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b\_h }\OtherTok{\textless{}{-}}\NormalTok{ mz\_h\_regr }\OtherTok{\textless{}{-}}\NormalTok{ v\_mz\_h\_regr }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{4}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  subsam }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(mysample, mysample}\SpecialCharTok{$}\NormalTok{Biome }\SpecialCharTok{==} \FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)[i])}
\NormalTok{  lm\_sample }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ subsam)}
\NormalTok{  b\_h[i] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(lm\_sample)[}\DecValTok{2}\NormalTok{]}
\NormalTok{  mz\_h\_regr[i] }\OtherTok{\textless{}{-}}\NormalTok{ mzh\_sam[i] }\SpecialCharTok{+}\NormalTok{ b\_h[i] }\SpecialCharTok{*}\NormalTok{ (mx\_h\_pop[i] }\SpecialCharTok{{-}}\NormalTok{ mx\_h\_sam[i])}
\NormalTok{  e }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(lm\_sample)}
\NormalTok{  S2e\_h }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(e)}
\NormalTok{  v\_mz\_h\_regr[i] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n\_h[i] }\SpecialCharTok{/}\NormalTok{ N\_h[i]) }\SpecialCharTok{*}\NormalTok{ S2e\_h }\SpecialCharTok{/}\NormalTok{ n\_h[i]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Finally, the separate regression estimate is computed as a weighted average of the regression estimates per stratum.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w\_h }\OtherTok{\textless{}{-}}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h)}
\FunctionTok{print}\NormalTok{(mz\_sepreg }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mz\_h\_regr))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 223.9426
\end{verbatim}

The standard error of the separate regression estimator is computed by the square root of the pooled variances of the regression estimator per stratum, using the squared relative sizes of the strata as weights.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_mz\_h\_regr) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sqrt}\NormalTok{(.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5.077558
\end{verbatim}

The separate regression estimator can be computed with package \textbf{survey}. The computation of the population totals merits special attention. For the simple regression estimator using simple random sampling these totals are the total number of population units and the population total of the covariate lnSWIR2. These are the population totals associated with the columns of the design matrix that is constructed with function \texttt{lm} to estimate the regression coefficients. The column with ones results in an estimated intercept, the column with lnSWIR2 values in an estimated slope.

The model that is fitted now is an analysis of covariance (ANCOVA) model\index{ANCOVA model} with factor Biome and covariate lnSWIR2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ancova }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Biome }\SpecialCharTok{*}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ mysample)}
\end{Highlighting}
\end{Shaded}

\textbf{R} uses the so-called cornerstone representation of the ANCOVA model. The reference level is stratum Mangrove. The question is what population totals must be passed to function \texttt{calibrate} with this ANCOVA model. This can be determined by printing the design matrix that is used to fit the ANCOVA model. Only the first two rows are printed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designmat }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(ancova, mysample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     (Intercept) BiomeForest_dry BiomeGrassland BiomeForest_moist  lnSWIR2
[1,]           1               0              0                 1 6.307024
[2,]           1               0              0                 1 6.236278
     BiomeForest_dry:lnSWIR2 BiomeGrassland:lnSWIR2 BiomeForest_moist:lnSWIR2
[1,]                       0                      0                  6.307024
[2,]                       0                      0                  6.236278
\end{verbatim}

With this model formulation the first population total is the total number of population units. The second, third, and fourth population totals are the number of population units in stratum levels 2, 3, and 4. The fifth population total is the population total of covariate lnSWIR2 and the sixth, seventh, and eighth population totals are the totals of covariate lnSWIR2 in stratum levels 2, 3, and 4.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_h }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(N\_h)}
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Biome =}\NormalTok{ biomes, N\_h)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mysample, }\AttributeTok{y =}\NormalTok{ lut)}
\NormalTok{design\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Biome), }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ N\_h)}
\NormalTok{tx\_pop }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{tx\_h\_pop }\OtherTok{\textless{}{-}}\NormalTok{ N\_h }\SpecialCharTok{*}\NormalTok{ mx\_h\_pop}
\NormalTok{totals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{sum}\NormalTok{(N\_h), N\_h[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)], tx\_pop, tx\_h\_pop[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)])}
\FunctionTok{names}\NormalTok{(totals) }\OtherTok{\textless{}{-}} \FunctionTok{names}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ancova))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(}
\NormalTok{  design\_stsi, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ Biome }\SpecialCharTok{*}\NormalTok{ lnSWIR2,}
  \AttributeTok{population =}\NormalTok{ totals, }\AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 223.94 5.8686
\end{verbatim}

\begin{rmdnote}
The line \texttt{names(totals)\ \textless{}-\ names(coef(ancova))} is not strictly needed. This is just to suppress a warning that the names of the numeric with the population totals does not match the names of the columns of the design matrix. As a consequence, we do not need to fit the ANCOVA model either.
\end{rmdnote}

Alternatively, we may use the following formula in function \texttt{lm}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ancova2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ Biome }\SpecialCharTok{/}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ mysample)}
\NormalTok{designmat }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(ancova, mysample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     (Intercept) BiomeForest_dry BiomeGrassland BiomeForest_moist  lnSWIR2
[1,]           1               0              0                 1 6.307024
[2,]           1               0              0                 1 6.236278
     BiomeForest_dry:lnSWIR2 BiomeGrassland:lnSWIR2 BiomeForest_moist:lnSWIR2
[1,]                       0                      0                  6.307024
[2,]                       0                      0                  6.236278
\end{verbatim}

With this formula the population totals are the number of population units in stratum levels 1, 2, 3, and 4, as well as the population totals of covariate lnSWIR2 of the strata.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{totals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(N\_h, tx\_h\_pop)}
\FunctionTok{names}\NormalTok{(totals) }\OtherTok{\textless{}{-}} \FunctionTok{names}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ancova2))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(}
\NormalTok{  design\_stsi, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ Biome }\SpecialCharTok{/}\NormalTok{ lnSWIR2, }\AttributeTok{population =}\NormalTok{ totals,}
  \AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 223.94 5.8686
\end{verbatim}

\hypertarget{combined-regression-estimator}{%
\subsubsection{Combined regression estimator}\label{combined-regression-estimator}}

The alternative to the separate simple regression estimator is the combined simple regression estimator\index{Regression estimator!combined regression estimator}:

\begin{equation}
\hat{\bar{z}}_{\mathrm{cregr}} = \hat{\bar{z}}_{\pi}+\hat{b}\left( \bar{x}-\hat{\bar{x}}_{\pi}\right) \;,
\label{eq:CombinedRegressionEstimator}
\end{equation}

with \(\hat{b}\) the estimated slope coefficient, estimated by Equation \eqref{eq:EstimatorGREGCoefficients}, discarding the variance of the residuals \(\sigma^2(\epsilon_k)\) as they are assumed constant, and using the appropriate inclusion probabilities which differ among the strata, and \(\hat{\bar{z}}_{\pi}\) and \(\hat{\bar{x}}_{\pi}\) the \(\pi\) estimators of the population mean of the study variable and the covariate for stratified simple random sampling, respectively. Working Equation \eqref{eq:EstimatorGREGCoefficients} out for stratified simple random sampling yields

\begin{equation}
\hat{b}=\frac{w^2_h \widehat{S^2}_h(z,x)}{w^2_h \widehat{S^2}_h(x)}\;,
\label{eq:bCombinedRegressionEstimator}
\end{equation}
with \(\widehat{S^2}_h(z,x)\) the estimated covariance of the study variable and the covariate in stratum \(h\) and \(\widehat{S^2}_h(x)\) the estimated variance of the covariate.

In the combined simple regression estimator only one regression coefficient \(b\) is estimated, the slope coefficient for the entire population. This combined regression estimator is recommended when the stratum sample sizes are so small (as in our case) that the estimated regression coefficients per stratum, \(\hat{b}_h\), become unreliable.

\begin{rmdcaution}
Estimator \eqref{eq:bCombinedRegressionEstimator} is for infinite populations and for stratified simple random sampling with replacement of finite populations. For sampling without replacement from finite populations, finite population corrections \(1-n_h/N_h\) must be added to the numerator and denominator of \(\hat{b}\) (\citet{coc77}, p.~202).
\end{rmdcaution}

The approximate variance of the combined regression estimator can be estimated as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute residuals: \(e_k = z_k - (\hat{a} + \hat{b} x_k)\), with \(\hat{a}\) and \(\hat{b}\) the estimated regression coefficients for the whole population.\\
\item
  Estimate for each stratum the variance of the estimator of the mean of the residuals: \(\widehat{V}\!\left(\hat{\bar{e}}_h\right)=\widehat{S^{2}}_h(e)/n_h\), with \(\widehat{S^{2}}_h(e)\) the estimated variance of the residuals in stratum \(h\).\\
\item
  Combine the estimated variances per stratum: \(\widehat{V}\!\left(\hat{\bar{z}}_{\text{cregr}}\right)=\sum_{h=1}^Hw^2_h\widehat{V}\!\left(\hat{\bar{e}}_h\right)\).
\end{enumerate}

The next code chunks show the estimation procedure. First, the population means of the study variable AGB and of the covariate lnSWIR2 are estimated by the \(\pi\) estimator, see Chapter \ref{STSI}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_h\_HT }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mx\_h\_HT }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mz\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mz\_h\_HT)}
\NormalTok{mx\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mx\_h\_HT)}
\end{Highlighting}
\end{Shaded}

The next step is to estimate the population regression coefficients, using Equation \eqref{eq:EstimatorGREGCoefficients} in which the variances \(\sigma^2(\epsilon_k)\) can be dropped, as these are assumed constant. The inclusion probabilities are in column \texttt{Prob} of \texttt{mysample}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\AttributeTok{x =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Prob, }\AttributeTok{nrow =}\NormalTok{ n, }\AttributeTok{ncol =}\NormalTok{ n)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =}\NormalTok{ n, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{data =} \DecValTok{1}\NormalTok{)}
\NormalTok{X[, }\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2}
\NormalTok{XWX }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ W }\SpecialCharTok{\%*\%}\NormalTok{ X}
\NormalTok{XWz }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ W }\SpecialCharTok{\%*\%}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB}
\FunctionTok{print}\NormalTok{(ab }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(}\FunctionTok{solve}\NormalTok{(XWX, XWz)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         [,1]      [,2]
[1,] 1678.268 -226.6772
\end{verbatim}

Note that the same estimates are obtained by model-based estimation, using weighted least squares\index{Weighted least squares}, based on the assumption that the variances \(\sigma^2(\epsilon_k)\) are proportional to the inclusion probabilities (which is a weird assumption).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_wls }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{weights =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ Prob, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{coef}\NormalTok{(lm\_wls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)     lnSWIR2 
  1678.2684   -226.6772 
\end{verbatim}

\begin{rmdnote}
In model-based estimation the weights differ among the units because of assumed differences in the variance of the residuals, whereas in design-based estimation we assign different weights to the observations because the units have different inclusion probabilities \citep{loh99}.
\end{rmdnote}

Finally, the combined regression estimate is computed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mz\_combreg }\OtherTok{\textless{}{-}}\NormalTok{ mz\_HT }\SpecialCharTok{+}\NormalTok{ ab[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ (mx\_pop }\SpecialCharTok{{-}}\NormalTok{ mx\_HT))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 224.1433
\end{verbatim}

To approximate the variance of the combined regression estimator first the residuals are computed. Then these residuals are used to estimate the spatial variance of the residuals within the strata, \(\widehat{S^{2}}_h(e)\), and the variance of the estimator of the mean of the residuals, \(\widehat{V}\!\left(\hat{\bar{e}}_h\right)\). Finally, by taking the square root the estimated standard error is obtained.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ (ab[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ ab[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{v\_me\_h }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{4}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  subsam }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(mysample, mysample}\SpecialCharTok{$}\NormalTok{Biome }\SpecialCharTok{==} \FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)[i])}
\NormalTok{  S2e\_h }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(subsam}\SpecialCharTok{$}\NormalTok{e)}
\NormalTok{  v\_me\_h[i] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n\_h[i] }\SpecialCharTok{/}\NormalTok{ N\_h[i]) }\SpecialCharTok{*}\NormalTok{ S2e\_h }\SpecialCharTok{/}\NormalTok{ n\_h[i]}
\NormalTok{\}}
\FunctionTok{print}\NormalTok{(se\_mz\_combreg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_me\_h)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5.122518
\end{verbatim}

Computing the combined regression estimator with package \textbf{survey} proceeds as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Biome), }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ N\_h)}
\NormalTok{totals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\FunctionTok{sum}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(}
\NormalTok{  design\_stsi, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{population =}\NormalTok{ totals,}
  \AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 224.14 5.8707
\end{verbatim}

Function \texttt{calibrate} computes the regression estimate and its standard error with the calibrated weights\index{Calibrated weights} \(g_k\) (\citet{sar92}, Equation (6.5.12)). This explains the difference between the two standard errors.

\hypertarget{RatioEstimator}{%
\section{Ratio estimator}\label{RatioEstimator}}

In some cases it is reasonable to assume that the fitted line passes through the origin. An example is the case study on poppy area in Kandahar (Chapter \ref{pps}). The covariate is the agricultural area within the 5 km squares that serve as sampling units. It is reasonable to assume that when the covariate equals zero, also the poppy area is zero. So, if we have an estimate of the ratio of the total poppy area in the population to the total agricultural area in the population and besides know the total agricultural area in the population, the total poppy area in the population can be estimated by multiplying the estimated ratio with the known population total agricultural area:

\begin{equation}
\hat{t}_{\mathrm{ratio}}(z)=\frac{\hat{t}_{\pi}(z)}{\hat{t}_{\pi}(x)} \;t(x) =  \hat{b} \;t(x)\;,
\label{eq:RatioEstimator}
\end{equation}

with \(\hat{t}_{\pi}(z)\) and \(\hat{t}_{\pi}(x)\) the \(\pi\) estimators of the total of the study variable (poppy area) and the ancillary variable (agricultural area), respectively, and \(t(x)\) the total of the ancillary variable, which must be known.

The working model\index{Working model} of the ratio estimator\index{Ratio estimator} is a heteroscedastic model, i.e.~a model with non-constant variance, without intercept (see Exercise 3 hereafter):

\begin{equation}
\begin{split}
Z(x_k) &= \beta \;x_k  + \epsilon_k \\
\sigma^2(\epsilon_k) &= \sigma^2 x_k \;,
\end{split}
\label{eq:ratiomodel}
\end{equation}

with \(\beta\) the slope of the line and \(\sigma^2\) a constant (variance of residual for \(x_k = 1\)). The residual variance is assumed proportional to the covariate \(x\).

\begin{rmdnote}
The ratio estimator was applied before to estimate the population mean or population total from a systematic random sample (Chapter \ref{SY}), a (two-stage) cluster random sample (Sections \ref{SIC} and \ref{TwostageSISI}), and a ppswor sample (Section \ref{ppswor}). By taking \(x_k = 1,\; k=1, \dots , N\), \(\hat{t}_{\pi}(x)\) in Equation \eqref{eq:RatioEstimator} is equal to \(\hat{N}\), and \(t(x)\) is equal to \(N\). For (two-stage) cluster random sampling \(M\) is used for the total number of population units (\(N\) is the total number of clusters or primary sampling units in the population) and thefore \(\hat{t}_{\pi}(x)=\hat{M}\) and \(t(x)=M\). This yields the ratio estimators of the population total appropriate for these sampling designs.
\end{rmdnote}

Equation \eqref{eq:RatioEstimator} is a general estimator that can be used for any probability sampling design, not only for simple random sampling. For simple random sampling the coefficient \(b\) is estimated by the ratio of the sample means of \(z\) and \(x\).

For simple random sampling the sampling variance of the ratio estimator of the population total can be approximated by

\begin{equation}
\widehat{V}\!\left(\hat{t}_{\mathrm{ratio}}(z)\right)=N^2\frac{\widehat{S^{2}}(e)}{n} \;,
\label{eq:VarianceRatioEstimatorSI}
\end{equation}

with \(\widehat{S^{2}}(e)\) the estimated variance of the residuals \(e_k=z_k-\hat{b}x_k\):

\begin{equation}
\widehat{S^{2}}(e)=\frac{1}{n-1}\sum_{k \in \mathcal{S}}e_k^2 \;.
\label{eq:VarianceResidualsRatioEstimator}
\end{equation}

For simple random sampling without replacement from finite populations Equation \eqref{eq:VarianceRatioEstimatorSI} must be multiplied by \(\left(1-\frac{n}{N}\right)\).

In \textbf{R} the ratio estimator for the total poppy area and the estimator of its variance for a simple random sample without replacement can be computed as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdKandahar)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdKandahar[units, ]}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{poppy) }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{agri)}
\NormalTok{tx\_pop }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri)}
\FunctionTok{print}\NormalTok{(tz\_ratio }\OtherTok{\textless{}{-}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ tx\_pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 55009.69
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{poppy }\SpecialCharTok{{-}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{agri}
\FunctionTok{print}\NormalTok{(se\_tz\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (n }\SpecialCharTok{/}\NormalTok{ N)) }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(e) }\SpecialCharTok{/}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 18847.31
\end{verbatim}

An improved variance approximation is obtained with Equation \eqref{eq:AlternativeVarianceRegressionEstimator}. For the ratio model and simple random sampling the calibrated weights are equal to (\citet{sar92}, p.~248)

\begin{equation}
g = \frac{t(x)}{\hat{t}_{\pi}(x)} \;,
\label{eq:weightsratiomodel}
\end{equation}

with \(t(x)\) the population total of the covariate and \(\hat{t}_{\pi}(x)\) the \(\pi\) estimate of the population total of the covariate.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N}
\NormalTok{tx\_HT }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{agri }\SpecialCharTok{/}\NormalTok{ pi)}
\NormalTok{g }\OtherTok{\textless{}{-}}\NormalTok{ tx\_pop }\SpecialCharTok{/}\NormalTok{ tx\_HT}
\NormalTok{S2ge }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(g}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ e}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\FunctionTok{print}\NormalTok{(se\_tz\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*}\NormalTok{ S2ge }\SpecialCharTok{/}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 17149.62
\end{verbatim}

The ratio estimate and the estimated standard error of the ratio estimator can be computed with package \textbf{survey} as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{N }\OtherTok{\textless{}{-}}\NormalTok{ N}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ N)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{svyratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ agri, }\AttributeTok{design =}\NormalTok{ design\_si)}
\FunctionTok{predict}\NormalTok{(b, }\AttributeTok{total =}\NormalTok{ tx\_pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$total
          agri
poppy 55009.69

$se
          agri
poppy 17149.62
\end{verbatim}



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SamplingDistributionRatio-1} 

}

\caption{Approximated sampling distribution of the ratio estimator (Ratio) and the \(\pi\) estimator (HT) of the total poppy area (ha) in Kandahar with simple random sampling without replacement of size 50.}\label{fig:SamplingDistributionRatio}
\end{figure}

Figure \ref{fig:SamplingDistributionRatio} shows the sampling distribution of the ratio estimator and the \(\pi\) estimator, obtained by repeating simple random sampling of size 50 and estimation 10,000 times. The average of the 10,000 ratio estimates of the total poppy area equals 62,512. The population total of poppy equals 63,038 ha, so the estimated bias of the ratio estimator equals -526 ha. The boxplots in Figure \ref{fig:SamplingDistributionRatio} show that the ratio estimator has less extreme outliers. The standard deviation of the 10,000 ratio estimates equals 24,177 ha. The gain in precision due to the ratio estimator, quantified by the ratio of the variance of the \(\pi\) estimator to the variance of the ratio estimator, equals 1.502.

\hypertarget{exercises-17}{%
\subsubsection*{Exercises}\label{exercises-17}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write an \textbf{R} script to compute the ratio of the population total poppy area to the population total agricultural area (\(t(z)/t(x)\)). Then use all data to fit a linear model without intercept for the poppy area, using the agricultural area as a covariate, assuming that the variance of the residuals is proportional to the agricultural area (heteroscedastic model). Hint: use function \texttt{lm} with argument \texttt{formula\ =\ poppy\ \textasciitilde{}\ agri\ -\ 1} and argument \texttt{weights\ =\ 1\ /\ agri}. Also fit a model without intercept, assuming a constant variance of the residuals (homoscedastic model). Compare the estimated slopes of the two models with the ratio of the total poppy area to the total agricultural area.
\end{enumerate}

\hypertarget{RatioEstimatorSTSI}{%
\subsection{Ratio estimators with stratified simple random sampling}\label{RatioEstimatorSTSI}}

With stratified simple random sampling, there are, similar to the regression estimator, two options for estimating a population parameter: either estimate the ratios separately for the strata or estimate a combined ratio. The separate ratio estimator\index{Ratio estimator!separate ratio estimator} of the population total is

\begin{equation}
\hat{t}_{\mathrm{sratio}}(z)=\sum_{h=1}^H \hat{t}_{\mathrm{ratio},h}(z) \;,
\label{eq:SeparateRatioEstimatorSTSI}
\end{equation}

with

\begin{equation}
\hat{t}_{\mathrm{ratio},h}(z)=\frac{\hat{t}_{\pi,h}(z)}{\hat{t}_{\pi,h}(x)} t_h(x) \;,
\label{eq:RatioEstimatorStratumTotal}
\end{equation}

in which \(\hat{t}_{\pi,h}(z)\) and \(\hat{t}_{\pi,h}(x)\) are the \(\pi\) estimators of the population total of the study variable and the covariate for stratum \(h\), respectively.

The combined ratio estimator\index{Ratio estimator!combined ratio estimator} is

\begin{equation}
\hat{t}_{\mathrm{cratio}}(z)=\frac{\sum_{h=1}^H\hat{t}_{\pi,h}(z)}{\sum_{h=1}^H\hat{t}_{\pi,h}(x)} t(x) \;.
\label{eq:CombinedRatioEstimatorSTSI}
\end{equation}

The code chunks below show how the combined and separate regression estimate can be computed with package \textbf{survey}. First, two equal-sized strata are computed using the median of the covariate \texttt{agri} as a stratum bound. Stratum sample sizes are computed, and a stratified simple random sample without replacement is selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{median\_agri }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri, }\AttributeTok{probs =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{grdKandahar}\SpecialCharTok{$}\NormalTok{stratum }\OtherTok{\textless{}{-}} \FunctionTok{findInterval}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri, median\_agri) }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{N\_h }\OtherTok{\textless{}{-}}  \FunctionTok{table}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{stratum)}
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(grdKandahar, }\AttributeTok{stratanames =} \StringTok{"stratum"}\NormalTok{,}
  \AttributeTok{size =}\NormalTok{ n\_h, }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(grdKandahar, units)}
\end{Highlighting}
\end{Shaded}

The stratum sizes \texttt{N\_h} are added to \texttt{mysample}, function \texttt{svydesign} specifies the sampling design, function \texttt{svyratio} estimates the population ratio and its variance, and finally function \texttt{predict} estimates the population total.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{stratum =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), N\_h)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mysample, }\AttributeTok{y =}\NormalTok{ lut)}
\NormalTok{design\_stsi }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}
  \AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ stratum, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ Freq)}
\NormalTok{common }\OtherTok{\textless{}{-}} \FunctionTok{svyratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ agri, design\_stsi, }\AttributeTok{separate =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{predict}\NormalTok{(common, }\AttributeTok{total =} \FunctionTok{sum}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$total
          agri
poppy 28389.02

$se
          agri
poppy 8845.847
\end{verbatim}

The same estimate is obtained with function \texttt{calibrate}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(}
\NormalTok{  design\_stsi, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ agri }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{population =}\NormalTok{ tx\_pop, }\AttributeTok{variance =} \DecValTok{1}\NormalTok{)}
\FunctionTok{svytotal}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      total     SE
poppy 28389 8845.8
\end{verbatim}

Computing the separate ratio estimator goes along the same lines. Function \texttt{svyratio} with argument \texttt{separate\ =\ TRUE} estimates the ratio and its variance for each stratum separately. To predict the population total the stratum totals of the covariate must be passed to function \texttt{predict} using argument \texttt{total}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{separate }\OtherTok{\textless{}{-}} \FunctionTok{svyratio}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ poppy, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ agri, design\_stsi, }\AttributeTok{separate =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{tx\_h\_pop }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdKandahar}\SpecialCharTok{$}\NormalTok{agri, }\AttributeTok{INDEX =}\NormalTok{ grdKandahar}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ sum)}
\FunctionTok{predict}\NormalTok{(separate, }\AttributeTok{total =}\NormalTok{ tx\_h\_pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$total
          agri
poppy 28331.32

$se
          agri
poppy 8882.492
\end{verbatim}

\hypertarget{PoststratifiedEstimator}{%
\subsection{Poststratified estimator}\label{PoststratifiedEstimator}}

In stratified random sampling (Chapter \ref{STSI}) the population is divided into several disjoint subpopulations and from each subpopulation a probability sample is selected. The subpopulations then serve as strata. The larger the difference in the stratum means and the smaller the variance within the strata, the larger the gain in precision compared to simple random sampling, see Subsection \ref{WhyStratify}.

The alternative to using the subpopulations as strata at the stage of sampling is to use them as poststrata in estimating the population mean. For instance, if we have selected a simple random sample from a spatial population and we have a map of subpopulations possibly related to the study variable, then these subpopulations still can be used in the poststratified estimator\index{Poststratified estimator}. What only needs to be done is to classify the selected units. Hereafter the subpopulations that serve as poststrata are referred to as groups.

For any probability sampling design the population mean can be estimated by

\begin{equation}
\hat{\bar{z}}_{\text{pos}}=
\sum_{g=1}^{G} w_{g}\frac{\hat{t}_g(z)}{\widehat{N}_{g}} =
\sum_{g=1}^{G} w_{g}\frac{\sum_{k \in \mathcal{S}_g}\frac{z_{k}}{\pi_k}}
{\sum_{k \in \mathcal{S}_g}\frac{1}{\pi_k}} \;,
\label{eq:PostStratifiedEstimator}
\end{equation}

where \(\mathcal{S}_g\) is the sample from group \(g\), \(w_{g}=N_g/N\) is the relative size of group \(g\), \(\hat{t}_g(z)\) is the estimated total of the study variable for group \(g\), \(\widehat{N}_{g}\) is the estimator of the size of group \(g\), and \(\pi_{k}\) is the inclusion probability of unit \(k\). The estimated group means are weighted by their relative sizes \(w_{g}\), which are assumed to be known. In spite of this, the group means are estimated by dividing the estimated group totals by their \emph{estimated} size, \(\widehat{N}_{g}\), because this ratio estimator is more precise than the \(\pi\) estimator of the group mean.

The poststratified estimator is the natural estimator for the one-way ANOVA model\index{ANOVA model!one-way ANOVA model},

\begin{equation}
\begin{split}
Z_k &= \mu_g  + \epsilon_k \\
\sigma^2_k &= \sigma^2_g \;,
\end{split}
\label{eq:ANOVAmodel}
\end{equation}

with \(\mu_g\) the mean for group (subpopulation) \(g=1, \dots , G\) and \(\sigma^2_g\) the variance of the study variable of group \(g\).

For simple random sampling, the poststratified estimator reduces to

\begin{equation}
\hat{\bar{z}}_{\text{pos}}=\sum_{g=1}^{G}w_{g}\,\bar{z}_{\mathcal{S}_g} \;,
\label{eq:PostStratifiedEstimatorSI}
\end{equation}

where \(\bar{z}_{\mathcal{S}_g}\) is the sample mean of group \(g\). If for all groups we have at least two sampling units, \(n_g \geq 2\), the variance of this poststratified estimator of the mean can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{pos}}|\mathbf{n}_g\right)=
\sum_{g=1}^{G}w_{g}^{2}\frac{\widehat{S_{g}^{2}}}{n_{g}} \;,
\label{eq:CondVarPostStratifiedEstimator}
\end{equation}

where \(n_{g}\) is the number of sampling units in group \(g\), and \(\widehat{S_{g}^{2}}\) is the estimated spatial variance of \(z\) in
group \(g\), which for simple random sampling can be estimated by

\begin{equation}
\widehat{S_{g}^{2}}=\frac{1}{n_{g}-1}\sum_{k \in \mathcal{S}_g}(z_{k}-\bar{z}_{\mathcal{S}_g})^{2} \;.
\label{eq:S2g}
\end{equation}

This is an estimator of the \emph{conditional} sampling variance, i.e.~the variance of the poststratified estimator over all simple random samples with group sample sizes, collected in the vector \(\mathbf{n}_g\), equal to the group sample sizes in the sample actually selected. The poststratified estimator requires that the sizes (areas) of the strata are known. See Section \ref{TwophaseStratification} for a sampling strategy that does not require known stratum sizes.

The poststratified estimator is illustrated with study area Voorst. We consider the situation that we do not have the map with the five combinations of soil type and land use that served as strata in Chapter \ref{STSI}. The soil-land use classes (groups) used in the poststratified estimator are only observed at the selected sampling units. Only three poststrata are distinguished: the original strata BA, EA, and PA are merged into one stratum SA with function \texttt{fct\_collapse} of package \textbf{forcats} \citep{forcats}. The sizes of these poststrata must be known.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(forcats)}
\NormalTok{grdVoorst}\SpecialCharTok{$}\NormalTok{poststratum }\OtherTok{\textless{}{-}} \FunctionTok{fct\_collapse}\NormalTok{(}
\NormalTok{  grdVoorst}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{SA =} \FunctionTok{c}\NormalTok{(}\StringTok{"BA"}\NormalTok{, }\StringTok{"EA"}\NormalTok{, }\StringTok{"PA"}\NormalTok{))}
\FunctionTok{print}\NormalTok{(N\_g }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdVoorst}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ grdVoorst}\SpecialCharTok{$}\NormalTok{poststratum, }\AttributeTok{FUN =}\NormalTok{ length))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  SA   RA   XF 
5523  659 1346 
\end{verbatim}

One hundred points are selected by simple random sampling with replacement. The expected sample sizes per group are proportional to the size of the groups, \(E(n_g/n) = N_g/N\), but for a single sample the sample proportions may deviate considerably from the population proportions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[units, ]}
\NormalTok{n\_g }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{poststratum, }\AttributeTok{FUN =}\NormalTok{ length)}
\FunctionTok{print}\NormalTok{(n\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
SA RA XF 
71  6 23 
\end{verbatim}

The population mean is estimated by first computing the sample means per group, followed by computing the weighted average of the sample means, using the relative sizes of the groups as weights.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_g }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{poststratum, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{w\_g }\OtherTok{\textless{}{-}}\NormalTok{ N\_g }\SpecialCharTok{/}\NormalTok{ N}
\FunctionTok{print}\NormalTok{(mz\_pst }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w\_g }\SpecialCharTok{*}\NormalTok{ mz\_g))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 85.11039
\end{verbatim}

The variance of the estimator of the mean is estimated by computing the sample variances per group, dividing these by the sample sizes per group, and computing the weighted average, using as weights the squared relative group sizes. This estimated sampling variance is the variance of the estimator of the mean over all simple random samples with 71 units of group SA, 6 units of group RA, and 23 units of XF.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2z\_g }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{poststratum, }\AttributeTok{FUN =}\NormalTok{ var)}
\NormalTok{v\_mz\_g }\OtherTok{\textless{}{-}}\NormalTok{ S2z\_g }\SpecialCharTok{/} \FunctionTok{as.numeric}\NormalTok{(n\_g)}
\FunctionTok{print}\NormalTok{(condse\_mz\_pst }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_g}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ v\_mz\_g)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.49969
\end{verbatim}

Note that this variance estimator can only be computed with at least two units per group. For this reason, I recommend to use a limited number of groups, especially for small sample sizes.

Function \texttt{postStratify} of package \textbf{survey} can be used to compute the poststratified estimator and its standard error.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ N }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{weights =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ weights, }\AttributeTok{data =}\NormalTok{ mysample)}
\NormalTok{pop }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{poststratum =} \FunctionTok{c}\NormalTok{(}\StringTok{"SA"}\NormalTok{, }\StringTok{"RA"}\NormalTok{, }\StringTok{"XF"}\NormalTok{), }\AttributeTok{Freq =}\NormalTok{ N\_g)}
\NormalTok{mysample\_pst }\OtherTok{\textless{}{-}} \FunctionTok{postStratify}\NormalTok{(}
\NormalTok{  design\_si, }\AttributeTok{strata =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ poststratum, }\AttributeTok{population =}\NormalTok{ pop)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, mysample\_pst)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   mean     SE
z 85.11 4.3942
\end{verbatim}

\begin{rmdwarning}
\citet{loh99} warns for data snooping\index{Data snooping}. By defining groups after analysing the data, arbitrarily small sampling variances of the estimated mean can be obtained.
\end{rmdwarning}

\hypertarget{RandomForest}{%
\section{Model-assisted estimation using machine learning techniques}\label{RandomForest}}

\citet{Breidt2017} review model-assisted estimators based on machine learning techniques\index{Machine learning technique}. Of special interest is the general approach proposed by \citet{Wu2001} for incorporating non-linear predictions in the model-assisted estimator. They show how non-linear predictions of the study variable, for instance obtained by a regression tree or random forest, can be used in the model-calibration estimator:

\begin{equation}
\hat{\bar{z}}_{\mathrm{MC}}= \hat{\bar{z}}_{\pi} + \hat{a}\left(1-\frac{1}{N}\sum_{k \in \mathcal{S}}\frac{1}{\pi_k}\right)+ \hat{b}\left(\frac{1}{N}\sum_{k=1}^N \hat{m}(\mathbf{x}_k) - \frac{1}{N}\sum_{k \in \mathcal{S}} \frac{\hat{m}(\mathbf{x}_k)}{\pi_k} \right)
\;,
\label{eq:ModelCalibrationEstimator}
\end{equation}

with \(\hat{b}\) a slope coefficient estimated by

\begin{equation}
\hat{b} = \frac{\sum_{k \in \mathcal{S}} 1/\pi_k \{\hat{m}(\mathbf{x}_k)-\hat{\bar{m}}_{\pi}\} \{z_k-\hat{\bar{z}}_{\pi}\}}{\sum_{k \in \mathcal{S}} 1/\pi_k \{\hat{m}(\mathbf{x}_k)-\hat{\bar{m}}_{\pi}\}^2}\;,
\label{eq:SlopeCalibrationEstimator}
\end{equation}

with \(\hat{\bar{z}}_{\pi}\) the \(\pi\) estimator of the population mean of the study variable, \(\hat{\bar{m}}_{\pi}\) the \(\pi\) estimator of the population mean of the predicted values, and \(\hat{a}\) an intercept estimated by

\begin{equation}
\hat{a} = (1-\hat{b})\left(\frac{1}{N}\sum_{k \in \mathcal{S}}\frac{z_k}{\pi_k}\right)\;.
\label{eq:InterceptCalibrationEstimator}
\end{equation}

The second term in Equation \eqref{eq:ModelCalibrationEstimator} cancels for all sampling designs for which the sum of the design weights, i.e.~the sum of the reciprocal of the inclusion probabilities, equals the population size: \(\sum_{k \in \mathcal{S}} 1/\pi_k=N\). Only for some unequal probability sampling designs this may not be the case.

The alternative is to plug the fitted values \(\hat{m}(\mathbf{x}_k)\) into the generalised difference estimator, Equation \eqref{eq:GeneralizedDifferenceEstimator}. If we drop the second term, the model-calibration estimator\index{Model-calibration estimator} can be rewritten as

\begin{equation}
\hat{\bar{z}}_{\mathrm{MC}}=\frac{1}{N}\sum_{k=1}^N\hat{b}\;\hat{m}(\mathbf{x}_k)+\frac{1}{N}\sum_{k \in \mathcal{S}}\frac{z_k-\hat{b}\;\hat{m}(\mathbf{x}_k)}{\pi_k}
\;.
\label{eq:ModelCalibrationEstimator2}
\end{equation}

Comparison with the generalised difference estimator, Equation \eqref{eq:GeneralizedDifferenceEstimator}, shows that these two estimators are equivalent when \(\hat{b}=1\). For non-linear working models, generally \(\hat{b} \neq 1\), so that these two estimators are not the same. \citet{Wu2003} shows that the calibration estimator has a general optimality property.

In case you are confused by all these model-assisted estimators, let me clarify. The most general estimator is the model-calibration estimator. If we take for \(\hat{b}\) the value 1, this estimator is equivalent to the generalised difference estimator (Equation \eqref{eq:GeneralizedDifferenceEstimator}). The predictions \(\hat{m}(\mathbf{x}_k)\) in these estimators can be computed either by a linear model or a non-linear model. If a linear model is used in the generalised difference estimator, this estimator is equal to the generalised regression estimator (Equation \eqref{eq:GREG}). With linear models \(\hat{b}\) in Equation \eqref{eq:ModelCalibrationEstimator} equals 1, so that all three estimators are equal.

For simple random sampling the inclusion probabilities of the units are the same for all units: \(\pi_k = n/N\), reducing Equations \eqref{eq:ModelCalibrationEstimator} and \eqref{eq:SlopeCalibrationEstimator} to

\begin{equation}
\hat{\bar{z}}_{\mathrm{MC}}= \frac{1}{n}\sum_{k \in \mathcal{S}} z_k + \hat{b}_{\mathrm{SI}}\left(\frac{1}{N}\sum_{k=1}^N \hat{m}(\mathbf{x}_k) - \frac{1}{n}\sum_{j \in \mathcal{S}} \hat{m}(\mathbf{x}_j) \right)\;,
\label{eq:ModelCalibrationEstimatorSI}
\end{equation}

with \(\hat{b}_{\mathrm{SI}}\) equal to

\begin{equation}
\hat{b}_{\mathrm{SI}} = \frac{\sum_{k \in \mathcal{S}} \{\hat{m}(\mathbf{x}_k)-\bar{m}_{\mathcal{S}}\}\{z_k-\bar{z}_{\mathcal{S}}\}}{\sum_{k \in \mathcal{S}} \{\hat{m}(\mathbf{x}_k)-\bar{m}_{\mathcal{S}}\}^2}\;,
\label{eq:RegressionCoefficientCalibrationEstimatorSI}
\end{equation}
with \(\bar{m}_{\mathcal{S}}\) the sample mean of the predicted values.

An estimator of the variance of the model-assisted calibration estimator is
\begin{equation}
\widehat{V}(\hat{\bar{z}}_{\mathrm{MC}})=\widehat{V}(\hat{\bar{e}}_{\pi})\;,
\label{eq:VarianceCalibrationestimator}
\end{equation}

with \(\hat{\bar{e}}_{\pi}\) the \(\pi\) estimator of the population mean of the residuals \(e\). For sampling designs with fixed sample size these residuals are equal to \(e_k=z_k-\hat{b}\;\hat{m}(\mathbf{x}_k)\). For simple random sampling with replacement from finite populations and simple random sampling from infinite populations the variance estimator equals

\begin{equation}
\widehat{V}(\hat{\bar{z}}_{\mathrm{MC}})=\frac{\widehat{S^2}(e)}{n}\;,
\label{eq:VarianceCalibrationestimatorSI}
\end{equation}

with \(\widehat{S^2}(e)\) the estimated population variance of the residuals.

An estimator of the variance of the generalised difference estimator is

\begin{equation}
\widehat{V}(\hat{\bar{z}}_{\mathrm{dif}})=\widehat{V}(\hat{\bar{d}}_{\pi})\;,
\label{eq:VarianceDifferenceestimator}
\end{equation}

with \(\hat{\bar{d}}_{\pi}\) the \(\pi\) estimator of the population mean of the differences \(d_k=z_k-\hat{m}(\mathbf{x}_k)\).

The data of Eastern Amazonia are used to illustrate model-assisted estimation of AGB, using five environmental covariates in predicting AGB. First, a regression tree\index{Regression tree} is used for prediction, after that a random forest\index{Random forest} is used for prediction. For an introduction to regression trees and random forest modelling, see this \href{https://victorzhou.com/blog/intro-to-random-forests/}{blog}. In this blog the study variable is a categorical variable, whereas in our example the study variable is quantitative (continuous). This is not essential. The only difference is the measure for quantifying how good a split is. With a quantitative study variable this is quantified by the following sum of squares:

\begin{equation}
SS=\sum_{g=1}^2\sum_{k \in \mathcal{S}_g}(z_{gk}-\bar{z}_{\mathcal{S}_g})^2  \;,
\label{eq:sumofsquaresbinarysplit}
\end{equation}

with \(\bar{z}_{\mathcal{S}_g}\) the sample mean of group \(g\).

\hypertarget{predicting-with-a-regression-tree}{%
\subsection{Predicting with a regression tree}\label{predicting-with-a-regression-tree}}

A simple random sample without replacement of size 100 is selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{covs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"SWIR2"}\NormalTok{, }\StringTok{"Terra\_PP"}\NormalTok{, }\StringTok{"Prec\_dm"}\NormalTok{, }\StringTok{"Elevation"}\NormalTok{, }\StringTok{"Clay"}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units, }\FunctionTok{c}\NormalTok{(}\StringTok{"AGB"}\NormalTok{, covs)]}
\end{Highlighting}
\end{Shaded}

Package \textbf{rpms} \citep{rpms} is used to build a regression tree for AGB, using all five covariates as predictors. Note that I now use the original untransformed SWIR2 as a predictor. Transforming predictors so that the relation with the study variable becomes linear is not needed when fitting a non-linear model such as a regression tree. Figure \ref{fig:regressiontreeAGB} shows the fitted tree.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpms)}
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpms}\NormalTok{(}
  \AttributeTok{rp\_equ =}\NormalTok{ AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ SWIR2 }\SpecialCharTok{+}\NormalTok{ Terra\_PP }\SpecialCharTok{+}\NormalTok{ Prec\_dm }\SpecialCharTok{+}\NormalTok{ Elevation }\SpecialCharTok{+}\NormalTok{ Clay,}
  \AttributeTok{data =} \FunctionTok{as.data.frame}\NormalTok{(mysample), }\AttributeTok{pval =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/rpms_tree} 

}

\caption{Regression tree for AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) calibrated on a simple random sample of size 100 from Eastern Amazonia.}\label{fig:regressiontreeAGB}
\end{figure}

The regression tree is used to predict AGB for all population units.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AGBpred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree, }\AttributeTok{newdata =}\NormalTok{ grdAmazonia)}
\end{Highlighting}
\end{Shaded}

The population mean is then estimated by the generalised difference estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{AGB[units] }\SpecialCharTok{{-}}\NormalTok{ AGBpred[units]}
\FunctionTok{mean}\NormalTok{(AGBpred) }\SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(d)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 226.7433
\end{verbatim}

Its standard error is estimated by the square root of the variance of the estimator of the mean differences.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2d }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(d)}
\FunctionTok{sqrt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*}\NormalTok{ S2d }\SpecialCharTok{/}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.212222
\end{verbatim}

This estimation procedure is implemented in function \texttt{gregTree} of package \textbf{mase} \citep{mase2018}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mase)}
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ N, n)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{gregTree}\NormalTok{(}
\NormalTok{  mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{xsample =}\NormalTok{ mysample[, covs],}
  \AttributeTok{xpop =}\NormalTok{ grdAmazonia[, covs], }\AttributeTok{pi =}\NormalTok{ pi,}
  \AttributeTok{var\_est =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{var\_method =} \StringTok{"LinHTSRS"}\NormalTok{)}
\NormalTok{res}\SpecialCharTok{$}\NormalTok{pop\_mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 226.7433
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{pop\_mean\_var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.212222
\end{verbatim}

The variance of the estimator of the mean can also be estimated by bootstrapping the sample (\citet{loh99}, Section 9.3.3).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{gregTree}\NormalTok{(}
\NormalTok{  mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{xsample =}\NormalTok{ mysample[, covs],}
  \AttributeTok{xpop =}\NormalTok{ grdAmazonia[, covs], }\AttributeTok{pi =}\NormalTok{ pi,}
  \AttributeTok{var\_est =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{var\_method =} \StringTok{"bootstrapSRS"}\NormalTok{, }\AttributeTok{B =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{pop\_mean\_var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      [,1]
[1,] 4.076
\end{verbatim}

The standard error obtained by the bootstrap is considerably larger than the previous standard error based on a Taylor linearisation of the estimator of the mean. As we will see hereafter, the Taylor linearisation seriously underestimates the true standard error.

The simple random sampling of 100 units and the model-assisted estimation are repeated 500 times, using a regression tree for prediction. The variance is estimated by Taylor linearisation (\texttt{var\_method\ =\ LinHTSRS}) and by bootstrapping (\texttt{var\_method\ =\ bootstrapSRS}) using 100 bootstrap samples.

The variance of the 500 estimated population means of AGB is 20.8 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}. Estimation of the variance through Taylor linearisation strongly underestimates the variance: the average of the 500 estimated variances equals 14.5 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}. On the contrary, the bootstrap variance estimator overestimates the variance: the average of the 500 estimated variances equals 23.4 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}. I prefer to overestimate my uncertainty about the mean, instead of being overoptimistic, and so I would recommend to report the bootstrap variance.

\hypertarget{predicting-with-a-random-forest}{%
\subsection{Predicting with a random forest}\label{predicting-with-a-random-forest}}

The package \textbf{ranger} \citep{Wright2017} is used to fit a random forest (RF) model for AGB using the five environmental covariates as predictors and the simple random sample of size 100 selected in the previous subsection. Function \texttt{importance} shows how often the covariates are used in a binary splitting. All five covariates are used, SWIR2 by far most often.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ranger)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{forest.sample }\OtherTok{\textless{}{-}} \FunctionTok{ranger}\NormalTok{(}
\NormalTok{  AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{num.trees =} \DecValTok{1000}\NormalTok{, }\AttributeTok{importance =} \StringTok{"impurity"}\NormalTok{)}
\FunctionTok{importance}\NormalTok{(forest.sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    SWIR2  Terra_PP   Prec_dm Elevation      Clay 
466318.39 214716.35 136505.65  62429.66  34612.68 
\end{verbatim}

Out-of-bag predictions for the selected units are saved in element \texttt{predictions} of the output object of function \texttt{ranger}. The fitted model is also used to predict AGB at all units (raster cells), using function \texttt{predict}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AGBpred\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ forest.sample}\SpecialCharTok{$}\NormalTok{predictions}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(forest.sample, }\AttributeTok{data =}\NormalTok{ grdAmazonia, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{AGBpred }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{predictions}
\end{Highlighting}
\end{Shaded}

Finally, the model-calibration estimate and the generalised difference estimate are computed. Both estimators and their variances are computed in two ways. They differ in how the study variable AGB is predicted for the sampling units:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  using all trees of the forest (the predictions obtained with function \texttt{predict}); or
\item
  using only the trees calibrated on bootstrap samples\index{Bootstrap sample} that do not include the sampling unit used as a prediction unit. These out-of-bag predictions are stored in element \texttt{predictions} of the output object of function \texttt{ranger}.
\end{enumerate}

The next code chunk shows how the model-calibration estimate can be computed with the AGB data of the simple random sample and the RF predictions of AGB. First, all trees are used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numer }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((AGBpred[units] }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred[units])) }\SpecialCharTok{*}
\NormalTok{             (mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB)))}
\NormalTok{denom }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((AGBpred[units] }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred[units]))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ numer }\SpecialCharTok{/}\NormalTok{ denom}
\NormalTok{mz\_MC }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB) }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(AGBpred) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred[units]))}
\NormalTok{u }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ AGBpred[units] }\SpecialCharTok{*}\NormalTok{ b}
\NormalTok{v\_mz\_MC }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(u) }\SpecialCharTok{/}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

Next, the out-of-bag predictions\index{Out-of-bag predictions} are used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numer }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((AGBpred\_OOB }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred\_OOB)) }\SpecialCharTok{*}
\NormalTok{             (mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB)))}
\NormalTok{denom }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((AGBpred\_OOB }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred\_OOB))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{b\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ numer }\SpecialCharTok{/}\NormalTok{ denom}
\NormalTok{mz\_MC\_OOB }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB) }\SpecialCharTok{+}\NormalTok{ b\_OOB }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(AGBpred) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(AGBpred\_OOB))}
\NormalTok{u\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ AGBpred\_OOB }\SpecialCharTok{*}\NormalTok{ b\_OOB}
\NormalTok{v\_mz\_MC\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(u\_OOB) }\SpecialCharTok{/}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

The two calibration estimates are about equal: 226.8 10\textsuperscript{9} kg ha\textsuperscript{-1} using sample predictions obtained with function \texttt{predict}, and 227.3 10\textsuperscript{9} kg ha\textsuperscript{-1} with the out-of-bag sample predictions. However, their estimated variances are largely different: 2.35 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2} and 12.46 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, respectively.

In the next code chunk the generalised difference estimate (Equation \eqref{eq:GeneralizedDifferenceEstimator}) is computed. Similar to the model-calibration estimate, this difference estimate is computed from predictions based on all trees and from the out-of-bag predictions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ AGBpred[units]}
\NormalTok{mz\_MD }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(AGBpred) }\SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(d)}
\NormalTok{v\_mz\_MD }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(d) }\SpecialCharTok{/}\NormalTok{ n}
\CommentTok{\#using out{-}of{-}bag predictions}
\NormalTok{d\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{AGB }\SpecialCharTok{{-}}\NormalTok{ AGBpred\_OOB}
\NormalTok{mz\_MD\_OOB }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(AGBpred) }\SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(d\_OOB)}
\NormalTok{v\_mz\_MD\_OOB }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*} \FunctionTok{var}\NormalTok{(d\_OOB) }\SpecialCharTok{/}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

For the difference estimator the results are very similar. The two difference estimates are 226.6 10\textsuperscript{9} kg ha\textsuperscript{-1} and 227.0 10\textsuperscript{9} kg ha\textsuperscript{-1}, and their estimated variances are 2.70 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2} and 12.80 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, respectively. The model-calibration estimate and the generalised difference estimate are nearly equal.

The sampling and estimation are repeated 1,000 times: 1,000 times a simple random sample without replacement of size 100 is selected. Each sample is used to calibrate a RF, each forest consisting of 1,000 trees. This results in 2 \(\times\) 1,000 model-calibration estimates and their estimated variances as well as 2 \(\times\) 1,000 difference estimates and their estimated variances. To limit the computing time, a 5 km \(\times\) 5 km subgrid of \texttt{grdAmazonia} is used for selecting the simple random samples and for predicting AGB with the RF.

For each estimator the 1,000 estimated means are used to compute the relative bias\index{Bias!relative bias}:

\begin{equation}
bias = \frac{\frac{1}{1000}\sum_{i=1}^{1000}\hat{\bar{z}}_i-\bar{z}}{\bar{z}}\;.
\label{eq:relativebias}
\end{equation}

Besides, for each estimator the variance of the 1,000 estimates is computed, which can be compared with the mean of the 1,000 estimated variances. The mean of the estimated variances is used to compute the variance to mean squared error ratio\index{Variance to mean squared error ratio}:

\begin{equation}
R = \frac{\frac{1}{1000}\sum_{i=1}^{1000}\hat{V}(\hat{\bar{z}}_i)}{MSE}\;,
\label{eq:VariancetoMSEratio}
\end{equation}

with

\begin{equation}
MSE= \frac{1}{1000}\sum_{i=1}^{1000}(\hat{\bar{z}}_i-\bar{z})^2\;.
\label{eq:MSE}
\end{equation}

Ideally, this ratio equals 1. If it is smaller than 1, the variance estimator underestimates the mean squared error.

Finally, the relative efficiency\index{Relative efficiency} is computed as the ratio of the MSE of the \(\pi\) estimator and the MSE of a model-assisted estimator. The \(\pi\) estimator is unbiased, so the MSE equals the variance, which can be computed without error by the population variance divided by the sample size. If the relative efficiency is larger than 1, the model-assisted estimator is more accurate than the \(\pi\) estimator.

The variance of the 1,000 model-calibration estimates (experimental variance), using all trees to predict AGB for the sampled units, equals 15.0. This is 5.65 times larger than the average of the 1,000 estimated variances, which equals 2.66. When using the out-of-bag sample predictions, the experimental variance is about equal to the average of the 1,000 variance estimates: 15.5 versus 15.0.

The reason of underestimation of the variance when predicting AGB at sample units with function \texttt{predict} is that all 1,000 trees are used in prediction, including the trees calibrated on bootstrap samples that contain the unit in the sample to be predicted. On the contrary, the out-of-bag predicted values are computed as the average of predictions from the trees calibrated on bootstrap samples that do not contain the sample unit to be predicted. The default sample fraction is 0.632, see argument \texttt{sample.fraction} of function \texttt{ranger}, so with 1,000 trees these predictions are the average of, on average, 368 tree predictions. This explains why the out-of-bag prediction errors are larger than the prediction errors obtained with function \texttt{predict}. In other words, the variance of the out-of-bag differences \(d\) and of the out-of-bag residuals \(u\) are larger than those obtained with predicting using all trees.

Hereafter I report the results obtained with the out-of-bag samples only.

The relative bias is negligibly small for all sample sizes (Table \ref{tab:CalibrationEstimatesAmazoniaOOB}). For \(n=250\) and 100 the average of the 1,000 estimated variances is smaller than the variance of the 1,000 estimated means, whereas for \(n=50\) the average of the 1,000 variance estimates is larger than the experimental variance of the estimated means. The variance to MSE ratio is smaller than 1 for \(n=250\) and 100, but larger than 1 for \(n=50\). The model-calibration estimator is much more accurate than the \(\pi\) estimator for all three sample sizes, as shown by the high relative efficiencies. The relative efficiency increases with the sample size.



\begin{table}

\caption{\label{tab:CalibrationEstimatesAmazoniaOOB}Summary statistics of 1,000 calibration estimates of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) and their estimated variances in Eastern Amazonia, using out-of-bag sample predictions from a RF model with five covariates as a working model, for simple random sampling without replacement and sample sizes 50, 100, and 250.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
 & 50 & 100 & 250\\
\midrule
Relative bias & -0.0014 & -0.0006 & -0.0012\\
Experimental variance & 33.9075 & 15.5255 & 5.6111\\
Mean variance estimates & 36.1512 & 14.9750 & 5.0467\\
Variance to MSE ratio & 1.0642 & 0.9642 & 0.8882\\
Relative efficiency & 5.0066 & 5.4755 & 5.9866\\
\bottomrule
\end{tabular}
\end{table}

The summary statistics for the performance of the generalised difference estimator are very similar to those of the model-calibration estimator (Table \ref{tab:DifferenceEstimatesAmazoniaOOB}).



\begin{table}

\caption{\label{tab:DifferenceEstimatesAmazoniaOOB}Summary statistics of 1,000 generalised difference estimates of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) and their estimated variances in Eastern Amazonia, using out-of-bag sample predictions from a RF model with five covariates as a working model, for simple random sampling without replacement and and sample sizes 50, 100, and 250.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
 & 50 & 100 & 250\\
\midrule
Relative bias & -0.0008 & -0.0006 & -0.0013\\
Experimental variance & 34.5188 & 16.2339 & 5.6891\\
Mean variance estimates & 38.4629 & 15.4568 & 5.1125\\
Variance to MSE ratio & 1.1144 & 0.9520 & 0.8867\\
Relative efficiency & 4.9275 & 5.2379 & 5.8997\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{big-data-and-volunteer-data}{%
\section{Big data and volunteer data}\label{big-data-and-volunteer-data}}

Over the past decades numerous large data sets have become available, and this number will further increase in the future, think of data sets collected by satellites. These data sets may contain valuable information about study variables, so that they can be used in model-assisted estimation of global (this chapter) or local means and totals (Chapter \ref{SmallAreaEstimation}) of these study variables.

Another interesting source of information are the geographic data collected by volunteers. Although these data typically are from non-probability samples\index{Non-probability sampling}, they can nevertheless render valuable information about the global or local means of study variables.

When the volunteer data\index{Volunteer data} are supplemented by a probability sample with observations of the study variable, the volunteer data can be used at the design stage and/or at the estimation stage. As an example of the first approach, the volunteer data are used to predict the study variable at a fine discretisation grid. These predictions are then used to construct strata for supplemental sampling, for instance by the \emph{cum-root-f} method (Section \ref{cumrootf}) or using the approach described in Section \ref{Ospats}.

At the estimation stage the volunteer data are used to predict the study variable at points of the supplemental probability sample and at the nodes of a discretisation grid. These predictions are then used in model-assisted estimation, using the generalised difference or regression estimator, as explained in this chapter. For more details and a simulation study, see \citet{bru03a}.

\citet{Stehman2018} compared the model-assisted estimation approach with a certainty stratum approach\index{Certainty stratum approach} for estimating the area covered by land cover classes and the accuracy of land cover maps. The volunteer data are treated as the data of a stratum of which all units are observed. A probability sample is selected from the remaining units not observed by the volunteers. The total (area of a land cover class) of the certainty stratum is added to the estimated total of the subpopulation not observed by the volunteers.

The model-assisted approach requires a supplemental sample with observations of the study variable \(z\). \citet{Kim2019} described an approach in which the big data\index{Big data} sample is combined with a probability sample with observations of one or more ancillary variables.

\citet{Kim2019} also describe an alternative approach that does not require a probability sample at all. In this approach the big data sample is subsampled to correct the selection bias in the big data sample. The subsample is selected by inverse sampling, using data on an ancillary variable \(x\), either from a census or a probability sample. The subsample is selected with conditional inclusion probabilities equal to the subsample size multiplied by an importance weight (\citet{Kim2019}, Equation 4).

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5366689 286.7   12043445 643.2  12043445  643.2
Vcells 26767549 204.3   89545810 683.2 177363197 1353.2
\end{verbatim}

\hypertarget{Twophase}{%
\chapter{Two-phase random sampling}\label{Twophase}}

The regression and ratio estimators of Chapter \ref{Modelassisted} require that the means of the ancillary variables are known. If these are unknown, but the ancillary variables can be measured cheaply, one may decide to estimate the population means of the ancillary variables from a large sample. The study variable is measured in a random subsample of this large sample only. This technique is known in the sampling literature as two-phase random sampling\index{Two-phase random sampling} or double sampling\index{Double sampling}. Another application of two-phase sampling is two-phase sampling for stratification. Stratified random sampling (Chapter \ref{STSI}) requires a map with the strata. The poststratified estimator of Subsection \ref{PoststratifiedEstimator} requires that the sizes of the strata are known. With two-phase sampling for stratification neither a map of the strata nor knowledge of the stratum sizes is required. Note that the term `phase' does not refer to a period of time; all data can be collected in one sampling campaign. Let me also explain the difference with two-stage cluster sampling (Chapter \ref{Twostage}). In two-stage cluster random sampling we have two types of sampling units, clusters of population units and individual population units. In two-phase sampling we have one type of sampling unit only, the objects of a discrete population or the elementary sampling units of a continuous population (Section \ref{BasicConcepts}).

In two-phase sampling for regression and two-phase sampling for stratification the two phases have the same aim, i.e.~to estimate the population mean of the study variable. The observations of the covariate(s) and/or strata in the first phase are merely done to increase the precision of the estimated mean of the study variable. Another application of two-phase sampling is subsampling an existing probability sample designed for a different aim. So, in this case the study variable observed in the second-phase sample may not be related to the variables observed in the first-phase sample.

An example is LUCAS-Topsoil \citep{Ballabio2019}. LUCAS-Topsoil is a subsample of approximately 22,000 units sampled from a much larger sample, the LUCAS sample, designed for estimating totals of land use and land cover classes across the European Union. It was not feasible to observe the soil properties at all sites of the LUCAS sample, and for this reason a subsample was selected. Regrettably, this subsample is not a probability sample from the LUCAS sample: the inclusion probabilities are either zero or unknown. Design-based or model-assisted estimation of means of soil properties for domains of interest is not feasible. The only option is model-based prediction.

In case the subsample is a probability subsample from the first-phase sample and no variable observed in the first-phase sample\index{First-phase sample} is of use for estimating the total or mean of the study variable observed in the subsample, the population total can be estimated by the \(\pi\) estimator:

\begin{equation}
\hat{t}(z) =\sum_{k \in \mathcal{S}_2}\frac{z_k}{\pi_{1k}\pi_{k|\mathcal{S}_1}} =\sum_{k \in \mathcal{S}_2}\frac{z_k}{\pi^*_{k}}
\;,
\label{eq:HTestimatorTotalDoubleSampling}
\end{equation}

with \(\pi_{1k}\) the probability that unit \(k\) is selected in the first phase, and \(\pi_{k|\mathcal{S}_1}\) the probability that unit \(k\) is selected in the second phase\index{Second-phase sample}, given the first-phase sample \(\mathcal{S}_1\). This general \(\pi\) estimator for two-phase sampling, referred to as the \(\pi^*\) estimator\index{$\pi^*$ estimator} by \citet{sar92}, can be used for any combination of probability sampling designs in the first and second phase.

To derive the variance it is convenient to write the total estimation error as the sum of two errors:

\begin{equation}
\begin{split}
\hat{t}(z)-t(z) &=\left(\sum_{k \in \mathcal{S}_1}\frac{z_k}{\pi_{1k}}-t(z)\right)+\left(\sum_{k \in \mathcal{S}_2}\frac{z_k}{\pi^*_{k}}-\sum_{k \in \mathcal{S}_1}\frac{z_k}{\pi_{1k}}\right)\\
& =e_1+e_2 \;.
\end{split}
\label{eq:DecomposeErrorsDoubleSampling}
\end{equation}

The first error \(e_1\) is the error in the estimated population total, as estimated by the usual \(\pi\) estimator using the study variable values for the units in the first-phase sample. This estimator cannot be computed in practice as the study variable values are only known for a subset of the units in the first-phase sample. The second error \(e_2\) is the difference between the \(\pi^*\) estimator using the study variable values for the units in the subsample only, and the \(\pi\) estimator using the study variable values for all units in the first-phase sample.

The variance of the \(\pi^*\) estimator can be decomposed into the variance of these two errors as follows:

\begin{equation}
V_{p_1,p_2}(\hat{t})=V_{p_1}E_{p_2}(\hat{t}|\mathcal{S}_1)+E_{p_1}V_{p_2}(\hat{t}|\mathcal{S}_1)=V_{p_1}(e_1)+E_{p_1}V_{p_2}(e_2|\mathcal{S}_1)\;,
\label{eq:VarHTestimatorDoubleSampling}
\end{equation}

with \(V_{p_1}\) and \(E_{p_1}\) the variance and expectation of the estimator for the population total over repeated sampling with the design of the first phase, respectively, and \(V_{p_2}\) and \(E_{p_2}\) the variance and expectation of the estimator for the population total over repeated sampling with the design of the second phase, respectively. The population mean can be estimated by the estimated total divided by the population size \(N\).

\hypertarget{TwophaseStratification}{%
\section{Two-phase random sampling for stratification}\label{TwophaseStratification}}

In two-phase sampling for stratification\index{Two-phase sampling!for stratification} in the first phase a large sample is taken and the selected sampling units are all classified. The classes thus formed are then used as strata in the second sampling phase. A stratified subsample is selected, and the study variable is observed on the units in the subsample only.

\begin{rmdnote}
This sampling design is applied, for instance, to monitor land use and land cover in the European Union by the LUCAS monitoring network already mentioned above. In the first phase a systematic random sample is selected, consisting of the nodes of a square sampling grid with a spacing of 2 km. Land use and land cover (LULC) are then determined at the selected grid nodes, using orthophotographs, satellite imagery, and fieldwork. The idea is that this procedure results in a more accurate classification of LULC at the selected units than by overlaying the grid nodes with an existing LULC map such as the Corine Land Cover map. The site-specific determinations of LULC classes are then used to select a stratified random subsample (second-phase sample). In 2018 the monitoring network was redesigned \citep{Eurostat2018}.
\end{rmdnote}

Two-phase sampling for stratification is now illustrated with study area Voorst. A map with five combinations of soil type and land use is available of this study area. These combinations were used as strata in Chapter \ref{STSI}, and the stratum sizes were used in the poststratified estimator of Subsection \ref{PoststratifiedEstimator}. Here we consider the situation that we do not have this map and that we do not know the sizes of these strata either. In the first phase a simple random sample of size 100 is selected. In the field the soil-land use combination is determined for the selected points, see Figure \ref{fig:DoubleSampleVoorst}. This time we assume that the field determinations are equal to the classes as shown on the map.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n1 }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdVoorst)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(N, }\AttributeTok{size =}\NormalTok{ n1, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[units, ]}
\end{Highlighting}
\end{Shaded}

The simple random sample is subsampled by stratified simple random sampling, using the soil-land use classes as strata. The total sample size of the second phase is set to 40. The number of points in the simple random sample per stratum is determined. Then the subsample size per stratum is computed for proportional allocation. Finally, function \texttt{strata} of package \textbf{sampling} \citep{Tille2016} is used to select a stratified simple random sample without replacement, see Chapter \ref{STSI} for details. At the 40 points of the second-phase the soil organic matter concentration (SOM) is measured.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\NormalTok{n2 }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{n1\_h }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{n2\_h }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(n1\_h }\SpecialCharTok{/}\NormalTok{ n1 }\SpecialCharTok{*}\NormalTok{ n2, }\DecValTok{0}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(mysample, }\AttributeTok{stratanames =} \StringTok{"stratum"}\NormalTok{,}
  \AttributeTok{size =}\NormalTok{ n2\_h[}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{stratum)], }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysubsample }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(mysample, units)}
\FunctionTok{table}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{stratum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
BA EA PA RA XF 
15  8  6  4  7 
\end{verbatim}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/DoubleSampleVoorst-1} 

}

\caption{Two-phase random sample for stratification from Voorst. Coloured dots: first-phase sample of 100 points selected by simple random sampling, with observations of the soil-land use combination.  Triangles: second-phase sample of 40 points selected by stratified simple random subsampling of the first-phase sample, using the soil-land use combinations as strata, with measurements of SOM.}\label{fig:DoubleSampleVoorst}
\end{figure}

With simple random sampling in the first phase and stratified simple random sampling in the second phase, the population mean can be estimated by

\begin{equation}
\hat{\bar{z}}=
\sum_{h=1}^{H_{\mathcal{S}_1}}\frac{n_{1h}}{n_{1}}\,\bar{z}_{\mathcal{S}_{2h}} 
\;,
\label{eq:EstimatedMeanDoubleStratification}
\end{equation}

where \(H_{\mathcal{S}_1}\) is the number of strata used for stratification of the first-phase sample, \(n_{1h}\) is the number of units in the first-phase sample that form stratum \(h\) in the second phase, \(n_{1}\) is the total number of units of the first-phase sample, and \(\bar{z}_{\mathcal{S}_{2h}}\) is the mean of the subsample from stratum \(h\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_h\_subsam }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysubsample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(n1\_h }\SpecialCharTok{/}\NormalTok{ n1 }\SpecialCharTok{*}\NormalTok{ mz\_h\_subsam, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The estimated population mean equals 85.6 g kg\textsuperscript{-1}. The sampling variance over repeated sampling with both designs can be approximated\footnote{In the approximation it is assumed that \(N\) is much larger than \(n_1\), and \((n_{1h}-1)/(n_1-1)\) is replaced by \(n_{1h}/n_1\).} by (\citet{sar92}, Equation at bottom of p.~353)

\begin{equation}
\widehat{V}\!(\hat{\bar{z}}) = \sum_{h=1}^{H_{\mathcal{S}_1}}\left( \frac{n_{1h}}{n_1}\right)^2
\frac{\widehat{S^2}_{\mathcal{S}_{2h}}}{n_{2h}} + \frac{1}{n_1}\sum_{h=1}^{H_{\mathcal{S}_1}} \frac{n_{1h}}{n_1}\left( \bar{z}_{\mathcal{S}_{2h}}-\hat{\bar{z}}\right)^2 
\;,
\label{eq:VarMeanDoubleStratification}
\end{equation}

with \(\widehat{S^2}_{\mathcal{S}_{2h}}\) the variance of \(z\) in the subsample from stratum \(h\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S2z\_h\_subsam }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{z, }\AttributeTok{INDEX =}\NormalTok{ mysubsample}\SpecialCharTok{$}\NormalTok{stratum, }\AttributeTok{FUN =}\NormalTok{ var)}
\NormalTok{w1\_h }\OtherTok{\textless{}{-}}\NormalTok{ n1\_h }\SpecialCharTok{/}\NormalTok{ n1}
\NormalTok{v\_mz\_1 }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w1\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ S2z\_h\_subsam }\SpecialCharTok{/}\NormalTok{ n2\_h)}
\NormalTok{v\_mz\_2 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ n1 }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(w1\_h }\SpecialCharTok{*}\NormalTok{ (mz\_h\_subsam }\SpecialCharTok{{-}}\NormalTok{ mz)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{se\_mz }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(v\_mz\_1 }\SpecialCharTok{+}\NormalTok{ v\_mz\_2)}
\end{Highlighting}
\end{Shaded}

The estimated standard error equals 7.1 g kg\textsuperscript{-1}.

The mean and its standard error can be estimated with functions \texttt{twophase} and \texttt{svymean} of package \textbf{survey} \citep{Lumley2020}. A data frame with the first-phase sample is passed to function \texttt{twophase} using argument \texttt{data}. A variable in this data frame, passed to function \texttt{twophase} with argument \texttt{subset}, is an indicator with value \texttt{TRUE} if this unit is selected in the second phase, and \texttt{FALSE} otherwise.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{stratum =} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{stratum)), }\AttributeTok{fpc2 =}\NormalTok{ n1\_h)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ind =} \ConstantTok{FALSE}\NormalTok{,}
         \AttributeTok{fpc1 =}\NormalTok{ N) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(lut, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{ind[units}\SpecialCharTok{$}\NormalTok{ID\_unit] }\OtherTok{\textless{}{-}} \ConstantTok{TRUE}
\NormalTok{design\_2phase }\OtherTok{\textless{}{-}}\NormalTok{ survey}\SpecialCharTok{::}\FunctionTok{twophase}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{), }\AttributeTok{strata =} \FunctionTok{list}\NormalTok{(}\ConstantTok{NULL}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ stratum),}
  \AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{subset =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ ind, }\AttributeTok{fpc =} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ fpc2))}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ z, design\_2phase)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    mean    SE
z 85.606 7.033
\end{verbatim}

As shown in the next code chunk the standard error is computed with the original variance estimator, without approximation (\citet{sar92}, Equation (9.4.14)).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v\_mz\_1 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}
  \FunctionTok{sum}\NormalTok{((((n1\_h }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n1 }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{{-}}\NormalTok{ ((n2\_h }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)))}
      \SpecialCharTok{*}\NormalTok{ w1\_h }\SpecialCharTok{*}\NormalTok{ S2z\_h\_subsam }\SpecialCharTok{/}\NormalTok{ n2\_h)}
\NormalTok{v\_mz\_2 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ N}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (N }\SpecialCharTok{*}\NormalTok{ (N }\SpecialCharTok{{-}}\NormalTok{ n1)) }\SpecialCharTok{/}\NormalTok{ (n1 }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}
  \FunctionTok{sum}\NormalTok{(w1\_h }\SpecialCharTok{*}\NormalTok{ (mz\_h\_subsam }\SpecialCharTok{{-}}\NormalTok{ mz)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\FunctionTok{sqrt}\NormalTok{(v\_mz\_1 }\SpecialCharTok{+}\NormalTok{ v\_mz\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7.032964
\end{verbatim}

\hypertarget{TwophaseRegression}{%
\section{Two-phase random sampling for regression}\label{TwophaseRegression}}

The simple regression estimator of Equation \eqref{eq:SimpleRegressionEstimatorSI} requires that the population mean of the ancillary variable \(x\) is known. This section, however, is about applying the regression estimator in situations where the mean of \(x\) is unknown\index{Two-phase sampling!for regression}. A possible application is estimating the soil organic carbon (SOC) stock (until a given depth) in an area. To estimate this carbon stock soil samples are collected and analysed in a laboratory. The laboratory measurements can be very accurate, but also expensive. Proximal sensors can be used to derive soil carbon concentrations from the spectra. Compared to laboratory measurements of soil the proximal sensor determinations are much cheaper, but also less accurate. If there is a relation between the laboratory and the proximal sensing determinations of SOC, then we expect that the regression estimator of the carbon stock will be more accurate than the \(\pi\) estimator which does not exploit the proximal sensing measurements. However, the population mean of the proximal sensing determinations is unknown. What we can do, is to estimate this mean from a large sample. Additionally, for a subsample of this large sample, SOC concentration is also measured in the laboratory. This is another example of two-phase sampling.

Intuitively, we understand that with two-phase sampling the variance of the regression estimator of the total carbon stock is larger than when the population mean of the proximal sensing determinations is known. There is a sampling error in the estimated population mean of the proximal sensing determinations, estimated from the large first-phase sample, and this error propagates to the error in the estimated total carbon stock.

Two-phase sampling for regression is now illustrated with Eastern Amazonia (Subsection \ref{Amazonia}). The study variable is the aboveground biomass (AGB), and lnSWIR2 is used here as a covariate. We do have a full coverage map of lnSWIR2, so two-phase sampling with a large first-phase sample to estimate the population mean of lnSWIR2 is not needed. Nevertheless, hereafter a two-phase sample is selected, and the population mean of lnSWIR2 is estimated from the first-phase sample. In doing so, the effect of ignorance of the population mean of the covariate on the variance of the regression estimator becomes apparent.

In the next code chunk a first-phase sample of 250 units (the dots in the plot) is selected by simple random sampling without replacement. In the second phase a subsample of 100 units (the triangles in the plot) is selected from the 250 units by simple random sampling without replacement. At all 250 units of the first-phase sample the covariate lnSWIR2 is measured, whereas AGB is measured at the 100 subsample units only.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{lnSWIR2 =} \FunctionTok{log}\NormalTok{(SWIR2))}
\NormalTok{n1 }\OtherTok{\textless{}{-}} \DecValTok{250}\NormalTok{; n2 }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units\_1 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\AttributeTok{size =}\NormalTok{ n1, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units\_1, ]}
\NormalTok{units\_2 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(n1, }\AttributeTok{size =}\NormalTok{ n2, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysubsample }\OtherTok{\textless{}{-}}\NormalTok{ mysample[units\_2, ]}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:twophaseAmazonia} shows the selected two-phase sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/twophaseAmazonia-1} 

}

\caption{Two-phase random sample for the regression estimator of the mean AGB in Eastern Amazonia. Coloured dots: simple random sample without replacement of 250 units with measurements of covariate lnSWIR2 (first-phase sample). Triangles: simple random subsample without replacement of 100 units with measurements of AGB (second-phase sample).}\label{fig:twophaseAmazonia}
\end{figure}

Estimation of the population mean or total by the regression estimator from a two-phase sample is very similar to estimation when the covariate mean is known, as described in Subsection \ref{RegressionEstimator} (Equation \eqref{eq:SimpleRegressionEstimatorSI})\index{Regression estimator!for two-phase sampling}. The observations of the \emph{subsample} can be used to estimate the regression coefficient \(b\). The true population mean of the ancillary variable, \(\bar{x}\) in Equation \eqref{eq:SimpleRegressionEstimatorSI}, is unknown now. This true mean is replaced by the mean as estimated from the relatively large first-phase sample, \(\bar{x}_{\mathcal{S}_1}\). The estimated mean of the covariate, \(\bar{x}_{\mathcal{S}}\) in Equation \eqref{eq:SimpleRegressionEstimatorSI}, is estimated from the subsample, \(\bar{x}_{\mathcal{S}_2}\). This leads to the following estimator:

\begin{equation}
\hat{\bar{z}}= \bar{z}_{\mathcal{S}_2}+\hat{b}\left( \bar{x}_{\mathcal{S}_1}-\bar{x}_{\mathcal{S}_2}\right) \;,
\label{eq:RegressionEstimatorTwoPhase}
\end{equation}

where \(\bar{z}_{\mathcal{S}_2}\) is the subsample mean of the study variable, and \(\bar{x}_{\mathcal{S}_1}\) and \(\bar{x}_{\mathcal{S}_2}\) are the means of the covariate in the first-phase sample and the subsample (i.e.~the second-phase sample), respectively.

The sampling variance is larger than that of the regression estimator with known mean of \(x\). The variance can be decomposed into a component equal to the sampling variance of the \(\pi\) estimator of the mean of \(z\) with the sampling design of the first phase (in this case simple random sampling without replacement), supposing that the study variable is observed on all units of the first-phase sample, and a component equal to the sampling variance of the regression estimator of the mean of \(z\) in the first-phase sample, with the design of the second-phase sample (again simple random sampling without replacement in this case):

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}\right)=(1-\frac{n_1}{N})\frac{\widehat{S^{2}}(z)}{n_1} + (1-\frac{n_2}{n_1}) \frac{\widehat{S^{2}}(e)}{n_2} \;,
\label{eq:VarianceRegressionEstimatorTwoPhase}
\end{equation}

with \(\widehat{S^{2}}(e)\) the variance of the regression residuals as estimated from the subsample:

\begin{equation}
\widehat{S^{2}}(e)=\frac{1}{(n_2-1)}\sum_{k \in \mathcal{S}_2}e_{k}^2 \;.
\label{eq:VarianceResidualsTwoPhase}
\end{equation}

The ratio's \((1-n_1/N)\) and \((1-n_2/n_1)\) in Equation \eqref{eq:VarianceRegressionEstimatorTwoPhase} are finite population corrections (fpcs). These fpcs account for the reduced variance due to sampling the finite population and subsampling the first-phase sample without replacement.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_subsample }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ mysubsample)}
\NormalTok{ab }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(lm\_subsample)}
\NormalTok{mx\_sam }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{mx\_subsam }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{mz\_subsam }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{AGB)}
\NormalTok{mz\_reg2ph }\OtherTok{\textless{}{-}}\NormalTok{ mz\_subsam }\SpecialCharTok{+}\NormalTok{ ab[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ (mx\_sam }\SpecialCharTok{{-}}\NormalTok{ mx\_subsam)}
\end{Highlighting}
\end{Shaded}

The estimated population mean equals \texttt{formatC(mz\_reg2ph,1)} 10\textsuperscript{9} kg ha\textsuperscript{-1}. The standard error can be approximated as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(lm\_subsample)}
\NormalTok{S2e }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(e}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n2 }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{S2z }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysubsample}\SpecialCharTok{$}\NormalTok{AGB)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(grdAmazonia)}
\NormalTok{se\_mz\_reg2ph }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n1 }\SpecialCharTok{/}\NormalTok{ N) }\SpecialCharTok{*}\NormalTok{ S2z }\SpecialCharTok{/}\NormalTok{ n1 }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n2 }\SpecialCharTok{/}\NormalTok{ n1) }\SpecialCharTok{*}\NormalTok{ S2e }\SpecialCharTok{/}\NormalTok{ n2)}
\end{Highlighting}
\end{Shaded}

The estimated standard error equals \texttt{formatC(se\_mz\_reg2ph,2)} 10\textsuperscript{9} kg ha\textsuperscript{-1}.

The regression estimator for two-phase sampling and its standard error can also be computed with package \textbf{survey}, as shown below. The standard error differs from the standard error computed above because it is computed with the g-weights, see Subsection \ref{RegressionEstimator}. Note argument \texttt{fpc\ =\ list(\textasciitilde{}\ N,\ NULL)}. There is no need to add the first-phase sample size as a second element of the list, because this sample size is simply the number of rows of the data frame. Setting the second element of the list to \texttt{NULL} does not mean that the standard error is computed for with replacement sampling in the second phase. Function \texttt{twophase} assumes that the second-phase units are always selected without replacement.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mysample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{id =} \FunctionTok{row\_number}\NormalTok{(),}
         \AttributeTok{N =}\NormalTok{ N,}
         \AttributeTok{ind =}\NormalTok{ id }\SpecialCharTok{\%in\%}\NormalTok{ units\_2)}
\NormalTok{design\_2phase }\OtherTok{\textless{}{-}}\NormalTok{ survey}\SpecialCharTok{::}\FunctionTok{twophase}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{), }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{subset =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ ind, }\AttributeTok{fpc =} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ N, }\ConstantTok{NULL}\NormalTok{))}
\NormalTok{mysample\_cal }\OtherTok{\textless{}{-}} \FunctionTok{calibrate}\NormalTok{(}
\NormalTok{  design\_2phase, }\AttributeTok{formula =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{calfun =} \StringTok{"linear"}\NormalTok{, }\AttributeTok{phase =} \DecValTok{2}\NormalTok{)}
\FunctionTok{svymean}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, mysample\_cal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mean     SE
AGB 228.07 7.2638
\end{verbatim}

\hypertarget{exercises-18}{%
\subsubsection*{Exercises}\label{exercises-18}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select a simple random sample without replacement of 250 units from Eastern Amazonia and a subsample of 100 units by simple random sampling without replacement. Repeat this 1,000 times in a for-loop.

  \begin{itemize}
  \tightlist
  \item
    Use each sample selected in the first phase (sample of 250 units) to estimate the population mean of AGB by the regression estimator (Equation \eqref{eq:SimpleRegressionEstimatorSI} in Chapter \ref{Modelassisted}). Assume that the AGB data are known for all units selected in the first phase. Use lnSWIR2 as a covariate.
  \item
    Compute the variance of the 10,000 regression estimates of the population mean of AGB.
  \item
    Use each two-phase sample to compute the regression estimator of AGB for two-phase sampling (Equation \eqref{eq:RegressionEstimatorTwoPhase}). Now only use the AGB data of the subsample. Estimate the population mean of lnSWIR2 from the first-phase sample of 250 units. Approximate the variance of the regression estimator for two-phase sampling (Equation \eqref{eq:VarianceRegressionEstimatorTwoPhase}).
  \item
    Compute the variance of the 10,000 regression estimates of the population mean of AGB for the two-phase sampling design.
  \item
    Compare the two variances and explain the difference.
  \item
    Compute the average of the 10,000 approximate variances and compare the result with the variance of the 10,000 estimated means, as estimated by the regression estimator for two-phase sampling.
  \end{itemize}
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5372529 287.0   12043445 643.2  12043445  643.2
Vcells 28059274 214.1   91428184 697.6 177363197 1353.2
\end{verbatim}

\hypertarget{RequiredSampleSize}{%
\chapter{Computing the required sample size}\label{RequiredSampleSize}}

An important decision in designing sampling schemes is the number of units to select. In other words, what should the sample size be? If a certain budget is available for sampling, we can determine the affordable sample size from this budget. A costs model is then needed.

The alternative to deriving the affordable sample size from the budget is to start from a requirement on the quality of the survey result obtained by statistical inference. Two types of inference are distinguished, estimation and testing. The required sample size\index{Required sample size} depends on the type of sampling design. With stratified random sampling we expect that we need fewer sampling units compared to simple random sampling to estimate the population mean with the same precision, whereas with cluster random sampling and two-stage cluster random sampling in general we need more sampling units. To compute the sample size given some quality requirement, we may start with computing the required sample size for simple random sampling and then correct this sample size to account for the design effect. Therefore I start with presenting formulas for computing the required sample size for simple random sampling. Section \ref{DesignEffect} describes how the required sample sizes for other types of sampling design can be derived.

Hereafter formulas for computing the required sample size are presented for simple random sampling \emph{with replacement} (SIR) of finite populations and simple random sampling of infinite populations. For simple random sampling \emph{without replacement} (SI) of finite populations these sample sizes can be corrected by \citep{loh99}

\begin{equation}
n_{\mathrm{SI}} = \frac{n}{1+\frac{n_{\mathrm{SIR}}}{N}} \;,
\label{eq:nreqSIR}
\end{equation}

with \(n\) the required sample size for simple random sampling with replacement.

\hypertarget{standard-error}{%
\section{Standard error}\label{standard-error}}

A first option is to set a limit on the variance of the \(\pi\) estimator of the population mean, see Equation \eqref{eq:VarMean}, or on the square root of this variance, the standard error of the estimator. Given a chosen limit for the standard error \(se_{\mathrm{max}}\), the required sample size for simple random sampling with replacement can be computed by

\begin{equation}
n = \left(\frac{S^*(z)}{se_{\mathrm{max}}}\right)^2 \;,
\label{eq:nreqse}
\end{equation}

with \(S^*(z)\) a prior estimate of the population standard deviation\index{Prior estimate!of population standard deviation}. The required sample size \(n\) should be rounded to the nearest integer greater than the right-hand side of Equation \eqref{eq:nreqse}. This also applies to the following equations.

For the population proportion (areal fraction) as the parameter of interest, the required sample size can be computed by (see Equation \eqref{eq:EstVarProportionSI})

\begin{equation}
n = \left(\frac{\sqrt{p^*(1-p^*)}}{se_{\mathrm{max}}}\right)^2+1 \;,
\label{eq:nreqseproportion}
\end{equation}

with \(p^*\) a prior estimate of the population proportion\index{Prior estimate!of population proportion}.

\begin{rmdnote}
To determine the required sample size for estimating the population proportion we need a prior estimate of the population parameter of interest itself, whereas for the population mean a prior estimate is needed of the population standard deviation. The parameter of which a prior estimate is needed for sample size determination is referred to as the design parameter\index{Design parameter}.
\end{rmdnote}

Alternatively, we may require that the \emph{relative} standard error, i.e.~the standard error of the estimator divided by the population mean, may not exceed a given limit \(rse_{\mathrm{max}}\). In this case the required sample size can be computed by

\begin{equation}
n = \left(\frac{cv^*}{rse_{\mathrm{max}}}\right)^2 \;,
\label{eq:nreqrse}
\end{equation}

with \(cv^*\) a prior estimate of the population coefficient of variation\index{Prior estimate!of population coefficient of variation} \(S(z)/\bar{z}\). For a constraint on the relative standard error of the population proportion estimator we obtain

\begin{equation}
n = \left(\frac{p^*(1-p^*)}{rse_{\mathrm{max}}\;p^*}\right)^2+1=\left(\frac{1-p^*}{rse_{\mathrm{max}}}\right)^2+1 \;.
\label{eq:nreqrse2}
\end{equation}

\hypertarget{ReqSampleSizeLengthCI}{%
\section{Length of confidence interval}\label{ReqSampleSizeLengthCI}}

Another option is to require that the length of the confidence interval of the population mean may not exceed a given limit \(l_{\mathrm{max}}\):

\begin{equation}
2 \; t_{\alpha/2,n-1}\frac{S(z)}{\sqrt{n}} \leq l_{\mathrm{max}} \;,
\label{eq:widthCI}
\end{equation}

with \(t_{\alpha/2,n-1}\) the \((1-\alpha/2)\) quantile of the \emph{t} distribution with \(n-1\) degrees of freedom, \(S(z)\) the population standard deviation of the study variable, and \(n\) the sample size. The problem is that we do not know the degrees of freedom (we want to determine the sample size \(n\)). Therefore \(t_{\alpha/2,n-1}\) is replaced by \(u_{\alpha/2}\), the \((1-\alpha/2)\) quantile of the standard normal distribution. Rearranging yields

\begin{equation}
n = \left(u_{\alpha/2}\frac{S^*(z)}{l_{\mathrm{max}}/2}\right)^2 \;.
\label{eq:nreqwidthCI}
\end{equation}

The requirement can also be formulated as

\begin{equation}
P(|\hat{\bar{z}}-\bar{z}| \leq d_{\mathrm{max}}) \leq 1-\alpha \;,
\label{eq:nreqwidthCIalt}
\end{equation}

with \(d_{\mathrm{max}}\) the margin of error\index{Margin of error}: \(d_{\mathrm{max}}=l_{\mathrm{max}}/2\).

An alternative is to require that with a large probability \(1-\alpha\) the absolute value of the \emph{relative} error of the estimated mean may not exceed a given limit \(r_{\mathrm{max}}\). In formula:

\begin{equation}
P\left(\frac{\lvert\hat{\bar{z}}-\bar{z}\rvert}{\bar{z}} \leq r_{\mathrm{max}}\right) \leq 1-\alpha \;.
\label{eq:nreqPrRelError}
\end{equation}

Noting that the absolute error equals \(r_{\mathrm{max}} \bar{z}\) and inserting this in Equation \eqref{eq:nreqwidthCI} gives

\begin{equation}
n = \left(u_{\alpha/2}\frac{cv^*}{r_{\mathrm{max}}}\right)^2 \;.
\label{eq:nreqPrRelError2}
\end{equation}

As an example the required sample size is computed for estimating the population mean of the soil organic matter concentration in Voorst. The requirement is that with a probability of 95\% the absolute value of the \emph{relative} error does not exceed 10\%. A prior estimate of 0.5 for the population coefficient of variation is used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{rmax }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{u }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\AttributeTok{p =} \DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.05} \SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{((u }\SpecialCharTok{*}\NormalTok{ cv }\SpecialCharTok{/}\NormalTok{ rmax)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The required sample size is 97. The same result is obtained with function \texttt{nContMoe} of package \textbf{PracTools} (\citet{PracTools}, \citet{Vaillant2018}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(PracTools)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{ceiling}\NormalTok{(}\FunctionTok{nContMoe}\NormalTok{(}\AttributeTok{moe.sw =} \DecValTok{2}\NormalTok{, }\AttributeTok{e =}\NormalTok{ rmax, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{CVpop =}\NormalTok{ cv)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 97
\end{verbatim}

\hypertarget{length-of-confidence-interval-for-a-proportion}{%
\subsection{Length of confidence interval for a proportion}\label{length-of-confidence-interval-for-a-proportion}}

Each of the methods for computing a confidence interval of a proportion described in Subsection \ref{ConfidenceIntervalProportion} can be used to compute the required sample size given a limit for the length of the confidence interval of a proportion. The most simple option is to base the required sample size on the Wald interval\index{Wald interval} (Equation \eqref{eq:Waldinterval}), so that the required sample size can be computed by

\begin{equation}
n = \left(u_{\alpha/2}\frac{\sqrt{p^*(1-p^*)}}{l_{\mathrm{max}}/2}\right)^2 +1\;.
\label{eq:nreqwidthCIprop}
\end{equation}

The Wald interval approximates the discrete binomial distribution by a normal distribution. See the rule of thumb in Subsection \ref{ConfidenceIntervalProportion} for when this approximation is reasonable.

Package \textbf{binomSamSize} \citep{Hohle2017} has quite a few functions for computing the required sample size. Function \texttt{ciss.wald} uses the normal approximation. In the next code chunk the required sample sizes are computed for a prior estimate of the population proportion \(p^*\) of 0.2.

\begin{rmdcaution}
Argument \texttt{d} in the functions below is \emph{half} the length of the confidence interval.
\end{rmdcaution}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(binomSamSize)}
\NormalTok{p\_prior }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{n\_prop\_wald }\OtherTok{\textless{}{-}} \FunctionTok{ciss.wald}\NormalTok{(}\AttributeTok{p0 =}\NormalTok{ p\_prior, }\AttributeTok{d =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{)}
\NormalTok{n\_prop\_agrcll }\OtherTok{\textless{}{-}} \FunctionTok{ciss.agresticoull}\NormalTok{(}\AttributeTok{p0 =}\NormalTok{ p\_prior, }\AttributeTok{d =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{)}
\NormalTok{n\_prop\_wilson }\OtherTok{\textless{}{-}} \FunctionTok{ciss.wilson}\NormalTok{(}\AttributeTok{p0 =}\NormalTok{ p\_prior, }\AttributeTok{d =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The required sample sizes are 62, 58, and 60, for the Wald, Agresti-Coull, and Wilson approximation of the binomial proportion confidence interval, respectively. The required sample size with function \texttt{ciss.wald} is one unit smaller than as computed with Equation \eqref{eq:nreqwidthCIprop}, as shown in the code chunk below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ceiling}\NormalTok{((}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(p\_prior }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_prior)) }\SpecialCharTok{/} \FloatTok{0.1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 63
\end{verbatim}

\hypertarget{statistical-testing-of-hypothesis}{%
\section{Statistical testing of hypothesis}\label{statistical-testing-of-hypothesis}}

The required sample size for testing a population mean with a two-sided alternative hypothesis can be computed by \citep{Ott2015}

\begin{equation}
n = \frac{S^2(z)}{\Delta^2}\;(u_{\alpha/2}+u_{\beta})^2 \;,
\label{eq:reqsamplesizetestingmean}
\end{equation}

with \(\Delta\) the smallest relevant difference\index{Smallest relevant difference} of the population mean from the test value\index{Test value}, \(\alpha\) the tolerable probability of a type I error\index{Probability of a type I error}, i.e.~the probability of rejecting the null hypothesis when the population mean is equal to the test value, \(\beta\) the tolerable probability of a type II error\index{Probability of a type II error}, i.e.~the probability of not rejecting the null hypothesis when the population mean is not equal to the test value, \(u_{\alpha/2}\) as before, and \(u_{\beta}\) the \((1-\beta)\) quantile of the standard normal distribution. The quantity \(1-\beta\) is the power of a test\index{Power of a test}: the probability of correctly rejecting the null hypothesis. For a one-sided test, \(u_{\alpha/2}\) must be replaced by \(u_{\alpha}\).

In the next code chunk the sample size required for a given target power is computed with the standard normal distribution (Equation \eqref{eq:reqsamplesizetestingmean}), as well as with the \emph{t} distribution using function \texttt{pwr.t.test} of package \textbf{pwr} \citep{pwr}\footnote{The same result is obtained with function \texttt{power.t.test} of the \textbf{stats} package.}. This requires some iterative algorithm, as the degrees of freedom of the \emph{t} distribution are a function of the sample size(s). The required sample size is computed for a one-sample test and a one-sided alternative hypothesis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(pwr)}
\NormalTok{sd }\OtherTok{\textless{}{-}} \DecValTok{4}\NormalTok{; delta }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{; alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}\NormalTok{; beta }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{n\_norm }\OtherTok{\textless{}{-}}\NormalTok{ (sd }\SpecialCharTok{/}\NormalTok{ delta)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{qnorm}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha) }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ beta))}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{n\_t }\OtherTok{\textless{}{-}} \FunctionTok{pwr.t.test}\NormalTok{(}
  \AttributeTok{d =}\NormalTok{ delta }\SpecialCharTok{/}\NormalTok{ sd, }\AttributeTok{sig.level =}\NormalTok{ alpha, }\AttributeTok{power =}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ beta),}
  \AttributeTok{type =} \StringTok{"one.sample"}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this example the required sample size computed with the \emph{t} distribution is two units larger than that obtained with the standard normal distribution: 101 versus 99. Package \textbf{pwr} has various functions for computing the power of a test given the sample size, or reversely, the sample size for a given power, such as for the two independent samples \emph{t} test, binomial test (for one proportion), test for two proportions, etc.

\hypertarget{sample-size-for-testing-a-proportion}{%
\subsection{Sample size for testing a proportion}\label{sample-size-for-testing-a-proportion}}

For testing a proportion a graph is computed with the power of a binomial test\index{Binomial test} against the sample size. This is illustrated with a one-sided alternative \(H_a: p > 0.20\) and a smallest relevant difference of 0.10.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_test }\OtherTok{\textless{}{-}} \FloatTok{0.20}\NormalTok{; alpha }\OtherTok{\textless{}{-}} \FloatTok{0.10}\NormalTok{; delta }\OtherTok{\textless{}{-}} \FloatTok{0.10}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{150}
\NormalTok{power }\OtherTok{\textless{}{-}}\NormalTok{ k\_min }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(n))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(n))) \{}
\NormalTok{  k\_min[i] }\OtherTok{\textless{}{-}} \FunctionTok{qbinom}\NormalTok{(}\AttributeTok{p =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha, }\AttributeTok{size =}\NormalTok{ n[i], }\AttributeTok{prob =}\NormalTok{ p\_test)}
\NormalTok{  power[i] }\OtherTok{\textless{}{-}} \FunctionTok{pbinom}\NormalTok{(}
    \AttributeTok{q =}\NormalTok{ k\_min[i], }\AttributeTok{size =}\NormalTok{ n[i], }\AttributeTok{prob =}\NormalTok{ p\_test }\SpecialCharTok{+}\NormalTok{ delta, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

As can be seen in the \textbf{R} code, as a first step for each total sample size the smallest number of successes \(k_{\mathrm{min}}\) is computed at which the null hypothesis is rejected. Then the binomial probability is computed of \(k_{\mathrm{min}}+1\) or more successes for a probability of success equal to \(p_{\mathrm{test}}+\Delta\). Note that there is no need to add 1 to \texttt{k\_min} as with argument \texttt{lower.tail\ =\ FALSE} the value specified by argument \texttt{q} is not included.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/powerbinomialtest-1} 

}

\caption{Power of right-tail binomial test (test proportion: 0.2; significance level: 0.10).}\label{fig:powerbinomialtest}
\end{figure}

Figure \ref{fig:powerbinomialtest} shows that the power does not increase monotonically with the sample size. The graph shows a saw-toothed behaviour. This is caused by the step-wise increase of the critical number of successes (\texttt{k\_min}) with the total sample size.

The required sample size can be computed in two ways. The first option is to compute the smallest sample size for which the power is larger than or equal to the required power \(1-\beta\). The alternative is to compute the smallest sample size for which the power is larger than or equal to \(1-\beta\) \emph{for all sample sizes larger than this}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n1 }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(n[}\FunctionTok{which}\NormalTok{(power }\SpecialCharTok{\textgreater{}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ beta)])}
\NormalTok{ind }\OtherTok{\textless{}{-}}\NormalTok{ (power }\SpecialCharTok{\textgreater{}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ beta)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(n))) \{}
  \ControlFlowTok{if}\NormalTok{ (ind[}\FunctionTok{length}\NormalTok{(n) }\SpecialCharTok{{-}}\NormalTok{ i] }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
    \ControlFlowTok{break}
\NormalTok{\}}
\NormalTok{n2 }\OtherTok{\textless{}{-}}\NormalTok{ n[}\FunctionTok{length}\NormalTok{(n) }\SpecialCharTok{{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

The smallest sample size at which the desired level of 0.8 is reached is 88. However, as can be seen in Figure \ref{fig:powerbinomialtest} for sample sizes 89, 90, 93, 94, and 97, the power drops below the desired level of 0.80. The smallest sample size at which the power stays above the level of 0.8 is 98.

Alternatively, we may use function \texttt{pwr.p.test} of package \textbf{pwr}. This is an approximation, using an arcsine transformation of proportions. The first step is to compute Cohen's \(h\)\index{Cohen's $h$}, which is a measure of the distance between two proportions: \(h = 2\;arcsin(\sqrt{p_1})-2\;arcsin(\sqrt{p_2})\). This can be done with function \texttt{ES.h}. The value of \(h\) must be positive, which is achieved when the proportion specified by argument \texttt{p1} is larger than the proportion specified by argument \texttt{p2}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h }\OtherTok{\textless{}{-}} \FunctionTok{ES.h}\NormalTok{(}\AttributeTok{p1 =} \FloatTok{0.30}\NormalTok{, }\AttributeTok{p2 =} \FloatTok{0.20}\NormalTok{)}
\NormalTok{n\_approx }\OtherTok{\textless{}{-}} \FunctionTok{pwr.p.test}\NormalTok{(}
\NormalTok{  h, }\AttributeTok{power =}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ beta), }\AttributeTok{sig.level =}\NormalTok{ alpha, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The approximated sample size equals 84, which is somewhat smaller than the required sample sizes computed above.

\hypertarget{exercises-19}{%
\subsubsection*{Exercises}\label{exercises-19}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to compute the required sample size, given a requirement in terms of the half-length of the confidence interval of a population proportion. Use a normal approximation for computing the confidence interval. Use a range of values for half the length of the interval: \(d = (0.01, 0.02, \dots , 0.49)\). Use a prior (anticipated) proportion of 0.1 and a significance level\index{Significance level} of 0.95. Plot the required sample size against \(d\). Explain what you see. Why is it needed to provide a prior proportion?\\
\item
  Do the same for a single value for the half-length of the confidence interval of 0.2 and a range of values for the prior proportion \(p^* = (0.01,0.02, \dots ,0.49)\). Explain what you see. Why is it not needed to compute the required sample size for prior proportions \(> 0.5\)?
\end{enumerate}

\hypertarget{DesignEffect}{%
\section{Accounting for design effect}\label{DesignEffect}}

The required sample sizes computed in the previous sections are all for simple random sampling in combination with the \(\pi\) estimator of the population mean. But what is the required sample size for other types of sampling design, such as stratified (simple) random sampling, systematic random sampling, two-stage cluster random sampling, and cluster random sampling? Broadly speaking we expect that with stratified random sampling and systematic random sampling the sampling variance of the estimator of the mean will be smaller than with simple random sampling of the same number of units, whereas with two-stage cluster random sampling and cluster random sampling we expect larger sampling variances. Therefore, reversely, for the first two types of sampling design we expect that the sample size required to achieve the same level of accuracy or confidence will be smaller than with simple random sampling, and for the latter two design types this sample size will be larger. The design effect\index{Design effect} is commonly quantified by the ratio of two sampling variances of the population mean estimator \citep{loh99}:

\begin{equation}
de(p,\hat{\bar{z}}) = \frac{V_p(\hat{\bar{z}})}{V_{\mathrm{SI}}(\hat{\bar{z}}_{\pi})}= \frac{V_p(\hat{\bar{z}})}{S^2(z)/n}\;,
\label{eq:designeffect}
\end{equation}

with \(V_p(\hat{\bar{z}})\) the sampling variance of an estimator (\(\pi\) estimator, regression estimator) of the population mean with sampling design \(p\) and \(V_{\mathrm{SI}}(\hat{\bar{z}}_{\pi})\) the sampling variance of the \(\pi\) estimator of the population mean with simple random sampling. Given an estimate of this design effect, the required sample size for a more complex sampling strategy (combination of sampling design and estimator), given a constraint on the standard error or the half-length of a confidence interval, can be computed by

\begin{equation}
n(p,\hat{\bar{z}}) = \sqrt{de(p,\hat{\bar{z}})} \; n(\mathrm{SI},\pi) \;.
\label{eq:nreqdesigneffect}
\end{equation}

\begin{rmdnote}
The design effect can also be quantified by the ratio of two standard errors. Then there is no need to take the square root of the design effect, as done in Equation \eqref{eq:nreqdesigneffect}, to compute the required sample size for a more complex design, given a constraint on the standard error or the half-length of a confidence interval.
\end{rmdnote}

\hypertarget{BayesianSampleSize}{%
\section{Bayesian sample size determination}\label{BayesianSampleSize}}

A serious drawback of the classical frequentist approach of computing the required sample size explained in the previous sections is that the required sample sizes are sensitive to the design parameters\index{Design parameter} \(S^*\), \(p^*\), and \(cv^*\). We are rather uncertain about these parameters, and therefore it is attractive to replace a single value for these parameters by a probability distribution. This leads to a different statistical approach of computing the required sample size, the Bayesian approach\index{Bayesian approach!to sample size determination}. This Bayesian approach also offers the possibility of accommodating existing information about the population mean or proportion. In this section I show how this approach can be used to compute the required sample size for estimating a population mean or proportion.

But before going into details, let me explain the basics of the Bayesian approach of statistical inference. In the previous sections the statistical inference was from the frequentist perspective. How does the frequency distribution of the estimator of the population mean look like if we repeat the selection of a sample with a given sampling design over and over? Is the mean of this frequency distribution, referred to as the sampling distribution, equal to the population mean, and what is the variance of this sampling distribution?

The Bayesian approach is fundamentally different. The frequency distribution of the frequentist approach is replaced by a probability distribution of the population mean reflecting our \emph{belief} about the population mean. Note that expressing our belief in terms of a probability distribution implies that in the Bayesian approach, contrary to the frequentist approach, the population mean is a random variable. Whereas in the frequentist approach it is incorrect to say that the probability that the population mean is inside the 95\% confidence interval equals 95\% (see Section \ref{ConfidenceInterval}), this is perfectly fine in the Bayesian approach. The term confidence interval is replaced by the term \emph{credible interval}\index{Credible interval} to underline the fundamental different meaning of the interval.

The first step in the Bayesian approach of statistical inference is to postulate a \emph{prior distribution}\index{Prior distribution} for the population parameter of interest. This prior distribution expresses our belief and uncertainty about the parameter before the sample data are taken into account.

The next step is to formalise a theory about the data. This boils down to making an assumption about the type of distribution function of the data. Can we safely assume that the data follow a normal or a binomial distribution? Once the type of distribution has been specified, we can write an equation for the probability of the data \emph{as a function of the parameter}. This function is referred to as the \emph{likelihood function}\index{Likelihood function}.

The final step is to revise our prior belief about the population parameter of interest, using the data and our theory about the data as expressed in the likelihood function. This results in the \emph{posterior distribution}\index{Posterior distribution} of the parameter. Our revised or updated belief is computed with Bayes' rule\index{Bayes' rule}:

\begin{equation}
f(\theta|\mathbf{z}) = \frac{f(\theta) f(\mathbf{z}|\theta)} {f(\mathbf{z})}\;,
\label{eq:BayesTheorem}
\end{equation}

with \(f(\theta|\mathbf{z})\) the posterior distribution, i.e.~the probability density\footnote{I assume here that the parameter of interest \(\theta\) is a continuous random variable.} of the parameter given the sample data, \(f(\theta)\) our prior belief in the parameters specified by a probability distribution (prior distribution), \(f(\mathbf{z}|\theta)\) the likelihood of the data, and \(f(\mathbf{z})\) the probability distribution of the data.

\hypertarget{bayesian-criteria-for-sample-size-computation}{%
\subsection{Bayesian criteria for sample size computation}\label{bayesian-criteria-for-sample-size-computation}}

Equation \eqref{eq:BayesTheorem} shows that the posterior distribution of the population parameter of interest depends on the probability distribution of the new data \(f(\mathbf{z})\). The problem is that these new data are not yet known. We are designing a sample, and the data yet are to be collected, so at first glance this might seem an unsolvable problem. However, what we could do is to simulate with the prior probability density function a large number of values of the population parameter(s), and with each parameter a large number of possible vectors with \(n\) data. Each data vector is then used to update the prior to the posterior, using Bayes' rule (Equation \eqref{eq:BayesTheorem}). For each posterior either the length of the highest posterior density (HPD) interval \index{Highest posterior density interval} with a coverage probability\index{Coverage probability} of \(1-\alpha\) is computed, or reversely, the coverage probability of the HPD interval of length \(l_{\mathrm{max}}\). Finally, the average of the lengths of the HPD intervals or the average of the coverage probabilities is computed, and these averages are compared with our precision requirement. If the average length is larger than \(l_{\mathrm{max}}\), or the coverage probability of intervals of length \(l_{\mathrm{max}}\) is smaller than \(1-\alpha\), then we must increase \(n\); if the average length is smaller than \(l_{\mathrm{max}}\), or the coverage probability of intervals of length \(l_{\mathrm{max}}\) is larger than \(1-\alpha\), then we must decrease \(n\). This whole procedure is repeated until our precision requirement is met. Simulation is one option to compute the sample size, (partly) analytical approaches are also available.

More formally, the procedure is as follows. The prior probability density function on the population parameter(s) \(\theta\) is used to compute for a given sample size \(n\) the \emph{predictive} distribution of the data:

\begin{equation}
f(\mathbf{z}|n) = \int_{\Theta} f(\mathbf{z}|\theta,n)f(\theta)\mathrm{d}\theta\;,
\label{eq:predictivedistribution}
\end{equation}

with \(\Theta\) the parameter space for \(\theta\) containing all possible values of \(\theta\). This predictive distribution\index{Predictive distribution} is also named the \emph{preposterior} distribution\index{Preposterior distribution}, stressing that the data are not yet accounted for in the distribution.

Even if \(\theta\) would be fixed, we do not have only one vector \(\mathbf{z}\) with \(n\) data values but a probability distribution, from which we can simulate possible data vectors, referred to as the data space \(\mathcal{Z}\). In case of a binomial probability and sample size \(n\), the data space \(\mathcal{Z}\) (in the form of the number of observed successes given sample size \(n\)) can be written as the set \(\{0,1,\dots,n\}\), i.e.~one vector of length \(n\) with all ``failures'', \(n\) vectors of length \(n\) with one success, \({n \choose 2}\) vectors with two successes, etc. Each data vector is associated with a probability density (for continuous data) or probability mass (for discrete data). As a consequence, we do not have only one posterior distribution function \(f(\theta|\mathbf{z})\), but as many as we have data vectors in the data space. For each posterior distribution function the coverage of the HPD interval of a given length can be computed, or reversely, the length of the HPD interval for a given coverage. This leads to various criteria for computing the required sample size, among which are the average length criterion (ALC)\index{Average length criterion}, the average coverage criterion (ACC)\index{Average coverage criterion}, and the worst outcome criterion (WOC)\index{Worst outcome criterion} (\citet{Joseph1995}, \citet{Joseph1997}).

\hypertarget{average-length-criterion}{%
\subsubsection{Average length criterion}\label{average-length-criterion}}

For a fixed posterior HPD interval coverage of \(100(1-\alpha)\)\% the smallest sample size \(n\) is determined such that

\begin{equation}
\int_{\mathcal{Z}} l(\mathbf{z},n) f(\mathbf{z}|n)\mathrm{d}\mathbf{z} \leq l_{\mathrm{max}}\;,
\label{eq:ALC}
\end{equation}

where \(f(\mathbf{z}|n)\) is the predictive distribution of the data (Equation \eqref{eq:predictivedistribution}) and \(l(\mathbf{z},n)\) is the length of the \(100(1-\alpha)\)\% HPD interval for data \(\mathbf{z}\) and sample size \(n\), obtained by solving

\begin{equation}
\int_v^{v+l(\mathbf{z},n)}f(\theta|\mathbf{z},n)\mathrm{d}\theta= 1-\alpha\;,
\label{eq:solveALC}
\end{equation}

for \(l(\mathbf{z},n)\), for each possible data set \(\mathbf{z} \in \mathcal{Z}\). \(f(\theta|\mathbf{z},n)\) is the posterior density of the population parameter of interest given the data \(\mathbf{z}\) and sample size \(n\). ALC ensures that the average length of \(100(1-\alpha)\)\% posterior HPD intervals, weighted by \(f(\mathbf{z}|n)\), is at most \(l_{\mathrm{max}}\).

\hypertarget{average-coverage-criterion}{%
\subsubsection{Average coverage criterion}\label{average-coverage-criterion}}

For a fixed posterior HPD interval of length \(l_\mathrm{max}\) the smallest sample size \(n\) is determined such that

\begin{equation}
\int_{\mathcal{Z}} \left\{ \int_v^{v+l_\mathrm{max}}f(\theta|\mathbf{z},n)\mathrm{d}\theta \right\} f(\mathbf{z}|n)\mathrm{d}\mathbf{z} \geq 1-\alpha \;.
\label{eq:ACC}
\end{equation}

ACC ensures that the average coverage of HPD intervals of length \(l_\mathrm{max}\) is at least \(1-\alpha\). The integral inside the curly brackets is the integral of the posterior density of the population parameter of interest over the HPD interval \((v,v+l_\mathrm{max})\), given a data vector \(\mathbf{z}\) of size \(n\). The mean of this integrated posterior density of the parameter of interest \(\theta\) is obtained by multiplying the integrated density with the predictive probability of the data and integrating over all possible data sets in \(\mathcal{Z}\).

\hypertarget{worst-outcome-criterion}{%
\subsubsection{Worst outcome criterion}\label{worst-outcome-criterion}}

Neither ALC nor ACC guarantee that for a particular data set \(\mathbf{z}\) the criterion is met, as both are defined as averages over all possible data sets in \(\mathcal{Z}\). A more conservative sample size can be computed by requiring that for all data sets \(\mathcal{Z}\) both criteria are met. \citet{Joseph1997} modified this criterion by restricting the data sets to a subset \(\mathcal{W}\) of most likely data sets. The criterion thus obtained is referred to as the modified worst outcome criterion, but I refer to it shortly as the worst outcome criterion (WOC). So, the criterion is

\begin{equation}
\mathrm{inf}_{\mathbf{z} \in \mathcal{W}} \left\{\int_v^{v+l(\mathbf{z},n)}f(\theta|\mathbf{z},n)\mathrm{d}\theta\right\} \geq 1- \alpha \;.
\label{eq:worst}
\end{equation}

The smallest sample size satisfying this condition is used as the sample size. For instance, if the 95\% most likely data sets are chosen as subspace \(\mathcal{W}\), WOC guarantees that there is 95\% assurance that the length of the \(100(1-\alpha)\)\% posterior HPD intervals will be at most \(l_{\mathrm{max}}\). The fraction of most likely data sets in subspace \(\mathcal{W}\) is referred to as the worst level.

\hypertarget{mixed-bayesian-likelihood-approach}{%
\subsection{Mixed Bayesian-likelihood approach}\label{mixed-bayesian-likelihood-approach}}

Besides the fully Bayesian approach, \citet{Joseph1997} describe a mixed Bayesian-likelihood approach\index{Mixed Bayesian-likelihood approach} for determining the sample size. In the mixed Bayesian-likelihood approach of sample size determination the prior distribution of the parameter(s) is only used to derive the predictive distribution of the data (Equation \eqref{eq:predictivedistribution}), not for deriving the posterior distributions of the parameter of interest for each data vector. For analysis of the posterior distribution, an uninformative prior\index{Uninformative prior} is therefore used. This mixed approach is of interest when, after the data have been collected, we prefer to estimate the population mean from these data only, using the frequentist approach described in previous sections.

An example of a situation where the mixed Bayesian-likelihood approach can be attractive is the following. Suppose some data of the study variable from the population of interest are already available, but we would like to collect more data so that we will be more confident about the (current) population mean once these new data are collected. The legacy data are used to construct a prior distribution. We have doubts about the quality of the legacy data because they were collected a long time ago and the study variable might have changed in the meantime. In that case the mixed Bayesian-likelihood approach can be a good option -- we are willing to use the legacy data to plan the sampling, but not to make statements about the current population.

No closed formula for computing the required sample size exists for this approach because the posterior density function \(f(\theta|z,n)\) is not a well-defined distribution as before. However, the required sample size still can be approximated by simulation.

\hypertarget{estimation-of-population-mean}{%
\subsection{Estimation of population mean}\label{estimation-of-population-mean}}

The three criteria (ALC, ACC, and WOC) described above are now used to compute the required sample size for estimating the population mean, assuming that the data come from a normal distribution. As we are uncertain about the population standard deviation \(\sigma\) (\(S^*(z)\) in Equation \eqref{eq:nreqwidthCI} is only a prior point estimate of \(\sigma\)), a prior distribution is assigned to this parameter. It is convenient to assign a gamma distribution as a prior distribution to the \emph{reciprocal} of the population variance, referred to as the precision parameter\index{Precision parameter} \(\lambda = 1/\sigma^2\). More precisely, a prior \emph{bivariate} normal-gamma distribution\index{Bivariate normal-gamma distribution} is assigned to the population mean and the precision parameter\footnote{This is equal to a normal-inverse gamma distribution to the population mean and population variance.}. With this prior distribution, the \emph{posterior} distribution of the population mean is fully defined, i.e.~both the type of distribution and its parameters are known. The prior distribution is so-called \emph{conjugate} with the normal distribution.

The gamma distribution\index{Gamma distribution} has two parameters \(a\) and \(b\). Figure \ref{fig:gammaprior} shows the gamma distribution for \(a=5\) and \(b=100\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{5}\NormalTok{; b }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{length =} \DecValTok{1000}\NormalTok{)}
\NormalTok{dg }\OtherTok{\textless{}{-}} \FunctionTok{dgamma}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{shape =}\NormalTok{ a, }\AttributeTok{scale =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ b)}
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ dg, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Density"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Precision"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/gammaprior-1} 

}

\caption{Prior gamma distribution for the precision parameter for a shape parameter $a=5$ and a scale parameter $1/b=1/100$.}\label{fig:gammaprior}
\end{figure}

The mean of the precision parameter \(\lambda\) is given by \(a/b\) and its standard deviation by \(\sqrt{a/b^2}\).

The normal-gamma prior is used to compute the predictive distribution for the data. For ACC the required sample size can then be computed with \citep{Adcock1988}

\begin{equation}
n = \frac{4b}{a\; l_{\mathrm{max}}^2}t^2_{2a;\alpha/2} - n_0 \;,
\label{eq:nreqACC}
\end{equation}

with \(t^2_{2a;\alpha/2}\) the squared \((1-\alpha/2)\) quantile of the (usual, i.e.~neither shifted nor scaled) \emph{t} distribution with \(2a\) degrees of freedom and \(n_0\) the number of prior points. The prior sample size \(n_0\) is only relevant if we have prior information about the population mean and an informative prior is used for this population mean. If we have no information about the population mean, a non-informative prior is used and \(n_0\) equals 0. Note that as \(a/b\) is the prior mean of the inverse of the population variance, Equation \eqref{eq:nreqACC} is similar to Equation \eqref{eq:nreqwidthCI}. The only difference is that a quantile from the standard normal distribution is replaced by a quantile from a \emph{t} distribution with \(2a\) degrees of freedom.

No closed-form formula exists for computing the smallest \(n\) satisfying ALC, but the solution can be found by a bisectional search algorithm \citep{Joseph1997}.

Package \textbf{SampleSizeMeans} \citep{Joseph2012} is used to compute Bayesian required sample sizes, using both criteria (ACC and ALC), for the fully Bayesian and the mixed Bayesian-likelihood approach. The gamma distribution plotted in Figure \ref{fig:gammaprior} is used as a prior distribution for the precision parameter \(\lambda\). As a reference, also the frequentist required sample size is computed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SampleSizeMeans)}
\NormalTok{lmax }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{n\_freq }\OtherTok{\textless{}{-}} \FunctionTok{mu.freq}\NormalTok{(}\AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{lambda =}\NormalTok{ a }\SpecialCharTok{/}\NormalTok{ b, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_alc }\OtherTok{\textless{}{-}} \FunctionTok{mu.alc}\NormalTok{(}\AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{n0 =} \DecValTok{0}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_alcmbl }\OtherTok{\textless{}{-}} \FunctionTok{mu.mblalc}\NormalTok{(}\AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_acc }\OtherTok{\textless{}{-}} \FunctionTok{mu.acc}\NormalTok{(}\AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{n0 =} \DecValTok{0}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_accmbl }\OtherTok{\textless{}{-}} \FunctionTok{mu.mblacc}\NormalTok{(}\AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_woc }\OtherTok{\textless{}{-}} \FunctionTok{mu.modwoc}\NormalTok{(}
  \AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{n0 =} \DecValTok{0}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{worst.level =} \FloatTok{0.95}\NormalTok{)}
\NormalTok{n\_wocmbl }\OtherTok{\textless{}{-}} \FunctionTok{mu.mblmodwoc}\NormalTok{(}
  \AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{worst.level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:requiredsamplesizesnormalmean}Required sample sizes for estimating a normal mean, computed with three criteria for the fully Bayesian and the mixed Bayesian-likelihood (MBL) approach. Freq refers to the required sample size computed with the frequentist approach.}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
Freq & ALC & ALC-MBL & ACC & ACC-MBL & WOC & WOC-MBL\\
\midrule
77 & 92 & 93 & 100 & 102 & 194 & 201\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:requiredsamplesizesnormalmean} shows that all six required sample sizes are larger than the frequentist required sample size. This makes sense as the frequentist approach does not account for uncertainty in the population variance parameter. The mixed approach leads to slightly larger required sample sizes than the fully Bayesian approach. This is because in the mixed approach the prior distribution of the precision parameter is not used. Apparently, we do not lose much information by ignoring this prior. With WOC the required sample sizes are about twice the sample sizes obtained with the other two criteria, but this depends of course on the size of the subspace \(\mathcal{W}\). If, for instance the 80\% most likely data sets are chosen as subspace \(\mathcal{W}\), the required sample sizes are much smaller.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_woc80 }\OtherTok{\textless{}{-}} \FunctionTok{mu.modwoc}\NormalTok{(}
  \AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{n0 =} \DecValTok{0}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{worst.level =} \FloatTok{0.80}\NormalTok{)}
\NormalTok{n\_wocmbl80 }\OtherTok{\textless{}{-}} \FunctionTok{mu.mblmodwoc}\NormalTok{(}
  \AttributeTok{len =}\NormalTok{ lmax, }\AttributeTok{alpha =}\NormalTok{ a, }\AttributeTok{beta =}\NormalTok{ b, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{worst.level =} \FloatTok{0.80}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The required sample sizes with this criterion are 124 and 128 using the fully Bayesian and the mixed Bayesian-likelihood approach, respectively.

\hypertarget{estimation-of-a-population-proportion}{%
\subsection{Estimation of a population proportion}\label{estimation-of-a-population-proportion}}

The same criteria can be used to estimate the proportion of a population, or in case of an infinite population the areal fraction, satisfying some condition \citep{Joseph1995}. With simple random sampling this boils down to estimating the probability-of-success parameter \(p\) of a binomial distribution. In this case the space of possible outcomes \(\mathcal{Z}\) is the number of successes, which is discrete: \(\mathcal{Z} = \{0,1,\dots ,n\}\) with \(n\) the sample size.

The conjugate prior\index{Conjugate prior} for the binomial likelihood is the beta distribution\index{Beta distribution}:

\begin{equation}
p \sim \frac{1}{B(c,d)} \pi^{c-1} (1-\pi)^{d-1} \;,
\label{eq:priorBetadistribution}
\end{equation}

where \(B(c,d)\) is the beta function. The two parameters \(c\) and \(d\) correspond to the number of `successes' and `failures' in the problem context. The larger these numbers, the more the prior information, and the more sharply defined the probability distribution. The plot below shows this distribution for \(c=0.6\) and \(d=2.4\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OtherTok{\textless{}{-}} \FloatTok{0.6}\NormalTok{; d }\OtherTok{\textless{}{-}} \FloatTok{2.4}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length =} \DecValTok{1000}\NormalTok{)}
\NormalTok{dbt }\OtherTok{\textless{}{-}} \FunctionTok{dbeta}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{shape1 =}\NormalTok{ c, }\AttributeTok{shape2 =}\NormalTok{ d)}
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ dbt, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Density"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Proportion"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/betaprior-1} 

}

\caption{Prior beta distribution for the binomial proportion for a beta function $B(0.6,2.4)$.}\label{fig:betaprior}
\end{figure}

The mean of the binomial proportion equals \(c/(c+d)\) and its standard deviation \(\sqrt{cd/\{(c+d+1)(c+d)^2\}}\).

The preposterior marginal distribution of the data is the beta-binomial distribution:

\begin{equation}
f(z|n) = \binom{n}{z}\frac{B(z+c,n-z+d)}{B(c,d)}\;,
\label{eq:preposteriorbinomialdata}
\end{equation}

and for a given number of successes \(z\) out of \(n\) trials the posterior distribution of \(p\) equals

\begin{equation}
f(p|z,n,c,d)=\frac{1}{B(z+c,n-z+d)} p^{z+c-1} (1-p)^{n-z+d-1} \;.  
\label{eq:posteriorbinomialdata}
\end{equation}

For the binomial parameter, criterion ALC (Equation \eqref{eq:ALC}) can be written as
\begin{equation}
\sum_{z=0}^n l(z,n)f(z,n) \leq l_{\mathrm{max}} \;.
\label{eq:ALCbinomial}
\end{equation}

To compute the smallest \(n\) satisfying this condition, for each value of \(z\) and each \(n\), \(l(z,n)\) must be computed so that

\begin{equation}
\int_v^{v+l(z,n)}f(p|z,n,c,d) \mathrm{d}p = 1-\alpha \;,
\label{eq:xxx}
\end{equation}

with \(v\) the lower bound of the HPD credible set given the sample size and the observed number of successes \(z\).

For the binomial parameter, criterion ACC (Equation \eqref{eq:ACC}) can be written as

\begin{equation}
\sum_{z=0}^n \mathrm{Pr}\{p \in (v,v+l_{\mathrm{max}})\}  f(z,n) \geq 1-\alpha \;,
\label{eq:ACCbinomial}
\end{equation}

with

\begin{equation}
\mathrm{Pr}\{p \in (v,v+l_{\mathrm{max}})\}  \propto \int_{v}^{v+l_{\mathrm{max}}}p^z(1-p)^{n-z} f(p) \mathrm{d}p\;,
\label{eq:Binomialprob}
\end{equation}

with \(f(p)\) the prior density of the binomial parameter.

For more details about ACC and ALC, and about how the required sample size can be computed with WOC in case of the binomial parameter \(p\), I refer to \citet{Joseph1995}.

The required sample sizes for ALC, ACC, and WOC described in the previous subsection, using the fully Bayesian approach or the mixed Bayesian-likelihood approach, can be computed with package \href{http://www.medicine.mcgill.ca/epidemiology/Joseph/software/Bayesian-Sample-Size.html}{\textbf{SampleSizeBinomial}}\citep{SampleSizeBinomial}. This package is used to compute the required sample sizes using the beta distribution shown in Figure \ref{fig:betaprior} as a prior for the population proportion. Note that argument \texttt{len} of the various functions of package \textbf{SampleSizeBinomial} specifies the total length of the confidence interval, not \emph{half} the length as passed to function \texttt{ciss.wald} using argument \texttt{d}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SampleSizeBinomial)}
\NormalTok{n\_alc }\OtherTok{\textless{}{-}} \FunctionTok{prop.alc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{n\_alcmbl }\OtherTok{\textless{}{-}} \FunctionTok{prop.mblalc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{n\_acc }\OtherTok{\textless{}{-}} \FunctionTok{prop.acc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{n\_accmbl }\OtherTok{\textless{}{-}} \FunctionTok{prop.mblacc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{n\_woc }\OtherTok{\textless{}{-}} \FunctionTok{prop.modwoc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{worst.level =} \FloatTok{0.80}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{n\_wocmbl }\OtherTok{\textless{}{-}} \FunctionTok{prop.mblmodwoc}\NormalTok{(}
  \AttributeTok{len =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ c, }\AttributeTok{beta =}\NormalTok{ d, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{exact =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{worst.level =} \FloatTok{0.80}\NormalTok{)}\SpecialCharTok{$}\NormalTok{n}
\FunctionTok{library}\NormalTok{(binomSamSize)}
\NormalTok{n\_freq }\OtherTok{\textless{}{-}} \FunctionTok{ciss.wald}\NormalTok{(}\AttributeTok{p0 =}\NormalTok{ c }\SpecialCharTok{/}\NormalTok{ (c }\SpecialCharTok{+}\NormalTok{ d), }\AttributeTok{d =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The required sample sizes are shown in Table \ref{tab:requiredsamplesizesbinomialproportion}.

\begin{table}

\caption{\label{tab:requiredsamplesizesbinomialproportion}Required sample sizes for estimating a binomial proportion, computed with three criteria for the fully Bayesian and the mixed Bayesian-likelihood (MBL) approach. Freq refers to the required sample size computed with the frequentist approach.}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
Freq & ALC & ALC-MBL & ACC & ACC-MBL & WOC & WOC-MBL\\
\midrule
62 & 33 & 38 & 50 & 53 & 80 & 81\\
\bottomrule
\end{tabular}
\end{table}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5384097 287.6   12043445 643.2  12043445  643.2
Vcells 26772772 204.3   91428184 697.6 177363197 1353.2
\end{verbatim}

\hypertarget{MBpredictionofDesignVariance}{%
\chapter{Model-based optimisation of probability sampling designs}\label{MBpredictionofDesignVariance}}

In Chapter \ref{Modelassisted} on model-assisted estimation I explained how a linear regression model or a non-linear model obtained with a machine learning algorithm can be used to increase the precision of design-based estimates of the population mean or total using the data collected by a given probability sampling design. In this chapter I will explain how a model of the study variable can be used at an earlier stage to optimise probability sampling designs. I will show how a model can help to choose between alternative sampling design types, for instance between systematic random sampling, spreading out the sampling units throughout the study area, and two-stage cluster random sampling, resulting in spatial clusters of sampling units. Besides I will explain how to use a model to optimise the sample size of a given sampling design type, for instance, the number of primary and secondary sampling units with two-stage cluster random sampling. The final section of this chapter is about how a model can be used to optimise spatial strata for stratified simple random sampling.

The models used in this chapter are all geostatistical models of the spatial variation. Chapter \ref{Introkriging} is an introduction to geostatistical modelling. Several geostatistical concepts explained in that chapter are needed here to predict the sampling variance.

A general geostatistical model of the spatial variation is

\begin{equation}
\begin{split}
Z(\mathbf{s}) &= \mu(\mathbf{s}) + \epsilon(\mathbf{s}) \\
\epsilon(\mathbf{s}) &\sim \mathcal{N}(0,\sigma^2) \\
\mathrm{Cov}(\epsilon(\mathbf{s}),\epsilon(\mathbf{s}^{\prime})) &= C(\mathbf{h}) \;,
\end{split}
\label{eq:geostatmodel}
\end{equation}

with \(Z(\mathbf{s})\) the study variable at location \(\mathbf{s}\), \(\mu(\mathbf{s})\) the mean at location \(\mathbf{s}\), \(\epsilon(\mathbf{s})\) the residual at location \(\mathbf{s}\), and \(C(\mathbf{h})\) the covariance of the residuals at two locations separated by vector \(\mathbf{h} = \mathbf{s}-\mathbf{s}^{\prime}\). The residuals are assumed to have a normal distribution with zero mean and a constant variance \(\sigma^2\) (\(\mathcal{N}(0,\sigma^2)\)).

The model of the spatial variation has several parameters. In case of a model in which the mean is a linear combination of covariates, these are the regression coefficients associated with the covariates and the parameters of a semivariogram describing the spatial dependence of the residuals. A semivariogram is a model for half the expectation of the squared difference of the study variable or the residuals of a model at two locations, referred to as the semivariance, as a function of the length (and direction) of the vector separating the two locations (Chapter \ref{Introkriging}).

Using the model to predict the sampling variance of a design-based estimator of a population mean requires prior knowledge of the semivariogram. When data from the study area of interest are available, these data can be used to choose a semivariogram model and to estimate the parameters of the model. If no such data are available, we must make a best guess, based on data collected in other areas. In all cases I recommend to keep the model as simple as possible.

\hypertarget{model-based-optimisation-of-sampling-design-type-and-sample-size}{%
\section{Model-based optimisation of sampling design type and sample size}\label{model-based-optimisation-of-sampling-design-type-and-sample-size}}

In Chapter \ref{RequiredSampleSize} I presented methods and formulas for computing the required sample size given various measures to quantify the quality of the survey result. These required sample sizes are for simple random sampling. For other types of sampling design, the required sample size can be approximated by multiplying the required sample size for simple random sampling with the design effect, see Section \ref{DesignEffect}. An alternative is to use a model of the spatial variation to predict the sampling variance of the estimator of the mean for the type of sampling design under study and a range of sample sizes, plotting the predicted variance (or standard error) against the sample size, and using this plot inversely to derive the required sample size given a constraint on the sampling variance (standard error).

The computed required sample size applies to several given parameters of the sampling design. For instance, for stratified random sampling the sample size is computed for a given stratification and sample size allocation scheme, for cluster random sampling for given clusters, and for two-stage cluster random sampling for given primary sampling units (PSUs) and the number of secondary sampling units (SSUs) selected per PSU draw. However, the model can also be used to optimise these sampling design parameters. For stratified random sampling the optimal allocation can be computed by predicting the population standard deviations within strata and using these predicted standard deviations in Equation \eqref{eq:optallocation}. Even the stratification can be optimised, see Section \ref{Ospats}. If we have a costs model for two-stage cluster random sampling the number of PSU draws and the number of SSUs per PSU draw can be optimised.

Model-based prediction of the sampling variance can also be useful to compare alternative types of sampling design at equal total costs or equal variance of the estimated population mean or total. For instance, to compare systematic random sampling, leading to good spatial coverage, and two-stage cluster random sampling, resulting in spatial clusters of observations.

Three approaches for model-based prediction of the sampling variance of a design-based estimator of the population mean (or total) are described: the analytical approach (Subsection \ref{AnalyticalApproach}), the geostatistical simulation approach (Subsection \ref{GeostatisticalSimulationApproach}), and the Bayesian approach (Subsection \ref{MBpredSamplingVarBayes}). In the analytical approach we assume that the mean, \(\mu(\mathbf{s})\) in Equation \eqref{eq:geostatmodel}, is everywhere the same. This assumption is relaxed in the geostatistical simulation approach. This simulation approach can also accommodate models in which the mean is a linear combination of covariates and/or spatial coordinates to predict the sampling variance. Furthermore, this simulation approach can be used to predict the sampling variance of the estimator of the mean of a trans-Gaussian variable, i.e.~a random variable that can be transformed to a Gaussian variable.

The predicted sampling variances of the estimated population mean obtained with the analytical and the geostatistical simulation approach are conditional on the model of the spatial variation. Uncertainty about this model is not accounted for. On the contrary, in the Bayesian approach we do account for our uncertainty about the assumed model, and we analyse how this uncertainty propagates to the sampling variance of the estimator of the mean.

In some publications the sampling variance as predicted with a statistical model is referred to as the anticipated variance\index{Anticipated variance} (\citet{sar92}, p.~450).

\hypertarget{AnalyticalApproach}{%
\subsection{Analytical approach}\label{AnalyticalApproach}}

In the analytical approach the sampling variance of the estimator of the mean is derived from mean semivariances within the study area\index{Mean semivariance!within a study area} and mean semivariances within the sample\index{Mean semivariance!within a sample}. Assuming isotropy, the mean semivariances are a function of the separation distance between pairs of points.

The sampling variance of the \(\pi\) estimator of the population mean can be predicted by (\citet{dom94}, \citet{gru06})

\begin{equation}
E_{\xi}\{V_p(\hat{\bar{z}})\}=\bar{\gamma}-E_p(\pmb{\lambda}^{\mathrm{T}}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda}) \;,
\label{eq:MBdesignvarAnydesign}
\end{equation}

where \(E_{\xi}(\cdot)\) is the statistical expectation over realisations from the model \(\xi\), \(E_{p}(\cdot)\) is the statistical expectation over repeated sampling with sampling design \(p\), \(V_{p}(\hat{\bar{z}})\) is the variance of the \(\pi\) estimator of the population mean over repeated sampling with sampling design \(p\), \(\bar{\gamma}\) is the mean semivariance of the random variable at two randomly selected locations in the study area, \(\pmb{\lambda}\) is the vector of design-based weights of the units of a sample selected with design \(p\), and \(\pmb{\Gamma}_{\mathcal{S}}\) is the matrix of semivariances between the units of a sample \(\mathcal{S}\) selected with design \(p\).

The mean semivariance \(\bar{\gamma}\) is a model-based prediction of the population variance (spatial variance), i.e.~the model-expectation of the population variance:

\begin{equation}
\bar{\gamma} = E_{\xi}\{\sigma^2(z)\}\:.
\label{eq:meansemivariance}
\end{equation}

The mean semivariance \(\bar{\gamma}\) can be calculated by discretising the study area by a fine square grid, computing the matrix with geographical distances between the discretisation nodes, transforming this into a semivariance matrix, and computing the average of all elements of the semivariance matrix. The second term \(E_p(\pmb{\lambda}^{\mathrm{T}}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda})\) can be evaluated by Monte Carlo simulation, repeatedly selecting a sample according to design \(p\), calculating \(\pmb{\lambda}^{\mathrm{T}}\pmb{\Gamma}_{\mathcal{S}}\pmb{\lambda}\), and averaging.

\begin{rmdnote}
The semivariance at zero distance (same location) is 0, so the diagonal of a semivariance matrix is filled with zeroes. If a semivariogram with nugget is assumed, the zeroes on the diagonal must be replaced by the nugget to compute \(\bar{\gamma}\). The same holds for the diagonal zeroes in \(\pmb{\Gamma}_{\mathcal{S}}\).\\
\end{rmdnote}

This generic procedure is still computationally demanding, but it is the only option for complex spatial sampling designs. For basic sampling designs the general formula can be worked out. For simple random sampling, the sampling variance can be predicted by

\begin{equation}
E_{\xi}\{V_\mathrm{SI}(\hat{\bar{z}})\}=\bar{\gamma }/n \;,
\label{eq:MBdesignvarSI}
\end{equation}

and for stratified simple random sampling by

\begin{equation}
E_{\xi}\{V_\mathrm{STSI}(\hat{\bar{z}})\}=\sum_{h=1}^H w^2_h \bar{\gamma_h}/n_h \;,
\label{eq:MBdesignvarSTSI}
\end{equation}

with \(H\) the number of strata, \(w_h\) the stratum weight (relative size), \(\bar{\gamma}_h\) the mean semivariance of stratum \(h\), and \(n_h\) the number of sampling units of stratum \(h\).

\begin{rmdnote}
The model-based predictions of the variances within the strata, \(\bar{\gamma}_h\), can also be used to compute the sample sizes for Neyman allocation, which are the optimal sample sizes when the mean costs per unit are equal for the strata. To compute these sample sizes the standard deviations \(S_h(z)\) in Equation \eqref{eq:Neymanallocation} are replaced by \(\sqrt{\bar{\gamma}_h}\).
\end{rmdnote}

For systematic random sampling (sampling on a randomly placed grid), the variance can be predicted by

\begin{equation}
E_{\xi}\{V_\mathrm{SY}(\hat{\bar{z}})\}=\bar{\gamma} - E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}}) \;,
\label{eq:MBdesignvarSY}
\end{equation}

with \(E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}})\) the design-expectation, i.e.~the expectation over repeated systematic sampling, of the mean semivariance within the systematic sample (grid). With systematic random sampling the number of grid points within the study area can vary among samples, as well as the spatial pattern of the points (Chapter \ref{SY}). Therefore multiple systematic random samples must be selected, and the average of the mean semivariance within the systematic sample must be computed.

The analytical approach is illustrated with the data of agricultural field Leest \citep{HofmanBrus2021}. Nitrate-N (NO\(_3\)-N) in kg ha\textsuperscript{-1} in the layer \(0-90\) cm, using a standard soil density of 1,500 kg m\(^{-3}\), is measured at 30 points. In the next code chunk these data are used to compute a sample semivariogram using the method-of-moments with function \texttt{variogram}, see Chapter \ref{Introkriging}. A spherical model without nugget is fitted to the sample semivariogram using function \texttt{fit.variogram}. The numbers in this plot are the numbers of pairs of points used to compute the semivariances.



\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\FunctionTok{coordinates}\NormalTok{(sampleLeest) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{vg }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(N }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ sampleLeest)}
\NormalTok{vgm\_MoM }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(}
\NormalTok{  vg, }\AttributeTok{model =} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =} \DecValTok{2000}\NormalTok{, }\AttributeTok{range =} \DecValTok{20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/VariogramLeest-1} 

}

\caption{Sample semivariogram and fitted spherical model for NO\textsubscript{3}-N in field Leest. Numbers are numbers of point-pairs used in computing semivariances.}\label{fig:VariogramLeest}
\end{figure}

The few data make that the sample semivariogram is very noisy. For the moment I ignore my uncertainty about the semivariogram parameters; in Subsection \ref{MBpredSamplingVarBayes} I will show how we can account for our uncertainty about the semivariogram parameters in model-based prediction of the sampling variance. A spherical semivariogram model\index{Semivariogram model} without nugget is fitted to the sample semivariogram, i.e.~the intercept is 0. The fitted range of the model is 45 m, and the fitted sill equals 966 (kg ha\textsuperscript{-1})\textsuperscript{2}. The fitted semivariogram is used to predict the sampling variance for three sampling designs: simple random sampling, stratified simple random sampling, and systematic random sampling. The costs for these three design types will be about equal, as the study area is small, so that the access time of the sampling points selected with the three designs is about equal. The sample size of the evaluated sampling designs is 25 points. As for systematic random sampling the number of points varies among the samples, this sampling design has an \emph{expected} sample size of 25 points.

\hypertarget{simple-random-sampling}{%
\subsubsection*{Simple random sampling}\label{simple-random-sampling}}


For simple random sampling we must compute the mean semivariance within the field (Equation \eqref{eq:MBdesignvarSI}). As shown in the next code chunk, the mean semivariance is approximated by discretising the field by a square grid of 2,000 points, computing the 2,000 \(\times\) 2,000 matrix with distances between all pairs of discretisation nodes, transforming this distance matrix into a semivariance matrix using function \texttt{variogramLine} of package \textbf{gstat} \citep{peb04}, and finally averaging the semivariances. Note that in this case we do not need to replace the zeroes on the diagonal of the semivariance matrix by the nugget, as a model without nugget is fitted. The geopackage file is read with function \texttt{read\_sf} of package \textbf{sf} \citep{sf}, resulting in a simple feature object. The projection attributes of this object are removed with function \texttt{st\_set\_crs}. The centres of square grid cells are selected with function \texttt{st\_make\_grid}. The centres inside the field are selected with \texttt{mygrid{[}field{]}}, and finally the coordinates are extracted with function \texttt{st\_coordinates}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{field }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{(}\FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/leest.gpkg"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sswr"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_set\_crs}\NormalTok{(NA\_crs\_)}
\NormalTok{mygrid }\OtherTok{\textless{}{-}} \FunctionTok{st\_make\_grid}\NormalTok{(field, }\AttributeTok{cellsize =} \DecValTok{2}\NormalTok{, }\AttributeTok{what =} \StringTok{"centers"}\NormalTok{)}
\NormalTok{mygrid }\OtherTok{\textless{}{-}}\NormalTok{ mygrid[field] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_coordinates}\NormalTok{(mygrid)}
\NormalTok{H }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(mygrid))}
\NormalTok{G }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgm\_MoM, }\AttributeTok{dist\_vector =}\NormalTok{ H)}
\NormalTok{m\_semivar\_field }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(G)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{Exi\_V\_SI }\OtherTok{\textless{}{-}}\NormalTok{ m\_semivar\_field }\SpecialCharTok{/}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

The model-based prediction of the sampling variance of the estimator of the mean with this design equals 35.0.

\hypertarget{stratified-simple-random-sampling}{%
\subsubsection*{Stratified simple random sampling}\label{stratified-simple-random-sampling}}


The strata of the stratified simple random sampling design are compact geographical strata\index{Compact geographical stratum} of equal size (Section \ref{geostrata}). The number of geostrata is equal to the sample size, 25 points, so that we have one point per stratum. With this design the sampling points are reasonably well spread out over the field, but not as good as with systematic random sampling. To predict the sampling variance we must compute the mean semivariances within the geostrata, see Equation \eqref{eq:MBdesignvarSTSI}. Note that the stratum weights are constant as the strata have equal size, \(w_h = 1/n\), and that \(n_h=1\). Therefore Equation \eqref{eq:MBdesignvarSTSI} reduces to

\begin{equation}
E_{\xi}\{V_\mathrm{STSI}(\hat{\bar{z}})\}=\frac{1}{n^2}\sum_{h=1}^H \bar{\gamma_h} \;.
\label{eq:MBdesignvarSTSI2}
\end{equation}

The next code chunk shows the computation of the mean semivariance per stratum and the model-based prediction of the sampling variance of the estimator of the mean. The matrix with the coordinates is first converted to a tibble, i.e.~a data frame of class \texttt{tbl\_df}. with function \texttt{as\_tibble}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\NormalTok{mygrid }\OtherTok{\textless{}{-}}\NormalTok{ mygrid }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{))}
\FunctionTok{gridded}\NormalTok{(mygrid) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{mygeostrata }\OtherTok{\textless{}{-}} \FunctionTok{stratify}\NormalTok{(mygrid, }\AttributeTok{nStrata =}\NormalTok{ n, }\AttributeTok{equalArea =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{nTry =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{m\_semivar\_geostrata }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =}\NormalTok{ n)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n) \{}
\NormalTok{ ids }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(mygeostrata}\SpecialCharTok{$}\NormalTok{stratumId }\SpecialCharTok{==}\NormalTok{ (i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{ mysubgrd }\OtherTok{\textless{}{-}}\NormalTok{ mygeostrata[ids, ]}
\NormalTok{ H\_geostratum }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(mysubgrd[, }\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)]))}
\NormalTok{ G\_geostratum }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgm\_MoM, }\AttributeTok{dist\_vector =}\NormalTok{ H\_geostratum)}
\NormalTok{ m\_semivar\_geostrata[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(G\_geostratum)}
\NormalTok{\}}
\NormalTok{Exi\_V\_STSI }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(m\_semivar\_geostrata) }\SpecialCharTok{/}\NormalTok{ n}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

The model-based prediction of the sampling variance with this design equals 13.5 (kg ha\textsuperscript{-1})\textsuperscript{2}, which is much smaller than with simple random sampling. The large stratification effect\index{Stratification effect} can be explained by the assumed strong spatial structure of NO\(_3\)-N in the agricultural field and the improved geographical spreading of the sampling points, see Figure \ref{fig:VariogramLeest}.

\hypertarget{systematic-random-sampling}{%
\subsubsection*{Systematic random sampling}\label{systematic-random-sampling}}


To predict the sampling variance for systematic random sampling with an expected sample size of 25 points, we must compute the design-expectation of the mean semivariance within the systematic sample (Equation \eqref{eq:MBdesignvarSY}). As shown in the next code chunk, I approximated this expectation by selecting 100 systematic random samples, computing the mean semivariance for each sample, and averaging. Finally, the model-based prediction of the sampling variance is computed by subtracting the average of the mean semivariances within a systematic sample from the mean semivariance within the field computed above.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{m\_semivar\_SY }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{100}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) \{}
\NormalTok{  mySYsample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mygrid, }\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{  H\_SY }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(mySYsample))}
\NormalTok{  G\_SY }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgm\_MoM, }\AttributeTok{dist\_vector =}\NormalTok{ H\_SY)}
\NormalTok{  m\_semivar\_SY[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(G\_SY)}
\NormalTok{\}}
\NormalTok{Exi\_V\_SY }\OtherTok{\textless{}{-}}\NormalTok{ m\_semivar\_field }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(m\_semivar\_SY)}
\end{Highlighting}
\end{Shaded}

The model-based prediction of the sampling variance of the estimator of the mean with this design equals 8.3 (kg ha\textsuperscript{-1})\textsuperscript{2}, which is smaller than that of stratified simple random sampling. This can be explained by the improved geographical spreading of the sampling points with systematic random sampling as compared to stratified simple random sampling with compact geographical strata.

\hypertarget{bulking-soil-aliquots-into-a-composite-sample}{%
\subsubsection{Bulking soil aliquots into a composite sample}\label{bulking-soil-aliquots-into-a-composite-sample}}

If the soil aliquots collected at the points of the stratified random sample are bulked into a composite, as is usually done in soil testing of agricultural fields, the procedure for predicting the variance of the estimator of the mean is slightly different. Only the composite sample\index{Composite sampling} is analysed in a laboratory on NO\(_3\)-N, not the individual soil aliquots\index{Soil aliquot}. This implies that the contribution of the measurement error\index{Measurement error} to the total uncertainty about the population mean is larger. To predict the sampling variance in this situation, we need the semivariogram of errorless measurements of NO\(_3\)-N, i.e.~of the true NO\(_3\)-N contents of soil aliquots collected at points. The sill of this semivariogram will be smaller than the sill of the semivariogram of measured NO\(_3\)-N data. A simple option is to subtract an estimate of the measurement error variance from the semivariogram of measured NO\(_3\)-N data that contain a measurement error. So, the measurement error variance is subtracted from the nugget. This may lead to negative nuggets, which is not allowed (a variance cannot be negative). The preferable alternative is to add the measurement error variance to the diagonal of the covariance matrix of the data in fitting the model with maximum likelihood, see function \texttt{ll} in Subsection \ref{MBpredSamplingVarBayes}.

\hypertarget{exercises-20}{%
\subsubsection*{Exercises}\label{exercises-20}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to predict the sampling variance of the estimator of the mean of NO\(_3\)-N of agricultural field Leest, for simple random sampling and a sample size of 25 points. Use in prediction a spherical semivariogram with a nugget of 483, a partial sill of 483, and a range of 44.6 m. The sum of the nugget and partial sill (966) is equal to the sill of the semivariogram used above in predicting sampling variances. Compare the predicted sampling variance with the predicted sampling variance for the same sampling design, obtained with the semivariogram without nugget. Explain the difference.\\
\item
  Write an \textbf{R} script to compute the required sample size for simple random sampling of agricultural field Leest, for a maximum length of a 95\% confidence interval of 20. Use the semivariogram without nugget in predicting the sampling variance. See Section \ref{ReqSampleSizeLengthCI} (Equation \eqref{eq:nreqwidthCI}) for how to compute the required sample size given a prior estimate of the standard deviation of the study variable in the population.\\
\item
  Do the same for systematic random sampling. Note that for this sampling design no such formula is available. Predict for a series of \emph{expected} sample sizes, \(n = 5,6,\dots , 40\), the sampling variance of the estimator of the mean, using Equation \eqref{eq:MBdesignvarSY}. Approximate \(E_{\mathrm{SY}}(\bar{\gamma}_{\mathrm{SY}})\) from ten repeated selections. Compute the length of the confidence interval from the predicted sampling variances, and plot the interval length against the sample size. Finally, determine the required sample size for a maximum length of 20. What is the design effect for an expected sample size of 34 points (the required sample size for simple random sampling), see Equation \eqref{eq:designeffect}? Also compute the design effect for expected sample sizes of \(5,6,\dots , 40\). Explain why the design effect is not constant.
\end{enumerate}

\hypertarget{GeostatisticalSimulationApproach}{%
\subsection{Geostatistical simulation approach}\label{GeostatisticalSimulationApproach}}

The alternative to the analytical approach is to use a geostatistical simulation\index{Geostatistical simulation} approach. It is computationally more demanding, but an advantage of this approach is its flexibility. It can also be used to predict the sampling variance of the estimator of the mean using a geostatistical model with a non-constant mean. And besides, this approach can also handle trans-Gaussian variables\index{Trans-Gaussian variable}, i.e.~variables whose distribution can be transformed into a normal distribution. In Subsection \ref{MBpredSamplingVarBayes} geostatistical simulation is used to predict the variance of the estimator of the mean of a lognormal variable.

The geostatistical simulation approach for predicting the sampling variance of a design-based estimator of the population mean involves the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select a large number \(S\) of random samples with sampling design \(p\).\\
\item
  Use the model to simulate values of the study variable for all sampling points.\\
\item
  Estimate for each sample the population mean, using the design-based estimator of the population mean for sampling design \(p\). This results in \(S\) estimated population means.\\
\item
  Compute the variance of the \(S\) estimated means.\\
\item
  Repeat steps 1 to 4 \(R\) times, and compute the mean of the \(R\) variances.
\end{enumerate}

This approach is illustrated with the western part of the Amhara region in Ethiopia (hereafter referred to as West-Amhara) where a large sample is available with organic matter data in the topsoil (SOM) in decagram per kg dry soil (dag kg\textsuperscript{-1}; 1 decagram = 10 gram). The soil samples are collected along roads (see Figure \ref{fig:spatialinfillEthiopia}). It is a convenience sample\index{Convenience sample}, not a probability sample, so these sample data cannot be used in design-based or model-assisted estimation of the mean or total soil carbon stock in the study area. However, the data can be used to model the spatial variation of the SOM concentration, and this geostatistical model\index{Geostatistical model} can then be used to design a probability sample for design-based estimation of the total mass of SOM. Apart from the point data of the SOM concentration, maps of covariates are available, such as a digital elevation model and remote sensing reflectance data. In the next code chunk I select four covariates to model the mean of the SOM concentration: elevation (dem), average near infrared reflectance (rfl-NIR), average red reflectance (rfl-red), and average land surface temperature (lst). I assume a normal distribution for the residuals of the linear model. The model parameters are estimated by restricted maximum likelihood\index{Restricted maximum likelihood estimation} (REML), using package \textbf{geoR} \citep{geoR}, see Subsection \ref{REML} for details on REML estimation of a geostatistical model. As a first step the projected coordinates of the sampling points are changed from m into km using function \texttt{mutate}. Using coordinates in m in function \texttt{likfit} could not find an optimal estimate for the range.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{sampleAmhara }\OtherTok{\textless{}{-}}\NormalTok{ sampleAmhara }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(}\AttributeTok{obj =}\NormalTok{ sampleAmhara, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{), }\AttributeTok{data.col =} \StringTok{"SOM"}\NormalTok{,}
  \AttributeTok{covar.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"dem"}\NormalTok{, }\StringTok{"rfl\_NIR"}\NormalTok{, }\StringTok{"rfl\_red"}\NormalTok{, }\StringTok{"lst"}\NormalTok{))}
\NormalTok{vgm\_REML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR,}
  \AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{50}\NormalTok{), }\AttributeTok{nugget =} \FloatTok{0.2}\NormalTok{,}
  \AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The estimated parameters of the residual semivariogram of the SOM concentration are shown in Table \ref{tab:VariogramREMLEthiopia}. The estimated regression coefficients are 12.9 for the intercept, 0.922 for elevation (dem), 7.41 for NIR reflectance, -10.42 for red reflectance, and -0.039 for land surface temperature.

Package \textbf{gstat} is used for geostatistical simulation, and therefore first the REML estimates of the semivariogram parameters are passed to function \texttt{vgm} using arguments \texttt{nugget}, \texttt{psill}, and \texttt{range} of function \texttt{vgm} of this package.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vgm\_REML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{tausq,}
  \AttributeTok{psill =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{sigmasq, }\AttributeTok{range =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{phi)}
\end{Highlighting}
\end{Shaded}

The fitted model of the spatial variation of the SOM concentration is used to compare systematic random sampling and two-stage cluster random sampling at equal variances of the estimator of the mean.

\hypertarget{systematic-random-sampling-1}{%
\subsubsection*{Systematic random sampling}\label{systematic-random-sampling-1}}


One hundred systematic random samples (\(S=100\)) with an expected sample size of 50 points (\(E[n]=50\)) are selected. The four covariates at the selected sampling points are extracted by overlaying the \texttt{SpatialPointsDataFrame} \texttt{mySYsamples} and the \texttt{SpatialPixelsDataFrame} \texttt{grdAmhara} with function \texttt{over} of package \textbf{sp} \citep{Pebesma2005}. Values at the sampling points are simulated by sequential Gaussian simulation\index{Sequential Gaussian simulation} \citep{goo97}, using function \texttt{krige} with argument \texttt{nsim\ =\ 1} of package \textbf{gstat}. Argument \texttt{dummy} is set to \texttt{TRUE} to enforce unconditional simulation\index{Geostatistical simulation!unconditional}.

\begin{rmdnote}
The alternative is conditional simulation\index{Geostatistical simulation!conditional}, using the data of the convenience sample as conditioning data. Conditional simulation is only recommended if the quality of these legacy data is sufficient, and we may trust that the study variable at the legacy points has not changed since these legacy data have been collected.
\end{rmdnote}

Note that by first drawing 100 samples, followed by simulating values of \(z\) at the selected sampling points, instead of first simulating values of \(z\) at the nodes of a discretisation grid, followed by selecting samples and overlaying with the simulated field, the simulated values of points in the same discretisation cell differ, so that we account for the infinite number of points in the population.

With systematic random sampling the sample mean is an approximately unbiased estimator of the population mean (Chapter \ref{SY}). Therefore, of each sample the mean of the simulated values is computed, using function \texttt{tapply}. Finally, the variance of the 100 sample means is computed. This is a conditional variance, conditional on the simulated values. In the code chunk below the whole procedure is repeated 100 times (\(R=100\)), leading to 100 conditional variances of sample means.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmhara }\OtherTok{\textless{}{-}}\NormalTok{ grdAmhara }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\FunctionTok{gridded}\NormalTok{(grdAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{S }\OtherTok{\textless{}{-}}\NormalTok{ R }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{v\_mzsim\_SY }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =}\NormalTok{ R)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R) \{}
\NormalTok{  mySYsamples }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{S) \{}
\NormalTok{    xy }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdAmhara, }\AttributeTok{n =} \DecValTok{50}\NormalTok{, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{)}
\NormalTok{    mySY }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{s1 =}\NormalTok{ xy}\SpecialCharTok{$}\NormalTok{x1, }\AttributeTok{s2 =}\NormalTok{ xy}\SpecialCharTok{$}\NormalTok{x2, }\AttributeTok{sample =} \FunctionTok{rep}\NormalTok{(j, }\FunctionTok{length}\NormalTok{(xy)))}
\NormalTok{    mySYsamples }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mySYsamples, mySY)}
\NormalTok{  \}}
  \FunctionTok{coordinates}\NormalTok{(mySYsamples) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(mySYsamples, grdAmhara)}
\NormalTok{  mySYs }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(mySYsamples, res[, }\FunctionTok{c}\NormalTok{(}\StringTok{"dem"}\NormalTok{, }\StringTok{"rfl\_NIR"}\NormalTok{, }\StringTok{"rfl\_red"}\NormalTok{, }\StringTok{"lst"}\NormalTok{)])}
  \FunctionTok{coordinates}\NormalTok{(mySYs) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{  zsim }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
\NormalTok{    dummy }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
    \AttributeTok{locations =}\NormalTok{ mySYs, }\AttributeTok{newdata =}\NormalTok{ mySYs,}
    \AttributeTok{model =}\NormalTok{ vgm\_REML\_gstat, }\AttributeTok{beta =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{beta,}
    \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{nsim =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{dummy =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{  m\_zsim }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(zsim}\SpecialCharTok{$}\NormalTok{sim1, }\AttributeTok{INDEX =}\NormalTok{ mySYs}\SpecialCharTok{$}\NormalTok{sample, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{  v\_mzsim\_SY[i] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(m\_zsim)}
\NormalTok{\}}
\NormalTok{grdAmhara }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(grdAmhara)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Exi\_vmz\_SY }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(v\_mzsim\_SY)}
\end{Highlighting}
\end{Shaded}

The mean of the 100 conditional variances equals 0.015 (dag kg\textsuperscript{-1})\textsuperscript{2}. This is a Monte Carlo approximation of the model-based prediction of the sampling variance of the ratio estimator of the mean for systematic random sampling with an expected sample size of 50.

\hypertarget{two-stage-cluster-random-sampling}{%
\subsubsection*{Two-stage cluster random sampling}\label{two-stage-cluster-random-sampling}}


Due to the geographical spreading of the sampling points with systematic random sampling, the accuracy of the estimated mean is expected to be high compared to that of other sampling designs of the same size. However, with large areas the time needed for travelling to the sampling points can become substantial, lowering the sampling efficiency. With large areas, sampling designs leading to spatial clusters of sampling points can be an attractive alternative. One option then is two-stage cluster random sampling, see Chapter \ref{Twostage}. The question is whether this alternative design is more efficient than systematic random sampling.

In the next code chunk 100 compact geostrata (see Section \ref{geostrata}) are computed for West-Amhara. Here these geostrata are not used as strata in stratified random sampling, but as PSUs in two-stage cluster random sampling. The difference is that in stratified random sampling from each geostratum at least one sampling unit is selected, whereas in two-stage cluster random sampling only a randomly selected subset of the geostrata is sampled. The compact geostrata, used as PSUs, are computed with function \texttt{kmeans}, and as a consequence the PSUs do not have equal size, see output of code chunk below. This is not needed in two-stage cluster random sampling, see Chapter \ref{Twostage}. If PSUs of equal size are preferred, then these can be computed with function \texttt{stratify} of package \textbf{spcosa} with argument \texttt{equalArea\ =\ TRUE}, see Section \ref{geostrata}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(}
\NormalTok{  grdAmhara[, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)], }\AttributeTok{iter.max =} \DecValTok{1000}\NormalTok{, }\AttributeTok{centers =} \DecValTok{100}\NormalTok{, }\AttributeTok{nstart =} \DecValTok{100}\NormalTok{)}
\NormalTok{mypsus }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{cluster}
\NormalTok{psusize }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{table}\NormalTok{(mypsus))}
\FunctionTok{summary}\NormalTok{(psusize)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   79.0   103.8   109.0   108.4   113.0   131.0 
\end{verbatim}

In the next code chunks I assume that the PSUs are selected with probabilities proportional to their size and with replacement (ppswr sampling), see Chapter \ref{Twostage}. In Section \ref{twostagesamplingestimators} formulas are presented for computing the optimal number of PSU draws and SSU draws per PSU draw. The optimal sample sizes are a function of the pooled variance of PSU means, \(S^2_{\mathrm{b}}\), and the pooled variance of secondary units (points) within the PSUs, \(S^2_{\mathrm{w}}\). In the current subsection these variance components are predicted with the geostatistical model.

As a first step a large number of maps are simulated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmhara}\SpecialCharTok{$}\NormalTok{psu }\OtherTok{\textless{}{-}}\NormalTok{ mypsus}
\FunctionTok{coordinates}\NormalTok{(grdAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{zsim }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
\NormalTok{  dummy }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
  \AttributeTok{locations =}\NormalTok{ grdAmhara, }\AttributeTok{newdata =}\NormalTok{ grdAmhara,}
  \AttributeTok{model =}\NormalTok{ vgm\_REML\_gstat, }\AttributeTok{beta =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{beta,}
  \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{nsim =} \DecValTok{1000}\NormalTok{,}
  \AttributeTok{dummy =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{debug.level =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{zsim }\OtherTok{\textless{}{-}}\NormalTok{ zsim[, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

For each simulated field the means of the PSUs and the variances of the simulated values within the PSUs are computed using function \texttt{tapply} in function \texttt{apply}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m\_zsim\_psu }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(zsim, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x)}
  \FunctionTok{tapply}\NormalTok{(x, }\AttributeTok{INDEX =}\NormalTok{ grdAmhara}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{FUN =}\NormalTok{ mean))}
\NormalTok{v\_zsim\_psu }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(zsim, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x)}
  \FunctionTok{tapply}\NormalTok{(x, }\AttributeTok{INDEX =}\NormalTok{ grdAmhara}\SpecialCharTok{$}\NormalTok{psu, }\AttributeTok{FUN =}\NormalTok{ var))}
\end{Highlighting}
\end{Shaded}

Next, for each simulated field the pooled variance of PSU means and the pooled variance within PSUs are computed, and finally these pooled variances are averaged over all simulated fields. The averages are approximations of the model-expectations of the pooled between unit and within unit variances, \(E_{\xi}[S^2_{\mathrm{b}}]\) and \(E_{\xi}[S^2_{\mathrm{w}}]\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_psu }\OtherTok{\textless{}{-}}\NormalTok{ psusize }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(psusize)}
\NormalTok{S2b }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(m\_zsim\_psu, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x)}
  \FunctionTok{sum}\NormalTok{(p\_psu }\SpecialCharTok{*}\NormalTok{ (x }\SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(p\_psu }\SpecialCharTok{*}\NormalTok{ x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{S2w }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(v\_zsim\_psu, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x)}
  \FunctionTok{sum}\NormalTok{(p\_psu }\SpecialCharTok{*}\NormalTok{ x))}
\NormalTok{Exi\_S2b }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(S2b)}
\NormalTok{Exi\_S2w }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(S2w)}
\end{Highlighting}
\end{Shaded}

The optimal sample sizes are computed for a simple linear costs model: \(C = c_0 + c_1n + c_2nm\), with \(c_0\) the fixed costs, \(c_1\) the access costs per PSU, including the access costs of the SSUs (points) within a given PSU, and \(c_2\) the observation costs per SSU. In the next code chunk I use \(c_1=2\) and \(c_2=1\). For the optimal sample sizes only the ratio of \(c_1\) and \(c_2\) is important, not their absolute values.

Given values for \(c_1\) and \(c_2\), the optimal number of PSU draws \(n\) and the optimal number of SSU draws per PSU draw \(m\) are computed, required for a sampling variance of the estimator of the mean equal to the sampling variance with systematic random sampling of 50 points, see Equations \eqref{eq:nopt} and \eqref{eq:mopt}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c1 }\OtherTok{\textless{}{-}} \DecValTok{2}\NormalTok{; c2 }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{nopt }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ Exi\_vmz\_SY }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(Exi\_S2w }\SpecialCharTok{*}\NormalTok{ Exi\_S2b) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(c2 }\SpecialCharTok{/}\NormalTok{ c1) }\SpecialCharTok{+}\NormalTok{ Exi\_S2b)}
\NormalTok{mopt }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(Exi\_S2w }\SpecialCharTok{/}\NormalTok{ Exi\_S2b) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(c1 }\SpecialCharTok{/}\NormalTok{ c2)}
\end{Highlighting}
\end{Shaded}

The optimal number of PSU draws is 26, and the optimal number of points per PSU draw equals 5. The total number of sampling points is 26 \(\times\) 5 = 130. This is much larger than the sample size of 50 obtained with systematic random sampling. The total observation costs therefore are substantially larger. However, the access time can be substantially smaller due to the spatial clustering of sampling points. To answer the question whether the costs saved by this reduced access time outweigh the extra costs of observation, the model for the access costs and observation costs must be further developed.

\hypertarget{MBpredSamplingVarBayes}{%
\subsection{Bayesian approach}\label{MBpredSamplingVarBayes}}

The model-based prediction of the variance of the design-based estimator of the population mean for a given sampling design is conditional on the model. If we change the model type or the model parameters, the predicted sampling variance also changes. In most situations we are quite uncertain about the model, even in situations where we have data that can be used to estimate the model parameters, as in the West-Amhara case study. Instead of using the best estimated model to predict the sampling variance as done in the previous sections, we may prefer to account for the uncertainty about the model parameters. This can be done through a Bayesian approach\index{Bayesian approach!to prediction of sampling variance}, in which the legacy data are used to update a prior distribution of the model parameters to a posterior distribution. For details about a Bayesian approach for estimating model parameters, see Section \ref{BayesianGridSpacing}. A sample from the posterior distribution of the model parameters is used one-by-one to predict the sampling variance. This can be done either analytically, as described in Subsection \ref{AnalyticalApproach}, or through geostatistical simulation, as described in Subsection \ref{GeostatisticalSimulationApproach}. Both approaches result in a \emph{distribution} of sampling variances, reflecting our uncertainty about the sampling variance of the estimator of the population mean due to uncertainty about the model parameters. The mean or median of the distribution of sampling variances can be used as the predicted sampling variance.

The Bayesian approach is illustrated with a case study on predicting the sampling variance of NO\(_3\)-N in agricultural field Melle in Belgium \citep{HofmanBrus2021}. As for field Leest used in Subsection \ref{AnalyticalApproach} data of NO\(_3\)-N are available at 30 points. The sampling points are approximately on the nodes of a square grid with a spacing of about 4.5 m. As a first step, I check whether we can safely assume that the data come from a normal distribution.



\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sampleMelle, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ N)) }\SpecialCharTok{+}
  \FunctionTok{geom\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_qq\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/qqplotMelle-1} 

}

\caption{Q-Q plot of NO\textsubscript{3}-N of field Melle.}\label{fig:qqplotMelle}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvalue }\OtherTok{\textless{}{-}} \FunctionTok{shapiro.test}\NormalTok{(sampleMelle}\SpecialCharTok{$}\NormalTok{N)}\SpecialCharTok{$}\NormalTok{p.value}
\end{Highlighting}
\end{Shaded}

The Q-Q plot\index{Q-Q plot} (Figure \ref{fig:qqplotMelle}) shows that a normal distribution is not very likely: there are too many large values, the distribution is skewed to the right. Also the \emph{p}-value\index{Significance level}\index{\emph{p}-value of a test} of the Shapiro-Wilk test\index{Shapiro-Wilk test} shows that we should reject the null hypothesis of a normal distribution for the data: \(p=0.0028\). I therefore proceed with the natural log of NO\(_3\)-N, in short lnN.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sampleMelle}\SpecialCharTok{$}\NormalTok{lnN }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(sampleMelle}\SpecialCharTok{$}\NormalTok{N)}
\end{Highlighting}
\end{Shaded}

As a first step the semivariogram of lnN is estimated by maximum likelihood\index{Maximum likelihood estimation} (Subsection \ref{MLestimationVariogram}). An exponential semivariogram model is assumed, see Equation \eqref{eq:exponential}.

\begin{rmdnote}
The parameters that are estimated are the reciprocal of the sill \(\lambda\), the ratio of spatial dependence\index{Ratio of spatial dependence} \(\xi\), defined as the partial sill divided by the sill, and the distance parameter \(\phi\). This parameterisation of the semivariogram is chosen because hereafter in the Bayesian approach prior distributions are chosen for these parameters.
\end{rmdnote}

The likelihood function is defined, using a somewhat unusual parameterisation, tailored to the Markov chain Monte Carlo (MCMC) sampling\index{Markov chain Monte Carlo sampling} from the posterior distribution of the semivariogram parameters. In MCMC a Markov chain of sampling units (vectors with semivariogram parameters) is generated using the previous sampling unit to randomly generate the next sampling unit (\citet{Gelman2013}, Chapter 11). In MCMC sampling the probability of accepting a proposed sampling unit \(\pmb{\theta}^*\) is a function of the ratio of the posterior density of the proposed sampling unit and that of the current sampling unit, \(f(\pmb{\theta}^*|\mathbf{z})/f(\pmb{\theta}_{t-1}|\mathbf{z})\), so that the normalising constant, the denominator of Equation \eqref{eq:BayesTheorem}, cancels.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mvtnorm)}
\NormalTok{ll }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(thetas) \{}
\NormalTok{  sill }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ thetas[}\DecValTok{1}\NormalTok{]}
\NormalTok{  psill }\OtherTok{\textless{}{-}}\NormalTok{ thetas[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ sill}
\NormalTok{  nugget }\OtherTok{\textless{}{-}}\NormalTok{ sill }\SpecialCharTok{{-}}\NormalTok{ psill}
\NormalTok{  vgmodel }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}
    \AttributeTok{model =}\NormalTok{ model, }\AttributeTok{psill =}\NormalTok{ psill, }\AttributeTok{range =}\NormalTok{ thetas[}\DecValTok{3}\NormalTok{], }\AttributeTok{nugget =}\NormalTok{ nugget)}
\NormalTok{  C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  XCX }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, X))}
\NormalTok{  XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, z))}
\NormalTok{  betaGLS }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(XCX, XCz)}
\NormalTok{  mu }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(X }\SpecialCharTok{\%*\%}\NormalTok{ betaGLS)}
\NormalTok{  logLik }\OtherTok{\textless{}{-}} \FunctionTok{dmvnorm}\NormalTok{(}\AttributeTok{x =}\NormalTok{ z, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sigma =}\NormalTok{ C, }\AttributeTok{log =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  logLik}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Next, initial estimates of the semivariogram parameters are computed by maximising the likelihood, using function \texttt{optim}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda.ini }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/} \FunctionTok{var}\NormalTok{(sampleMelle}\SpecialCharTok{$}\NormalTok{lnN)}
\NormalTok{xi.ini }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{phi.ini }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{pars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(lambda.ini, xi.ini, phi.ini)}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(sampleMelle[, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)]))}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(sampleMelle), }\DecValTok{1}\NormalTok{)}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ sampleMelle}\SpecialCharTok{$}\NormalTok{lnN}
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"Exp"}
\NormalTok{vgML }\OtherTok{\textless{}{-}} \FunctionTok{optim}\NormalTok{(pars, ll, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{fnscale =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{),}
  \AttributeTok{lower =} \FunctionTok{c}\NormalTok{(}\FloatTok{1e{-}6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{1e{-}6}\NormalTok{), }\AttributeTok{upper =} \FunctionTok{c}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{150}\NormalTok{), }\AttributeTok{method =} \StringTok{"L{-}BFGS{-}B"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The maximum likelihood (ML) estimates of the semivariogram parameters are used as initial values in MCMC sampling. A uniform prior is used for the inverse of the sill parameter, \(\lambda=1/\sigma^2\), with a lower bound of \(10^{-6}\) and an upper bound of 1. For the relative nugget, \(\tau^2/\sigma^2\), a uniform prior is assumed with a lower bound of 0 and an upper bound of 1. For the distance parameter \(\phi\) of the exponential semivariogram a uniform prior is assumed, with a lower bound of \(10^{-6}\) m and an upper bound of 150 m.

These priors can be defined by function \texttt{createUniformPrior} of package \textbf{BayesianTools} \citep{Hartig2018}. Function \texttt{createBayesianSetup} is then used to define the setup of the MCMC sampling, specifying the likelihood function, the prior, and the vector with best prior estimates of the model parameters, passed to function \texttt{createBayesianSetup} using argument \texttt{best}. Argument \texttt{sampler} of function \texttt{runMCMC} specifies the type of MCMC sampler. I used the differential evolution algorithm\index{Differential evolution algorithm} of \citet{terBraak2008}. Argument \texttt{start} of function \texttt{getSample} specifies the burn-in period\index{Burn-in period}, i.e.~the number of first samples that are discarded to diminish the influence of the initial semivariogram parameter values. Argument \texttt{numSamples} specifies the sample size, i.e.~the number of saved vectors with semivariogram parameter values, drawn from the posterior distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BayesianTools)}
\NormalTok{priors }\OtherTok{\textless{}{-}} \FunctionTok{createUniformPrior}\NormalTok{(}\AttributeTok{lower =} \FunctionTok{c}\NormalTok{(}\FloatTok{1e{-}6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{1e{-}6}\NormalTok{),}
                             \AttributeTok{upper =} \FunctionTok{c}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{150}\NormalTok{))}
\NormalTok{bestML }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(vgML}\SpecialCharTok{$}\NormalTok{par[}\DecValTok{1}\NormalTok{], vgML}\SpecialCharTok{$}\NormalTok{par[}\DecValTok{2}\NormalTok{], vgML}\SpecialCharTok{$}\NormalTok{par[}\DecValTok{3}\NormalTok{])}
\NormalTok{setup }\OtherTok{\textless{}{-}} \FunctionTok{createBayesianSetup}\NormalTok{(}\AttributeTok{likelihood =}\NormalTok{ ll, }\AttributeTok{prior =}\NormalTok{ priors,}
  \AttributeTok{best =}\NormalTok{ bestML, }\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{"lambda"}\NormalTok{, }\StringTok{"xi"}\NormalTok{, }\StringTok{"phi"}\NormalTok{))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{runMCMC}\NormalTok{(setup, }\AttributeTok{sampler =} \StringTok{"DEzs"}\NormalTok{)}
\NormalTok{MCMCsample }\OtherTok{\textless{}{-}} \FunctionTok{getSample}\NormalTok{(res, }\AttributeTok{start =} \DecValTok{1000}\NormalTok{, }\AttributeTok{numSamples =} \DecValTok{1000}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:MCMCsampleVariogramlnN} shows several semivariograms, sampled by MCMC from the posterior distribution of the estimated semivariogram parameters.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MCMCsampleVariogramlnN-1} 

}

\caption{Semivariograms of the natural log of NO\textsubscript{3}-N for field Melle obtained by MCMC sampling from posterior distribution of the estimated semivariogram parameters.}\label{fig:MCMCsampleVariogramlnN}
\end{figure}

The evaluated sampling design is the same as used in Subsection \ref{AnalyticalApproach} for field Leest: stratified simple random sampling, using compact geographical strata of equal size, a total sample size of 25 points, and one point per stratum.

The next step is to simulate with each of the sampled semivariograms a large number of maps of lnN. This is done by sequential Gaussian simulation, conditional on the available data. The simulated values are backtransformed. Each simulated map is then used to compute the variance of the simulated values within the geostrata \(S^2_h\). These stratum variances are used to compute the sampling variance of the estimator of the mean. Plugging \(w_h = 1/n\) (all strata have equal size) into Equation \eqref{eq:EstVarMeanSTSI} and using \(n_h=1\) in Equation \eqref{eq:EstVarstratummean} yields (compare with Equation \eqref{eq:MBdesignvarSTSI2})

\begin{equation}
    V(\hat{\bar{z}}) = \frac{1}{n^2}\sum_{h=1}^H S^2_h \;.
    \label{eq:VarSTSIMelles}
\end{equation}

In the code chunk below I use the first 100 sampled semivariograms to simulate with each semivariogram 100 maps.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{data =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{100}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{100}\NormalTok{)}
\FunctionTok{coordinates}\NormalTok{(sampleMelle) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) \{}
\NormalTok{  sill }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ MCMCsample}\SpecialCharTok{$}\NormalTok{lambda[i]}
\NormalTok{  psill }\OtherTok{\textless{}{-}}\NormalTok{ MCMCsample}\SpecialCharTok{$}\NormalTok{xi[i] }\SpecialCharTok{*}\NormalTok{ sill}
\NormalTok{  nug }\OtherTok{\textless{}{-}}\NormalTok{ sill }\SpecialCharTok{{-}}\NormalTok{ psill}
\NormalTok{  range }\OtherTok{\textless{}{-}}\NormalTok{ MCMCsample}\SpecialCharTok{$}\NormalTok{phi[i]}
\NormalTok{  vgmdl }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{nugget =}\NormalTok{ nug, }\AttributeTok{psill =}\NormalTok{ psill, }\AttributeTok{range =}\NormalTok{ range)}
\NormalTok{  ysim }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
\NormalTok{    lnN }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{locations =}\NormalTok{ sampleMelle, }\AttributeTok{newdata =}\NormalTok{ mygrid,}
    \AttributeTok{model =}\NormalTok{ vgmdl,}
    \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{nsim =} \DecValTok{100}\NormalTok{,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{  zsim }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(ysim[, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)])}
\NormalTok{  S2h }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(zsim, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x)}
    \FunctionTok{tapply}\NormalTok{(x, }\AttributeTok{INDEX =} \FunctionTok{as.factor}\NormalTok{(mygeostrata}\SpecialCharTok{$}\NormalTok{stratumId), }\AttributeTok{FUN =}\NormalTok{ var))}
\NormalTok{  V[i, ] }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ n}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*} \FunctionTok{apply}\NormalTok{(S2h, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ sum)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:plotsimulatedmapsMelle} shows sixteen maps simulated with the first four semivariograms. The four maps in a row (a to d) are simulated with the same semivariogram. All maps show that the simulated data have positive skew, which is in agreement with the prior data. The data obtained by simulating from a lognormal distribution are always strictly positive. This is not guaranteed when simulating from a normal distribution.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/plotsimulatedmapsMelle-1} 

}

\caption{Maps of NO\textsubscript{3}-N of field Melle simulated with four semivariograms (rows). Each semivariogram is used to simulate four maps (columns a-d).}\label{fig:plotsimulatedmapsMelle}
\end{figure}

The sampling variances of the estimated mean of NO\(_3\)-N obtained with these sixteen maps are shown below.

\begin{verbatim}
      a     b     c     d
1 1.364 0.831 0.878 0.847
2 1.379 1.151 0.991 1.162
3 0.669 0.594 0.522 0.530
4 0.932 1.949 0.878 0.739
\end{verbatim}

The sampling variance shows quite strong variation among the maps. The frequency distribution of Figure \ref{fig:histogramNMelle} shows our uncertainty about the sampling variance, due to uncertainty about the semivariogram, as well as due to uncertainty about the spatial distribution of NO\(_3\)-N within the agricultural field given the semivariogram and the available data from that field.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histogramNMelle-1} 

}

\caption{Frequency distribution of simulated sampling variances of the \(\pi\) estimator of the mean of NO\textsubscript{3}-N of field Melle, for stratified simple random sampling, using 25 compact geostrata of equal size, and one point per stratum.}\label{fig:histogramNMelle}
\end{figure}

As a model-based prediction of the sampling variance we can take the mean or the median of the sampling variances over all 100 \(\times\) 100 simulated maps, which are equal to 0.728 (dag kg\textsuperscript{-1}) and 0.666 (dag kg\textsuperscript{-1}), respectively. If we want to be more safe, we can take a high quantile, e.g.~the P90 of this distribution as the predicted sampling variance, which is equal to 1.100 (dag kg\textsuperscript{-1}).

I used the 30 available NO\(_3\)-N data as conditioning data in geostatistical simulation. Unconditional simulation is recommended if we cannot rely on the quality of the legacy data, for instance due to a temporal change in lnN since the time the legacy data have been observed. For NO\(_3\)-N this might well be the case. I believe that, although the effect of 30 observations on the simulated fields and on the uncertainty distribution of the sampling variance will be very small, one still may prefer unconditional simulation. With unconditional simulation we must assign the model-mean \(\mu\) to argument \texttt{beta} of function \texttt{krige}. The estimated model-mean can be estimated by generalised least squares, see function \texttt{ll} above.

\hypertarget{Ospats}{%
\section{Model-based optimisation of spatial strata}\label{Ospats}}

In this section a spatial stratification method is described that uses model predictions of the study variable as a stratification variable. As opposed to \emph{cum-root-f} stratification this spatial stratification method accounts for errors in the predictions, as well as for spatial correlation of the prediction errors \citep{deGruijter2015}.

The \textbf{Julia} package \textbf{Ospats} is an implementation of this stratification method. In \textbf{Ospats}\index{Optimal spatial stratification} the stratification is optimised through iterative reallocation of the raster cells to the strata. Recently, this stratification method was implemented in the package \textbf{SamplingStrata} (\citet{Barcaroli2014}, \citet{Barcaroli2020}). However, the algorithm used to optimise the strata differs from that in \textbf{Ospats}. In \textbf{SamplingStrata} the stratification is optimised by optimising the bounds\index{Stratum bound} (splitting points) on the stratification variable with a genetic algorithm\index{Genetic algorithm}. Optimisation of the strata through optimisation of the bounds on the stratification variable necessarily leads to non-overlapping strata, while with iterative reallocation\index{Iterative reallocation} the strata may overlap, i.e.~when the strata are sorted on the mean of the stratification variable, the upper bound of a stratum can be larger than the lower bound of the next stratum. As argued by \citet{deGruijter2015} optimisation of strata through optimisation of the stratum bounds can be suboptimal. On the other hand, optimisation of the stratum bounds needs fewer computations and therefore is quicker.

The situation considered in this section is that prior data are available, either from the study area itself or from another similar area, that can be used to fit a linear regression model for the study variable, using one or more quantitative covariates and/or factors as predictors. These predictors must be available in the study area so that the fitted model can be used to map the study variable in the study area. We wish to collect (more) data by stratified simple random sampling, to be used in design-based estimation of the population mean or total of the study variable. The central research question then is how to construct these strata.

Recall the variance estimator of the mean estimator for stratified simple random sampling (Equations \eqref{eq:EstVarMeanSTSI} and \eqref{eq:EstVarstratummean}):

\begin{equation}
V\!\left(\hat{\bar{z}}\right)=\sum\limits_{h=1}^{H}w_{h}^{2} \frac{S^2_h(z)}{n_h}\;.
\label{eq:VarMeanSTSI2}
\end{equation}

Plugging the stratum sample sizes under optimal allocation (Equation \eqref{eq:optallocation}) into Equation \eqref{eq:VarMeanSTSI2}, yields

\begin{equation}
V\!\left(\hat{\bar{z}}\right)=\frac{1}{n}\left(\sum\limits_{h=1}^{H}w_h S_h(z) \sqrt{c_h} \sum_{h=1}^H \frac{w_h S_h(z)}{\sqrt{c_h}}\right)\;.
\label{eq:VSTSINeyman}
\end{equation}

So, given the total sample size \(n\) the variance of the estimator of the mean is minimal when the criterion

\begin{equation}
O = \sum\limits_{h=1}^{H}w_h S_h(z) \sqrt{c_h} \sum_{h=1}^H \frac{w_h S_h(z)}{\sqrt{c_h}}
\label{eq:minicritospats}
\end{equation}

is minimised.

Assuming that the costs are equal for all population units, so that the mean costs are the same for all strata, the minimisation criterion reduces to

\begin{equation}
O = \left(\sum\limits_{h=1}^H w_h S_h(z)\right)^2\;.
\label{eq:EOconstantch}
\end{equation}

In practice we do not know the values of the study variable \(z\). \citet{deGruijter2015} consider the situation where we have predictions of the study variable from a linear regression model: \(\hat{z} = z + \epsilon\), with \(\epsilon\) the prediction error. So, this implies that we do not know the population standard deviations within the strata, \(S_h(z)\) of Equation \eqref{eq:VSTSINeyman}. What we do have are the stratum standard deviations of the predictions of \(z\): \(S_h(\hat{z})\). With many statistical models, such as regression and kriging models, the standard deviation of the predictions is smaller than that of the study variable: \(S_h(\hat{z}) < S_h(z)\). This is known as the smoothing or levelling effect.

The stratum standard deviations in the minimisation criterion are replaced by model-expectations of the stratum standard deviations, i.e.~by model-based predictions of the stratum standard deviations, \(E_{\xi}[S_h(z)]\). This leads to the following minimisation criterion:

\begin{equation}
E_{\xi}[O] = \left(\sum\limits_{h=1}^H w_h E_{\xi}[S_h(z)]\right)^2\;.
\label{eq:EOconstantch2}
\end{equation}

The stratum variances are predicted by

\begin{equation}
E_{\xi}[S^2_h(z)]=\frac{1}{N^2_h}\sum_{i=1}^{N_h-1}\sum_{j=i+1}^{N_h}E_{\xi}[d^2_{ij}]\;,
\end{equation}

with \(d^2_{ij} = (z_i-z_j)^2\) the squared difference of the study variable values at two nodes of a discretisation grid. The model-expectation of the squared differences are equal to

\begin{equation}
E_{\xi}[d^2_{ij}] = (\hat{z}_i-\hat{z}_j)^2+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j)
\label{eq:Exid2ij}
\;, 
\end{equation}

with \(S^2(\epsilon_i)\) the variance of the prediction error at node \(i\) and \(S^2(\epsilon_i,\epsilon_j)\) the covariance of the prediction errors at nodes \(i\) and \(j\). The authors then argue that for smoothers, such as kriging and regression, the first term must be divided by the squared correlation coefficient \(R^2\):

\begin{equation}
E_{\xi}[d^2_{ij}] = \frac{(\hat{z}_i-\hat{z}_j)^2}{R^2}+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j) \;.
\label{eq:Exid2ij2}
\end{equation}

The predicted stratum standard deviations are approximated by the square root of Equation \eqref{eq:Exid2ij2}. Plugging these model-based predictions of the stratum standard deviations into the minimisation criterion, Equation \eqref{eq:EOconstantch}, yields

\begin{equation}
E_{\xi}[O] = \frac{1}{N} \sum\limits_{h=1}^H \left( \sum_{i=1}^{N_h-1}\sum_{j=i+1}^{N_h}\frac{(\hat{z}_i-\hat{z}_j)^2}{R^2}+S^2(\epsilon_i)+S^2(\epsilon_j)-2S^2(\epsilon_i,\epsilon_j) \right)^{1 / 2}\;.
\label{eq:minicritospatsDeGruijter}
\end{equation}

Optimal spatial stratification with package \textbf{SamplingStrata} is illustrated with a survey of the SOM concentration (g kg\textsuperscript{-1}) in the topsoil (A horizon) of Xuancheng (China). Three samples are available. These three samples are merged. The total number of sampling points is 183. This sample is used to fit a simple linear regression model for the SOM concentration, using the elevation of the surface (dem) as a predictor. Function \texttt{lm} of the \textbf{stats} package is used to fit the simple linear regression model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_SOM }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(SOM\_A\_hori }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem, }\AttributeTok{data =}\NormalTok{ sampleXuancheng)}
\end{Highlighting}
\end{Shaded}

In fitting a linear regression model we assume that the relation is linear, the residual variance is constant (independent of the fitted value), and the residuals have a normal distribution. These assumptions are checked with a scatter plot of the residuals against the fitted value and a Q-Q plot\index{Q-Q plot}, respectively (Figure \ref{fig:checkassumptions}).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/checkassumptions-1} 

}

\caption{Scatter plot of residuals against fitted value and Q-Q plot of residuals, for a simple linear regression model of the SOM concentration in Xuancheng, using elevation as a predictor.}\label{fig:checkassumptions}
\end{figure}

The scatter plot shows that the first assumption is realistic. No pattern can be seen: at all fitted values the residuals are scattered around the horizontal line. However, the second and third assumption are questionable: the residual variance clearly increases with the fitted value, and the distribution of the residuals has positive skew, i.e.~it has a long upper tail. There clearly is some evidence that these two assumptions are violated. Possibly these problems can be solved by fitting a model for the natural log of the SOM concentration.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/checkassumptions2-1} 

}

\caption{Scatter plot of residuals against fitted value and Q-Q plot of residuals, for a simple linear regression model of the natural log of the SOM concentration in Xuancheng, using elevation as a predictor.}\label{fig:checkassumptions2}
\end{figure}

The variance of the residuals is more constant (Figure \ref{fig:checkassumptions2}), and the Q-Q plot is improved, although we now have too many strong negative residuals for a normal distribution. I proceed with the model for natural-log transformed SOM (lnSOM). The fitted linear regression model is used to predict lnSOM at the nodes of a 200 m \(\times\) 200 m discretisation grid.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_lnSOM, }\AttributeTok{newdata =} \FunctionTok{as}\NormalTok{(grdXuancheng, }\StringTok{"data.frame"}\NormalTok{), }\AttributeTok{se.fit =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{grdXuancheng }\OtherTok{\textless{}{-}} \FunctionTok{within}\NormalTok{(grdXuancheng, \{}
\NormalTok{  lnSOMpred }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{fit; varpred }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{se.fit}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

The predictions and their standard errors are shown in Figure \ref{fig:predictedlnSOM}.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/predictedlnSOM-1} 

}

\caption{Predicted natural log of the SOM concentration (g kg\textsuperscript{-1}) in the topsoil of Xuancheng and the standard error (se) of the predictor, obtained with a linear regression model with elevation as a predictor.}\label{fig:predictedlnSOM}
\end{figure}

Let us check now whether the spatial structure of the study variable lnSOM is fully captured by the mean, modelled as a linear function of elevation. This can be checked by estimating the semivariogram of the model residuals. If the semivariogram of the residuals is pure nugget (the semivariance does not increase with distance), then we can assume that the prediction errors are independent. In that case we do not need to account for a covariance of the prediction errors in optimisation of the spatial strata. However, if the semivariogram does show spatial structure, we must account for a covariance of the prediction errors. Figure \ref{fig:residualvariogramSOM} shows the sample semivariogram of the residuals computed with function \texttt{variogram} of package \textbf{gstat}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{sampleXuancheng }\OtherTok{\textless{}{-}}\NormalTok{ sampleXuancheng }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\FunctionTok{coordinates}\NormalTok{(sampleXuancheng) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{vg }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(lnSOM }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem, }\AttributeTok{data =}\NormalTok{ sampleXuancheng)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/residualvariogramSOM-1} 

}

\caption{Sample semivariogram of the residuals of a simple linear regression model for the natural log of the SOM concentration in Xuancheng. Numbers are numbers of point-pairs used in computing semivariances.}\label{fig:residualvariogramSOM}
\end{figure}

The sample semivariogram does not show much spatial structure, but the first two points in the semivariogram have somewhat smaller values. This indicates that the residuals at two close points, say \(< \pm 5\) km are not independent, whereas if the distance between the two points \(> \pm 5\) km, they are independent. This spatial dependency of the residuals can be modelled, e.g.~by an exponential function. The exponential semivariogram has three parameters, the nugget\index{Nugget} variance \(c_0\), the partial sill\index{Partial sill} \(c_1\), and the distance parameter\index{Distance parameter} \(\phi\). The total number of model parameters now is five: two regression coefficients (intercept and slope for elevation) and three semivariogram parameters. All five parameters can best be estimated by restricted maximum likelihood\index{Restricted maximum likelihood estimation}, see Subsection \ref{REML}. Table \ref{tab:TableModelXuancheng} shows the estimated regression coefficients and semivariogram parameters. Up to a distance of about three times the estimated distance parameter \(\phi\), which is about 8 km, the residuals are spatially correlated; beyond that distance, they are hardly correlated anymore.



\begin{table}

\caption{\label{tab:TableModelXuancheng}Estimated regression coefficients (intercept and slope for dem) and parameters of an exponential semivariogram for the natural log of the SOM concentration (g kg\textsuperscript{-1}) in Xuancheng.}
\centering
\begin{tabular}[t]{rrrrr}
\toprule
Int & dem & Nugget & Partial sill & Distance parameter (km)\\
\midrule
2.771 & 0.00222 & 0.085 & 0.061 & 2.588\\
\bottomrule
\end{tabular}
\end{table}

We conclude that the errors in the regression model predictions are not independent, although the correlation will be weak in this case, and that we must account for this correlation in optimising the spatial strata.

The discretisation grid with predicted lnSOM consists of 115,526 nodes. These are too many for function \texttt{optimStrata}. The grid is therefore thinned to a grid with a spacing of 800 m \(\times\) 800 m, resulting in 7,257 nodes.

The first step in optimisation of spatial strata with package \textbf{SamplingStrata} is to build the sampling frame with function \texttt{buildFrameSpatial}. Argument \texttt{X} specifies the stratification variables, and argument \texttt{Y} specifies the study variables. In our case we have only one stratification variable and one study variable, and these are the same variable. Argument \texttt{variance} specifies the variance of the prediction error of the study variable. Variable \texttt{dom} is an identifier of the domain of interest of which we want to estimate the mean or total. I assign the value 1 to all population units, see code chunk below, which implies that the stratification is optimised for the entire population. If we have multiple domains of interest, the stratification is optimised for each domain separately.

Finally, as a preparatory step we must specify how precise the estimated mean should be. This precision must be specified in terms of the coefficient of variation (cv), i.e.~the standard error of the estimated mean divided by the mean. I use a cv of 0.005. In case of multiple domains of interest and multiple study variables a cv must be specified per domain and per study variable. This precision requirement is used to compute the sample size for Neyman allocation (Equation \eqref{eq:Neymanallocation})\footnote{For multivariate stratification, i.e.~stratification with multiple study variables, Bethel allocation is used to compute the required sample size.}. The optimal stratification is independent of the precision requirement.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SamplingStrata)}
\NormalTok{subgrd}\SpecialCharTok{$}\NormalTok{id }\OtherTok{\textless{}{-}} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(subgrd))}
\NormalTok{subgrd}\SpecialCharTok{$}\NormalTok{dom }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(subgrd))}
\NormalTok{frame }\OtherTok{\textless{}{-}} \FunctionTok{buildFrameSpatial}\NormalTok{(}\AttributeTok{df =}\NormalTok{ subgrd, }\AttributeTok{id =} \StringTok{"id"}\NormalTok{, }\AttributeTok{X =} \FunctionTok{c}\NormalTok{(}\StringTok{"lnSOMpred"}\NormalTok{), }\AttributeTok{Y =} \FunctionTok{c}\NormalTok{(}\StringTok{"lnSOMpred"}\NormalTok{),}
  \AttributeTok{variance =} \FunctionTok{c}\NormalTok{(}\StringTok{"varpred"}\NormalTok{), }\AttributeTok{lon =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{lat =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{domainvalue =} \StringTok{"dom"}\NormalTok{)}
\NormalTok{cv }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{DOM =} \StringTok{"DOM1"}\NormalTok{, }\AttributeTok{CV1 =} \FloatTok{0.005}\NormalTok{, }\AttributeTok{domainvalue =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The optimal spatial stratification can be computed with function \texttt{optimStrata}, with argument \texttt{method\ =\ "spatial"}. The \(R^2\) value of the linear regression model, used in the minimisation criterion (Equation \eqref{eq:minicritospatsDeGruijter}), can be specified with argument \texttt{fitting}.

\begin{rmdnote}
I am not sure that the correction factor \(R^2\) in Equation \eqref{eq:Exid2ij2} is really needed. I believe that the smoothing effect is already accounted for by the variances and covariances of the prediction errors. I used an \(R^2\) value of 1.
\end{rmdnote}

Arguments \texttt{range} and \texttt{kappa} are parameters of an exponential semivariogram, needed for computing the covariance of the prediction errors. Function \texttt{optimStrata} uses an extra parameter in the exponential semivariogram: \(c_0+c_1\mathrm{exp}(-\kappa h/\phi)\). So, for the usual exponential semivariogram (Equation \eqref{eq:exponential}) \texttt{kappa} equals 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimStrata}\NormalTok{(}
  \AttributeTok{framesamp =}\NormalTok{ frame, }\AttributeTok{method =} \StringTok{"spatial"}\NormalTok{, }\AttributeTok{errors =}\NormalTok{ cv, }\AttributeTok{nStrata =} \DecValTok{5}\NormalTok{,}
  \AttributeTok{fitting =} \DecValTok{1}\NormalTok{, }\AttributeTok{range =} \FunctionTok{c}\NormalTok{(vgm\_REML}\SpecialCharTok{$}\NormalTok{phi), }\AttributeTok{kappa =} \DecValTok{1}\NormalTok{, }\AttributeTok{showPlot =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A summary of the optimised strata can be obtained with function \texttt{summaryStrata}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(smr\_strata }\OtherTok{\textless{}{-}} \FunctionTok{summaryStrata}\NormalTok{(}
\NormalTok{  res}\SpecialCharTok{$}\NormalTok{framenew, res}\SpecialCharTok{$}\NormalTok{aggr\_strata, }\AttributeTok{progress =} \ConstantTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Domain Stratum Population Allocation SamplingRate Lower_X1 Upper_X1
1      1       1       3090         12     0.004035 2.767950 2.862539
2      1       2       1931         10     0.005087 2.864846 2.991733
3      1       3       1133         10     0.008555 2.994040 3.215515
4      1       4        769         11     0.014398 3.217822 3.600789
5      1       5        334         11     0.033443 3.605403 5.098052
\end{verbatim}

In the next code chunk it is checked whether the coefficient of variation is indeed equal to the desired value of 0.005.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{strata }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{aggr\_strata}
\NormalTok{framenew }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{framenew}
\NormalTok{N\_h }\OtherTok{\textless{}{-}}\NormalTok{ strata}\SpecialCharTok{$}\NormalTok{N}
\NormalTok{w\_h }\OtherTok{\textless{}{-}}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h)}
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_h}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ strata}\SpecialCharTok{$}\NormalTok{S1}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ strata}\SpecialCharTok{$}\NormalTok{SOLUZ))}
\NormalTok{se }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(framenew}\SpecialCharTok{$}\NormalTok{Y1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.005033349
\end{verbatim}

The coefficient of variation can also be computed with function \texttt{expected\_CV}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{expected\_CV}\NormalTok{(strata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     cv(Y1)
DOM1  0.005
\end{verbatim}

Figure \ref{fig:optimalstrataXuanchengSamplingStrata} shows the optimised strata. I used the stratum bounds in \texttt{data.frame} \texttt{smr\_strata}, to compute the stratum for all raster cells of the original 200 m \(\times\) 200 m grid.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/optimalstrataXuanchengSamplingStrata-1} 

}

\caption{Model-based optimal strata for estimating the mean of the natural log of the SOM concentration in Xuancheng.}\label{fig:optimalstrataXuanchengSamplingStrata}
\end{figure}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5499941 293.8   12043445 643.2  12043445  643.2
Vcells 27548384 210.2   87915873 670.8 177363197 1353.2
\end{verbatim}

\hypertarget{SmallAreaEstimation}{%
\chapter{Sampling for estimating parameters of (small) domains}\label{SmallAreaEstimation}}

This chapter is about probability sampling and estimation of means or totals of subpopulations (subareas, subregions). In the sampling literature these subpopulations are referred to as domains of interest\index{Domain of interest}, or shortly domains. Ideally, at the stage of designing a sample these domains are known, and of every population unit we know to which domain it belongs. In that situation it is most convenient to use these domains as strata in random sampling, so that we can control the sample size in each domain (Chapter \ref{STSI}).

If we have multiple maps with domains, think for instance of a soil class map, a map with land cover classes, and a map with countries, we can make an overlay of these maps to construct the cross-tabulation strata. However, this may result in numerous strata, in some cases even more than the sample size. In this situation an attractive solution is multi-way stratification (Subsection \ref{Multiwaystratification}). With this design the domains of interest are used as strata, not their cross-classification, and the sample sizes of these marginal strata are controlled.

Even with a multi-way stratified sample, resulting in controlled sample sizes for each domain, the sample size of a domain can be too small for a reliable estimate of the mean or total when using just the data of this domain. In this case we may use model-assisted estimators (Chapter \ref{Modelassisted}) to increase the precision. Not only the data collected from a given domain are used to estimate the mean or total, but also data outside the domain (Section \ref{SmallDomainsModelAssisted}) (\citet{cha94}, \citet{Rao2003}, \citet{Falorsi2008}).

We may also wish to estimate the mean or total of domains that are not used as (marginal) strata. The sample size in these domains is then not controlled and varies among samples selected with the sampling design. As before with multi-way stratified sampling, the mean can either be estimated with the direct estimator, using the data from the domain only (Section \ref{LargeDomainsDirectEstimator}), or a model-assisted estimator, also using data from outside the domain (Section \ref{SmallDomainsModelAssisted}).

\hypertarget{LargeDomainsDirectEstimator}{%
\section{Direct estimator for large domains}\label{LargeDomainsDirectEstimator}}

If the sample size of a domain \(d\) is considered large enough to obtain a reliable estimate of the mean and, besides, the size of the domain is known, the mean of that domain can be estimated by the direct estimator\index{Direct estimator}:

\begin{equation}
\hat{\bar{z}}_{d}=\frac{1}{N_{d}}\sum_{k \in \mathcal{S}_d}\frac{z_{dk}}{\pi _{dk}} \;,
\label{eq:piestimatormeandomain}
\end{equation}

where \(N_{d}\) is the size of the domain, \(z_{dk}\) is the value for unit \(k\) of domain \(d\), and \(\pi _{dk}\) is the inclusion probability of this point.

When the domain is not used as a (marginal) stratum, so that the sample size of the domain is random, the mean of the domain can best be estimated by the ratio estimator:

\begin{equation}
\hat{\bar{z}}_{\text{ratio},d}= \frac{\hat{t}_d(z)}{\widehat{N}_d}=
\frac{\sum_{k \in \mathcal{S}_d}\frac{z_{dk}}{\pi_{dk}}}{\sum_{k \in \mathcal{S}_d}\frac{1}{\pi_{dk}}} \;.
\label{eq:generalratiodomain}
\end{equation}

\begin{rmdnote}
The ratio estimator\index{Ratio estimator} can also be used when the size of the domain is unknown. An example of this is estimating the mean of soil classes \emph{as observed in the field}, not \emph{as depicted on a soil map}. A soil map is impure, i.e.~the map units contain patches with other soil classes than as indicated on the map. The area of a given true soil class is not known.
\end{rmdnote}

For simple random sampling without replacement \(\pi_{dk} = n/N\). Inserting this in Equation \eqref{eq:generalratiodomain} gives

\begin{equation}
\hat{\bar{z}}_{\text{ratio},d}=\frac{1}{n_{d}}\sum_{k \in \mathcal{S}_d}z_{dk} \;.
\label{eq:ratiodomainSI}
\end{equation}

The mean of the domain is simply estimated by the mean of the \(z\)-values observed in the domain, i.e.~the sample mean in domain \(d\). The variance of this estimator can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{ratio},d}\right) =
\frac{1}{\hat{a}_{d}^{2}}\cdot\frac{1}{n\,(n-1)}\sum_{k \in \mathcal{S}_d}(z_{dk}-\bar{z}_{\mathcal{S}_d})^{2} \;,
\label{eq:VarratiodomainSI}
\end{equation}

where \(\bar{z}_{\mathcal{S}_d}\) is the sample mean in domain \(d\) and \(\hat{a}_{d}\) is the estimated relative size of domain \(d\):

\begin{equation}
\hat{a}_{d}=\frac{n_{d}}{n} \;.
\label{eq:estimatedrelativesizedomain}
\end{equation}

I refer to Section (8.2.2) in \citet{gru06} for the ratio estimator and its standard error with stratified simple random sampling, in case the domains cut across the strata, and other sampling designs.

The ratio estimator and its standard error can be computed with function \texttt{svyby} of package \textbf{survey} \citep{Lumley2020}. This is illustrated with Eastern Amazonia. We wish to estimate the mean aboveground biomass (AGB) of the sixteen ecoregions from a simple random sample of 200 units.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(survey)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{N =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n)}
\NormalTok{design\_si }\OtherTok{\textless{}{-}} \FunctionTok{svydesign}\NormalTok{(}\AttributeTok{id =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{fpc =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ N)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{svyby}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ AGB, }\AttributeTok{by =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ Ecoregion, }\AttributeTok{design =}\NormalTok{ design\_si, }\AttributeTok{FUN =}\NormalTok{ svymean)}
\end{Highlighting}
\end{Shaded}

The ratio estimates of the mean AGB are shown in Table \ref{tab:TableRatioEstimatesEcoregions}. Two ecoregions are missing in the table: no units are selected from these ecoregions so that a direct estimate is not available. There are three ecoregions with an estimated standard error of 0.0. These ecoregions have less than two sampling units only, so that the standard error cannot be estimated.



\begin{table}

\caption{\label{tab:TableRatioEstimatesEcoregions}Ratio estimates and estimated standard errors of the ratio estimator of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, with simple random sampling without replacement of size 200. The estimated standard errors of 0.0 are non-availables.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Ecoregion & AGB & se\\
\midrule
Cerrado & 99.7 & 15.6\\
Guianan highland moist forests & 296.0 & 0.0\\
Guianan lowland moist forests & 263.0 & 0.0\\
Gurupa varzea & 80.0 & 0.0\\
Madeira-Tapajos moist forests & 286.0 & 14.0\\
Marajo varzea & 116.6 & 27.2\\
Maranhao Babassu forests & 90.0 & 9.6\\
Mato Grosso tropical dry forests & 177.0 & 90.7\\
Monte Alegre varzea & 189.5 & 89.0\\
Purus-Madeira moist forests & 145.5 & 47.1\\
Tapajos-Xingu moist forests & 288.6 & 8.9\\
Tocantins/Pindare moist forests & 176.3 & 17.9\\
Uatuma-Trombetas moist forests & 274.7 & 6.7\\
Xingu-Tocantins-Araguaia moist forests & 223.1 & 16.6\\
\bottomrule
\end{tabular}
\end{table}

The simple random sampling is repeated 1,000 times, and every sample is used to estimate the mean AGB of the ecoregions both with the \(\pi\) estimator and the ratio estimator. As can be seen in Table \ref{tab:TableRatiovsHTEstimatesEcoregions} the standard deviation of the ratio estimates is much smaller than that of the \(\pi\) estimates. The reason is that the number of sampling units in an ecoregion varies among samples, i.e.~the sample size of an ecoregion is random. When many units are selected from an ecoregion, the estimated total of that ecoregion is large. The estimated mean as obtained with the \(\pi\) estimator then is large too, because the estimated total is divided by the fixed size (total number of population units, \(N_d\)) of the ecoregion. However, in the ratio estimator the size of an ecoregion is estimated from the same sample, although we know its size, see Equation \eqref{eq:generalratiodomain}. With many units selected from an ecoregion, the estimated size of that ecoregion, \(\widehat{N}_d\), is also large. By dividing the large estimated total by the large estimated size, a more stable estimate of the mean of the domain is obtained. For quite a few ecoregions the standard deviations are very large, especially of the \(\pi\) estimator. These are the ecoregions with very small average sample sizes. With simple random sampling the expected sample size can simply be computed by \(E[n] = n \; N_d/N\). In the following section alternative estimators are described for these ecoregions with small expected sample sizes. To speed up the computations I used a 5 km \(\times\) 5 km subgrid of \texttt{grdAmazonia} in this sampling experiment.



\begin{table}

\caption{\label{tab:TableRatiovsHTEstimatesEcoregions}Standard deviations of 1,000 \(\pi\) estimates (HT) and 1,000 ratio estimates (Ratio) of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, with simple random sampling without replacement of size 200. n: expected sample size.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
Ecoregion & HT & Ratio & n\\
\midrule
Amazon-Orinoco-Southern Caribbean mangroves & 136.9 & 36.9 & 0.87\\
Cerrado & 38.6 & 18.2 & 8.16\\
Guianan highland moist forests & 271.4 & 29.5 & 0.71\\
Guianan lowland moist forests & 160.0 & 17.9 & 2.51\\
Guianan savanna & 101.5 & 67.1 & 2.86\\
Gurupa varzea & 103.7 & 57.8 & 0.99\\
Madeira-Tapajos moist forests & 55.9 & 14.2 & 22.96\\
Marajo varzea & 48.6 & 24.7 & 10.80\\
Maranhao Babassu forests & 59.3 & 25.7 & 4.61\\
Mato Grosso tropical dry forests & 72.7 & 41.1 & 2.98\\
Monte Alegre varzea & 120.2 & 63.3 & 2.27\\
Purus-Madeira moist forests & 288.0 & 55.5 & 0.45\\
Tapajos-Xingu moist forests & 45.5 & 12.0 & 31.51\\
Tocantins/Pindare moist forests & 31.5 & 15.3 & 28.39\\
Uatuma-Trombetas moist forests & 33.4 & 8.1 & 52.37\\
Xingu-Tocantins-Araguaia moist forests & 42.4 & 17.2 & 27.56\\
\bottomrule
\end{tabular}
\end{table}

No covariates are used in the ratio estimator. If we wish to exploit covariates, the mean of a domain can best be estimated by the ratio of the regression estimate of the domain total and the estimated size of the domain:

\begin{equation}
\hat{\bar{z}}_{\text{ratio},d}= \frac{\hat{t}_{\text{regr},d}(z)}{\widehat{N}_d}\;.
\end{equation}

For a large domain with a reasonable sample size, the regression estimate can be computed from the data of that domain (Chapter \ref{Modelassisted}). For small domains, also the data from outside these domains can be used to estimate the population regression coefficients. This is explained in Subsection \ref{RegressionestimatorSmallDomain}.

\hypertarget{SmallDomainsModelAssisted}{%
\section{Model-assisted estimators for small domains}\label{SmallDomainsModelAssisted}}

When the domains are not well represented in the sample, the direct estimators from the previous section lead to large standard errors. In this situation we may try to increase the precision by also using observations from outside the domain. If we have covariates related to the study variable, we may exploit this ancillary information by fitting a regression model relating the study variable to the covariates and using the fitted model to predict the study variable for all population units (nodes of discretisation grid), see Chapter \ref{Modelassisted}\index{Model-assisted approach}. However, for a small domain\index{Small domain} we may have too few sampled units in that domain to fit a separate regression model. The alternative then is to use the entire sample to estimate the regression coefficients, and to use this global regression model to estimate the means of the domains. This introduces a systematic error, a design-bias, in the estimator. However, this extra error is potentially outweighed by the reduction of the random error due to the use of the globally estimated regression coefficients. If one or more units are selected from a domain, the observations of the study variable of these units can be used to correct for the bias. This leads to the regression estimator for small domains\index{Regression estimator!for small domains}. In the absence of such data, the mean of the domain can still be estimated by the so-called synthetic estimator\index{Synthetic estimator}.

There are quite a few packages for model-assisted estimation of means of small areas, the \textbf{maSAE} package \citep{maSAE}, the \textbf{JoSAE} package \citep{JoSAE}, the \textbf{rsae} package \citep{rsae}, and the \textbf{forestinventory} package \citep{Hill2021}. I use package \textbf{forestinventory} for model-assisted estimation (Subsections \ref{RegressionestimatorSmallDomain} and \ref{SyntheticestimatorSmallDomain}) and package \textbf{JoSAE} for model-based prediction of the means of small areas (Section \ref{SmallAreaModelBased}).

\hypertarget{RegressionestimatorSmallDomain}{%
\subsection{Regression estimator}\label{RegressionestimatorSmallDomain}}

In the regression estimator the potential bias due to the globally estimated regression coefficients can be eliminated by adding the \(\pi\) estimator of the mean of the regression residuals to the mean of the predictions in the domain (compare with Equation \eqref{eq:GREG}) (\citet{Mandallaz2007}, \citet{Mandallaz2013}):

\begin{equation}
\hat{\bar{z}}_{\text{regr},d} = \frac{1}{N_d} \sum_{k=1}^{N_d} \mathbf{x}^{\mathrm{T}}_{dk} \hat{\mathbf{b}} + \frac{1}{N_d} \sum_{k \in \mathcal{S}_d} \frac{e_{dk}}{\pi_{dk}} = \bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\mathbf{b}} + \frac{1}{N_d} \sum_{k \in \mathcal{S}_d} \frac{e_{dk}}{\pi_{dk}} \;,
\label{eq:regressionestimatorsmalldomain}
\end{equation}

with \(\mathbf{x}_{dk}\) the vector with covariate values for unit \(k\) in domain \(d\), \(\hat{\mathbf{b}}\) the vector with globally estimated regression coefficients, \(e_{dk}\) the residual for unit \(k\) in domain \(d\), \(\pi_{dk}\) the inclusion probability of that unit, and \(\bar{\mathbf{x}}_d\) the mean of the covariates in domain \(d\). Alternatively, the mean of the residuals in a domain is estimated by the ratio estimator:

\begin{equation}
\hat{\bar{z}}_{\text{regr},d} =  \bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\mathbf{b}} + \frac{1}{\widehat{N}_d} \sum_{k \in \mathcal{S}_d} \frac{e_{dk}}{\pi_{dk}} \;,
\label{eq:regressionestimatorsmalldomainratio}
\end{equation}

with \(\widehat{N}_d\) the estimated size of domain \(d\), see Equation \eqref{eq:generalratiodomain}. The regression coefficients can be estimated by Equation \eqref{eq:EstimatorMultipleRegressionCoefficients}. With simple random sampling the second term in Equation \eqref{eq:regressionestimatorsmalldomainratio} is equal to the sample mean of the residuals, so that the estimator reduces to

\begin{equation}
\hat{\bar{z}}_{\text{regr},d}=\bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\mathbf{b}} + \bar{e}_{\mathcal{S}_d}\;,
\label{eq:regressionestimatorsmalldomainSI}
\end{equation}

with \(\bar{e}_{\mathcal{S}_d}\) the sample mean of the residuals in domain \(d\).

A regression estimate can only be computed if we have at least one observation of the study variable in the domain \(d\). The variance of the regression estimator of the mean for a small domain can be estimated by \citep{Hill2021}

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{regr},d}\right) = \bar{\mathbf{x}}_d^{\mathrm{T}} \widehat{\mathbf{C}}(\hat{\mathbf{b}}) \bar{\mathbf{x}}_d + \widehat{V}\!\left(\hat{\bar{e}}_d \right)\;,
\label{eq:Varregressionestimatorsmalldomain}
\end{equation}

with \(\widehat{\mathbf{C}}(\hat{\mathbf{b}})\) the matrix with estimated sampling variances and covariances of the regression coefficients. The first variance component is the contribution due to uncertainty about the regression coefficients, the second component accounts for the uncertainty about the mean of the residuals in the domain. For simple random sampling the sampling variance of the \(\pi\) estimator of the mean of the residuals in a domain can be estimated by the sample variance of the residuals in that domain divided by the sample size \(n_d\). This variance estimator is presented in \citet{Hill2021}. If the domain is not used as a stratum and the domain mean of the residuals is estimated by the ratio estimator, the second variance component can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{e}}_{\text{ratio},d}\right) = \left(\frac{n}{n_{d}}\right)^{2}\cdot\frac{1}{n\,(n-1)}\sum_{k \in \mathcal{S}_d}(e_{dk}-\bar{e}_{\mathcal{S}_d})^{2} \;.
\label{eq:Varratioestimatorofmeanresidual}
\end{equation}

With simple random sampling the sampling variances and covariances of the estimated regression coefficients can be estimated by (Equation 2 in \citet{Hill2021})

\begin{equation}
\widehat{\mathbf{C}}(\hat{\mathbf{b}}) = \frac{1}{n} \left( \sum_{k \in \mathcal{S}} \mathbf{x}_k \mathbf{x}^{\mathrm{T}}_k \right) ^{-1} \left( \frac{1}{n^2} \sum_{k \in \mathcal{S}} e_k^2  \mathbf{x}_k \mathbf{x}^{\mathrm{T}}_k \right) \frac{1}{n}\left(\sum_{k \in \mathcal{S}}^n \mathbf{x}_k \mathbf{x}^{\mathrm{T}}_k \right)^{-1} \;.
\label{eq:samplingVarregressioncoefficients}
\end{equation}

The sampling variances and covariances of the estimators of the population regression coefficients are not equal to the model-variances and covariances as obtained with multiple linear regression, using functions \texttt{lm} and \texttt{vcov}, see Section \ref{GREG} and Chapter \ref{Approaches}.

Function \texttt{twophase} of package \textbf{forestinventory} \citep{Hill2021} can be used to compute the regression estimate for small domains and its standard error.

\begin{rmdnote}
The function name `twophase' is somewhat confusing. It suggests that we have a large sample which is subsampled in a second phase, as described in Chapter \ref{Twophase}. This is not the case here. However, upon considering infinite populations, \citet{Hill2021} treat the grid that discretises the infinite population as the first-phase sample. The sampling error introduced by this discretisation grid can then be accounted for. I ignore this sampling error, it will be very small anyway, because the number of grid cells is very large.
\end{rmdnote}

By assigning the domain means of the covariates to argument \texttt{exhaustive} of function \texttt{twophase} the sampling error of the first phase is ignored. Function \texttt{twophase} assumes simple random sampling (unless optional argument \texttt{cluster} is used). Note that for the unobserved population units (not selected units) the AGB values are changed into non-availables. In package \textbf{survey} also a function \texttt{twophase} is defined, for this reason the name of the package is made explicit by \texttt{forestinventory::twophase}. With argument \texttt{psmall\ =\ TRUE} and element \texttt{unbiased\ =\ TRUE} in the list \texttt{small\_area} the regression estimate is computed. Log-transformed SWIR2 is used as a covariate in the regression estimator of the mean AGB of the ecoregions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(forestinventory)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{lnSWIR2 =} \FunctionTok{log}\NormalTok{(SWIR2),}
         \AttributeTok{id =} \FunctionTok{row\_number}\NormalTok{(),}
         \AttributeTok{ind =} \FunctionTok{as.integer}\NormalTok{(id }\SpecialCharTok{\%in\%}\NormalTok{ units))}
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{AGB[grdAmazonia}\SpecialCharTok{$}\NormalTok{ind }\SpecialCharTok{==}\NormalTok{ 0L] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{mx\_eco\_pop }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2, }\AttributeTok{INDEX =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{Ecoregion, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{mX\_eco\_pop }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Intercept =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{length}\NormalTok{(mx\_eco\_pop)), }\AttributeTok{lnSWIR2 =}\NormalTok{ mx\_eco\_pop)}
\NormalTok{ecos\_in\_sam }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{Ecoregion)}
\NormalTok{res }\OtherTok{\textless{}{-}}\NormalTok{ forestinventory}\SpecialCharTok{::}\FunctionTok{twophase}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{data =} \FunctionTok{as.data.frame}\NormalTok{(grdAmazonia),}
  \AttributeTok{phase\_id =} \FunctionTok{list}\NormalTok{(}\AttributeTok{phase.col =} \StringTok{"ind"}\NormalTok{, }\AttributeTok{terrgrid.id =} \DecValTok{1}\NormalTok{),}
  \AttributeTok{small\_area =} \FunctionTok{list}\NormalTok{(}\AttributeTok{sa.col =} \StringTok{"Ecoregion"}\NormalTok{,}
                    \AttributeTok{areas =} \FunctionTok{sort}\NormalTok{(ecos\_in\_sam),}
                    \AttributeTok{unbiased =} \ConstantTok{TRUE}\NormalTok{),}
  \AttributeTok{psmall =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{exhaustive =}\NormalTok{ mX\_eco\_pop)}
\NormalTok{regr }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{estimation}
\end{Highlighting}
\end{Shaded}



\begin{table}

\caption{\label{tab:TableRegressionEstimatesEcoregions}Regression estimates of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, for simple random sample without replacement of size 200, using lnSWIR2 as a predictor. For explanation of variances of regression estimator, see text. n2G: sample size of ecoregion; NA: not available; NaN: not a number.}
\centering
\begin{tabular}[t]{lrllr}
\toprule
Ecoregion & AGB & ext\_var & g\_var & n2G\\
\midrule
Cerrado & 105.5 & 51.6 & 82.6 & 12\\
Guianan highland moist forests & 281.8 & NA & NaN & 1\\
Guianan lowland moist forests & 280.3 & NA & NaN & 1\\
Gurupa varzea & 57.8 & NA & NaN & 1\\
Madeira-Tapajos moist forests & 296.1 & 91.2 & 107.3 & 19\\
Marajo varzea & 163.1 & 535.2 & 546.0 & 10\\
Maranhao Babassu forests & 114.2 & 157.1 & 178.1 & 7\\
Mato Grosso tropical dry forests & 144.6 & 959.6 & 981.5 & 2\\
Monte Alegre varzea & 209.1 & 4,105.7 & 4,117.3 & 2\\
Purus-Madeira moist forests & 225.7 & 2,428.9 & 2,441.1 & 2\\
Tapajos-Xingu moist forests & 277.8 & 23.4 & 36.9 & 38\\
Tocantins/Pindare moist forests & 157.8 & 75.8 & 87.7 & 30\\
Uatuma-Trombetas moist forests & 270.6 & 33.3 & 47.5 & 46\\
Xingu-Tocantins-Araguaia moist forests & 223.6 & 51.1 & 61.6 & 29\\
\bottomrule
\end{tabular}
\end{table}

The alternative is to save the selected units (the sample) in a data frame, passed to function \texttt{twophase} with argument \texttt{data}. The results are identical because the true means of the covariate \(x\) specified with argument \texttt{exhaustive} contains all required information at the population level.

For two ecoregions no regression estimate of the mean AGB is obtained (Table \ref{tab:TableRegressionEstimatesEcoregions}). No units are selected from these domains. The estimated variance of the estimated domain mean is in the column g\_var. In the estimated variance ext\_var the first variance component of Equation \eqref{eq:Varregressionestimatorsmalldomain} is ignored. Note that for the ecoregions with a sample size of one unit (the sample size per domain is in column \texttt{n2G}) no estimate of the variance is available, because the variance of the estimated mean of the residuals cannot be estimated from one unit.

Figure \ref{fig:RatioversusRegrEcoregions} shows the regression estimates plotted against the ratio estimates. The intercept of the line, fitted with ordinary least squares (OLS), is larger than 0, and the slope is smaller than 1. Using the regression model predictions in the estimation of the means leads to some smoothing.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/RatioversusRegrEcoregions-1} 

}

\caption{Scatter plot of the ratio and the regression estimates of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia for simple random sample without replacement of size 200. In the regression estimate lnSWIR2 is used as a predictor. The line is fitted by ordinary least squares.}\label{fig:RatioversusRegrEcoregions}
\end{figure}

I quantified the gain in precision of the estimated mean AGB due to the use of the regression model by the variance of the ratio estimator divided by the variance of the regression estimator (Table \ref{tab:TableGainRegressionestimator}). For ratios larger than 1 there is a gain in precision. Both variances are estimated from 1,000 repeated ratio and regression estimates obtained with simple random sampling without replacement of size 200. For all but two small ecoregions there is a gain. For quite a few ecoregions the gain is quite large. These are the ecoregions where the globally fitted regression model explains a large part of the spatial variation of AGB.

\begin{table}

\caption{\label{tab:TableGainRegressionestimator}Estimated gain in precision of the estimated mean AGB of ecoregions in Eastern Amazonia, as quantified by the ratio of the estimated variance of the ratio estimator (no covariate used) to the estimated variance of the regression estimator (using lnSWIR2 as a predictor), for simple random sampling without replacement of size 200.}
\centering
\begin{tabular}[t]{lr}
\toprule
Ecoregion & Gain\\
\midrule
Amazon-Orinoco-Southern Caribbean mangroves & 0.57\\
Cerrado & 1.63\\
Guianan highland moist forests & 1.01\\
Guianan lowland moist forests & 1.26\\
Guianan savanna & 6.70\\
Gurupa varzea & 0.65\\
Madeira-Tapajos moist forests & 1.44\\
Marajo varzea & 1.87\\
Maranhao Babassu forests & 1.70\\
Mato Grosso tropical dry forests & 2.81\\
Monte Alegre varzea & 1.21\\
Purus-Madeira moist forests & 1.74\\
Tapajos-Xingu moist forests & 2.73\\
Tocantins/Pindare moist forests & 2.56\\
Uatuma-Trombetas moist forests & 2.10\\
Xingu-Tocantins-Araguaia moist forests & 4.06\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{SyntheticestimatorSmallDomain}{%
\subsection{Synthetic estimator}\label{SyntheticestimatorSmallDomain}}

For small domains from which no units are selected, the mean can still be estimated by the synthetic estimator\index{Synthetic estimator}, also referred to as the synthetic regression estimator, by dropping the second term in Equation \eqref{eq:regressionestimatorsmalldomain}:

\begin{equation}
\hat{\bar{z}}_{\text{syn},d}=\bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\mathbf{b}}\;.
\label{eq:syntheticestimatorsmalldomain}
\end{equation}

The variance can be estimated by

\begin{equation}
\widehat{V}\!\left(\hat{\bar{z}}_{\text{syn},d}\right) = \bar{\mathbf{x}}_d^{\mathrm{T}} \widehat{\mathbf{C}}(\hat{\mathbf{b}}) \bar{\mathbf{x}}_d \;.
\label{eq:Varsyntheticestimatorsmalldomain}
\end{equation}

This is equal to the first variance component of Equation \eqref{eq:Varregressionestimatorsmalldomain}.
The synthetic estimate can be computed with function \texttt{twophase}, with argument \texttt{psmall\ =\ FALSE} and element \texttt{unbiased\ =\ FALSE} in the list \texttt{small\_area}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}}\NormalTok{ forestinventory}\SpecialCharTok{::}\FunctionTok{twophase}\NormalTok{(AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{data =} \FunctionTok{as.data.frame}\NormalTok{(grdAmazonia),}
  \AttributeTok{phase\_id =} \FunctionTok{list}\NormalTok{(}\AttributeTok{phase.col =} \StringTok{"ind"}\NormalTok{, }\AttributeTok{terrgrid.id =} \DecValTok{1}\NormalTok{),}
  \AttributeTok{small\_area =} \FunctionTok{list}\NormalTok{(}\AttributeTok{sa.col =} \StringTok{"Ecoregion"}\NormalTok{, }\AttributeTok{areas =}\NormalTok{ ecoregions, }\AttributeTok{unbiased =} \ConstantTok{FALSE}\NormalTok{),}
  \AttributeTok{psmall =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{exhaustive =}\NormalTok{ mX\_eco\_pop)}
\NormalTok{synt }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{estimation}
\end{Highlighting}
\end{Shaded}



\begin{table}

\caption{\label{tab:TableSyntheticEstimates}Synthetic estimates of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, for simple random sample without replacement of size 200, using lnSWIR2 as a predictor. n2G: sample size of ecoregion.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
Ecoregion & AGB & g\_var & n2G\\
\midrule
Amazon-Orinoco-Southern Caribbean mangroves & 225.3 & 10.6 & 0\\
Cerrado & 81.6 & 31.0 & 12\\
Guianan highland moist forests & 278.6 & 16.0 & 1\\
Guianan lowland moist forests & 277.3 & 15.8 & 1\\
Guianan savanna & 171.8 & 12.2 & 0\\
Gurupa varzea & 218.2 & 10.4 & 1\\
Madeira-Tapajos moist forests & 279.2 & 16.1 & 19\\
Marajo varzea & 230.6 & 10.8 & 10\\
Maranhao Babassu forests & 118.3 & 20.9 & 7\\
Mato Grosso tropical dry forests & 114.0 & 21.9 & 2\\
Monte Alegre varzea & 242.6 & 11.6 & 2\\
Purus-Madeira moist forests & 250.4 & 12.3 & 2\\
Tapajos-Xingu moist forests & 261.1 & 13.4 & 38\\
Tocantins/Pindare moist forests & 175.7 & 11.9 & 30\\
Uatuma-Trombetas moist forests & 267.2 & 14.2 & 46\\
Xingu-Tocantins-Araguaia moist forests & 221.9 & 10.5 & 29\\
\bottomrule
\end{tabular}
\end{table}

For all ecoregions, also the unsampled ones, a synthetic estimate of the mean AGB is obtained (Table \ref{tab:TableSyntheticEstimates}). For the sampled ecoregions the synthetic estimate differs from the regression estimate. This difference can be quite large for ecoregions with a small sample size. Averaged over all sampled ecoregions the difference, computed as synthetic estimate minus regression estimate, equals 14.9 10\textsuperscript{9} kg ha\textsuperscript{-1}. The variance of the regression estimator is always much larger than the variance of the synthetic estimator. The difference is the variance of the estimator of the domain mean of the residuals. However, recall that the regression estimator is design-unbiased, whereas the synthetic estimator is not. A more fair comparison is on the basis of the root mean squared error (RMSE) (Table \ref{tab:tableRMSEs}). For the regression estimator the RMSE is equal to its standard error (and therefore not shown in the table).

\begin{table}

\caption{\label{tab:tableRMSEs}Estimated standard error (se), bias, and root mean squared error (RMSE) of the regression estimator (reg) and the synthetic estimator (syn) of the mean AGB of ecoregions in Eastern Amazonia. The regression estimator is design-unbiased, so the RMSE of the regression estimator is equal to its standard error.}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
Ecoregion & RMSE reg & se syn & bias syn & RMSE syn\\
\midrule
Amazon-Orinoco Carib. mangroves & 48.8 & 3.7 & 96.2 & 96.3\\
Cerrado & 14.2 & 7.1 & -17.3 & 18.7\\
Guianan highland moist forests & 29.4 & 4.9 & -1.2 & 5.0\\
Guianan lowland moist forests & 15.9 & 4.8 & -7.2 & 8.7\\
Guianan savanna & 25.9 & 4.1 & 12.3 & 13.0\\
Gurupa varzea & 71.8 & 3.7 & 119.4 & 119.5\\
Madeira-Tapajos moist forests & 11.8 & 4.9 & -2.2 & 5.4\\
Marajo varzea & 18.1 & 3.8 & 74.4 & 74.5\\
Maranhao Babassu forests & 19.7 & 5.7 & 3.9 & 6.9\\
Mato Grosso tropical dry forests & 24.5 & 5.8 & 3.4 & 6.7\\
Monte Alegre varzea & 57.5 & 3.9 & 50.6 & 50.8\\
Purus-Madeira moist forests & 42.1 & 4.2 & 32.9 & 33.1\\
Tapajos-Xingu moist forests & 7.3 & 4.4 & -18.5 & 19.0\\
Tocantins/Pindare moist forests & 9.5 & 4.0 & 14.7 & 15.3\\
Uatuma-Trombetas moist forests & 5.6 & 4.5 & -14.2 & 14.9\\
Xingu-Toc.-Arag. moist forests & 8.5 & 3.7 & -2.5 & 4.4\\
\bottomrule
\end{tabular}
\end{table}

In the synthetic estimator and the regression estimator both quantitative covariates and categorical variables can be used. If one or more categorical variables are included in the estimator, the variable names in the data frame with the true means of the ancillary variables per domain, specified with argument \texttt{exhaustive}, must correspond to the column names of the design matrix that is generated with function \texttt{lm}, see Subsection \ref{RegressionEstimatorSTSI}.

\hypertarget{SmallAreaModelBased}{%
\section{Model-based prediction}\label{SmallAreaModelBased}}

The alternative for design-based and model-assisted estimation of the means or totals of small domains is model-based prediction. The fundamental difference between model-assisted estimation and model-based prediction is explained in Chapter \ref{Approaches}. The models used in this section are linear mixed models\index{Linear mixed model}. In a linear mixed model the mean of the study variable is modelled as a linear combination of covariates, similar to a linear regression model. The difference with a linear regression model is that the residuals of the mean are not assumed independent. The dependency of the residuals is also modelled. Two types of linear mixed model are described, a random intercept model and a geostatistical model.

\hypertarget{random-intercept-model}{%
\subsection{Random intercept model}\label{random-intercept-model}}

A basic linear mixed model that can be used for model-based prediction of means of small domains is the random intercept model\index{Random intercept model}:

\begin{equation}
\begin{split}
Z_{dk} &= \mathbf{x}_{dk}^{\text{T}} \pmb{\beta} + v_d + \epsilon_{dk} \\
v_d &\sim \mathcal{N}(0,\sigma^2_v) \\
\epsilon_{dk} &\sim \mathcal{N}(0,\sigma^2_{\epsilon}) \;.
\end{split}
\label{eq:RandomInterceptModel}
\end{equation}

Two random variables are now involved, both with a normal distribution with mean zero: \(v_d\), a random intercept at the domain level with variance \(\sigma^2_v\), and the residuals \(\epsilon_{dk}\) at the unit level with variance \(\sigma^2_{\epsilon}\). The variance \(\sigma^2_v\) can be interpreted as a measure of the heterogeneity among the domains after accounting for the fixed effect \citep{Breidenbach2012}. With this model the mean of a domain can be predicted by

\begin{equation}
\hat{\bar{z}}_{\text{mb},d} = \bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\pmb{\beta}} + \hat{v}_d \;,
\label{eq:mbpredictordomainmeanrandomintercept}
\end{equation}

with \(\hat{\pmb{\beta}}\) the best linear unbiased estimates (BLUE) of the regression coefficients and \(\hat{v}_d\) the best linear unbiased prediction (BLUP) of the intercept for domain \(d\), \(v_d\). The model-based predictor can also be written as

\begin{equation}
\hat{\bar{z}}_{\text{mb},d} = \bar{\mathbf{x}}_d^{\mathrm{T}} \hat{\pmb{\beta}} + \lambda_d \left( \frac{1}{n_d }\sum_{k \in \mathcal{S}_d} \epsilon_{dk} \right) \;,
\label{eq:mbpredictordomainmeanrandomintercept2}
\end{equation}

with \(\lambda_d\) a weight for the second term that corrects for the bias of the synthetic estimator. This weight is computed by

\begin{equation}
\lambda_d = \frac{\hat{\sigma}^2_v}{\hat{\sigma}^2_v + \hat{\sigma}^2_{\epsilon}/n_d}\;.
\label{eq:weightrandomintercept}
\end{equation}

This equation shows that the larger the estimated residual variance \(\hat{\sigma}^2_{\epsilon}\), the smaller the weight for the bias correction factor, and the larger the sample size \(n_d\), the larger the weight. Comparing Equations \eqref{eq:mbpredictordomainmeanrandomintercept} and \eqref{eq:mbpredictordomainmeanrandomintercept2} shows that the random intercept of a domain is predicted by the sample mean of the residuals of that domain, multiplied by a weight factor computed by Equation \eqref{eq:weightrandomintercept}.

The means of the small domains can be computed with function \texttt{eblup.mse.f.wrap} of package \textbf{JoSAE} \citep{JoSAE}. It requires as input a linear mixed model generated with function \texttt{lme} of package \textbf{nlme} \citep{nlme}. The simple random sample of size 200 selected before is used to fit the linear mixed model, with lnSWIR2 as a fixed effect, i.e.~the effect of lnSWIR2 on the mean AGB. The random effect is added by assigning another formula to argument \texttt{random}. The formula \texttt{\textasciitilde{}\ 1\ \textbar{}\ Ecoregion} means that the intercept is treated as a random variable and that it varies among the ecoregions. This linear mixed model is referred to as a random intercept model: the intercepts are allowed to differ among the small domains, whereas the effects of the covariates, lnSWIR2 in our case, is equal for all domains.

Tibble \texttt{grdAmazonia} is converted to a \texttt{data.frame} to avoid problems with function \texttt{eblup.mse.f.wrap} hereafter. A simple random sample with replacement of size 200 is selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ x1 }\SpecialCharTok{/}\DecValTok{1000}\NormalTok{,}
         \AttributeTok{x2 =}\NormalTok{ x2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(x1, x2, AGB, lnSWIR2, Ecoregion) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(nlme)}
\FunctionTok{library}\NormalTok{(JoSAE)}
\NormalTok{lmm\_AGB }\OtherTok{\textless{}{-}} \FunctionTok{lme}\NormalTok{(}\AttributeTok{fixed =}\NormalTok{ AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2, }\AttributeTok{data =}\NormalTok{ mysample, }\AttributeTok{random =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{|}\NormalTok{ Ecoregion)}
\end{Highlighting}
\end{Shaded}

The fixed effects\index{Fixed effect} of the linear mixed model can be extracted with function \texttt{fixed.effects}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fixed\_lmm }\OtherTok{\textless{}{-}} \FunctionTok{fixed.effects}\NormalTok{(lmm\_AGB)}
\end{Highlighting}
\end{Shaded}

The fixed effects of the linear mixed model differ somewhat from the fixed effects in the simple linear regression model (fixed\_lm):

\begin{verbatim}
             fixed_lm fixed_lmm
(Intercept) 1778.1959 1667.9759
lnSWIR2     -241.1567 -225.6561
\end{verbatim}

The random effect\index{Random effect} can be extracted with function \texttt{random.effects}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{random.effects}\NormalTok{(lmm\_AGB)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                                       (Intercept)
Cerrado                                  21.439891
Guianan highland moist forests            6.397816
Guianan lowland moist forests             5.547995
Gurupa varzea                           -52.985839
Madeira-Tapajos moist forests            27.479921
Marajo varzea                           -50.587786
Maranhao Babassu forests                 -1.702322
Mato Grosso tropical dry forests         18.812207
Monte Alegre varzea                     -12.201148
Purus-Madeira moist forests              -9.320683
Tapajos-Xingu moist forests              28.760508
Tocantins/Pindare moist forests          -8.940962
Uatuma-Trombetas moist forests           16.165017
Xingu-Tocantins-Araguaia moist forests   11.135385
\end{verbatim}

The random intercepts are added to the fixed intercept; the coefficient of lnSWIR2 is the same for all ecoregions:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(lmm\_AGB)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                                       (Intercept)   lnSWIR2
Cerrado                                   1689.416 -225.6561
Guianan highland moist forests            1674.374 -225.6561
Guianan lowland moist forests             1673.524 -225.6561
Gurupa varzea                             1614.990 -225.6561
Madeira-Tapajos moist forests             1695.456 -225.6561
Marajo varzea                             1617.388 -225.6561
Maranhao Babassu forests                  1666.274 -225.6561
Mato Grosso tropical dry forests          1686.788 -225.6561
Monte Alegre varzea                       1655.775 -225.6561
Purus-Madeira moist forests               1658.655 -225.6561
Tapajos-Xingu moist forests               1696.736 -225.6561
Tocantins/Pindare moist forests           1659.035 -225.6561
Uatuma-Trombetas moist forests            1684.141 -225.6561
Xingu-Tocantins-Araguaia moist forests    1679.111 -225.6561
\end{verbatim}

The fitted model can now be used to predict the means of the ecoregions as follows. As a first step a data frame must be defined, with the size and the population mean of the covariate lnSWIR2 per domain. This data frame is passed to function \texttt{eblup.mse.f.wrap} with argument \texttt{domain.data}. This function computes the model-based prediction, as well as the regression estimator (Equation \eqref{eq:regressionestimatorsmalldomain}) and the synthetic estimator (Equation \eqref{eq:syntheticestimatorsmalldomain}) and their variances. The model-based predictor is the variable \texttt{EBLUP} in the output data frame. For the model-based predictor two standard errors are computed, see \citet{Breidenbach2012} for details.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_eco }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{INDEX =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{Ecoregion, }\AttributeTok{FUN =}\NormalTok{ length)}
\NormalTok{df\_eco }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Ecoregion =}\NormalTok{ ecoregions, }\AttributeTok{N =}\NormalTok{ N\_eco, }\AttributeTok{lnSWIR2 =}\NormalTok{ mx\_eco\_pop)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{eblup.mse.f.wrap}\NormalTok{(}\AttributeTok{domain.data =}\NormalTok{ df\_eco, }\AttributeTok{lme.obj =}\NormalTok{ lmm\_AGB)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Ecoregion =}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{domain.ID, }\AttributeTok{mb =}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{EBLUP,}
  \AttributeTok{se.1 =}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{EBLUP.se}\FloatTok{.1}\NormalTok{, }\AttributeTok{se.2 =}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{EBLUP.se}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Table \ref{tab:TableRandomInterceptModelEstimates} shows the model-based predictions and the estimated standard errors of the mean AGB of the ecoregions, obtained with the random intercept model.



\begin{table}

\caption{\label{tab:TableRandomInterceptModelEstimates}Model-based predictions of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, for simple random sample without replacement of size 200, obtained with the random intercept model and lnSWIR2 as a predictor. se.1 and se.2 are standard errors, for explanation see text.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
Ecoregion & AGB & se.1 & se.2\\
\midrule
Cerrado & 101.9 & 11.4 & 11.5\\
Guianan highland moist forests & 271.1 & 25.8 & 26.4\\
Guianan lowland moist forests & 269.1 & 25.8 & 26.4\\
Gurupa varzea & 155.3 & 36.0 & 31.8\\
Madeira-Tapajos moist forests & 292.8 & 9.3 & 9.3\\
Marajo varzea & 169.3 & 13.6 & 13.2\\
Maranhao Babassu forests & 113.1 & 14.1 & 14.4\\
Mato Grosso tropical dry forests & 129.6 & 22.9 & 23.1\\
Monte Alegre varzea & 218.9 & 22.2 & 22.7\\
Purus-Madeira moist forests & 229.0 & 22.2 & 22.7\\
Tapajos-Xingu moist forests & 277.2 & 6.7 & 6.7\\
Tocantins/Pindare moist forests & 159.6 & 7.4 & 7.5\\
Uatuma-Trombetas moist forests & 270.2 & 6.0 & 6.0\\
Xingu-Tocantins-Araguaia moist forests & 222.9 & 7.5 & 7.6\\
\bottomrule
\end{tabular}
\end{table}

Note that with this model no predictions of the mean AGB are obtained for the unsampled ecoregions. This is because the random intercept \(v_d\) cannot be predicted in the absence of data, see Equations \eqref{eq:mbpredictordomainmeanrandomintercept} and \eqref{eq:mbpredictordomainmeanrandomintercept2}.

\hypertarget{geostatistical-model}{%
\subsection{Geostatistical model}\label{geostatistical-model}}

In a geostatistical model (see Equation \eqref{eq:OKmodel} for a geostatistical model with a constant mean and Equation \eqref{eq:KEDmodel2} for a model with a mean that is a linear combination of covariates) there is only one random variable, the residual of the model-mean, not two random variables as in the random intercept model. In a geostatistical model the covariance of the residuals of the mean at two locations is modelled as a function of the distance (and direction) of the points. Instead of the covariance often the semivariance is modelled, i.e.~half the variance of the difference of the residuals at two locations, see Chapter \ref{Introkriging} for details.

The simple random sample of size 200 selected before is used to estimate the regression coefficients for the mean, an intercept, and a slope coefficient for lnSWIR2, and besides the parameters of a spherical semivariogram model for the residuals of the mean. The two regression coefficients and the three semivariogram parameters are estimated by restricted maximum likelihood (REML), see Subsection \ref{REML}. This estimation procedure is also used in function \texttt{lme} to fit the random intercept model. Here function \texttt{likfit} of package \textbf{geoR} \citep{geoR} is used to estimate the model parameters. First, a geoR object must be generated with function \texttt{as.geodata}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(mysample, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{), }\AttributeTok{data.col =} \StringTok{"AGB"}\NormalTok{, }\AttributeTok{covar.col =} \StringTok{"lnSWIR2"}\NormalTok{)}
\NormalTok{vgm\_REML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{,}
  \AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{600}\NormalTok{, }\DecValTok{600}\NormalTok{), }\AttributeTok{nugget =} \DecValTok{1500}\NormalTok{,}
  \AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The estimated intercept and slope are 1,744 and -236.5, respectively. The estimated semivariogram parameters are 1,623 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, 700 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, and 652 km for the nugget, partial sill, and range, respectively. These model parameters are used to predict AGB for all units in the population, using function \texttt{krige} of package \textbf{gstat} \citep{peb04}. The REML estimates of the semivariogram parameters are passed to function \texttt{vgm} with arguments \texttt{nugget}, \texttt{psill}, and \texttt{range}. The coordinates of the sample are shifted to a random point within a 1 km \(\times\) 1 km grid cell. This is done to avoid that a sampling point coincides with a prediction point, which leads to an error message when predicting AGB at the nodes of the grid.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{x1, }\AttributeTok{amount =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{x2, }\AttributeTok{amount =} \FloatTok{0.5}\NormalTok{)}
\FunctionTok{coordinates}\NormalTok{(mysample) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{vgm\_REML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{,}
  \AttributeTok{nugget =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{nugget, }\AttributeTok{psill =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{sigmasq, }\AttributeTok{range =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{phi)}
\FunctionTok{coordinates}\NormalTok{(grdAmazonia) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{predictions  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
  \AttributeTok{formula =}\NormalTok{ AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{locations =}\NormalTok{ mysample,}
  \AttributeTok{newdata =}\NormalTok{ grdAmazonia,}
  \AttributeTok{model =}\NormalTok{ vgm\_REML\_gstat,}
  \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The first six rows of \texttt{predictions} are shown below.

\begin{verbatim}
         x1       x2 var1.pred var1.var
1 -6628.193 188.4642  295.8800 1987.472
2 -6627.193 188.4642  294.8188 1986.125
3 -6626.193 188.4642  287.2958 1984.268
4 -6625.193 188.4642  280.1586 1982.756
5 -6624.193 188.4642  290.3905 1982.185
6 -6623.193 188.4642  299.5091 1982.027
\end{verbatim}

Besides a prediction (variable \texttt{var1.pred}), for every population unit the variance of the prediction error is computed (\texttt{var1.var}). The unit-wise predictions can be averaged across all units of an ecoregion to obtain a model-based prediction of the mean of that ecoregion.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AGBpred\_unit }\OtherTok{\textless{}{-}}\NormalTok{ predictions}\SpecialCharTok{$}\NormalTok{var1.pred}
\NormalTok{mz\_eco\_mb }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(AGBpred\_unit, }\AttributeTok{INDEX =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{Ecoregion,}
                    \AttributeTok{FUN =}\NormalTok{ mean) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{round}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A difficulty is the computation of the standard error of these model-based predictions of the ecoregion mean. We cannot simply sum the unit-wise variances and divide the sum by the squared number of units, because the prediction errors of units with a mutual distance smaller than the estimated range of the spherical semivariogram are correlated. A straightforward approach to obtain the standard error of the predicted mean is geostatistical simulation\index{Geostatistical simulation}. A large number of maps are simulated, conditional on the selected sample. For an infinite number of maps, the ``average map'', i.e.~the map obtained by averaging for each unit all simulated values of that unit, is equal to the map with predicted AGB. For each simulated map, the average of the simulated values across all units of an ecoregion is computed. This results in as many averages as we have simulated maps. The variance of the averages of an ecoregion is an estimate of the variance of the predicted mean of that ecoregion. To reduce computing time a 5 km \(\times\) 5 km subgrid of \texttt{grdAmazonia} is used in the geostatistical simulation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\AttributeTok{file =} \StringTok{"results/grdAmazonia\_5km.rds"}\NormalTok{)}
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{lnSWIR2 =} \FunctionTok{log}\NormalTok{(SWIR2))}
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{1000}
\FunctionTok{coordinates}\NormalTok{(grdAmazonia) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{simulations  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
  \AttributeTok{formula =}\NormalTok{ AGB }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnSWIR2,}
  \AttributeTok{locations =}\NormalTok{ mysample,}
  \AttributeTok{newdata =}\NormalTok{ grdAmazonia,}
  \AttributeTok{model =}\NormalTok{ vgm\_REML\_gstat,}
  \AttributeTok{nmax =} \DecValTok{100}\NormalTok{, }\AttributeTok{nsim =}\NormalTok{ nsim,}
  \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(grdAmazonia)}
\NormalTok{AGBsim\_eco }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(ecoregions), }\AttributeTok{ncol =}\NormalTok{ nsim)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nsim) \{}
\NormalTok{  AGBsim\_eco[, i] }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(simulations[, i }\SpecialCharTok{+} \DecValTok{2}\NormalTok{],}
  \AttributeTok{INDEX =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{Ecoregion, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}



\begin{table}

\caption{\label{tab:TableGeostatisticalModelEstimates}Model-based predictions of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, using a simple random sample without replacement of size 200, obtained with the geostatistical model and lnSWIR2 as a predictor for the mean. se: standard error of predicted mean.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Ecoregion & AGB & se\\
\midrule
Amazon-Orinoco-Southern Caribbean mangroves & 191.1 & 22.4\\
Cerrado & 96.8 & 12.1\\
Guianan highland moist forests & 299.1 & 28.1\\
Guianan lowland moist forests & 279.3 & 16.4\\
Guianan savanna & 166.1 & 10.2\\
Gurupa varzea & 201.2 & 15.6\\
Madeira-Tapajos moist forests & 287.0 & 8.6\\
Marajo varzea & 194.6 & 11.3\\
Maranhao Babassu forests & 121.6 & 12.0\\
Mato Grosso tropical dry forests & 121.4 & 11.7\\
Monte Alegre varzea & 241.4 & 10.8\\
Purus-Madeira moist forests & 229.0 & 24.3\\
Tapajos-Xingu moist forests & 273.8 & 8.2\\
Tocantins/Pindare moist forests & 163.0 & 6.8\\
Uatuma-Trombetas moist forests & 265.9 & 6.4\\
Xingu-Tocantins-Araguaia moist forests & 220.0 & 6.2\\
\bottomrule
\end{tabular}
\end{table}

Similar to the synthetic estimator, for all ecoregions an estimate of the mean AGB is obtained, also for the unsampled ecoregions (Table \ref{tab:TableGeostatisticalModelEstimates}). The model-based prediction is strongly correlated with the synthetic estimate (Figure \ref{fig:MBvsSynt}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MBvsSynt-1} 

}

\caption{Scatter plot of the model-based prediction and the synthetic estimate of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia. The solid line is the 1:1 line.}\label{fig:MBvsSynt}
\end{figure}

The most striking difference is the standard error. The standard errors of the synthetic estimator range from 3.7 to 7.1 (Table \ref{tab:tableRMSEs}), whereas the standard errors of the geostatistical predictions range from 6.2 to 28.1. However, these two standard errors are fundamentally different and should not be compared. The standard error of the synthetic estimator is a \emph{sampling} standard error, i.e.~it quantifies the variation of the estimated mean of an ecoregion over repeated random sampling with the sampling design, in this case simple random sampling of 200 units. The model-based standard error is not a sampling standard error but a model standard error, which expresses our uncertainty about the means of the domains due to our imperfect knowledge of the spatial variation of AGB. Given the observations of AGB at the selected sample, the map with the covariate lnSWIR2, and the estimated semivariogram model parameters, we are uncertain about the exact value of AGB at unsampled units. No other samples are considered than the one actually selected. For the fundamental difference between design-based, model-assisted, and model-based estimates of means, I refer to Section \ref{DBvsMB} and Chapter \ref{Approaches}.

It makes more sense to compare the two model-based predictions, the random intercept model predictions and the geostatistical predictions, and their standard errors. Figure \ref{fig:MBvsMB} shows that the two model-based predictions are very similar.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MBvsMB-1} 

}

\caption{Scatter plot of model-based predictions of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions in Eastern Amazonia, obtained with the random intercept model and the geostatistical model. The solid line is the 1:1 line.}\label{fig:MBvsMB}
\end{figure}

For four ecoregions the standard errors of the geostatistical model predictions are much smaller than those of the random intercept model predictions (Figure \ref{fig:MBvsMBse}). These are ecoregions with small sample sizes.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MBvsMBse-1} 

}

\caption{Scatter plot of the estimated standard error of model-based predictions of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of ecoregions obtained with the random intercept model and the geostatistical model, using a simple random sample without replacement of size 200 from Eastern Amazonia. The numbers refer to the number of sampling units in an ecoregion. The solid line is the 1:1 line.}\label{fig:MBvsMBse}
\end{figure}

\begin{rmdnote}
If a different semivariogram model were used, both the predicted means per ecoregion and the standard errors would be different. Especially the variance is sensitive to the semivariogram. For this reason the model-based predictions are also referred to as model-dependent predictions\index{Model-dependent predictor}, see Chapter \ref{Approaches}.
\end{rmdnote}

\hypertarget{supplemental-probability-sampling-of-small-domains}{%
\section{Supplemental probability sampling of small domains}\label{supplemental-probability-sampling-of-small-domains}}

The sample size in small domains of interest can be so small that no reliable statistical estimate of the mean or total of these domains can be obtained. In this case we may decide to collect a supplemental sample\index{Supplemental sample} from these domains. It is convenient to use these domains as strata in supplemental probability sampling, so that we can control the sample sizes in the strata. If we can safely assume that the study variable at the units of the first sample are not changed, there is no need to revisit these units, otherwise we must revisit them to observe the current values.

There are two approaches for using the two probability samples to estimate the population mean or total of a small domain \citep{Grafstrom2019}. In the first approach the two samples are combined, and then the merged sample is used to estimate the population mean or total. In the second approach not the samples are combined, but the two estimates from the separate samples. In this section only the first approach is illustrated with a simple situation in which the two samples are easily combined. I refer to \citet{Grafstrom2019} for a more general approach of how multiple probability samples can be combined.

Suppose that the original sample is a simple random sample from the entire study area. A supplemental sample is selected from small domains, i.e.~domains that have few selected units only. For a given small domain, the first sample is supplemented by selecting a simple random sample from the units not yet selected in the first sample. The size of the supplemental sample of a domain depends on the number of units of that domain in the first sample. The first sample is supplemented so that the total sample size of that domain is fixed. In this case the combined sample of a domain is a simple random sample from that domain, so that the usual estimators for simple random sampling can be used to estimate the domain mean or total and its standard error.

This sampling strategy is illustrated with Eastern Amazonia. A simple random sample without replacement of 400 units is selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{biomes }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Mangrove"}\NormalTok{, }\StringTok{"Forest.dry"}\NormalTok{, }\StringTok{"Grassland"}\NormalTok{, }\StringTok{"Forest.moist"}\NormalTok{)}
\FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome) }\OtherTok{\textless{}{-}}\NormalTok{ biomes}
\NormalTok{n1 }\OtherTok{\textless{}{-}} \DecValTok{400}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{units\_1 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\AttributeTok{size =}\NormalTok{ n1, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample\_1 }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units\_1, }\FunctionTok{c}\NormalTok{(}\StringTok{"AGB"}\NormalTok{, }\StringTok{"Biome"}\NormalTok{)]}
\FunctionTok{print}\NormalTok{(n1\_biome }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(mysample\_1}\SpecialCharTok{$}\NormalTok{Biome))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Mangrove   Forest.dry    Grassland Forest.moist 
           2            9           26          363 
\end{verbatim}

The selected units are removed from the sampling frame. For each of the three small biomes, Mangrove, Forest.dry, and Grassland, the size of the supplemental sample is computed so that the total sample size becomes 40. The supplemental sample is selected by stratified simple random sampling without replacement, using the small biomes as strata (Chapter \ref{STSI}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units\_notselected }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[}\SpecialCharTok{{-}}\NormalTok{units\_1, ]}
\NormalTok{Biomes\_NFM }\OtherTok{\textless{}{-}}\NormalTok{ units\_notselected[units\_notselected}\SpecialCharTok{$}\NormalTok{Biome }\SpecialCharTok{!=} \StringTok{"Forest.moist"}\NormalTok{, ]}
\NormalTok{n\_biome }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{n2\_biome }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(n\_biome, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}}\NormalTok{ n1\_biome[}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{]}
\NormalTok{ord }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(Biomes\_NFM}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{units\_2 }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(Biomes\_NFM, }\AttributeTok{stratanames =} \StringTok{"Biome"}\NormalTok{,}
  \AttributeTok{size =}\NormalTok{ n2\_biome[ord], }\AttributeTok{method =} \StringTok{"srswor"}\NormalTok{)}
\NormalTok{mysample\_2 }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(Biomes\_NFM, units\_2)}
\NormalTok{mysample\_2 }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_2[}\FunctionTok{c}\NormalTok{(}\StringTok{"AGB"}\NormalTok{, }\StringTok{"Biome"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

The two samples are merged, and the means of the domains are estimated by the sample means.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysample\_1, mysample\_2)}
\FunctionTok{print}\NormalTok{(mz\_biome }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ mean))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Mangrove   Forest.dry    Grassland Forest.moist 
    112.8000     122.1750     123.6250     233.6749 
\end{verbatim}

Finally, the standard error is estimated, accounting for sampling without replacement from a finite population (Equation \eqref{eq:EstVarMeanSI}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N\_biome }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{fpc }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ n\_biome }\SpecialCharTok{/}\NormalTok{ N\_biome)}
\NormalTok{S2z\_biome }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{AGB, }\AttributeTok{INDEX =}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{Biome, }\AttributeTok{FUN =}\NormalTok{ var)}
\FunctionTok{print}\NormalTok{(se\_mz\_biome }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(fpc }\SpecialCharTok{*}\NormalTok{ (S2z\_biome }\SpecialCharTok{/}\NormalTok{ n\_biome)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Mangrove   Forest.dry    Grassland Forest.moist 
    5.227434     8.213407    11.709257    13.937597 
\end{verbatim}

This sampling approach and estimation are repeated 10,000 times, i.e.~10,000 times a simple random sample without replacement of size 400 is selected from Eastern Amazonia, and the samples from the three small domains are supplemented so that the total sample sizes in these domains become 40. In two out of the 10,000 samples the size of the first sample in one of the domains exceeded 40 units. These two samples are discarded. Ideally, these samples are not discarded, but their sizes in the small domains are reduced to 40 units, which are then used to estimate the means of the domains.



\begin{table}

\caption{\label{tab:SmalldomainEstimates}Summary statistics of 10,000 estimated means of AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) of small domains (biomes) in Eastern Amazonia, estimated by combining a simple random sample without replacement of size 400 from all units and a supplemental stratified simple random sample without replacement from the units in the small domains not included in the simple random sample. The total sample size per small domain is 40.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & Mangrove & Dry forest & Grassland\\
\midrule
Average of estimated means & 122.476 & 113.983 & 114.462\\
True means & 122.494 & 113.931 & 114.390\\
Standard deviation of estimated means & 6.186 & 7.563 & 10.986\\
Average of estimated standard errors & 6.169 & 7.450 & 10.946\\
Coverage rate 95\% & 0.950 & 0.937 & 0.945\\
Coverage rate 90\% & 0.903 & 0.888 & 0.896\\
Coverage rate 80\% & 0.801 & 0.792 & 0.799\\
\bottomrule
\end{tabular}
\end{table}

For all three small domains the average of the 10,000 estimated means of AGB is about equal to the true mean (Table \ref{tab:SmalldomainEstimates}). Also the mean of the 10,000 estimated standard errors is very close to the standard deviation of the 10,000 estimated means. The coverage rates of 95\%, 90\%, and 80\% confidence intervals are about equal to the nominal coverage rates.

This simple approach is feasible because at the domain level the two merged samples are a simple random sample. This approach is also applicable when the first sample is a stratified simple random sample from the entire population, and the supplemental sample is a stratified simple random sample from a small domain using as strata the intersections of the strata used in the first phase and that domain.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5541521 296.0   12043445 643.2  12043445  643.2
Vcells 27192609 207.5   88519913 675.4 177363197 1353.2
\end{verbatim}

\hypertarget{RepeatedSurveys}{%
\chapter{Repeated sample surveys for monitoring population parameters}\label{RepeatedSurveys}}

The previous chapters are all about sampling to estimate population parameters \emph{at a given time}. The survey is done in a relatively short period of time, so that we can safely assume that the study variable has not changed during that period. This chapter is about repeating the sample survey two or more times, to estimate, for instance, a temporal change in a population parameter\index{Repeated surveys for monitoring}. Sampling locations are selected by probability sampling, by any design type. In most cases sampling times are not selected randomly, but purposively. For instance, to monitor the carbon stock in the soil of a country, we may decide to repeat the survey after five years, in the same season of the year as the first survey.

\hypertarget{space-time-designs}{%
\section{Space-time designs}\label{space-time-designs}}

An overview of space-time designs\index{Space-time design} is presented by \citet{gru06}. Five of these designs are schematically shown in Figure \ref{fig:SpaceTimeDesigns}. With repeated sampling in two-dimensional space there are three dimensions: two spatial and one time dimension. Sampling locations shown in Figure \ref{fig:SpaceTimeDesigns} are selected by simple random sampling, but this is not essential for the space-time designs.

In the static-synchronous (SS) design\index{Space-time design!static-synchronous design}, referred to as a pure panel\index{Pure panel} by \citet{ful99}, all sampling locations selected in the first survey are revisited in all subsequent surveys. On the contrary, in an independent synchronous (IS) design\index{Space-time design!independent-synchronous design} a probability sample is selected in each survey independently from the samples selected in the previous surveys. The serially alternating (SA) design\index{Space-time design!serially alternating design} is a compromise between an SS and an IS design. The sample selected in the first survey is revisited in the third survey. The sample of the second survey is selected independently from the sample of the first survey, and these locations are revisited in the fourth survey. In this case the period of revisits is two, i.e.~two sampling intervals between consecutive surveys, but this can also be increased. For instance with a period of three, three samples are selected, independently from each other, for the first three surveys, and these samples are revisited in subsequent surveys.

Two other compromise designs are a supplemented panel (SP) design\index{Space-time design!supplemented panel design} and a rotating panel (RP) design\index{Space-time design!rotating panel design}. In an SP design only a subset of the sampling locations of the first survey is revisited in the subsequent surveys. These are the permanent sampling locations observed in all subsequent surveys. The permanent sampling locations are supplemented by samples that are selected independently from the samples in the previous surveys. In Figure \ref{fig:SpaceTimeDesigns}, half of the sampling locations (ten locations) is permanent (panel a), i.e.~revisited in all surveys, but the proportion of permanent sampling locations can be smaller or larger and, if prior information on the variation in space and time is available, even can be optimised for estimating the current mean. Also in an RP design sampling units of the previous survey are partially replaced by new units. The difference with an SP design is that there are no permanent sampling units, i.e.~no units observed in all surveys. All sampling units are sequentially rotated out and in again at the subsequent sampling times.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SpaceTimeDesigns-1} 

}

\caption{Space-time designs for monitoring population parameters. The sampling locations in 2D are plotted in one dimension, along the horizontal axis. A selected unit along this axis actually represents a sampling location in 2D. Twenty sampling locations are selected by simple random sampling. SS: static-synchronous design; IS: independent synchronous design; SA: serially alternating design; SP: supplemented panel design; RP: rotating panel design.}\label{fig:SpaceTimeDesigns}
\end{figure}

In Figure \ref{fig:SpaceTimeDesigns} the shape and colour of the symbols represent a panel. A panel is a group of sampling locations that is observed in the same surveys. In the SS design there is only one panel. All locations are observed in all surveys, so all locations are in the same panel. In the IS design there are as many panels as there are surveys. In the SA design with a period of two the number of panels equals the number of surveys divided by two. In these three space-time designs (SS, IS, and SA) all sampling locations of a given survey are in the same panel. This is not the case in the SP and RP designs. In Figure \ref{fig:SpaceTimeDesigns} in each survey two panels are observed. In the SP sample there is one panel of permanent sampling locations (pure panel part of sample) and another panel of swarming sampling locations observed in one survey only. In the RP sample of Figure \ref{fig:SpaceTimeDesigns} the sampling locations are observed in two consecutive surveys, however this number can be increased. For instance, in an `in-for-three' rotational sample \citep{McLaren2001} the sampling locations stay in the sample for three consecutive surveys. The number of panels per sampling time is then three. Also, similar to an SA design, in an IS, SP, and RP design we may decide after several surveys to stop selecting new sampling locations and to revisit existing locations. The concept of panels is needed hereafter in estimating space-time population parameters.

\hypertarget{SpaceTimeparameters}{%
\section{Space-time population parameters}\label{SpaceTimeparameters}}

The data of repeated surveys can be used to estimate various parameters of the space-time universe. I will focus on the mean as a parameter, but estimation of a total or proportion is straightforward, think for instance of the total amount of greenhouse gas emissions from the soil in a given study area during some period. In this chapter I show how to estimate the current mean, i.e.~the population mean (spatial mean) in the last survey, the change of the mean between two surveys, the temporal trend of the mean, and the space-time mean. The current mean need not be defined here as only one survey (one sampling time) is involved in this parameter, so that the definition in Subsection \ref{PopulationParameters} is also relevant here.

The change of the mean is defined as the spatial mean at a given survey minus this mean at an earlier survey\index{Change of spatial mean (total)}. For finite populations the definition is

\begin{equation}
\bar{d}_{ab}=\frac{1}{N}\left(\sum_{k=1}^N z_k(t_b) -\sum_{k=1}^N z_k(t_a) \right)=\frac{1}{N}\sum_{k=1}^N d_{abk}\;,
\label{eq:ChangePopMeanFinite}
\end{equation}

with \(d_{abk}\) the change of the study variable in the period between time \(t_a\) and \(t_b\) for unit \(k\). For infinite populations the sums are replaced by integrals:

\begin{equation}
\bar{d}_{ab}=\frac{1}{A}\left(\int_{\mathbf{s} \in \mathcal{A}} z(\mathbf{s},t_b) \;\mathrm{d}\mathbf{s}-\int_{\mathbf{s} \in \mathcal{A}} z(\mathbf{s},t_a) \;\mathrm{d}\mathbf{s}\right)=\frac{1}{A}\int_{\mathbf{s} \in \mathcal{A}}d_{ab}(\mathbf{s})\;,
\label{eq:ChangePopMean}
\end{equation}

with \(d_{ab}(\mathbf{s})\) the change of the study variable in the period between time \(t_a\) and \(t_b\) at location \(\mathbf{s}\).

With more than two surveys an interesting population parameter is the \emph{average change per time unit} of the mean, referred to as the temporal trend of the spatial mean\index{Temporal trend of spatial mean}. It is defined as a linear combination of the spatial means at the sampling times \citep{Breidt99}:

\begin{equation}
b=\sum_{j=1}^R w_j \bar{z}_j \;,
\label{eq:TrendofMean}
\end{equation}

with \(R\) the number of sampling times, \(\bar{z}_j\) the spatial mean at time \(t_j\), and weights \(w_j\) equal to

\begin{equation}
w_j = \frac{t_j-\bar{t}}{\sum_{j=1}^R(t_j-\bar{t})^2} \;,
\label{eq:weightsTrendofMean}
\end{equation}

with \(\bar{t}\) the mean of the sampling times.

\begin{rmdnote}
The temporal trend is defined as a parameter of a space-time population, not as a parameter of a time-series model.
\end{rmdnote}

A space-time mean can be defined as the average of the spatial means at the sampling times. In this definition the temporal universe is discrete and restricted to the sampling times. The target universe consists of a finite set of spatial populations:

\begin{equation}
\bar{\bar{z}}_{\mathcal{U}}=\frac{1}{R} \sum_{j=1}^R \bar{z_j}\;.
\label{eq:SpacetimeMeanDiscrete}
\end{equation}

Alternatively, a space-time mean for a continuous temporal universe \(\mathcal{T}\) is defined as

\begin{equation}
\bar{\bar{z}}_{\mathcal{U}} = \frac{1}{T}\int_{t \in \mathcal{T}}\bar{z}_t\;,
\label{eq:SpacetimeMeanContinuous}
\end{equation}

with \(T\) the length of the monitoring period and \(\bar{z}_t\) the spatial mean at time \(t\).

\hypertarget{design-based-generalised-least-squares-estimation-of-spatial-means}{%
\section{Design-based generalised least squares estimation of spatial means}\label{design-based-generalised-least-squares-estimation-of-spatial-means}}

Rotational sampling has a long tradition in agronomy, forestry, and in social studies. Early papers on how sample data from previous times can be used to increase the precision of estimates of the current mean are \citet{jessen1942}, \citet{patterson1950}, \citet{Ware1962}, and \citet{woodruff1963}. \citet{gurney1965} developed general theory for these estimators, which I will present now.

In overlapping samples such as an SP and an RP sample we may define one estimate of a spatial mean per `panel'. These panel-specific estimates of the mean at a given sampling time, based on observations at that time only, are referred to as elementary estimates\index{Elementary estimate}.

The essence of the estimation method described in this section is to estimate the spatial mean at a given time point as a weighted average of the elementary estimates \emph{of all time points}, with the weights determined by the variances and covariances of the elementary estimates. Collecting all elementary estimates of the spatial means of the different sampling times in vector \(\hat{\mathbf{z}}\), we can write

\begin{equation}
\hat{\mathbf{z}}=\mathbf{X} \mathbf{z} + \mathbf{e} \;,
\label{eq:zbf}
\end{equation}

with \(\mathbf{z}\) the vector of true spatial means \(\bar{z}(t_1), \dots ,\bar{z}(t_R)\) at the \(R\) sampling times, \(\mathbf{X}\) the (\(P \times R\)) design matrix with zeroes and ones that selects the appropriate elements from \(\mathbf{z}\) (\(P\) is the total number of elementary estimates), and \(\mathbf{e}\) the \(P\)-vector of sampling errors with variance-covariance matrix \(\mathbf{C}\). With unbiased elementary estimators the expectation of \(\mathbf{e}\) is a vector with zeroes.

With an SS, an IS, and an SA design the design matrix \(\mathbf{X}\) is the identity matrix of size \(R\), i.e.~an \(R \times R\) square matrix with ones on the diagonal and zeroes in all off-diagonal entries. For the SP design of Figure \ref{fig:SpaceTimeDesigns} the design matrix \(\mathbf{X}\) is

\begin{equation}
\mathbf{X}=
\begin{bmatrix}
1 &0 &0 &0\\
0 &1 &0 &0\\
0 &0 &1 &0\\
0 &0 &0 &1\\
1 &0 &0 &0\\
0 &1 &0 &0\\
0 &0 &1 &0\\
0 &0 &0 &1
\end{bmatrix}
\;.
\label{eq:XSP}
\end{equation}

The first four rows of this matrix are associated with the elementary estimates of the spatial means at the four times from panel a, the panel with permanent sampling locations, hereafter referred to as the static-synchronous subsample. The remaining rows correspond to the elementary estimates from the other four panels, the swarming locations, hereafter referred to as the independent-synchronous subsamples. For the RP design of Figure \ref{fig:SpaceTimeDesigns} the design matrix equals

\begin{equation}
\mathbf{X}=
\begin{bmatrix}
1 &0 &0 &0\\
1 &0 &0 &0\\
0 &1 &0 &0\\
0 &1 &0 &0\\
0 &0 &1 &0\\
0 &0 &1 &0\\
0 &0 &0 &1\\
0 &0 &0 &1
\end{bmatrix}
\;.
\label{eq:XRP}
\end{equation}

The first two rows correspond to the two elementary estimates of the mean at time \(t_1\) from panels a and b, the third and fourth row correspond to the elementary estimate at time \(t_2\) from panels b and c, respectively, etc.

The minimum variance linear unbiased estimator (MVLUE) of the spatial means at the different times is the design-based generalised least squares (GLS) estimator \index{Design-based generalised least squares estimator} \citep{bin88}:

\begin{equation}
\hat{\mathbf{z}}_{\mathrm{GLS}}=(\mathbf{X}^{\text{T}}\mathbf{C}^{-1}\mathbf{X})^{-1} \mathbf{X}^{\text{T}} \mathbf{C}^{-1} \hat{\mathbf{z}}\;.
\label{eq:DBGLS}
\end{equation}

To define matrix \(\mathbf{C}\) for the SP design in Figure \ref{fig:SpaceTimeDesigns}, let \(\hat{\bar{z}}_{jp}\) denote the estimated mean at time \(t_j, j = 1,2,3,4\) in subsample \(p, p \in (a,b,c,d,e)\), with panel \(a\) the permanent sampling locations (SS subsample) and panels \(b,c,d,e\) the swarming sampling locations (IS subsamples). If the eight elementary estimates in \(\hat{\mathbf{z}}\) are ordered as (\(\hat{\bar{z}}_{1a},\hat{\bar{z}}_{2a},\hat{\bar{z}}_{3a},\hat{\bar{z}}_{4a},\hat{\bar{z}}_{1b},\hat{\bar{z}}_{2c},\hat{\bar{z}}_{3d},\hat{\bar{z}}_{4e}\)), the variance-covariance matrix \(\mathbf{C}\) equals

\begin{equation}
\mathbf{C}=
\begin{bmatrix}
V_{1a} &C_{1,2} &C_{1,3} &C_{1,4} &0 &0 &0 &0 \\
C_{2,1} &V_{2a} &C_{2,3} &C_{2,4} &0 &0 &0 &0 \\
C_{3,1} &C_{3,2} &V_{3a} &C_{3,4} &0 &0 &0 &0 \\
C_{4,1} &C_{4,2} &C_{4,3} &V_{4a} &0 &0 &0 &0 \\
0 &0 &0 &0 &V_{1b} &0 &0 &0 \\
0 &0 &0 &0 &0 &V_{2c} &0 &0 \\
0 &0 &0 &0 &0 &0 &V_{3d} &0 \\
0 &0 &0 &0 &0 &0 &0 &V_{4e}
\end{bmatrix}
\;.
\label{eq:CmatrixSP}
\end{equation}

The covariances of the elementary estimates of the IS subsamples are zero because these are estimated from independently selected samples (off-diagonal elements in lower-right (4 \(\times\) 4) submatrix). Also the covariances of the elementary estimates from the SS subsample and an IS subsample are zero for the same reason (upper-right submatrix and lower-left submatrix). The covariances of the four elementary estimates from the SS subsample are not zero because these are estimated from the same set of sampling locations.

Ordering the elementary estimates of the RP sample by the sampling times, the variance-covariance matrix equals

\begin{equation}
\mathbf{C}=
\begin{bmatrix}
V_{1a} &0 &0 &0 &0 &0 &0 &0 \\
0 &V_{1b} &C_{1,2} &0 &0 &0 &0 &0 \\
0 &C_{2,1} &V_{2b} &0 &0 &0 &0 &0 \\
0 &0 &0 &V_{2c} &C_{2,3} &0 &0 &0 \\
0 &0 &0 &C_{3,2} &V_{3c} &0 &0 &0 \\
0 &0 &0 &0 &0 &V_{3d} &C_{3,4} &0 \\
0 &0 &0 &0 &0 &C_{4,3} &V_{4d} &0 \\
0 &0 &0 &0 &0 &0 &0 &V_{4e}
\end{bmatrix}
\;.
\label{eq:CmatrixRP}
\end{equation}

Only the elementary estimates estimated from the same panel are correlated, for instance the elementary estimates of the spatial means at times \(t_1\) and \(t_2\), estimated from panel b.

For the SA design of Figure \ref{fig:SpaceTimeDesigns} the variance-covariance matrix equals (there is only one estimate per time)

\begin{equation}
\mathbf{C}=
\begin{bmatrix}
V_{1} &0 &C_{1,3} &0  \\
0 &V_{2} &0 &C_{2,4}  \\
C_{3,1} &0 &V_{3} &0  \\
0 &C_{4,2} &0 &V_{4}  
\end{bmatrix}
\;.
\label{eq:CmatrixSA}
\end{equation}

In practice matrix \(\mathbf{C}\) in Equation \eqref{eq:DBGLS} is unknown and is replaced by a matrix with design-based estimates of the variances and covariances of the elementary estimators. With simple random sampling with replacement from finite populations and simple random sampling of infinite populations the variance of an elementary estimator of the spatial mean at a given time can be estimated by Equation \eqref{eq:EstVarMeanSIR}. The covariance of the elementary estimators of the spatial means at two sampling times, using the data of the same panel, can be estimated by

\begin{equation}
\widehat{C}_{ab} =  \frac{\widehat{S^2}_{ab}}{m} \;,
\label{eq:covartwoelementaryestimates}
\end{equation}

with \(m\) the number of sampling locations in the panel and \(\widehat{S^2}_{ab}\) the estimated covariance of the study variable at times \(t_a\) and \(t_b\), estimated by

\begin{equation}
\widehat{S^2}_{ab} = \frac{1}{m-1}\sum_{k=1}^m (z_{apk}-\hat{\bar{z}}_{ap})(z_{bpk}-\hat{\bar{z}}_{bp}) \;,
\label{eq:S2ab}
\end{equation}

with \(z_{apk}\) the study variable of unit \(k\) in panel \(p\) at time \(t_a\) and \(\hat{\bar{z}}_{ap}\) the spatial mean at time \(t_a\) as estimated from panel \(p\).

The variances and covariances of the GLS estimators of the spatial means at the \(R\) sampling times can be estimated by

\begin{equation}
\mbox{Cov}(\hat{\mathbf{z}}_{\mathrm{GLS}}) = (\mathbf{X}^{\text{T}}\widehat{\mathbf{C}}^{-1}\mathbf{X})^{-1}
\label{eq:CovGLS} \;.
\end{equation}

Given the design-based GLS estimates of the spatial means at the different times it is an easy job to compute the estimated change of the mean between two surveys, the estimated temporal trend of the mean, and the estimated space-time mean.

\hypertarget{current-mean}{%
\subsection{Current mean}\label{current-mean}}

As explained above, with the SS, IS, and SA designs the design matrix \(\mathbf{X}\) is the identity matrix of size \(R\). From this it follows that for these space-time designs \(\hat{\mathbf{z}}_{\mathrm{GLS}}=\hat{\mathbf{z}}\), see Equation \eqref{eq:DBGLS}, and \(\mbox{Cov}(\hat{\mathbf{z}}_{\mathrm{GLS}})=\mbox{Cov}(\hat{\mathbf{z}})=\mathbf{C}\). In words, the GLS estimator of the spatial mean at a given time equals the usual \(\pi\) estimator of the mean at that time, and the variance-covariance matrix of the GLS estimators of the spatial means equals the variance-covariance matrix of the \(\pi\) estimators.

With SP and RP sampling in space-time there is partial overlap between the samples at the different times, and so the samples at the previous times can be used to increase the precision of the estimated mean at the last time (current mean). The estimated current mean is simply the last element in \(\hat{\mathbf{z}}_{\mathrm{GLS}}\). The estimated variance of the estimator of the current mean is the element in the final row and final column of the variance-covariance matrix of the estimated spatial means (Equation \eqref{eq:CovGLS}). These two space-time designs with partial replacement of sampling locations may yield a more precise estimate of the current mean than the other three space-time designs.

\hypertarget{change-of-the-spatial-mean}{%
\subsection{Change of the spatial mean}\label{change-of-the-spatial-mean}}

The change of the spatial mean between two sampling times can simply be estimated by subtracting the estimated spatial means at these two times. With the SS, IS, and SA designs these means are estimated by the \(\pi\) estimators. With the SP and RP designs the two spatial means are estimated by the GLS estimators. The variance of the estimator of the change can be estimated by the sum of the estimated variances of the spatial mean estimators at the two sampling times, minus two times the estimated covariance of the two estimators. The covariance is maximal when all sampling locations are revisited, leading to the most precise estimate of the change of the spatial mean. With SP and RP sampling the covariance of the two spatial mean estimators is smaller, and so the variance of the change estimator is larger.

\hypertarget{temporal-trend-of-the-spatial-mean}{%
\subsection{Temporal trend of the spatial mean}\label{temporal-trend-of-the-spatial-mean}}

The temporal trend of the mean is estimated by the weighted average of the (GLS) estimated means at \(t_1,\dots ,t_R\), with weights equal to Equation \eqref{eq:weightsTrendofMean}:

\begin{equation}
\hat{b}=\sum_{j=1}^R w_j \hat{\bar{z}}_{\mathrm{GLS},j} \;.
\label{eq:EstimatorTrendofMean}
\end{equation}

The variance of the estimator of the temporal trend can be estimated by

\begin{equation}
\widehat{V}(\hat{b}) = \mathbf{w}^{\prime}\widehat{\mathbf{C}}(\hat{\mathbf{z}}_{\mathrm{GLS}}) \mathbf{w}\;.
\label{eq:VarEstimatorTrendofMean}
\end{equation}

\citet{Brus2011} compared the space-time designs for estimating the temporal trend of the spatial means, under a first order autoregressive time-series model of the spatial means. The SS design performed best when the correlation is strong, say \(> 0.8\). What is the best design depends amongst others on the strength of the correlation and the number of sampling times. A safe choice is an SA design. With strong positive correlation, say \(>0.9\), the SS design can be a good choice, but remarkably for weak positive correlation this design performed relatively poor.

For an application of an SP design to estimate the temporal trend of the areal fractions of several vegetation types, see \citet{Brus2014c}. Sampling locations are selected by a design that spreads the locations evenly over the study area (systematic unaligned sampling, which is a modified version of systematic sampling).

\hypertarget{space-time-mean}{%
\subsection{Space-time mean}\label{space-time-mean}}

The space-time mean as defined in Equation \eqref{eq:SpacetimeMeanDiscrete} can be estimated by the average of the (GLS) estimated spatial means at the \(R\) sampling times. The variance of this estimator can be estimated by Equation \eqref{eq:VarEstimatorTrendofMean} using constant weights, equal to \(1/R\), for the \(R\) estimators of the mean. An IS design yields the most precise estimate of the space-time mean compared to the other space-time designs when the correlation of collocated measurements of the study variable is positive \citep{coc77}. With the other space-time designs there is redundant information due to the revisits.

For design-based estimation of the space-time mean of a continuous temporal universe as defined in Equation \eqref{eq:SpacetimeMeanContinuous} both the sampling locations and the sampling times must be selected by probability sampling. Figure \ref{fig:SpaceTimeDesignProb} shows an SS sample and an IS sample of twenty locations and six times, where both locations and times are selected by simple random sampling.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SpaceTimeDesignProb-1} 

}

\caption{Space-time designs for estimating the space-time mean of a continuous temporal universe. Both locations and times are selected by simple random sampling. SS: static-synchronous design; IS: independent synchronous design.}\label{fig:SpaceTimeDesignProb}
\end{figure}

An IS sample in which both locations and times are selected by probability sampling can be considered as a two-stage cluster random sample from a space-time universe (Chapter \ref{Twostage}). The primary sampling units (PSUs) are the spatial sections of that universe (horizontal lines in Figure \ref{fig:SpaceTimeDesignProb}), the secondary sampling units (SSUs) are the sampling locations. The space-time mean can therefore be estimated by Equation \eqref{eq:EstMeanTwostage}, and its variance by Equation \eqref{eq:VarEstMeanTwostage}. For simple random sampling, both in space and in time, and a linear costs model \(C = c_0 + c_1n + c_2nm\) Equations \eqref{eq:nopt} and \eqref{eq:mopt} can be used to optimise the number of sampling times (PSUs, \(n\)) and the number of sampling locations (SSUs, \(m\)) per time. The pooled within-unit variance, \(S^2_\text{w}\), is in this case the time-averaged spatial variance of the study variable at a given time, and the between-unit variance, \(S^2_\text{b}\), is the variance of the spatial means over time.

Estimation of the space-time mean from an SS sample in which both locations and times are selected by probability sampling is as for an IS sample. However, estimation of the variance of the space-time mean estimator is more complicated. For the variance of the estimator of the space-time mean with an SS space-time design and simple random sampling of both locations and times, see Equation (15.8) in \citet{gru06}. Due to the two-fold alignment of the sampling units no unbiased estimator of the variance is available. The variance estimator of two-stage cluster sampling can be used to approximate the variance, but this variance estimator does not account for a possible temporal correlation of the estimated spatial means, resulting in an underestimation of the variance.

For an application of an IS design, to estimate the space-time mean of nutrients (nitrogen and phosphorous) in surface waters, see \citet{bru08b} and \citet{Knotters2010d}. In both applications sampling times are selected by stratified simple random sampling, with periods of two months as strata. In \citet{bru08b} sampling locations are selected by stratified simple random sampling as well.

\hypertarget{case-study-annual-mean-daily-temperature-in-iberia}{%
\section{Case study: annual mean daily temperature in Iberia}\label{case-study-annual-mean-daily-temperature-in-iberia}}

The space-time designs are illustrated with the annual mean air temperature at two metres above the earth surface (TAS) in Iberia for the years 2004, 2009, 2014, and 2019 (Subsection \ref{TASIberia}).

Sampling locations are selected by simple random sampling. The sample size is 100 locations per survey, so with four surveys we have 400 observations in total, but not with all space-time designs at 400 different sampling locations. In the next sections I will show how a space-time sample with a given space-time design can be selected, and how the population parameters described in Section \ref{SpaceTimeparameters} can be estimated.

\hypertarget{static-synchronous-design}{%
\subsection{Static-synchronous design}\label{static-synchronous-design}}

Selecting an SS space-time sample, using simple random sampling as a spatial design, is straightforward. We can simply select a single simple random sample of size \(n=100\). The locations of this sample are observed at all times (Figure \ref{fig:sampleIberiaSS}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grd }\OtherTok{\textless{}{-}}\NormalTok{ grdIberia }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{,}
         \AttributeTok{y =}\NormalTok{ y }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grd), }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample\_SS }\OtherTok{\textless{}{-}}\NormalTok{ grd[units, ]}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleIberiaSS-1} 

}

\caption{Static-synchronous space-time sample from Iberia. Locations are selected by simple random sampling.}\label{fig:sampleIberiaSS}
\end{figure}

The spatial means at the four times can be estimated by the sample means (Equation \eqref{eq:HTMeanSI}), the variances of the mean estimators by Equation \eqref{eq:EstVarMeanSIR}. The covariances of the estimators of the means at two different times can be estimated by Equation \eqref{eq:covartwoelementaryestimates} with \(m\) equal to the sample size \(n\). The estimated current mean (the spatial mean at the fourth survey) and the estimated standard error of the estimator of the current mean can be simply extracted from the vector with estimated means and from the matrix with estimated variances and covariances.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(mysample\_SS[, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)], }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysample\_SS[, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]) }\SpecialCharTok{/}\NormalTok{ n}
\CommentTok{\#current mean}
\NormalTok{mz\_cur\_SS }\OtherTok{\textless{}{-}}\NormalTok{ mz[}\DecValTok{4}\NormalTok{]}
\NormalTok{se\_mz\_cur\_SS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(C[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

The change of the spatial mean from the first to the fourth survey can simply be estimated by subtracting the estimated spatial mean of the first survey from the estimated mean of the fourth survey. The standard error of this estimator can be estimated by the sum of the estimated variances of the two spatial mean estimators, minus two times the estimated covariance of the two mean estimators, and finally taking the square root.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d\_mz\_SS }\OtherTok{\textless{}{-}}\NormalTok{ mz[}\DecValTok{4}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ mz[}\DecValTok{1}\NormalTok{]}
\NormalTok{se\_d\_mz\_SS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(C[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ C[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ C[}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

The same estimates are obtained by defining a weight vector with values -1 and 1 for the first and last element, respectively, and 0 for the other two elements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{d\_mz\_SS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_d\_mz\_SS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

The temporal trend of the spatial means can be estimated much in the same way, but using a different vector with weights (Equation \eqref{eq:weightsTrendofMean}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{2004}\NormalTok{, }\AttributeTok{to =} \DecValTok{2019}\NormalTok{, }\AttributeTok{by =} \DecValTok{5}\NormalTok{)}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mz\_trend\_SS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_mz\_trend\_SS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

The estimated temporal trend equals 0.0403 \(^\circ\)C \(y^{-1}\), and the estimated standard error equals 0.0024794 \(^\circ\)C \(y^{-1}\). Using \texttt{t\ =\ 1:4} yields the estimated average change in annual mean temperature \emph{per five years}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\FunctionTok{print}\NormalTok{(mz\_trend\_SS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          [,1]
[1,] 0.2016378
\end{verbatim}

Using a constant weight vector with values 1/4 yields the estimated space-time mean and the standard error of the space-time mean estimator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{mz\_st\_SS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_mz\_st\_SS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

\hypertarget{independent-synchronous-design}{%
\subsection{Independent synchronous design}\label{independent-synchronous-design}}

To select an IS space-time sample with four sampling times, we simply select \(4n=400\) sampling locations. Figure \ref{fig:sampleIberiaIS} shows the selected IS space-time sample. A variable identifying the panel of the selected sampling units is added to the data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grd), }\AttributeTok{size =} \DecValTok{4} \SpecialCharTok{*}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample\_IS }\OtherTok{\textless{}{-}}\NormalTok{ grd[units, ]}
\NormalTok{mysample\_IS}\SpecialCharTok{$}\NormalTok{panel }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{), }\AttributeTok{each =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{rmdnote}
The units of the finite population are selected by simple random sampling \emph{with replacement}. As a consequence, there can be partial overlap between the samples at the different times, i.e.~some units are observed at multiple times. However, this overlap is by chance, it is not coordinated as in an SP and RP design. By selecting the units with replacement the estimators of the spatial means are independent (covariance of estimators equals zero). For infinite populations such as points such as points in an area, there will be no overlap, so that the covariance of the estimators equals zero.
\end{rmdnote}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleIberiaIS-1} 

}

\caption{Independent synchronous space-time sample from Iberia. Locations are selected by simple random sampling.}\label{fig:sampleIberiaIS}
\end{figure}

The spatial means are estimated with the \(\pi\) estimator as there is no partial overlap of the spatial samples. All covariances of the mean estimators are zero. Estimation of the space-time parameters is as before with the SS space-time sample. Four data frames of \(n\) rows are first made with the data observed in a specific panel. The variables of these four data frames are then joined into a single data frame. The spatial means at the four times are then estimated by the sample means, computed with function \texttt{apply}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{panel\_a }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_IS, panel }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2004"}\NormalTok{)]}
\NormalTok{panel\_b }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_IS, panel }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2009"}\NormalTok{)]}
\NormalTok{panel\_c }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_IS, panel }\SpecialCharTok{==} \StringTok{"c"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2014"}\NormalTok{)]}
\NormalTok{panel\_d }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_IS, panel }\SpecialCharTok{==} \StringTok{"d"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2019"}\NormalTok{)]}
\NormalTok{panel\_abcd }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(panel\_a, panel\_b, panel\_c, panel\_d)}
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(panel\_abcd, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(panel\_abcd) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{C[}\FunctionTok{row}\NormalTok{(C) }\SpecialCharTok{!=} \FunctionTok{col}\NormalTok{(C)] }\OtherTok{\textless{}{-}} \DecValTok{0}
\CommentTok{\#current mean}
\NormalTok{mz\_cur\_IS }\OtherTok{\textless{}{-}}\NormalTok{ mz[}\DecValTok{4}\NormalTok{]}
\NormalTok{se\_mz\_cur\_IS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(C[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\CommentTok{\#change of mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{d\_mz\_IS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_d\_mz\_IS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#trend of mean}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mz\_trend\_IS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_mz\_trend\_IS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#space{-}time mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{mz\_st\_IS }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_mz\_st\_IS }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

\hypertarget{serially-alternating-design}{%
\subsection{Serially alternating design}\label{serially-alternating-design}}

To select an SA space-time sample with a period of two, \(2n=200\) sampling locations are selected. A variable is added to \texttt{mysample\_SA} indicating the panel of the sampling locations. Figure \ref{fig:sampleIberiaSA} shows the selected SA space-time sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grd), }\AttributeTok{size =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample\_SA }\OtherTok{\textless{}{-}}\NormalTok{ grd[units, ]}
\NormalTok{mysample\_SA}\SpecialCharTok{$}\NormalTok{panel }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{), }\AttributeTok{each =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleIberiaSA-1} 

}

\caption{Serially alternating space-time sample from Iberia. Locations are selected by simple random sampling.}\label{fig:sampleIberiaSA}
\end{figure}

In SA sampling there is no partial overlap of the spatial samples at different times: there is either no overlap or full overlap. Spatial means therefore can estimated by the usual \(\pi\) estimator. Two data frames of \(n\) rows are first made with the data observed in a specific panel. The variables of these two data frames are then joined into a single data frame. The spatial means at the four times are then estimated by the sample means, computed with function \texttt{apply}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{panel\_a }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_SA, panel }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2004"}\NormalTok{, }\StringTok{"TAS2014"}\NormalTok{)]}
\NormalTok{panel\_b }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(mysample\_SA, panel }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{)[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2009"}\NormalTok{, }\StringTok{"TAS2019"}\NormalTok{)]}
\NormalTok{panel\_ab }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(panel\_a[}\DecValTok{1}\NormalTok{], panel\_b[}\DecValTok{1}\NormalTok{], panel\_a[}\DecValTok{2}\NormalTok{], panel\_b[}\DecValTok{2}\NormalTok{])}
\NormalTok{mz }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(panel\_ab, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ mean)}
\end{Highlighting}
\end{Shaded}

To compute the matrix with estimated variances and covariances of the spatial mean estimators, first the full matrix is computed. Then the estimated covariances of spatial means of consecutive surveys are replaced by zeroes as the samples of these consecutive surveys are selected independently from each other, so that the two estimators are independent. Estimation of the space-time parameters is as before with the SS space-time sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(panel\_ab) }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{odd }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{C[}\FunctionTok{row}\NormalTok{(C) }\SpecialCharTok{\%in\%}\NormalTok{ odd }\SpecialCharTok{\&} \SpecialCharTok{!}\NormalTok{(}\FunctionTok{col}\NormalTok{(C) }\SpecialCharTok{\%in\%}\NormalTok{ odd)] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{C[}\SpecialCharTok{!}\NormalTok{(}\FunctionTok{row}\NormalTok{(C) }\SpecialCharTok{\%in\%}\NormalTok{ odd) }\SpecialCharTok{\&} \FunctionTok{col}\NormalTok{(C) }\SpecialCharTok{\%in\%}\NormalTok{ odd] }\OtherTok{\textless{}{-}} \DecValTok{0}

\CommentTok{\#current mean}
\NormalTok{mz\_cur\_SA }\OtherTok{\textless{}{-}}\NormalTok{ mz[}\DecValTok{4}\NormalTok{]}
\NormalTok{se\_mz\_cur\_SA }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(C[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{] }\SpecialCharTok{/}\NormalTok{ n)}
\CommentTok{\#change of mean from time 1 to time 4}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{d\_mz\_SA }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_d\_mz\_SA }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#trend of mean}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mz\_trend\_SA }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz}
\NormalTok{se\_mz\_trend\_SA }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#space{-}time mean}
\NormalTok{mz\_st\_SA }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(mz)}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{se\_mz\_st\_SA }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ C }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

\hypertarget{supplemented-panel-design}{%
\subsection{Supplemented panel design}\label{supplemented-panel-design}}

With SP sampling and four sampling times we have five panels, one panel with fixed sampling locations and four panels with swarming locations (Figure \ref{fig:SpaceTimeDesigns}). Each panel consists of \(n/2\) sampling locations, so in total \(5n/2=250\) locations are selected. A variable indicating the panel is added to the data frame with the selected sampling locations. Figure \ref{fig:sampleIberiaSP} shows the selected SP sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grd), }\AttributeTok{size =} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample\_SP }\OtherTok{\textless{}{-}}\NormalTok{ grd[units, ]}
\NormalTok{mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{, }\StringTok{"e"}\NormalTok{), }\AttributeTok{each =}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleIberiaSP-1} 

}

\caption{Supplemented panel space-time sample from Iberia. Locations are selected by simple random sampling. The permanent sampling locations are indicated by the filled dots, the swarming locations by the other symbols.}\label{fig:sampleIberiaSP}
\end{figure}

With SP sampling the spatial means are estimated by the design-based GLS estimator (Equation \eqref{eq:DBGLS}). As a first step the eight elementary estimates (two per sampling time) are computed and collected in a vector. Note the order of the elementary estimates: first the estimated spatial means of 2004, 2009, 2014, and 2019, estimated from the panel with fixed sampling locations, then the estimated spatial means estimated from the panels with swarming locations. The design matrix \(\mathbf{X}\) corresponding to this order of elementary estimates is constructed.

\begin{rmdnote}
Ordering the elementary estimates by sampling time is also fine, but then the design matrix \(\mathbf{X}\) should be adapted to this order.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_1 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2004, }\AttributeTok{INDEX =}\NormalTok{ mysample\_SP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]}
\NormalTok{mz\_2 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2009, }\AttributeTok{INDEX =}\NormalTok{ mysample\_SP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)]}
\NormalTok{mz\_3 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2014, }\AttributeTok{INDEX =}\NormalTok{ mysample\_SP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{)]}
\NormalTok{mz\_4 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2019, }\AttributeTok{INDEX =}\NormalTok{ mysample\_SP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)]}
\NormalTok{mz\_el }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(mz\_1[}\StringTok{"a"}\NormalTok{], mz\_2[}\StringTok{"a"}\NormalTok{], mz\_3[}\StringTok{"a"}\NormalTok{], mz\_4[}\StringTok{"a"}\NormalTok{],}
\NormalTok{           mz\_1[}\StringTok{"b"}\NormalTok{], mz\_2[}\StringTok{"c"}\NormalTok{], mz\_3[}\StringTok{"d"}\NormalTok{], mz\_4[}\StringTok{"e"}\NormalTok{])}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\DecValTok{4}\NormalTok{), }\FunctionTok{diag}\NormalTok{(}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The variances and covariances of the elementary estimates of the panel with fixed locations (SS subsample) are estimated, as well as the variances of the elementary estimates of the panels with swarming locations (IS subsample). The two variance-covariance matrices and a 4 \(\times\) 4 submatrix with all zeroes are combined into a single matrix, see matrix \eqref{eq:CmatrixSP}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysubsample\_SS }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_SP[mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{, ]}
\NormalTok{C\_SS }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(}
\NormalTok{  mysubsample\_SS[, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2004"}\NormalTok{, }\StringTok{"TAS2009"}\NormalTok{, }\StringTok{"TAS2014"}\NormalTok{, }\StringTok{"TAS2019"}\NormalTok{)]) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysubsample\_IS }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2004[mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{],}
\NormalTok{                        mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2009[mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"c"}\NormalTok{],}
\NormalTok{                        mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2014[mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"d"}\NormalTok{],}
\NormalTok{                        mysample\_SP}\SpecialCharTok{$}\NormalTok{TAS2019[mysample\_SP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"e"}\NormalTok{])}
\NormalTok{C\_IS }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysubsample\_IS) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{C\_IS[}\FunctionTok{row}\NormalTok{(C\_IS) }\SpecialCharTok{!=} \FunctionTok{col}\NormalTok{(C\_IS)] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{zeroes }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{4}\NormalTok{)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(C\_SS, zeroes), }\FunctionTok{cbind}\NormalTok{(zeroes, C\_IS))}
\end{Highlighting}
\end{Shaded}

The design-based GLS estimates of the spatial means can be computed as follows, see Equation \eqref{eq:DBGLS}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XCXinv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, X)))}
\NormalTok{XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, mz\_el))}
\NormalTok{mz\_GLS }\OtherTok{\textless{}{-}}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ XCz}
\end{Highlighting}
\end{Shaded}

Computing the estimated space-time parameters from the design-based GLS estimated spatial means is straightforward.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#current mean}
\NormalTok{mz\_cur\_SP }\OtherTok{\textless{}{-}}\NormalTok{ mz\_GLS[}\DecValTok{4}\NormalTok{]}
\NormalTok{se\_mz\_cur\_SP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(XCXinv[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\CommentTok{\#change of mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{d\_mz\_SP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_d\_mz\_SP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#trend of mean}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mz\_trend\_SP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_mz\_trend\_SP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#space{-}time mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{mz\_st\_SP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_mz\_st\_SP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

\hypertarget{rotating-panel-design}{%
\subsection{Rotating panel design}\label{rotating-panel-design}}

Similar to the SP design, with an in-for-two RP design and four sampling times we have five panels, each consisting of \(n/2\) sampling locations, so that in total \(5n/2=250\) locations are selected. Figure \ref{fig:sampleIberiaRP} shows the selected space-time sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grd), }\AttributeTok{size =} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample\_RP }\OtherTok{\textless{}{-}}\NormalTok{ grd[units, ]}
\NormalTok{mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{, }\StringTok{"e"}\NormalTok{), }\AttributeTok{each =}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/sampleIberiaRP-1} 

}

\caption{In-for-two rotating panel space-time sample from Iberia. Locations are selected by simple random sampling. Half of the sampling locations observed in a given year are also observed in the consecutive survey.}\label{fig:sampleIberiaRP}
\end{figure}

Two elementary estimates per sampling time are computed and collected in a vector. Note that now the elementary estimates are ordered by sampling time. The design matrix corresponding to this order is constructed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mz\_1 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_RP}\SpecialCharTok{$}\NormalTok{TAS2004, }\AttributeTok{INDEX =}\NormalTok{ mysample\_RP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]}
\NormalTok{mz\_2 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_RP}\SpecialCharTok{$}\NormalTok{TAS2009, }\AttributeTok{INDEX =}\NormalTok{ mysample\_RP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)]}
\NormalTok{mz\_3 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_RP}\SpecialCharTok{$}\NormalTok{TAS2014, }\AttributeTok{INDEX =}\NormalTok{ mysample\_RP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)]}
\NormalTok{mz\_4 }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(}
\NormalTok{  mysample\_RP}\SpecialCharTok{$}\NormalTok{TAS2019, }\AttributeTok{INDEX =}\NormalTok{ mysample\_RP}\SpecialCharTok{$}\NormalTok{panel, }\AttributeTok{FUN =}\NormalTok{ mean)[}\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)]}
\NormalTok{mz\_el }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(mz\_1, mz\_2, mz\_3, mz\_4)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DecValTok{2}\NormalTok{),}
              \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DecValTok{2}\NormalTok{),}
              \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DecValTok{2}\NormalTok{),}
              \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DecValTok{2}\NormalTok{)), }\AttributeTok{nrow =} \DecValTok{8}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{4}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To construct the variance-covariance matrix of the eight elementary estimates, first the 2 \(\times\) 2 matrices with estimated variances and covariances are computed for panels b, c, and d.~These three panels are used to estimate the spatial means of two consecutive years: the locations of panel b are used to estimate the spatial means of the years 2004 and 2009, panel c for the years 2009 and 2014, and panel d for the years 2014 and 2019 (Figure \ref{fig:SpaceTimeDesigns}). These three matrices are copied into the 8 \(\times\) 8 matrix, see matrix \eqref{eq:CmatrixRP}. Finally, the estimated variances of the estimators of the spatial means in 2004 and 2019 are computed and copied to the upper-left and bottom-right entry of the variance-covariance matrix, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysubsample }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_RP[mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2004"}\NormalTok{, }\StringTok{"TAS2009"}\NormalTok{)]}
\NormalTok{C\_b }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysubsample) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysubsample }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_RP[mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"c"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2009"}\NormalTok{, }\StringTok{"TAS2014"}\NormalTok{)]}
\NormalTok{C\_c }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysubsample) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{mysubsample }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_RP[mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"d"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"TAS2014"}\NormalTok{, }\StringTok{"TAS2019"}\NormalTok{)]}
\NormalTok{C\_d }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysubsample) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{data =} \DecValTok{0}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{8}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{8}\NormalTok{)}
\NormalTok{C[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ C\_b}
\NormalTok{C[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{4}\SpecialCharTok{:}\DecValTok{5}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ C\_c}
\NormalTok{C[}\DecValTok{6}\SpecialCharTok{:}\DecValTok{7}\NormalTok{, }\DecValTok{6}\SpecialCharTok{:}\DecValTok{7}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ C\_d}
\NormalTok{C[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysample\_RP[mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{, }\StringTok{"TAS2004"}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{C[}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(mysample\_RP[mysample\_RP}\SpecialCharTok{$}\NormalTok{panel }\SpecialCharTok{==} \StringTok{"e"}\NormalTok{, }\StringTok{"TAS2019"}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The design-based GLS estimates of the spatial means for the four sampling times are computed as before, followed by computing the estimated space-time parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XCXinv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, X)))}
\NormalTok{XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, mz\_el))}
\NormalTok{mz\_GLS }\OtherTok{\textless{}{-}}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ XCz}
\CommentTok{\#current mean}
\NormalTok{mz\_cur\_RP }\OtherTok{\textless{}{-}}\NormalTok{ mz\_GLS[}\DecValTok{4}\NormalTok{]}
\NormalTok{se\_mz\_cur\_RP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(XCXinv[}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{])}
\CommentTok{\#change of mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{d\_mz\_RP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_d\_mz\_RP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#trend of mean}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ (t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{((t }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(t))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{mz\_trend\_RP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_mz\_trend\_RP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\CommentTok{\#space{-}time mean}
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{mz\_st\_RP }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ mz\_GLS}
\NormalTok{se\_mz\_st\_RP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{t}\NormalTok{(w) }\SpecialCharTok{\%*\%}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ w)}
\end{Highlighting}
\end{Shaded}

\hypertarget{sampling-experiment}{%
\subsection{Sampling experiment}\label{sampling-experiment}}

The random sampling with the five space-time designs and estimation of the four space-time parameters is repeated 10,000 times. The standard deviations of the 10,000 estimates of a space-time parameter are shown in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters}. Note that to determine the standard errors of the estimators of the space-time parameters for the SS, IS, and SA designs a sampling experiment is not really needed. These can be computed without error because we have exhaustive knowledge of the study variable at all sampling times. However, for the SP and RP designs a sampling experiment is needed to approximate the design-expectation of the standard error of the estimators of the space-time parameters. This is because the space-time parameters are derived from the GLS estimator of the spatial means, and the GLS estimator is a function of the \emph{estimated} covariances of the elementary estimates (Equation \eqref{eq:DBGLS}). Using the true covariance of the elementary estimates in the GLS estimator, instead of the estimated covariance, leads to an underestimation of the standard error. Computing the true standard errors of the estimators of the space-time parameters for the various space-time designs is left as an exercise.

As a reference for the standard deviations in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters}: the current mean (spatial mean air temperature in 2019) equals 14.59 \(^\circ\)C, the change of the mean from 2004 to 2019 equals 0.611 \(^\circ\)C, the temporal trend equals 0.198 \(^\circ\)C \emph{per five years}, and the space-time mean equals 14.44 \(^\circ\)C.

\begin{table}

\caption{\label{tab:TableRepeatedEstimatesSpaceTimeParameters}Standard deviations of 10,000 estimates of space-time parameters of annual mean temperature in Iberia, with static-synchronous (SS), independent synchronous (IS), serially alternating (SA), supplemented panel (SP), and rotating panel (RP) space-time sampling, and simple random sampling with replacement of 100 locations per sampling time.}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
 & Current mean & Change of mean & Trend of mean & Space-time mean\\
\midrule
SS & 0.2709 & 0.0343 & 0.0123 & 0.2741\\
IS & 0.2653 & 0.3873 & 0.1221 & 0.1354\\
SA & 0.2676 & 0.3894 & 0.0787 & 0.1910\\
SP & 0.1755 & 0.0481 & 0.0171 & 0.1770\\
RP & 0.1769 & 0.0840 & 0.0299 & 0.1744\\
\bottomrule
\end{tabular}
\end{table}

Estimates of the current mean with the SP and RP designs are much more precise than with the SS, IS, and SA designs. This is because with designs SP and RP there is partial overlap with the samples of the other years. If the study variable at different years is correlated, we can profit from the data of previous years. In our case this correlation is very strong:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(grd[, }\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          TAS2004   TAS2009   TAS2014   TAS2019
TAS2004 1.0000000 0.9950227 0.9878301 0.9927014
TAS2009 0.9950227 1.0000000 0.9875005 0.9960541
TAS2014 0.9878301 0.9875005 1.0000000 0.9938060
TAS2019 0.9927014 0.9960541 0.9938060 1.0000000
\end{verbatim}

The differences in standard deviations of the estimated current means among the SS, IS, and SA designs are due to random variation: the true standard errors of the current mean estimator are equal for these three space-time designs.

The strong correlation also explains that the estimated change of the spatial mean from 2004 to 2019 with the SS design is much more precise than with the IS and SA designs. With the IS and SA designs the sample of 2019 is selected independently from the sample of 2004, so that the covariance of the two spatial mean estimators is zero. With the SS design two times this covariance is subtracted from the sum of the variances of the spatial mean estimators. The standard error of the estimator of the change of the spatial mean from 2009 to 2019 with the SA design (not shown in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters}) is much smaller than that of the change from 2004 to 2019 because the spatial means at these two times are estimated from the same sample, so that we profit from the strong positive correlation. The standard error of the change estimator with the SP design is slightly larger than the standard error with the SS design, because with this design there is only partial overlap, so that we profit less from the correlation. The standard error with the RP design is larger than that of the SP design because with the RP design there is no overlap of the samples of 2004 and 2019 (Figure \ref{fig:SpaceTimeDesigns}). Despite the absence of overlap, the standard error is still considerably smaller than those with the IS and SA designs because the spatial means of 2004 and 2019 are estimated by the GLS estimator that uses the data of all years, so that we still profit from the correlation.

Estimation of the temporal trend of the spatial mean is most precise with the SS design, closely followed by the SP design, and least precise with the IS design. This is in agreement with the results of \citet{Brus2011} and \citet{Brus2013}. On the contrary, estimation of the space-time mean is most precise with the IS design and least precise with the SS design. With strong persistence of the spatial patterns, as in our case, it is not efficient to observe the same sampling locations at all times when interest is in the space-time mean. In our case with very strong correlation, the larger the total number of sampling locations over all sampling times is, the smaller the standard error of the space-time mean estimator is. The total number of sampling locations in this case study are \(n\) with SS, \(4n\) with IS, \(2n\) with SA, and \(5n/2\) with SP and RP.

\hypertarget{space-time-sampling-with-stratified-random-sampling-in-space}{%
\section{Space-time sampling with stratified random sampling in space}\label{space-time-sampling-with-stratified-random-sampling-in-space}}

In real-world applications one will often use more efficient sampling designs than simple random sampling for selecting spatial sampling units. For instance, in the case study of the previous section stratified simple random sampling using climate zones is most likely more efficient than simple random sampling.

To select a space-time sample with stratified simple random sampling as a spatial design, the selection procedures described above for the five basic types of space-time design are applied at the level of the strata. Estimation of the space-time parameters goes along the same lines, using the \(\pi\) estimator of the spatial mean and the estimator of the standard error presented in Chapter \ref{STSI}. With the SP and RP designs, the covariance of the elementary estimators of the spatial means at two sampling times using the data of the same panel, can be estimated by

\begin{equation}
\widehat{C}_{ab} =  \sum_{h=1}^H w^2_h \frac{\widehat{S^2}_{abh}}{m_h} \;,
\label{eq:covartwoelementaryestimatesSTSI}
\end{equation}

with \(\widehat{S^2}_{abh}\) the estimated covariance of the study variable at times \(t_a\) and \(t_b\) in stratum \(h\), and \(m_h\) the number of sampling locations in the panel in stratum \(h\).

Interesting new developments are presented by \citet{WangZhu2019} and \citet{ZhaoGrafstrom2020}.

\hypertarget{exercises-21}{%
\subsubsection*{Exercises}\label{exercises-21}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute for the annual mean temperature data of Iberia the true standard error of the estimator of (i) the spatial mean in 2019; (ii) the change of the spatial mean from 2004 to 2019; (iii) the temporal trend of the spatial mean (average change per five years in the period 2004 - 2019); and (iv) the space-time mean, for all five space-time designs and simple random sampling with replacement of 100 units per time. Use for the designs SP and RP the true covariances of the elementary estimates in the GLS estimators of the spatial means.

  \begin{itemize}
  \tightlist
  \item
    Compare the standard errors with the standard deviations in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters}. Explain why for the designs SP and RP the true standard errors of the estimators of all space-time parameters are slightly smaller than the standard deviations in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters}.\\
  \end{itemize}
\item
  With an SP and an RP design the change of the mean can also be estimated by the difference of the \(\pi\) estimates of the spatial means at the two times, instead of the difference of the two GLS estimates. The variance of the difference of the \(\pi\) estimators of two simple random samples at different times with partial overlap equals
  \begin{equation}
  V(\bar{d}_{ab})=\frac{S^2_a}{n} + \frac{S^2_b}{n} - 2\frac{m\;S^2_{ab}}{n^2}\;,
  \label{eq:varChangeofMeanHT}
  \end{equation}
  with \(S^2_a\) and \(S^2_b\) the spatial variance at time \(t_a\) and \(t_b\), respectively, \(S^2_{ab}\) the spatial covariance of the study variable at times \(t_a\) and \(t_b\), \(n\) the size of the simple random samples, and \(m\) the number of units observed at both times. Compute for Iberia the standard error of the estimator of the change of the mean with Equation \eqref{eq:varChangeofMeanHT}, using the \emph{true} spatial variances and covariances for the years 2004 and 2019, for simple random samples of size 100 (\(n=100\)) and a matching proportion of 0.5 (\(m=50\)). Compare with the true standard error of the estimator of the change of the mean using the GLS estimators computed in the previous exercise. Explain that the standard error of the \(\pi\) estimators is larger than the standard error with the GLS estimators.
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5544857 296.2   12043445 643.2  12043445  643.2
Vcells 29114228 222.2  121702176 928.6 189381883 1444.9
\end{verbatim}

\hypertarget{part-sampling-for-mapping}{%
\part{Sampling for mapping}\label{part-sampling-for-mapping}}

\hypertarget{IntroSamplingforMapping}{%
\chapter{Introduction to sampling for mapping}\label{IntroSamplingforMapping}}

\hypertarget{when-is-probability-sampling-not-required}{%
\section{When is probability sampling not required?}\label{when-is-probability-sampling-not-required}}

This second part of the book deals with sampling for mapping, i.e.~for predicting the study variable at the nodes of a fine discretisation grid. For mapping a model-based sampling approach is the most natural option. When a statistical model, i.e.~a model containing an error term modelled by a probability distribution, is used to map the study variable from the sample data, selection of the sampling units by probability sampling is not strictly needed anymore in order to make statistical statements about the population, i.e.~statements with quantified uncertainty, see Section \ref{DBvsMB}. As a consequence, there is room for optimising the sampling units by searching for those units that lead to the most accurate map, for instance, the map with the smallest squared prediction error averaged over all locations in the mapped study area, see Chapter \ref{Validation}.

As an illustration, consider the following statistical model to be used for mapping: a simple linear regression model for the study variable to be mapped:

\begin{equation}
Z_k = \beta_0 + \beta_1 x_k + \epsilon_k \;,
\label{eq:simplelinearregressionmodel}
\end{equation}

with \(Z_k\) the study variable of unit \(k\), \(\beta_0\) and \(\beta_1\) regression coefficients, \(x_k\) a covariate for unit \(k\) used as a predictor, and \(\epsilon_k\) the error (residual) at unit \(k\), normally distributed with mean zero and a constant variance \(\sigma^2\). The errors are assumed independent, so that \(\text{Cov}(\epsilon_k,\epsilon_j)=0\) for all \(k \neq j\). Figure \ref{fig:twosamples} shows a simple random sample without replacement and the sample optimised for mapping with a simple linear regression model. Both samples are plotted on a map of the covariate \(x\).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/twosamples-1} 

}

\caption{Simple random sample and optimal sample for mapping with a simple linear regression model, plotted on a map of the covariate.}\label{fig:twosamples}
\end{figure}

The optimal sample for mapping with a simple linear regression model contains the units with the smallest and the largest values of the covariate \(x\). The optimal sample shows strong spatial clustering. Spatial clustering is not avoided because in a simple linear regression model we assume that the residuals are not spatially correlated. In Chapter \ref{MBSamplePattern} I will show that when the residuals are spatially correlated, spatial clustering of sampling units is avoided. The standard errors of both regression coefficients are considerably smaller for the optimal sample (Table \ref{tab:sebetas}). The joint uncertainty about the two regression coefficients, quantified by the determinant of the variance-covariance matrix\index{Determinant of variance-covariance matrix} of the regression coefficient estimators, is also much smaller for the optimal sample. When we are less uncertain about the regression coefficients, we are also less uncertain about the regression model predictions of the study variable \(z\) at points where we have observations of the covariate \(x\) only. We can conclude that for mapping with a simple linear regression model, in this example simple random sampling is not a good option.

\begin{table}

\caption{\label{tab:sebetas}Standard errors and determinant of the variance-covariance matrix of estimators of the regression coefficients for the simple random sample (SI) and the optimal sample.}
\centering
\begin{tabular}[t]{llll}
\toprule
Sampling design & se intercept & se slope & Determinant\\
\midrule
SI & 1.70 & 0.118 & 0.003876\\
Optimal & 1.06 & 0.050 & 0.000940\\
\bottomrule
\end{tabular}
\end{table}

Of course, this simple example would only be applicable if we have evidence of a linear relation between study variable \(z\) and covariate \(x\), and in addition if we are willing to rely on the assumption that the residuals are not spatially correlated.

\hypertarget{sampling-for-simultaneously-mapping-and-estimating-means}{%
\section{Sampling for simultaneously mapping and estimating means}\label{sampling-for-simultaneously-mapping-and-estimating-means}}

Although probability sampling is not strictly needed for mapping with a statistical model, in some situations, when feasible, it can still be advantageous to select a probability sample. If the aim of the survey is to map the study variable, as well as to estimate the mean or total for the entire study area or for several subareas, probability sampling can be a good option. Think, for instance, of sampling for the dual objectives of mapping and at the same time estimating soil carbon stocks. Although the statistical model used for mapping can also be used for model-based prediction of the total carbon stocks in the study area and subareas (Section \ref{SmallAreaModelBased}), we may prefer to estimate these totals by design-based or model-assisted inference. The advantage of design-based and model-assisted estimation of these totals is their validity\index{Validity}. Validity means that an objective assessment of the uncertainty of the estimated mean or total is warranted, and that the coverage of confidence intervals is (almost) correct, provided that the sample is large enough to assume an approximately normal distribution of the estimator and design-unbiasedness of the variance estimator, see Chapter \ref{Approaches}. In design-based estimation no model of the spatial variation is used. Discussions about how realistic modelling assumptions are, therefore are avoided. In model-assisted estimation these discussions are irrelevant as well, because we do not rely on these assumptions. A poor model results in large variances of the estimated mean or total and, as a consequence, a wide confidence interval, so that the coverage of the confidence interval is in agreement with the nominal coverage, see Section \ref{ModelassistedvsModeldependent} for more details.

The question then is: what is a suitable probability sampling design for both aims? First, I would recommend a sampling design with equal inclusion probabilities. This is because in standard model-based inference unequal inclusion probabilities are not accounted for, which may lead to systematic prediction errors when small or large values are overrepresented in the sample (Section \ref{BiasandVariance}).

Second, in case we have subareas of which we would like to estimate the mean or total (domains of interest), using these subareas as strata in stratified random sampling makes sense, unless there are too many. This requires that of all population units (nodes of discretisation grid) we must know to which subarea it belongs, so that this information can be added to the sampling frame.

Third, a sampling design spreading out the sampling units in geographical space is attractive as well, for instance through compact geographical stratification (Section \ref{geostrata}) or sampling with the local pivotal method (Subsection \ref{LPM}). We may profit from this geographical spreading if some version of kriging is used for mapping (Chapter \ref{Introkriging}). In addition, the geographical spreading may enhance the coverage of the space spanned by covariates related to the study variable. Spreading in covariate space can also be explicitly accounted for using the covariates as spreading variables in the local pivotal method.

As an illustration I selected a single sample of 500 units from Eastern Amazonia with the dual aim of mapping aboveground biomass (AGB) as well as estimating the means of AGB for four biomes. The biomes are used as strata in stratified random sampling. First, the stratum sample sizes are computed for proportional allocation, so that the inclusion probabilities are approximately equal for all population units.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{biomes }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Mangrove"}\NormalTok{, }\StringTok{"Forest\_dry"}\NormalTok{, }\StringTok{"Grassland"}\NormalTok{, }\StringTok{"Forest\_moist"}\NormalTok{)}
\FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome) }\OtherTok{\textless{}{-}}\NormalTok{ biomes}
\NormalTok{N\_h }\OtherTok{\textless{}{-}}  \FunctionTok{table}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}
\NormalTok{n\_h }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h))}
\NormalTok{n\_h[}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ n\_h[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{+} \DecValTok{1}
\FunctionTok{print}\NormalTok{(n\_h)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Mangrove   Forest_dry    Grassland Forest_moist 
           2           11           28          459 
\end{verbatim}

Biome Forest\_moist is by far the largest biome with a sample size of 459 points.

In the next code chunk a balanced sample is selected with equal inclusion probabilities, using both the categorical variable biome and the continuous variable lnSWIR2 as balancing variables (Subsection \ref{StratifiedsamplingasBalancedsampling}). The geographical coordinates are used as spreading variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BalancedSampling)}
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2 }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{SWIR2)}
\NormalTok{pi }\OtherTok{\textless{}{-}}\NormalTok{ n\_h }\SpecialCharTok{/}\NormalTok{ N\_h}
\NormalTok{stratalabels }\OtherTok{\textless{}{-}} \FunctionTok{levels}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{Biome)}
\NormalTok{lut }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Biome =}\NormalTok{ stratalabels, }\AttributeTok{pi =} \FunctionTok{as.numeric}\NormalTok{(pi))}
\NormalTok{grdAmazonia }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdAmazonia, }\AttributeTok{y =}\NormalTok{ lut)}
\NormalTok{Xbal }\OtherTok{\textless{}{-}} \FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ Biome }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ grdAmazonia) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{cbind}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{lnSWIR2)}
\NormalTok{Xspread }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(grdAmazonia}\SpecialCharTok{$}\NormalTok{x1, grdAmazonia}\SpecialCharTok{$}\NormalTok{x2)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{lcube}\NormalTok{(}\AttributeTok{Xbal =}\NormalTok{ Xbal, }\AttributeTok{Xspread =}\NormalTok{ Xspread, }\AttributeTok{prob =}\NormalTok{ grdAmazonia}\SpecialCharTok{$}\NormalTok{pi)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units, ]}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:Sample4MappingandEstimationAmazonia} shows the selected sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/Sample4MappingandEstimationAmazonia-1} 

}

\caption{Balanced sample of size 500 from Eastern Amazonia, balanced on biome and lnSWIR2, with geographical spreading. Equal inclusion probabilities are used.}\label{fig:Sample4MappingandEstimationAmazonia}
\end{figure}

I think this is a suitable sample, both for mapping AGB across the entire study area, for instance by kriging with an external drift (Section \ref{IntroKED}), and for estimating the mean AGB of the four biomes. For biome Forest\_moist the population mean can be estimated from the data of this biome only, using the \(\pi\) estimator, as the sample size of this biome is very large (Section \ref{BalancedandSpreaded}). For the other three biomes we may prefer model-assisted estimation for small domains as described in Section \ref{SmallDomainsModelAssisted}.

In this example I used one quantitative covariate, lnSWIR2, for balancing the sample. If we have a legacy sample that can be used to fit a linear or non-linear model, for instance a random forest using multiple covariates and factors as predictors (Chapter \ref{Modelassisted}), then this model can be used to predict the study variable for all population units, so that we can use the predictions of the study variable to balance the sample, see Section \ref{RandomForest}.

\hypertarget{broad-overview-of-sampling-designs-for-mapping}{%
\section{Broad overview of sampling designs for mapping}\label{broad-overview-of-sampling-designs-for-mapping}}

The non-probability sampling designs for mapping described in the following chapters can be grouped into three categories \citep{Brus2019b}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  geometric sampling designs\index{Geometric sampling design} (Chapters \ref{RegularGridSpatialCoverage} and \ref{kmeans});
\item
  adapted experimental designs\index{Adapted experimental design} (Chapters \ref{cLHS} and \ref{SpatialResponseSurface}); and
\item
  model-based sampling designs (Chapters \ref{MBgridspacing} and \ref{MBSamplePattern}).
\end{enumerate}

Square and triangular grids are examples of geometric sampling designs; the sampling units show a regular, geometric spatial pattern. In other geometric sampling designs the spatial pattern is not perfectly regular. Yet these are classified as geometric sampling designs when the samples are obtained by minimising some geometric criterion, i.e.~a criterion defined in terms of distances between the sampling units and the nodes of a fine prediction grid discretising the study area (Section \ref{SpatialCoverage} and Chapter \ref{kmeans}).

In model-based sampling designs\index{Model-based sampling} the samples are obtained by minimising a criterion that is defined in terms of variances of prediction errors. An example is the mean kriging variance criterion, i.e.~the average of the kriging variances over all nodes of the prediction grid. Model-based sampling therefore requires prior knowledge of the model of spatial variation. Such a model must be specified and justified. Once this model is given the sample can be optimised. In Chapter \ref{MBgridspacing} I will show how a spatial model can be used to optimise the spacing of a square grid given a requirement on the accuracy of the map. The grid spacing determines the number of sampling units, so this optimisation boils down to determining the required sample size. In Chapter \ref{MBSamplePattern} I will show how a sample of a given size can be further optimised through optimisation of the spatial coordinates of the sampling units.

In Chapter \ref{GeneralIntro} the design-based and model-based approaches for sampling and statistical inference were introduced. Note that a model-based approach does not necessarily imply model-based sampling. The adjective model-based refers to the model-based inference, not to the selection of the units. In a model-based approach sampling units can be, but need not be, selected by model-based sampling. If they are, then both in selecting the units and in mapping a statistical model is used. In most cases the two models differ: once the sample data are collected, these are used to update the postulated model used for designing the sample. The updated model is then used in mapping.

Besides geometric and model-based sampling designs for spatial survey a third category can be distinguished: sampling designs that are adaptations of experimental designs. An adaptation is necessary because in contrast to experiments, in observational studies one is not free to choose combinations of levels of different factors. For instance, when two covariates are strongly positively correlated, it may happen that there are no units with a relatively large value for one covariate and a relatively small value for the other covariate.

In a full factorial design\index{Full factorial design} all combinations of factor levels are observed. For instance, suppose we have only two covariates, e.g.~application rates for N and P in an agricultural experiment, and four levels for each covariate. To account for possible non-linear effects, a good option is to have multiple plots for all 4 \(\times\) 4 combinations. This is referred to as a full factorial design. With \(k\) factors and \(l\) levels per factor the total number of observations is \(l^k\). With numerous factors and/or numerous levels per factor this becomes unfeasible in practice. Alternative designs have been developed that need fewer observations but still provide detailed information about how the study variable responds to changes in the factor levels. Examples are Latin hypercube samples\index{Latin hypercube sample} and response surface designs\index{Response surface design}. The survey sampling analogues of these experimental designs are described in Chapters \ref{cLHS} and \ref{SpatialResponseSurface}, respectively.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5545449 296.2   12043445 643.2  12043445  643.2
Vcells 27702067 211.4   97361741 742.9 189381883 1444.9
\end{verbatim}

\hypertarget{RegularGridSpatialCoverage}{%
\chapter{Regular grid and spatial coverage sampling}\label{RegularGridSpatialCoverage}}

This chapter describes and illustrates two sampling designs by which the sampling locations are evenly spread throughout the study area: regular grid sampling and spatial coverage sampling. In a final section the spatial coverage sampling design is used to fill in the empty spaces of an existing sample.

\hypertarget{Regulargrid}{%
\section{Regular grid sampling}\label{Regulargrid}}

Sampling on a regular grid\index{Regular grid} is an attractive option for mapping because of its simplicity. The data collected on the grid nodes are not used for design-based estimation of the population mean or total. For this reason the grid need not be placed randomly on the study area as in systematic random sampling (Chapter \ref{SY}). The grid can be located such that the grid nodes optimally cover the study area in the sense of the average distance of the nodes of a fine discretisation grid to the nearest node of the sampling grid. Commonly used grid configurations are square and triangular. If the grid data are used in kriging (Chapter \ref{Introkriging}), the optimal configuration depends, among others, on the semivariogram model. If the study variable shows moderate to strong spatial autocorrelation (see Section \ref{OrdinaryKriging}), triangular grids outperform square grids.

Besides the shape of the sampling grid cells, we must decide on the grid spacing\index{Grid spacing}. The grid spacing determines the number of sampling units in the study area, i.e.~the sample size. There are two options to decide on this spacing, either starting from the available budget or from a requirement on the quality of the map. The latter is explained in Chapter \ref{MBgridspacing}, as this requires a model of the spatial variation, and as a consequence this is an example of model-based sampling. Starting from the available budget and an estimate of the costs per sampling unit, we first compute the affordable sample size. Then we may derive from this number the grid spacing. For square grids, the grid spacing in meters is calculated as \(\sqrt{A/n}\), where \(A\) is the area in m\textsuperscript{2} and \(n\) is the number of sampling units (sample size).

Grids can be selected with function \texttt{spsample} of package \textbf{sp} \citep{Pebesma2005}. Argument \texttt{offset} is used to select a grid non-randomly. Either a sample size can be specified, using argument \texttt{n}, or a grid spacing, using argument \texttt{cellsize}. In the next code chunk a square grid is selected with a spacing of 200 m.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{gridded}\NormalTok{(grdVoorst) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ grdVoorst, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DecValTok{200}\NormalTok{),}
  \AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:gridVoorst} shows the selected square grid.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/gridVoorst-1} 

}

\caption{Non-random square grid sample with a grid spacing of 200 m from Voorst.}\label{fig:gridVoorst}
\end{figure}

The number of grid points in this example equals 115. Nodes of the square grid in parts of the area not belonging to the population of interest, such as built-up areas and roads, are discarded by \texttt{spsample} (these nodes are not included in the sampling frame file \texttt{grdVoorst}). As a consequence, there are some undersampled areas\index{Undersampled area}, for instance in the middle of the study area where two roads cross. If we use the square grid in spatial interpolation, e.g.~by ordinary kriging, we are more uncertain about the predictions in these undersampled areas than in areas where the grid is complete. In the next section I will show how this local undersampling can be avoided.

\hypertarget{exercises-22}{%
\subsubsection*{Exercises}\label{exercises-22}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select a square grid of size 100 from West-Amhara in Ethiopia. Use \texttt{grdAmhara} of package \textbf{sswr} as a sampling frame. Use a fixed starting point of the grid, i.e.~do not select the grid randomly.

  \begin{itemize}
  \tightlist
  \item
    Compute the number of selected grid points. How comes that it is not exactly equal to 100?
  \item
    Select a square grid with a spacing of 10.2 km, and compute the sample size.
  \item
    Write a for-loop to select 200 times a square grid of, on average, 100 points with random starting point. Set a seed so that the result can be reproduced. Determine for each randomly selected grid the number of selected grid points, and save this in a numeric. Compute summary statistics of the sample size, and plot a histogram.
  \item
    Select a square grid of exactly 100 points.
  \end{itemize}
\end{enumerate}

\hypertarget{SpatialCoverage}{%
\section{Spatial coverage sampling}\label{SpatialCoverage}}

Local undersampling with regular grids can be avoided by relaxing the constraint that the sampling units are restricted to the nodes of a regular grid. This is what is done in \emph{spatial coverage sampling}\index{Spatial coverage sampling} or, in case of a sample that is added to an existing sample, in \emph{spatial infill sampling}\index{Spatial infill sampling}. Spatial coverage and infill samples cover the area or fill in the empty space as uniformly as possible. The sampling units are obtained by minimising a criterion that is defined in terms of the geographic distances between the nodes of a fine discretisation grid and the sampling units. \citet{bru07c} proposed to minimise the mean of the squared distances of the grid nodes to their nearest sampling unit (mean squared shortest distance, MSSD\index{Mean squared shortest distance}):

\begin{equation}
MSSD=\frac{1}{N}\sum_{k=1}^{N}\min_{j}\left(D_{kj}^{2}\right) \;,
\label{eq:MSSD}
\end{equation}

where \(N\) is the total number of nodes of the discretisation grid and \(D_{kj}\) is the distance between the \(k\)th grid node and the \(j\)th sampling point. This distance measure can be minimised by the k-means algorithm, which is a numerical, iterative procedure. Figure \ref{fig:spatialcoveragesamplefromsquare} illustrates the selection of a spatial coverage sample of four points from a square. In this simple example the optimal spatial coverage sample is known, being the centres of the four subsquares of equal size. A simple random sample of four points serves as the initial solution. Each raster cell is then assigned to the closest sampling point. This is the initial clustering. In the next iteration the centres of the initial clusters are computed. Next, the raster cells are re-assigned to the closest new centres. This continues until there is no change anymore. In this case only nine iterations are needed, where an iteration consists of computing the clusters by assigning the raster cells to the nearest centre (sampling unit), followed by computing the centres of these clusters. Figure \ref{fig:spatialcoveragesamplefromsquare} shows the first, second, and ninth iteration.

\begin{figure}

{\centering \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-1} \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-2} \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-3} \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-4} \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-5} \includegraphics[width=0.47\linewidth]{SpatialSampling_files/figure-latex/spatialcoveragesamplefromsquare-6} 

}

\caption{First, second, and ninth iteration of the k-means algorithm to select a spatial coverage sample of four points from a square. Iterations are rowwise from top to bottom. In the left column of subfigures the clusters are computed by assigning the raster cells to the nearest centre. In the right column of subfigures the centres of the clusters are computed.}\label{fig:spatialcoveragesamplefromsquare}
\end{figure}

The same algorithm was used in Chapter \ref{STSI} to construct compact geographical strata (shortly referred to as geostrata) for stratified random sampling. The clusters serve as strata. In stratified random sampling, one or more sampling units are selected randomly from each geostratum. However, for mapping purposes probability sampling is not required, so the random selection of a unit within each stratum is not needed. With random selection the spatial coverage is suboptimal. Here the centres of the final clusters (geostrata) are used as sampling points. This improves the spatial coverage compared to stratified \emph{random} sampling.

In probability sampling we may want to have strata of equal area (clusters of equal size) so that the sampling design becomes self-weighting. For mapping equally sized clusters are not recommended as it may lead to samples with suboptimal spatial coverage.

\begin{rmdnote}
In Figure \ref{fig:spatialcoveragesamplefromsquare} the clusters are of equal size but this is an artefact. Equally sized clusters are not guaranteed by the illustrated k-means algorithm. Clustering the raster cells of a square into four clusters is a very special case. In other cases the clusters computed with the k-means algorithm described above might well have unequal size. In package \textbf{spcosa} also a different k-means algorithm is implemented, using swops, enforcing compact clusters of equal size.
\end{rmdnote}

Spatial coverage samples can be computed with package \textbf{spcosa} \citep{walvoort2010}, using functions \texttt{stratify} and \texttt{spsample}, see code chunk below. Argument \texttt{nTry} of function \texttt{stratify} specifies the number of initial stratifications in k-means clustering. Note that function \texttt{spsample} of package \textbf{spcosa} without optional argument \texttt{n} selects non-randomly one point in each cluster, being the centre. Figure \ref{fig:spatcovVoorst} shows a spatial coverage sample of the same size as the regular grid in study area Voorst (Figure \ref{fig:gridVoorst}). Note that the undersampled area in the centre of the study area is now covered by a sampling point.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{115}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\FunctionTok{gridded}\NormalTok{(grdVoorst) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{mystrata }\OtherTok{\textless{}{-}}\NormalTok{ spcosa}\SpecialCharTok{::}\FunctionTok{stratify}\NormalTok{(}
\NormalTok{  grdVoorst, }\AttributeTok{nStrata =}\NormalTok{ n, }\AttributeTok{equalArea =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{nTry =} \DecValTok{10}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(mystrata) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as}\NormalTok{(}\StringTok{"data.frame"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/spatcovVoorst-1} 

}

\caption{Spatial coverage sample from Voorst.}\label{fig:spatcovVoorst}
\end{figure}

If the clusters need not be of equal size, we may also use function \texttt{kmeans} of the \textbf{stats} package, using the spatial coordinates as clustering variables. This requires less computing time, especially with large data sets.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdVoorst }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(grdVoorst)}
\NormalTok{mystrata\_kmeans }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(}
\NormalTok{  grdVoorst[, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)], }\AttributeTok{centers =}\NormalTok{ n, }\AttributeTok{iter.max =} \DecValTok{10000}\NormalTok{, }\AttributeTok{nstart =} \DecValTok{10}\NormalTok{)}
\NormalTok{mysample\_kmeans }\OtherTok{\textless{}{-}}\NormalTok{ mystrata\_kmeans}\SpecialCharTok{$}\NormalTok{centers }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

When function \texttt{kmeans} is used to compute the spatial coverage sample, there is no guarantee that the computed centres of the clusters, used as sampling points, are inside the study area. In Figure \ref{fig:kmeanscenters} there are eight such centres.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/kmeanscenters-1} 

}

\caption{Centres of spatial clusters computed with function \texttt{kmeans}.}\label{fig:kmeanscenters}
\end{figure}

This problem can easily be solved by selecting points inside the study area closest to the centres that are outside the study area. Function \texttt{rdist} of package \textbf{fields} is used to compute a matrix with distances between the centres outside the study area and the nodes of the discretisation grid. Then function \texttt{apply} is used with argument \texttt{FUN\ =\ which.min} to compute the discretisation nodes closest to the centres outside the study area. A similar procedure is implemented in function \texttt{spsample} of package \textbf{spcosa} when the centres of the clusters are selected as sampling points (so, when argument \texttt{n} of function \texttt{spsample} is not used).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(fields)}
\FunctionTok{gridded}\NormalTok{(grdVoorst) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\FunctionTok{coordinates}\NormalTok{(mysample\_kmeans) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(mysample\_kmeans, grdVoorst)}
\NormalTok{inside }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{z))}
\NormalTok{units\_out }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(inside }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{grdVoorst }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(grdVoorst)}
\NormalTok{mysample\_kmeans }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(mysample\_kmeans)}
\NormalTok{D }\OtherTok{\textless{}{-}}\NormalTok{ fields}\SpecialCharTok{::}\FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ mysample\_kmeans[units\_out, ],}
  \AttributeTok{x2 =}\NormalTok{ grdVoorst[, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)])}
\NormalTok{units\_close }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(D, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ which.min)}
\NormalTok{mysample\_kmeans[units\_out, ] }\OtherTok{\textless{}{-}}\NormalTok{ grdVoorst[units\_close, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercises-23}{%
\subsubsection*{Exercises}\label{exercises-23}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In forestry and vegetation surveys square and circular plots are often used as sampling units, for instance, 2 m squares or circles with a diameter of 2 m. To study the relation between the vegetation and the soil, soil samples must be collected from the vegetation plots. Suppose we want to collect four soil samples from a square plot. Where would you locate the four sampling points, so that they optimally cover the plot?\\
\item
  Suppose we are also interested in the accuracy of the estimated plot means of the soil properties, not just the means. In that case the soil samples should not be bulked into a composite sample, but analysed separately. How would you select the sampling points in this case?\\
\item
  For circular vegetation plots it is less clear where the sampling points with smallest MSSD (Equation \eqref{eq:MSSD}) are. Write an \textbf{R} script to compute a spatial coverage sample of five points from a circular plot discretised by the nodes of a fine square grid. Use argument \texttt{equalArea\ =\ FALSE}. Check the size (number of raster cells) of the strata. Repeat this for six sampling points.\\
\item
  Consider the case of six strata. The strata are not of equal size. If the soil samples are bulked into a composite sample, the measurement on this single sample is a biased estimator of the plot mean. How can this bias be avoided?
\end{enumerate}

\hypertarget{SpatialInfill}{%
\section{Spatial infill sampling}\label{SpatialInfill}}

If georeferenced data are available that can be used for mapping the study variable, but we need more data for mapping, it is attractive to account for these existing sampling units when selecting the additional units. The aim now is to fill in the empty spaces, i.e.~the parts of the study area not covered by the existing sampling units. This is referred to as \emph{spatial infill sampling}. Existing sampling units can easily be accommodated in the k-means algorithm, using them as fixed cluster centres\index{Fixed cluster centre}.

Figure \ref{fig:spatialinfillEthiopia} shows a spatial infill sample for West-Amhara. A large set of legacy data on soil organic matter (SOM) in mass percentage (dag kg\textsuperscript{-1}) is available, but these data come from strongly spatially clustered units along roads (the prior points in Figure \ref{fig:spatialinfillEthiopia}). This is a nice example of a convenience sample. The legacy data are not ideal for mapping the SOM concentration throughout West-Amhara. Clearly, it is desirable to collect additional data in the off-road parts of the study area, with the exception of the northeastern part where we have already quite a few data not near the main roads. The legacy data are passed to function \texttt{stratify} of package \textbf{spcosa} with argument \texttt{priorPoints}. The object assigned to this argument must be of class \texttt{SpatialPoints} or \texttt{SpatialPointsDataFrame}. This optional argument fixes these points as cluster centres. A spatial infill sample of 100 points is selected, taking into account these fixed points.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{gridded}\NormalTok{(grdAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{ntot }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{+} \FunctionTok{nrow}\NormalTok{(sampleAmhara)}
\FunctionTok{coordinates}\NormalTok{(sampleAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\FunctionTok{proj4string}\NormalTok{(sampleAmhara) }\OtherTok{\textless{}{-}} \ConstantTok{NA\_character\_}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mystrata }\OtherTok{\textless{}{-}}\NormalTok{ spcosa}\SpecialCharTok{::}\FunctionTok{stratify}\NormalTok{(grdAmhara, }\AttributeTok{nStrata =}\NormalTok{ ntot,}
  \AttributeTok{priorPoints =}\NormalTok{ sampleAmhara, }\AttributeTok{nTry =} \DecValTok{10}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(mystrata)}
\FunctionTok{plot}\NormalTok{(mystrata, mysample)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/spatialinfillEthiopia-1} 

}

\caption{Spatial infill sample of 100 points from West-Amhara.}\label{fig:spatialinfillEthiopia}
\end{figure}

In the output object of \texttt{spsample} both the prior and the new sampling points are included. The new points can be obtained as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(mysample}\SpecialCharTok{@}\NormalTok{isPriorPoint }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(mysample, }\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{mysample\_new }\OtherTok{\textless{}{-}}\NormalTok{ mysample[units, ]}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercises-24}{%
\subsubsection*{Exercises}\label{exercises-24}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write an \textbf{R} script to select a spatial infill sample of size 100 from study area Xuancheng in China. Use the iPSM sample in tibble \texttt{sampleXuancheng} of package \textbf{sswr} as a legacy sample. To map the SOM concentration we want to measure the SOM concentration at 100 more sampling points.

  \begin{itemize}
  \tightlist
  \item
    Read the file \texttt{data/Elevation\_Xuancheng.rds} with function \texttt{rast} of package \textbf{terra}, and use this file as a discretisation of the study area.
  \item
    For computational reasons there are far too many raster cells. That many cells are not needed to select a spatial infill sample. Subsample the raster file by selecting a square grid with a spacing of 900 m \(\times\) 900 m. First convert the \texttt{SpatRaster} object to a \texttt{data.frame}, and then change it to a \texttt{SpatialPixelsDataFrame} using function \texttt{gridded}. Then use function \texttt{spsample} with argument \texttt{type\ =\ "regular"}.
  \item
    Select a spatial infill sample using functions \texttt{stratify} and \texttt{sample} of package \textbf{spcosa}.
  \end{itemize}
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5565405 297.3   12043445 643.2  12043445  643.2
Vcells 27348798 208.7   77889393 594.3 189381883 1444.9
\end{verbatim}

\hypertarget{kmeans}{%
\chapter{Covariate space coverage sampling}\label{kmeans}}

Regular grid sampling and spatial coverage sampling are pure spatial sampling designs. Covariates possibly related to the study variable are not accounted for in selecting sampling units. This can be suboptimal when the study variable is related to covariates of which maps are available, think for instance of remote sensing imagery or digital elevation models related to soil properties. Maps of these covariates can be used in mapping the study variable by, for instance, a multiple linear regression model or a random forest. This chapter describes a simple, straightforward method for selecting sampling units on the basis of the covariate values of the raster cells.

The simplest option for covariate space coverage (CSC) sampling\index{Covariate space coverage sampling} is to cluster the raster cells by the k-means clustering algorithm in covariate space. Similar to spatial coverage sampling (Section \ref{SpatialCoverage}) the mean squared shortest distance (MSSD) is minimised, but now the distance is not measured in geographical space but in a \(p\)-dimensional space spanned by the \(p\) covariates. Think of this space as a multidimensional scatter plot with the covariates along the axes. The covariates are centred and scaled so that their means become zero and standard deviations become one. This is needed because, contrary to the spatial coordinates used as clustering variables in spatial coverage sampling, the ranges of the covariates in the population can differ greatly. In the clustering of the raster cells the mean squared shortest \emph{scaled} distance (MSSSD) is minimised. The name `scaled distance' can be confusing. Not the distances are scaled, but rather the distances are computed in a space spanned by the scaled covariates.

In the next code chunk a CSC sample of twenty units is selected from Eastern Amazonia. All five quantitative covariates, SWIR2, Terra\_PP, Prec\_dm, Elevation, and Clay, are used as covariates. To select twenty units, twenty clusters are constructed using function \texttt{kmeans} of the \textbf{stats} package \citep{R2020}. The number of clusters is passed to function \texttt{kmeans} with argument \texttt{centers}. Note that the number of clusters is not based, as would be usual in cluster analysis, on the assumed number of subregions with a high density of units in the multivariate distribution, but rather on the number of sampling units. The k-means clustering algorithm is a deterministic algorithm, i.e.~the final optimised clustering is fully determined by the initial clustering. This final clustering can be suboptimal, i.e.~the minimised MSSSD value is somewhat larger than the global minimum. Therefore the clustering should be repeated many times, every time starting with a different random initial clustering. The number of repeats is specified with argument \texttt{nstart}. The best solution is automatically kept. To speed up the computations a 5 km \(\times\) 5 km subgrid of \texttt{grdAmazonia} is used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covs }\OtherTok{\textless{}{-}}  \FunctionTok{c}\NormalTok{(}\StringTok{"SWIR2"}\NormalTok{, }\StringTok{"Terra\_PP"}\NormalTok{, }\StringTok{"Prec\_dm"}\NormalTok{, }\StringTok{"Elevation"}\NormalTok{, }\StringTok{"Clay"}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{20}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{myclusters }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(}
  \FunctionTok{scale}\NormalTok{(grdAmazonia[, covs]), }\AttributeTok{centers =}\NormalTok{ n, }\AttributeTok{iter.max =} \DecValTok{10000}\NormalTok{, }\AttributeTok{nstart =} \DecValTok{100}\NormalTok{)}
\NormalTok{grdAmazonia}\SpecialCharTok{$}\NormalTok{cluster }\OtherTok{\textless{}{-}}\NormalTok{ myclusters}\SpecialCharTok{$}\NormalTok{cluster}
\end{Highlighting}
\end{Shaded}

Raster cells with the shortest scaled Euclidean distance in covariate-space to the centres of the clusters are selected as the sampling units. To this end first a matrix with the distances of all the raster cells to the cluster centres is computed with function \texttt{rdist} of package \textbf{fields} \citep{fields}. The raster cells closest to the centres are computed with function \texttt{apply}, using argument \texttt{FUN\ =\ which.min}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(fields)}
\NormalTok{covs\_s }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(grdAmazonia[, covs])}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ myclusters}\SpecialCharTok{$}\NormalTok{centers, }\AttributeTok{x2 =}\NormalTok{ covs\_s)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(D, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ which.min)}
\NormalTok{myCSCsample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[units, ]}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:CSCsample} shows the clustering of the raster cells and the raster cells closest in covariate space to the centres, used as the selected sample. In Figure \ref{fig:CSCsampleinscatter} the selected sample is plotted in biplots of some pairs of covariates. In the biplots some sampling units are clearly clustered. However, this is misleading, as actually we must look in five-dimensional space to see whether the units are clustered. Two units with a large separation distance in a five-dimensional space can look quite close when projected on a two-dimensional plane.

The next code chunk shows how the MSSSD of the selected sample can be computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =} \FunctionTok{scale}\NormalTok{(}
\NormalTok{  myCSCsample[, covs], }\AttributeTok{center =} \FunctionTok{attr}\NormalTok{(covs\_s, }\StringTok{"scaled:center"}\NormalTok{),}
  \AttributeTok{scale =} \FunctionTok{attr}\NormalTok{(covs\_s, }\StringTok{"scaled:scale"}\NormalTok{)), }\AttributeTok{x2 =}\NormalTok{ covs\_s)}
\NormalTok{dmin }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(D, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, min)}
\NormalTok{MSSSD }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(dmin}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that to centre and scale the covariate values in the CSC sample, the population means and the population standard deviations are used, as passed to function \texttt{scale} with arguments \texttt{center} and \texttt{scale}. If these means and standard deviations are unspecified the \emph{sample} means and the \emph{sample} standard deviations are used, resulting in an incorrect value of the minimised MSSSD value. The MSSSD of the selected sample equals 1.004.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CSCsample-1} 

}

\caption{Covariate space coverage sample of twenty units from Eastern Amazonia, obtained with k-means clustering using five covariates, plotted on a map of the clusters.}\label{fig:CSCsample}
\end{figure}



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CSCsampleinscatter-1} 

}

\caption{Covariate space coverage sample of Figure \ref{fig:CSCsample} plotted in biplots of covariates, coloured by cluster.}\label{fig:CSCsampleinscatter}
\end{figure}

Instead of function \texttt{kmeans} we may use function \texttt{kmeanspp} of package \textbf{LICORS} \citep{Goerg2013}. This function is an implementation of the k-means++ algorithm \citep{Arthur2007}. This algorithm consists of two parts, namely the selection of an optimised initial sample, followed by the standard k-means. The algorithm is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select one unit (raster cell) at random.\\
\item
  For each unsampled unit \(j\), compute \(d_{kj}\), i.e.~the distance in standardised covariate-space between \(j\) and the nearest unit \(k\) that has already been selected.\\
\item
  Choose one new raster cell at random as a new sampling unit with probabilities proportional to \(d^2_{kj}\) and add the selected raster cell to the set of selected cells.\\
\item
  Repeat steps 2 and 3 until \(n\) centres have been selected.\\
\item
  Now that the initial centres have been selected, proceed using standard k-means.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(LICORS)}
\NormalTok{myclusters }\OtherTok{\textless{}{-}} \FunctionTok{kmeanspp}\NormalTok{(}
  \FunctionTok{scale}\NormalTok{(grdAmazonia[, covs]), }\AttributeTok{k =}\NormalTok{ n, }\AttributeTok{iter.max =} \DecValTok{10000}\NormalTok{, }\AttributeTok{nstart =} \DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Due to the improved initial centres, the risk of ending in a local minimum is reduced. The k-means++ algorithm\index{\emph{k}-means++ algorithm} is of most interest for small sample sizes. For large sample sizes the extra time needed for computing the initial centres can become substantial and may not outweigh the larger number of starts that can be afforded with the usual k-means algorithm for the same computing time.

\hypertarget{covariate-space-infill-sampling}{%
\section{Covariate space infill sampling}\label{covariate-space-infill-sampling}}

If we have legacy data that can be used to fit a model for mapping, it is more efficient to select an infill sample\index{Covariate space infill sampling}, similar to spatial infill sampling explained in Section \ref{SpatialInfill}. The only difference with spatial infill sampling is that the legacy data are now plotted in the space spanned by the covariates. The empty regions we would like to fill in are now the undersampled regions in this covariate space. The legacy sample units serve as fixed cluster centres, they cannot move through the covariate space during the optimisation of the infill sample. In the next code chunk a function is define for covariate space infill sampling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CSIS }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(fixed, nsup, nstarts, mygrd) \{}
\NormalTok{  n\_fix }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(fixed)}
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(mygrd)}
\NormalTok{  units }\OtherTok{\textless{}{-}}\NormalTok{ fixed}\SpecialCharTok{$}\NormalTok{units}
\NormalTok{  mygrd\_minfx }\OtherTok{\textless{}{-}}\NormalTok{ mygrd[}\SpecialCharTok{{-}}\NormalTok{units, ]}
\NormalTok{  MSSSD\_cur }\OtherTok{\textless{}{-}} \ConstantTok{NA}
  \ControlFlowTok{for}\NormalTok{ (s }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nstarts) \{}
\NormalTok{    units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(mygrd\_minfx), nsup)}
\NormalTok{    centers\_sup }\OtherTok{\textless{}{-}}\NormalTok{ mygrd\_minfx[units, ]}
\NormalTok{    centers }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(fixed[, }\FunctionTok{names}\NormalTok{(mygrd)], centers\_sup)}
    \ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{      D }\OtherTok{\textless{}{-}} \FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ centers, }\AttributeTok{x2 =}\NormalTok{ mygrd)}
\NormalTok{      clusters }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(}\AttributeTok{X =}\NormalTok{ D, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ which.min) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.factor}\NormalTok{(.)}
\NormalTok{      centers\_cur }\OtherTok{\textless{}{-}}\NormalTok{ centers}
      \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{p) \{}
\NormalTok{        centers[, i] }\OtherTok{\textless{}{-}} \FunctionTok{tapply}\NormalTok{(mygrd[, i], }\AttributeTok{INDEX =}\NormalTok{ clusters, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{      \}}
      \CommentTok{\#restore fixed centers}
\NormalTok{      centers[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n\_fix, ] }\OtherTok{\textless{}{-}}\NormalTok{ centers\_cur[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n\_fix, ]}
      \CommentTok{\#check convergence}
\NormalTok{      sumd }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ centers, }\AttributeTok{x2 =}\NormalTok{ centers\_cur)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sum}\NormalTok{(.)}
      \ControlFlowTok{if}\NormalTok{ (sumd }\SpecialCharTok{\textless{}} \FloatTok{1E{-}12}\NormalTok{) \{}
\NormalTok{        D }\OtherTok{\textless{}{-}} \FunctionTok{rdist}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ centers, }\AttributeTok{x2 =}\NormalTok{ mygrd)}
\NormalTok{        Dmin }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(}\AttributeTok{X =}\NormalTok{ D, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ min)}
\NormalTok{        MSSSD }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Dmin}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ (s }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{|}\NormalTok{ MSSSD }\SpecialCharTok{\textless{}}\NormalTok{ MSSSD\_cur) \{}
\NormalTok{          centers\_best }\OtherTok{\textless{}{-}}\NormalTok{ centers}
\NormalTok{          clusters\_best }\OtherTok{\textless{}{-}}\NormalTok{ clusters}
\NormalTok{          MSSSD\_cur }\OtherTok{\textless{}{-}}\NormalTok{ MSSSD}
\NormalTok{        \}}
        \ControlFlowTok{break}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{list}\NormalTok{(}\AttributeTok{centers =}\NormalTok{ centers\_best, }\AttributeTok{clusters =}\NormalTok{ clusters\_best)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The function is used to select an infill sample of fifteen units from Eastern Amazonia. A legacy sample of five units is randomly selected.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\DecValTok{5}\NormalTok{)}
\NormalTok{fixed }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(units, }\FunctionTok{scale}\NormalTok{(grdAmazonia[, covs])[units, ])}
\NormalTok{mygrd }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{scale}\NormalTok{(grdAmazonia[, covs]))}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{CSIS}\NormalTok{(}\AttributeTok{fixed =}\NormalTok{ fixed, }\AttributeTok{nsup =} \DecValTok{15}\NormalTok{, }\AttributeTok{nstarts =} \DecValTok{10}\NormalTok{, }\AttributeTok{mygrd =}\NormalTok{ mygrd)}
\end{Highlighting}
\end{Shaded}

Figures \ref{fig:CSCIS} and \ref{fig:CSInfillsampleinscatter} show the selected sample plotted on a map of the clusters and in biplots of covariates, respectively.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CSCIS-1} 

}

\caption{Covariate space infill sample of fifteen units from Eastern Amazonia, obtained with k-means clustering and five fixed cluster centres, plotted on a map of the clusters. The dots represent the fixed centres (legacy sample), the triangles the infill sample.}\label{fig:CSCIS}
\end{figure}



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CSInfillsampleinscatter-1} 

}

\caption{Covariate space infill sample of Figure \ref{fig:CSCIS} plotted in biplots of covariates, coloured by cluster. The dots represent the fixed centres (legacy sample), the triangles the infill sample.}\label{fig:CSInfillsampleinscatter}
\end{figure}

\hypertarget{PerformanceCSC}{%
\section{Performance of covariate space coverage sampling in random forest prediction}\label{PerformanceCSC}}

CSC sampling can be a good candidate for a sampling design if we have multiple maps of covariates, and in addition if we do not want to rely on a linear relation between the study variable and the covariates. In this situation we may consider mapping with machine learning algorithms\index{Machine learning technique} such as neural networks and random forests\index{Random forest} (RF).

I used the Eastern Amazonia data set to evaluate CSC sampling for mapping the aboveground biomass (AGB). The five covariates are used as predictors in RF modelling. The calibrated models are used to predict AGB at the units of a validation sample of size 25,000 selected by simple random sampling without replacement from the 1 km \(\times\) 1 km grid, excluding the cells of the 10 km \(\times\) 10 km grid from which the calibration samples are selected. The predicted AGB values at the validation units are compared with the true AGB values, and the prediction errors are computed. The sample mean of the (squared) prediction error is a design-unbiased estimator of the population mean (squared) error, i.e.~the mean of the (squared) errors at all population units (excluding the units of the 10 km \(\times\) 10 km grid), see Chapter \ref{Validation}.

Three sample sizes are used, \(n=\) 25, 50, 100. Of each sample size 500 CSC samples are selected using the k-means algorithm, leading to 1,500 CSC samples in total. The numbers of starts are 500, 350, and 200 for \(n=\) 25, 50, and 100, respectively. With these numbers of starts the computing time was about equal to conditioned Latin hypercube sampling, see next chapter. Each sample is used to calibrate a RF model. Simple random sampling (SI) is used as a reference sampling design that ignores the covariates. The results are described in detail in the next chapter. In short: for \(n=25\) and \(50\) CSC sampling performs on average somewhat better than SI, for \(n=100\) they perform about equal. Most striking is the smaller spread in the map quality indices with CSC as compared to SI.

In Figure \ref{fig:RelationMSSSDRMSE} the root mean squared error (RMSE) of the RF predictions of AGB is plotted against the minimised MSSSD, both for the \(3 \times 500\) CSC samples and for the 3 \(\times\) 500 simple random samples. It is no surprise that for all three sample sizes the minimised MSSSD values of the CSC samples is substantially smaller than those of the SI samples. However, despite the substantial smaller MSSSD values, the RMSE values for the CSC samples are only a bit smaller than those of the SI samples. Only for \(n=50\) a moderately strong positive correlation can be seen: \(r=0.513\). For \(n=25\) the correlation is 0.264 only, and for \(n=100\) it is even negative: \(r=-0.183\). On average in this case study CSC and SI perform about equal (Table \ref{tab:TableRMSE4CSCandSI}). However, especially with \(n=25\) and 50 the sampling distribution of RMSE with SI has a long right tail. This implies that with SI there is a serious risk that a sample will be selected resulting in poor RF predictions of AGB.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/RelationMSSSDRMSE-1} 

}

\caption{Scatter plot of the minimisation criterion MSSSD and the root mean squared error (RMSE) of RF predictions of AGB in Eastern Amazonia for covariate space coverage (CSC) sampling and simple random (SI) sampling, and three sample sizes.}\label{fig:RelationMSSSDRMSE}
\end{figure}

\begin{table}

\caption{\label{tab:TableRMSE4CSCandSI}Mean RMSE of RF predictions of AGB in Eastern Amazonia of 500 covariate space coverage (CSC) samples and 500 simple random (SI) samples, and three sample sizes.}
\centering
\begin{tabular}[t]{rrr}
\toprule
Sample size & CSC & SI\\
\midrule
25 & 49.30 & 50.58\\
50 & 40.85 & 43.16\\
100 & 39.33 & 38.83\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{exercises-25}{%
\subsubsection*{Exercises}\label{exercises-25}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select a covariate space coverage sample of size 20 from Hunter Valley (\texttt{grdHunterValley} of package \textbf{sswr}). Use the covariates cti (compound topographic index, which is the same as topographic wetness index), ndvi (normalised difference vegetation index), and elevation\_m in k-means clustering of the raster cells. Plot the clusters and the sample on a map of cti and in a biplot of cti against ndvi.
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5548428 296.4   12043445 643.2  12043445  643.2
Vcells 27216821 207.7   77889393 594.3 189381883 1444.9
\end{verbatim}

\hypertarget{cLHS}{%
\chapter{Conditioned Latin hypercube sampling}\label{cLHS}}

This chapter and the next one on response surface sampling are about experimental designs that have been adapted for spatial surveys. Adaptation is necessary because, in contrast to experiments, in observational studies one is not free to choose any possible combination of levels of different factors. When two covariates are strongly positively correlated it may happen that there are no population units with a relatively large value for one covariate and a relatively small value for the other covariate. By contrast, in experimental research it is possible to select any combination of factor levels.

In a full factorial design\index{Full factorial design} all combinations of factor levels\index{Factor level} are observed. With \(k\) factors and \(l\) levels per factor the total number of observations is \(l^k\). With numerous factors and/or numerous levels per factor observing \(l^k\) experimental units becomes unfeasible in practice. Alternative experimental designs have been developed that need fewer observations but still provide detailed information about how the study variable responds to changes in the factor levels. In this chapter I will describe and illustrate the survey sampling analogue of Latin hypercube sampling\index{Latin hypercube sample}. Response surface sampling follows in the next chapter.

Latin hypercube sampling is used in designing industrial processes, agricultural experiments, and computer experiments, with numerous covariates and/or factors of which we want to study the effect on the output \citep{McKay1979}. A much cheaper alternative to a full factorial design is an experiment with, for all covariates, exactly one observation per level. So, in the agricultural experiment described in Chapter \ref{IntroSamplingforMapping} with the application rates of N and P as factors and four levels for each factor, this would entail four observations only, distributed in a square in such way that we have in all rows and in all columns one observation, see Figure \ref{fig:LatinSquare}. This is referred to as a Latin square. The generalisation of a Latin square to a higher number of dimensions is a Latin hypercube (LH).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{SpatialSampling_files/figure-latex/LatinSquare-1} 

}

\caption{Latin square for agricultural experiment with four application rates of N and P.}\label{fig:LatinSquare}
\end{figure}

\citet{Minasny2006} adapted Latin hypercube sampling for observational studies; this adaptation is referred to as conditioned Latin hypercube (cLH) sampling\index{Conditioned Latin hypercube sampling}. For each covariate a series of intervals (marginal strata) is defined. The number of marginal strata per covariate is equal to the sample size, so that the total number of marginal strata equals \(p^n\), with \(p\) the number of covariates and \(n\) the sample size. The bounds of the marginal strata are chosen such that the numbers of raster cells in these marginal strata are equal. This is achieved by using the quantiles corresponding to evenly spaced cumulative probabilities as stratum bounds. For instance, for five marginal strata we use the quantiles corresponding to the cumulative probabilities 0.2, 0.4, 0.6, and 0.8.

The minimisation criterion proposed by \citet{Minasny2006} is a weighted sum of three components:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  O1: the sum over all marginal strata of the absolute deviations of the marginal stratum sample size from the targeted sample size (equal to 1);
\item
  O2: the sum over all classes of categorical covariates of the absolute deviations of the sample proportion of a given class from the population proportion of that class; and
\item
  O3: the sum over all entries of the correlation matrix of the absolute deviation of the correlation in the sample from the correlation in the population.
\end{enumerate}

With cLH sampling the marginal distributions of the covariates in the sample are close to these distributions in the population. This can be advantageous for mapping methods that do not rely on linear relations, for instance in machine learning techniques like classification and regression trees (CART), and random forests (RF). In addition, criterion O3 ensures that the correlations between predictors are respected in the sample set.

cLH samples can be selected with function \texttt{clhs} of package \textbf{clhs} \citep{Roudier2011}. With this package the criterion is minimised by simulated annealing, see Section \ref{SSA} for an explanation of this optimisation method. Arguments \texttt{iter}, \texttt{temp}, \texttt{tdecrease}, and \texttt{length.cycle} of function \texttt{clhs} are control parameters of the simulated annealing algorithm. In the next code chunk I use default values for these arguments. With argument \texttt{weights} the weights of the components of the minimisation criterion can be set. The default weights are equal to 1.

Argument \texttt{cost} is for cost-constrained cLH sampling \citep{Roudier2012}, and argument \texttt{eta} can be used to control the sampling intensities of the marginal strata \citep{Minasny2010}. This argument is of interest if we would like to oversample the marginal strata near the edge of the multivariate distribution.

cLH sampling is illustrated with the five covariates of Eastern Amazonia that were used before in covariate space coverage sampling (Chapter \ref{kmeans}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(clhs)}
\NormalTok{covs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"SWIR2"}\NormalTok{, }\StringTok{"Terra\_PP"}\NormalTok{, }\StringTok{"Prec\_dm"}\NormalTok{, }\StringTok{"Elevation"}\NormalTok{, }\StringTok{"Clay"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{clhs}\NormalTok{(}
\NormalTok{  grdAmazonia[, covs], }\AttributeTok{size =} \DecValTok{20}\NormalTok{, }\AttributeTok{iter =} \DecValTok{50000}\NormalTok{, }\AttributeTok{temp =} \DecValTok{1}\NormalTok{, }\AttributeTok{tdecrease =} \FloatTok{0.95}\NormalTok{,}
  \AttributeTok{length.cycle =} \DecValTok{10}\NormalTok{, }\AttributeTok{progress =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{simple =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample\_CLH }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[res}\SpecialCharTok{$}\NormalTok{index\_samples, ]}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:cLHS} shows the selected sample in a map of SWIR2. In Figure \ref{fig:cLHSscat} the sample is plotted in a biplot of Prec\_dm against SWIR2. Each black dot in the biplot represents one grid cell in the population. The vertical and horizontal lines in the biplot are at the bounds of the marginal strata of SWIR2 and Prec\_dm, respectively. The number of grid cells between two consecutive vertical lines is constant, as well as the number of grid cells between two consecutive horizontal lines, i.e.~the marginal strata have equal sizes. The intervals are the narrowest where the density of grid cells in the plot is highest. Ideally, in each column and row there is exactly one sampling unit (red dot).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/cLHS-1} 

}

\caption{Conditioned Latin hypercube sample from Eastern Amazonia in a map of SWIR2.}\label{fig:cLHS}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/cLHSscat-1} 

}

\caption{Conditioned Latin hypercube sample plotted in a biplot of precipitation in the dryest month against SWIR2. The vertical and horizontal lines are at the bounds of the marginal strata of the covariates SWIR2 and precipitation dryest month, respectively.}\label{fig:cLHSscat}
\end{figure}

Figure \ref{fig:StratumSampleSizes} shows the sample sizes for all 100 marginal strata. The next code chunk shows how the marginal stratum sample sizes are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probs }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \FunctionTok{nrow}\NormalTok{(mysample\_CLH) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{bounds }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(grdAmazonia[, covs], }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{quantile}\NormalTok{(x, }\AttributeTok{probs =}\NormalTok{ probs))}
\NormalTok{mysample\_CLH }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(mysample\_CLH)}
\NormalTok{counts }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(i)}
  \FunctionTok{hist}\NormalTok{(mysample\_CLH[, i }\SpecialCharTok{+} \DecValTok{3}\NormalTok{], bounds[, i], }\AttributeTok{plot =} \ConstantTok{FALSE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{counts)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/StratumSampleSizes-1} 

}

\caption{Sample sizes of marginal strata for the conditioned Latin hypercube sample of size twenty from Eastern Amazonia.}\label{fig:StratumSampleSizes}
\end{figure}

For all marginal strata\index{Marginal stratum} with one sampling unit the contribution to component O1 of the minimisation criterion is 0. For marginal strata with zero or two sampling units, the contribution is 1, for marginal strata with three sampling units the contribution equals 2, et cetera. In Figure \ref{fig:StratumSampleSizes} there are four marginal strata with zero units and four marginal strata with two units. Component O1 therefore equals 8 in this case.

Figure \ref{fig:tracecLHS} shows the trace of the objective function, i.e.~the values of the minimisation criterion during the optimisation. The trace plot indicates that 50,000 iterations are sufficient, I do not expect that the criterion can be reduced anymore. The final value of the minimisation criterion is extracted with function \texttt{tail} using argument \texttt{n\ =\ 1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trace }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{obj}
\FunctionTok{tail}\NormalTok{(trace, }\AttributeTok{n =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9.51994
\end{verbatim}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/tracecLHS-1} 

}

\caption{Trace of minimisation criterion during optimisation of conditioned Latin hypercube sampling from Eastern Amazonia.}\label{fig:tracecLHS}
\end{figure}

In the next code chunk the minimised value of the criterion is computed ``by hand''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{O1 }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(countslf}\SpecialCharTok{$}\NormalTok{counts }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{rho }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(grdAmazonia[, }\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{)])}
\NormalTok{r }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(mysample\_CLH[, }\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{)])}
\NormalTok{O3 }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(rho }\SpecialCharTok{{-}}\NormalTok{ r))}
\FunctionTok{print}\NormalTok{(O1 }\SpecialCharTok{+}\NormalTok{ O3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9.51994
\end{verbatim}

\hypertarget{exercises-26}{%
\subsubsection*{Exercises}\label{exercises-26}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the data of Hunter Valley (\texttt{grdHunterValley} of package \textbf{sswr}) to select a cLH sample of size 50, using elevation\_m, slope\_deg, cos\_aspect, cti, and ndvi as covariates. Plot the selected sample in a map of covariate cti, and plot the selected sample in a biplot of cti against elevation\_m. In which part of the biplot are most units selected, and which part is undersampled?\\
\item
  Load the simulated data of Figure \ref{fig:twosamples} (\texttt{results/SimulatedSquare.rda}), and select a cLH sample of size 16, using the covariate \(x\) and the spatial coordinates as stratification variables. Plot the selected sample in the square with simulated covariate values.

  \begin{itemize}
  \tightlist
  \item
    What do you think of the geographical spreading of the sampling units? Is it optimal?
  \item
    Compute the number of sampling units in the marginal strata of \(s1\), \(s2\), and the covariate \(x\). First compute the bounds of these marginal strata. Are all marginal strata of \(s1\) and \(s2\) sampled? Suppose that all marginal strata of \(s1\) and \(s2\) are sampled (contain one sampling point), does this guarantee good spatial coverage?
  \item
    Plot the trace of the minimisation criterion, and retrieve the minimised value. Is this minimised value in agreement with the marginal stratum sample sizes?
  \end{itemize}
\end{enumerate}

\hypertarget{cLHIS}{%
\section{Conditioned Latin hypercube infill sampling}\label{cLHIS}}

Package \textbf{clhs} can also be used for selecting a conditioned Latin hypercube sample in addition to existing sampling units (legacy sample), as in spatial infill sampling (Section \ref{SpatialCoverage}). The units of the legacy sample are assigned to argument \texttt{must.include}. Argument \texttt{size} must be set to the total sample size, i.e.~the number of mandatory units (legacy sample units) plus the number of additional infill units.

To illustrate conditioned Latin hypercube \emph{infill} sampling (cLHIS), in the next code chunk I select a simple random sample of ten units from Eastern Amazonia to serve as the legacy sample. Twenty new units are selected by cLHIS. The ten mandatory units (i.e.~units which are already sampled and thus must be in the sample set computed by cLHIS) are at the end of the vector with the index of the selected raster cells.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdAmazonia), }\DecValTok{10}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{clhs}\NormalTok{(grdAmazonia[, covs], }\AttributeTok{size =} \DecValTok{30}\NormalTok{, }\AttributeTok{must.include =}\NormalTok{ units,}
  \AttributeTok{tdecrease =} \FloatTok{0.95}\NormalTok{, }\AttributeTok{iter =} \DecValTok{50000}\NormalTok{, }\AttributeTok{progress =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{simple =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mysample\_CLHI }\OtherTok{\textless{}{-}}\NormalTok{ grdAmazonia[res}\SpecialCharTok{$}\NormalTok{index\_samples, ]}
\NormalTok{mysample\_CLHI}\SpecialCharTok{$}\NormalTok{free }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{10}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:cLHIS} shows the selected Latin hypercube infill sample in a map of SWIR2. In Figure \ref{fig:cLHISscat} the sample is plotted in a biplot of SWIR2 against Prec\_dm. The marginal strata already covered by the legacy sample are mostly avoided by the additional sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/cLHIS-1} 

}

\caption{Conditioned Latin hypercube infill sample from Eastern Amazonia in a map of SWIR2. Legacy units have free-value 0, infill units have free-value 1.}\label{fig:cLHIS}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/cLHISscat-1} 

}

\caption{Conditioned Latin hypercube infill sample plotted in a biplot of SWIR2 against precipitation in the dryest month. Legacy units have free-value 0, infill units have free-value 1.}\label{fig:cLHISscat}
\end{figure}

\hypertarget{performance-of-conditioned-latin-hypercube-sampling-in-random-forest-prediction}{%
\section{Performance of conditioned Latin hypercube sampling in random forest prediction}\label{performance-of-conditioned-latin-hypercube-sampling-in-random-forest-prediction}}

The performance of cLH sampling is studied in the same experiment as covariate space coverage sampling of the previous chapter. In total 500 cLH samples of size 25 are selected and an equal number of samples of size 50 and 100. Each sample is used to calibrate a RF model for the aboveground biomass (AGB) using five covariates as predictors. The calibrated models are used to predict AGB at the 25,000 validation units selected by simple random sampling without replacement. Simple random (SI) sampling is added as a reference sampling design that ignores the covariates. The prediction errors are used to estimate three map quality indices\index{Map quality index}, the population mean error\index{Population mean error} (ME), the population root mean squared error\index{Population root mean squared error} (RMSE), and the population Nash-Sutcliffe model efficiency coefficient\index{Model efficiency coefficient} (MEC), see Chapter \ref{Validation}.

Figure \ref{fig:boxplotsval} shows the results as boxplots, each based on 500 estimates. For \(n=25\) and \(100\) cLH sampling performs best in terms of RMSE and MEC, whereas for \(n=50\) CSC sampling performs best. For \(n=25\) and \(50\) the boxplots of cLH and SI show quite a few outliers with large values of RMSE, resulting in small values of MEC. For CSC these map quality indices are more stable. Remarkably, for \(n=100\) SI sampling performs about equal to CSC and cLH sampling.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/boxplotsval-1} 

}

\caption{Boxplots of ME, RMSE, and MEC of predictions with RF models calibrated on conditioned Latin hypercube (cLH), covariate space coverage (CSC), and simple random (SI) samples from Eastern Amazonia, for sample sizes of 25, 50, and 100 units.}\label{fig:boxplotsval}
\end{figure}

In Figure \ref{fig:RelationO1O3RMSE} the RMSE is plotted against the minimised criterion (O1 + O3) for the cLH and the SI samples. For all three sample sizes there is a weak positive correlation of the minimisation criterion and the RMSE: for \(n=25\), 50, and 100 this correlation is 0.369, 0.290, and 0.140, respectively. On average cLH performs slightly better than SI for \(n=25\) (Table \ref{tab:TableRMSE4cLHandSI}). The gain in accuracy decreases with the sample size. For \(n=100\) the two designs perform about equal. Especially for \(n=25\) and 50 the distribution of RMSE with SI has a long right tail. For these small sample sizes the risk of selecting an SI sample leading to a poor map with large RMSE is much larger than with cLH sampling.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/RelationO1O3RMSE-1} 

}

\caption{Biplot of the minimisation criterion (O1 + O3) and the RMSE of RF predictions of AGB in Eastern Amazonia for conditioned Latin hypercube (cLH) sampling and simple random (SI) sampling, and three sample sizes.}\label{fig:RelationO1O3RMSE}
\end{figure}

\begin{table}

\caption{\label{tab:TableRMSE4cLHandSI}Mean RMSE of RF predictions of AGB in Eastern Amazonia of 500 conditioned Latin hypercube (cLH) samples and 500 simple random (SI) samples, and three sample sizes.}
\centering
\begin{tabular}[t]{rrr}
\toprule
Sample size & cLH & SI\\
\midrule
25 & 47.64 & 50.58\\
50 & 41.81 & 43.16\\
100 & 38.45 & 38.83\\
\bottomrule
\end{tabular}
\end{table}

These results are somewhat different from the results of \citet{Wadoux2019} and \citet{Ma2020}. In these case studies cLH sampling appeared to be an inefficient design for selecting a calibration sample that is subsequently used for mapping. \citet{Wadoux2019} compared cLH, CSC, spatial coverage sampling (SC) (Section \ref{SpatialCoverage}), and SI for mapping soil organic carbon in France with a RF model. The latter two sampling designs do not exploit the covariates in selecting the calibration units. Sample sizes were 100, 200, 500, and 1,000. cLH performed worse (larger RMSE) than CSC and not significantly better than SI for all sample sizes.

\citet{Ma2020} compared cLH, CSC, and SI for mapping soil classes by various models, among which a RF model, in a study area in Germany. Sample sizes were 20, 30, 40, 50, 75, and 100 points. They found no relation between the minimisation criterion of cLH and the overall accuracy of the map with predicted soil classes. Models calibrated on CSC samples performed better on average, i.e.~on average the overall accuracy of the maps obtained by calibrating the models on these CSC samples was higher. cLH was hardly better than SI.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5553390 296.6   12043445 643.2  12043445  643.2
Vcells 27227230 207.8   77889393 594.3 189381883 1444.9
\end{verbatim}

\hypertarget{SpatialResponseSurface}{%
\chapter{Spatial response surface sampling}\label{SpatialResponseSurface}}

As with conditioned Latin hypercube sampling, spatial response surface sampling\index{Spatial response surface sampling} is an experimental design adapted for spatial surveys. Experimental response surface designs aim at finding an optimum of the response within specified ranges of the factors. There are many types of response surface designs, see \citet{myers2002}. With response surface sampling one assumes that some type of low order regression model can be used to accurately approximate the relationship between the study variable and the covariates. A commonly used design is the central composite design\index{Central composite design}. The data obtained with this design are used to fit a multiple linear regression model with quadratic terms, yielding a curved, quadratic surface of the response.

The response surface sampling approach is an adaptation of an experimental design, but at the same time it is an example of a model-based sampling design. Sampling units are selected to implicitly optimise the estimation of the quadratic regression model. However, this optimisation is done under one or more spatial constraints. Unconstrained optimisation of the sampling design under the linear regression model will not prevent the units from spatial clustering, see the optimal sample in Figure \ref{fig:twosamples}. The assumption of independent data might be violated when the sampling units are spatially clustered. For this reason the response surface sampling design selects samples with good spatial coverage, so that the design becomes robust against violation of the independence assumption.

\citet{lesch95} adapted the response surface methodology for observational studies. Several problems needed to be tackled. First, when multiple covariates are used, the covariates must be decorrelated. Second, when sampling units are spatially clustered, the assumption in linear regression modelling of spatially uncorrelated model residuals can be violated. To address these two problems \citet{lesch95} proposed the following procedure; see also \citet{lesch2005}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Transform the covariate matrix into a scaled, centred, decorrelated matrix by principal components analysis (PCA).\\
\item
  Choose the response surface design type.\\
\item
  Select candidate sampling units based on the distance from the design points in the space spanned by the principal components. Select multiple sampling units per design point.\\
\item
  Select the combination of candidate sampling units with the highest value for a criterion that quantifies how uniform the sample is spread across the study area.
\end{enumerate}

This design has been applied, among others, for mapping soil salinity (ECe), using electromagnetic induction (EM) measurements and surface array conductivity measurements as predictors in multiple linear regression models. For applications, see \citet{corwin2005}, \citet{lesch2005}, \citet{fitzgerald2006}, \citet{Corwin2010}, and \citet{Fitzgerald2010}.

Spatial response surface sampling is illustrated with the EM measurements (mS m\textsuperscript{-1}) of the apparent electrical conductivity on the 80 ha Cotton Research Farm in Uzbekistan. The EM measurements in vertical dipole mode, with transmitter at 1 m and 0.5 m from the receiver, are on transects covering the Cotton Research Farm (Figure \ref{fig:EMdataUzbekistan}). As a first step the natural log of the two EM measurements are interpolated by ordinary kriging to a fine grid (Figure \ref{fig:EMdataUzbekistan2}). These ordinary kriging predictions of lnEM are used as covariates in response surface sampling. The two covariates are strongly correlated, \(r=0.73\), as expected since they are interpolations of measurements of the same variable but of different overlapping layers.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/EMdataUzbekistan-1} 

}

\caption{Natural log of EM measurements on the Cotton Research Farm (with transmitter at 1 m and 0.5 m from receiver).}\label{fig:EMdataUzbekistan}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/EMdataUzbekistan2-1} 

}

\caption{Interpolated surfaces of natural log of EM measurements on the Cotton Research Farm, used as covariates in spatial response surface sampling.}\label{fig:EMdataUzbekistan2}
\end{figure}

Function \texttt{prcomp} of the \textbf{stats} package \citep{R2020} is used to compute the principal component scores\index{Principal component score} for all units in the population (grid cells). The two covariates are centred and scaled, i.e.~standardised principal components are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(lnEM100cm, lnEM50cm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{prcomp}\NormalTok{(}\AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The means of the two principal component scores are 0, but their standard deviations are not zero but 1.330 and 0.480. Therefore the principal component scores are divided by these standard deviations. They then will have the same weight in the following steps.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grdCRF }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{PC1 =}\NormalTok{ pc}\SpecialCharTok{$}\NormalTok{x[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{/}\NormalTok{ pc}\SpecialCharTok{$}\NormalTok{sdev[}\DecValTok{1}\NormalTok{],}
    \AttributeTok{PC2 =}\NormalTok{ pc}\SpecialCharTok{$}\NormalTok{x[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{/}\NormalTok{ pc}\SpecialCharTok{$}\NormalTok{sdev[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

Function \texttt{ccd} of package \textbf{rsm} \citep{Lenth2009} is now used to generate a central composite response surface design\index{Central composite response surface design} (CCRSD). Argument \texttt{basis} specifies the number of factors, which is two in our case. Argument \texttt{n0} is the number of centre points, and argument \texttt{alpha} determines the position of the star points (explained hereafter).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rsm)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\FunctionTok{print}\NormalTok{(ccdesign }\OtherTok{\textless{}{-}} \FunctionTok{ccd}\NormalTok{(}\AttributeTok{basis =} \DecValTok{2}\NormalTok{, }\AttributeTok{n0 =} \DecValTok{1}\NormalTok{, }\AttributeTok{alpha =} \StringTok{"rotatable"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   run.order std.order  x1.as.is  x2.as.is Block
1          1         4  1.000000  1.000000     1
2          2         5  0.000000  0.000000     1
3          3         2  1.000000 -1.000000     1
4          4         1 -1.000000 -1.000000     1
5          5         3 -1.000000  1.000000     1
6          1         5  0.000000  0.000000     2
7          2         3  0.000000 -1.414214     2
8          3         1 -1.414214  0.000000     2
9          4         4  0.000000  1.414214     2
10         5         2  1.414214  0.000000     2

Data are stored in coded form using these coding formulas ...
x1 ~ x1.as.is
x2 ~ x2.as.is
\end{verbatim}

The experiment consists of two blocks, each of five experimental units. Block 1, the so-called cube block, consists of one centre point and four cube points\index{Cube point}. In the experimental unit represented by the centre point both factors have levels in the centre of the experimental range. In the experimental units represented by the cube points the levels of both factors is either -1 or +1 unit in the design space. Block 2, referred to as the star block, consists of one centre point and four star points\index{Star point}. With \texttt{alpha\ =\ "rotatable"} the star points are on the circle circumscribing the square (Figure \ref{fig:ccdesign}).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/ccdesign-1} 

}

\caption{Rotatable central composite design for two factors.}\label{fig:ccdesign}
\end{figure}

To adapt this design for an observational study, we drop one of the centre points (0,0).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ccd\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ ccdesign}\SpecialCharTok{$}\NormalTok{x1, }\AttributeTok{x2 =}\NormalTok{ ccdesign}\SpecialCharTok{$}\NormalTok{x2)}
\NormalTok{ccd\_df }\OtherTok{\textless{}{-}}\NormalTok{ ccd\_df[}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

The coordinates of the CCRSD design points are multiplied by a factor so that a large proportion \(p\) of the bivariate standardised principal component scores of the population units is covered by the circle that passes through the design points (Figure \ref{fig:ccdesign}). The factor is computed as a sample quantile of the empirical distribution of the distances of the points in the scatter to the centre. For \(p\) I chose 0.7.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(grdCRF}\SpecialCharTok{$}\NormalTok{PC1}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ grdCRF}\SpecialCharTok{$}\NormalTok{PC2}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{fct }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(d, }\AttributeTok{p =} \FloatTok{0.7}\NormalTok{)}
\FunctionTok{print}\NormalTok{(fct)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     70% 
1.472547 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ccd\_df }\OtherTok{\textless{}{-}}\NormalTok{ ccd\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ x1 }\SpecialCharTok{*}\NormalTok{ fct, }\AttributeTok{x2 =}\NormalTok{ x2 }\SpecialCharTok{*}\NormalTok{ fct)}
\end{Highlighting}
\end{Shaded}

The next step is to select for each design point several candidate sampling points. For each of the nine design points\index{Design point} eight points are selected that are closest to that design point. This results in 9 \(\times\) 8 candidate sampling points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{candi\_all }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(ccd\_df))) \{}
\NormalTok{    d2dpnt }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((grdCRF}\SpecialCharTok{$}\NormalTok{PC1 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x1[i])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}
\NormalTok{      (grdCRF}\SpecialCharTok{$}\NormalTok{PC2 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x2[i])}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{    grdCRF }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF[}\FunctionTok{order}\NormalTok{(d2dpnt), ]}
\NormalTok{    candi }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{"point\_id"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"PC1"}\NormalTok{, }\StringTok{"PC2"}\NormalTok{)]}
\NormalTok{    candi}\SpecialCharTok{$}\NormalTok{dpnt }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{    candi\_all }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(candi\_all, candi)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:candidatelocations} shows the nine clusters of candidate sampling points around the design points. Note that the location of the candidate sampling points associated with the design points with coordinates (0,-2.13), (1.51,-1.51), and (2.13,0) are all far inside the circle that passes through the design points. So, for the optimised sample there will be three points with principal component scores that considerably differ from the ideal values according to the CCRSD design.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/candidatelocations-1} 

}

\caption{Clusters of points (red points) around the design points (triangles) of a CCRSD (two covariates), serving as candidate sampling points.}\label{fig:candidatelocations}
\end{figure}

Figure \ref{fig:candidatesingeospace} shows that in geographical space for most design points there are multiple spatial clusters of candidate units. For instance, for design point nine there are three clusters of candidate sampling units. Due to this, there is scope to optimise the sample computationally.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/candidatesingeospace-1} 

}

\caption{Candidate sampling points plotted on a map of the first standardised principal component (PC1).}\label{fig:candidatesingeospace}
\end{figure}

As a first step an initial subsample from the candidate sampling units is selected by stratified simple random sampling, using the levels of factor \texttt{dpnt} as strata. Function \texttt{strata} of package \textbf{sampling} is used for stratified random sampling \citep{Tille2016}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sampling)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units\_stsi }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(}
\NormalTok{  candi\_all, }\AttributeTok{stratanames =} \StringTok{"dpnt"}\NormalTok{, }\AttributeTok{size =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{))}
\NormalTok{mysample0 }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(candi\_all, units\_stsi) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{(ID\_unit}\SpecialCharTok{:}\NormalTok{Stratum))}
\end{Highlighting}
\end{Shaded}

The locations of the nine sampling units are now optimised by minimising a criterion that is a function of the distance between the nine sampling points. Two minimisation criteria are implemented, a geometric criterion and a model-based criterion.

In the geometric criterion (as proposed by \citet{lesch2005}) for each sampling point the log of the shortest distance to the other points is computed. The minimisation criterion is the negative of the sample mean of these distances.

The model-based minimisation criterion is the average correlation of the sampling points. This criterion requires as input the parameters of a residual correlogram (see Section \ref{IntroKED}). I assume an exponential correlogram without nugget, so that the only parameter to be chosen is the distance parameter \(\phi\) (Equation \eqref{eq:exponential}). Three times \(\phi\) is referred to as the effective range\index{Effective range} of the exponential correlogram. The correlation of the random variables at two points separated by this distance is 0.05.

A penalty term is added to the geometric or the model-based minimisation criterion, equal to the average distance of the sampling points to the associated design points, multiplied by a weight. With weights \(> 0\) sampling points close to the design points are preferred over more distant points.

In the next code chunk a function is defined for computing the minimisation criterion. Given a chosen value for \(\phi\), the 9 \(\times\) 9 distance matrix of the sampling points can be converted into a correlation matrix, using function \texttt{variogramLine} of package \textbf{gstat} \citep{peb04}. Argument \texttt{weight} is an optional argument with default value 0.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{getCriterion }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(mysample, dpnt, }\AttributeTok{weight =} \DecValTok{0}\NormalTok{, }\AttributeTok{phi =} \ConstantTok{NULL}\NormalTok{) \{}
\NormalTok{  D2dpnt }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((mysample}\SpecialCharTok{$}\NormalTok{PC1 }\SpecialCharTok{{-}}\NormalTok{ dpnt}\SpecialCharTok{$}\NormalTok{x1)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (mysample}\SpecialCharTok{$}\NormalTok{PC2 }\SpecialCharTok{{-}}\NormalTok{ dpnt}\SpecialCharTok{$}\NormalTok{x2)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  D }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(mysample[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)]))}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.null}\NormalTok{(phi)) \{}
    \FunctionTok{diag}\NormalTok{(D) }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{    logdmin }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(D, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ min, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ log}
\NormalTok{    criterion\_cur }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{logdmin) }\SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(D2dpnt) }\SpecialCharTok{*}\NormalTok{ weight}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    vgmodel }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{psill =} \DecValTok{1}\NormalTok{, }\AttributeTok{range =}\NormalTok{ phi)}
\NormalTok{    C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    criterion\_cur }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(C) }\SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(D2dpnt) }\SpecialCharTok{*}\NormalTok{ weight}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(criterion\_cur)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Function \texttt{getCriterion} is used to compute the geometric criterion for the initial sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{criterion\_geo }\OtherTok{\textless{}{-}} \FunctionTok{getCriterion}\NormalTok{(}\AttributeTok{mysample =}\NormalTok{ mysample0, }\AttributeTok{dpnt =}\NormalTok{ ccd\_df)}
\end{Highlighting}
\end{Shaded}

The initial value of the geometric criterion is -4.829. In the next code chunk the initial value for the model-based criterion is computed for an effective range of 150 m.

\begin{rmdnote}
It does not make sense to make the effective range smaller than the size of the grid cells, which is 25 m in our case. For smaller ranges the correlation matrix is for any sample a matrix with zeroes. If the effective range is smaller than the smallest distance between two points in a cluster, the mean correlation is equal for all samples.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{phi }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{criterion\_mb }\OtherTok{\textless{}{-}} \FunctionTok{getCriterion}\NormalTok{(}\AttributeTok{mysample =}\NormalTok{ mysample0, }\AttributeTok{dpnt =}\NormalTok{ ccd\_df, }\AttributeTok{phi =}\NormalTok{ phi)}
\end{Highlighting}
\end{Shaded}

The initial value of the model-based criterion is 0.134.

The objective function defining the minimisation criterion is minimised with simulated annealing\index{Simulated annealing} (\citet{Kirkpatrick1983}, \citet{Aarts1987}). One sampling point is randomly selected and replaced by another candidate sampling point from the same cluster. If the criterion of the new sample is smaller than that of the current sample, the new sample is accepted, if it is larger it is accepted with a probability that is a function of the change in the criterion (the larger the increase, the smaller the acceptance probability) and of an annealing parameter named the temperature (the higher the temperature, the larger the probability of accepting a new, poorer sample, given an increase of the criterion). See Section \ref{SSA} for a more detailed introduction to simulated annealing.

The sampling pattern can be optimised with function \texttt{anneal} of package \textbf{sswr}. The arguments of this function will be clear from the description of the sampling procedure above.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mySRSsample }\OtherTok{\textless{}{-}} \FunctionTok{anneal}\NormalTok{(}
  \AttributeTok{mysample =}\NormalTok{ mysample0, }\AttributeTok{candidates =}\NormalTok{ candi\_all, }\AttributeTok{dpnt =}\NormalTok{ ccd\_df, }\AttributeTok{phi =} \DecValTok{50}\NormalTok{,}
  \AttributeTok{T\_ini =} \DecValTok{1}\NormalTok{, }\AttributeTok{coolingRate =} \FloatTok{0.9}\NormalTok{, }\AttributeTok{maxPermuted =} \DecValTok{25} \SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(mysample0),}
  \AttributeTok{maxNoChange =} \DecValTok{20}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:CCRSDinPCspace} shows the optimised CCRSD samples plotted in the space spanned by the two principal components, obtained with the geometric and the model-based criterion, plotted together with the design points. The two optimised samples are very similar.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CCRSDinPCspace-1} 

}

\caption{Principal component scores of the spatial CCRSD sample (triangles), optimised with the geometric and the model-based criterion. Dots: design points of CCRSD.}\label{fig:CCRSDinPCspace}
\end{figure}

Figure \ref{fig:CCRSDSample} shows the two optimised CCRSD samples plotted in geographical space on the first standardised principal component scores.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CCRSDSample-1} 

}

\caption{CCRSD sample from the Cotton Research Farm, optimised with the geometric and the model-based criterion, plotted on a map of the first standardised principal component (PC1).}\label{fig:CCRSDSample}
\end{figure}

\hypertarget{IncreaseSampleSize}{%
\section{Increasing the sample size}\label{IncreaseSampleSize}}

Nine points are rather few for fitting a polynomial regression model, especially for a second-order polynomial with interaction. Therefore, in experiments often multiple observations are done for each design point. Increasing the sample size of a response surface sample in observational studies is not straightforward. The challenge is to avoid spatial clustering of sampling points. A simple solution is to select multiple points from each subset of candidate sampling units. The success of this solution depends on how strong the candidate sampling units are spatially clustered. For the Cotton Research Farm for most design points the candidate sampling units are not in one spatial cluster, so in this case the solution may work properly. I increased the number of candidate sampling units per design point to sixteen, so that there is a larger choice in the optimisation of the sampling pattern.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{candi\_all }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(ccd\_df))) \{}
\NormalTok{    d2dpnt }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((grdCRF}\SpecialCharTok{$}\NormalTok{PC1 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x1[i])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}
\NormalTok{      (grdCRF}\SpecialCharTok{$}\NormalTok{PC2 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x2[i])}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{    grdCRF }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF[}\FunctionTok{order}\NormalTok{(d2dpnt), ]}
\NormalTok{    candi }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{16}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{"point\_id"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"PC1"}\NormalTok{, }\StringTok{"PC2"}\NormalTok{)]}
\NormalTok{    candi}\SpecialCharTok{$}\NormalTok{dpnt }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{    candi\_all }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(candi\_all, candi)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

A stratified simple random subsample of two points per stratum is selected, which serves as an initial sample.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units\_stsi }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(}
\NormalTok{  candi\_all, }\AttributeTok{stratanames =} \StringTok{"dpnt"}\NormalTok{, }\AttributeTok{size =} \FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{9}\NormalTok{))}
\NormalTok{mysample0 }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(candi\_all, units\_stsi) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{(ID\_unit}\SpecialCharTok{:}\NormalTok{Stratum))}
\end{Highlighting}
\end{Shaded}

The data frame with the design points must be doubled. Note that the order of the design points must be equal to the order in the stratified subsample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tmp }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(ccd\_df, }\AttributeTok{dpnt =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{)}
\NormalTok{ccd\_df2 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(tmp, tmp)}
\NormalTok{ccd\_df2 }\OtherTok{\textless{}{-}}\NormalTok{ ccd\_df2[}\FunctionTok{order}\NormalTok{(ccd\_df2}\SpecialCharTok{$}\NormalTok{dpnt), ]}
\end{Highlighting}
\end{Shaded}

Figures \ref{fig:CCRSDUzbekistan2n} and \ref{fig:CCRSDinPCSpace2n} show the optimised CCRSD sample of eighteen points in geographical and principal component space, respectively, obtained with the model-based criterion, an effective range of 150 m, and zero weight for the penalty term. Sampling points are not spatially clustered, so I do not expect violation of the assumption of independent residuals. In principal component space all points are pretty close to the design points, except for the four design points in the lower right corner, where no candidate units near these design points are available.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/CCRSDUzbekistan2n-1} 

}

\caption{CCRSD sample with two points per design point, from the Cotton Research Farm, plotted on a map of the first standardised principal component (PC1).}\label{fig:CCRSDUzbekistan2n}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/CCRSDinPCSpace2n-1} 

}

\caption{CCRSD sample (triangles) with two points per design point (dots), optimised with model-based criterion, plotted in the space spanned by the two standardised principal components.}\label{fig:CCRSDinPCSpace2n}
\end{figure}

\hypertarget{stratified-spatial-response-surface-sampling}{%
\section{Stratified spatial response surface sampling}\label{stratified-spatial-response-surface-sampling}}

The sample size can also be increased by stratified spatial response surface sampling\index{Stratified spatial response surface sampling}. The strata are subareas of the study area. When the subsets of candidate sampling units for some design points are strongly spatially clustered, the final optimised sample obtained with the method of the previous section may also show strong spatial clustering. An alternative is then to split the study area into two or more subareas (strata) and to select from each stratum candidate sampling units. This guarantees that for each design point we have at least as many spatial clusters of candidate units as we have strata.

\begin{rmdnote}
The spatial strata are not used for fitting separate regression models. All data are used to fit one (second-order) polynomial regression model.
\end{rmdnote}

Figure \ref{fig:StrataCRF4CCRSD} shows two subareas used as strata in stratified response surface sampling of the Cotton Research Farm.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/StrataCRF4CCRSD-1} 

}

\caption{Two subareas of the Cotton Research Farm used as strata in stratified CCRSD sampling.}\label{fig:StrataCRF4CCRSD}
\end{figure}

The candidate sampling units are selected in a double for-loop. The outer loop is over the strata, the inner loop over the design points. Note that variable \texttt{dpnt} continues to increase by 1 after the inner-loop over the nine design points in subarea 1 is completed, so that variable \texttt{dpnt} (used as a stratification variable in subsampling the sample of candidate sampling points) now has values \(1,2, \dots , 18\). An equal number of candidate sampling points per design point in both strata (eight points) is selected by sorting the points of a stratum by the distance to a design point using function \texttt{order}. Figure \ref{fig:candidatesSTResponse} shows the candidate sampling points for stratified CCRSD sampling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{candi\_all }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (h }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)) \{}
\NormalTok{  data\_stratum }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(subarea }\SpecialCharTok{==}\NormalTok{ h)}
\NormalTok{  candi\_stratum }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(ccd\_df))) \{}
\NormalTok{      d2dpnt }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((data\_stratum}\SpecialCharTok{$}\NormalTok{PC1 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x1[i])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}
\NormalTok{                     (data\_stratum}\SpecialCharTok{$}\NormalTok{PC2 }\SpecialCharTok{{-}}\NormalTok{ ccd\_df}\SpecialCharTok{$}\NormalTok{x2[i])}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{      data\_stratum }\OtherTok{\textless{}{-}}\NormalTok{ data\_stratum[}\FunctionTok{order}\NormalTok{(d2dpnt), ]}
\NormalTok{      candi }\OtherTok{\textless{}{-}}\NormalTok{ data\_stratum[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{),}
          \FunctionTok{c}\NormalTok{(}\StringTok{"point\_id"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"PC1"}\NormalTok{, }\StringTok{"PC2"}\NormalTok{, }\StringTok{"subarea"}\NormalTok{)]}
\NormalTok{      candi}\SpecialCharTok{$}\NormalTok{dpnt }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ (h }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(ccd\_df)}
\NormalTok{      candi\_stratum }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(candi\_stratum, candi)}
\NormalTok{  \}}
\NormalTok{  candi\_all }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(candi\_all, candi\_stratum)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/candidatesSTResponse-1} 

}

\caption{Candidate sampling points for stratified CCRSD sampling, plotted on a map of the first principal component (PC1).}\label{fig:candidatesSTResponse}
\end{figure}

As before, \texttt{dpnt} is used as a stratum identifier to subsample the candidate sampling units. Finally, the number of rows in \texttt{data.frame} \texttt{ccd\_df} with the design points is doubled.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units\_stsi }\OtherTok{\textless{}{-}}\NormalTok{ sampling}\SpecialCharTok{::}\FunctionTok{strata}\NormalTok{(}
\NormalTok{  candi\_all, }\AttributeTok{stratanames =} \StringTok{"dpnt"}\NormalTok{, }\AttributeTok{size =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{18}\NormalTok{))}
\NormalTok{mysample0 }\OtherTok{\textless{}{-}} \FunctionTok{getdata}\NormalTok{(candi\_all, units\_stsi) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{(ID\_unit}\SpecialCharTok{:}\NormalTok{Stratum))}
\NormalTok{ccd\_df2 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(ccd\_df, ccd\_df)}
\end{Highlighting}
\end{Shaded}

Figures \ref{fig:StratifiedCCRSD} and \ref{fig:StratifiedCCRSDinPCSpace} show the optimised sample of eighteen points in geographical and principal component space, obtained with the model-based criterion with an effective range of 150 m. The pattern in the principal component space is worse compared to the pattern in Figure \ref{fig:CCRSDinPCSpace2n}. In stratum 1 the distance to the star point at the top and the upper left and upper right cube points is very large. In this stratum no population units are present that are close to these design points. By adding a penalty term to the minimisation criterion that is proportional to the distance to the design points, the distance is somewhat decreased but not really for the three design points mentioned above (Figure \ref{fig:CCRSDinPCSpace2n}). Also note the spatial cluster of three sampling units in Figure \ref{fig:StratifiedCCRSD} obtained with a weight equal to 5.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/StratifiedCCRSD-1} 

}

\caption{Stratified CCRSD samples from the Cotton Research Farm, optimised with the model-based criterion, obtained without (weight = 0) and with penalty (weight = 5) for a large average distance to design points.}\label{fig:StratifiedCCRSD}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/StratifiedCCRSDinPCSpace-1} 

}

\caption{Principal component scores of the stratified CCRSD sample, optimised with the model-based criterion, obtained without (weight = 0) and with penalty (weight = 5) for a large average distance to design points (dots).}\label{fig:StratifiedCCRSDinPCSpace}
\end{figure}

\hypertarget{mapping}{%
\section{Mapping}\label{mapping}}

Once that data are collected, the study variable is mapped by fitting a multiple linear regression model using the two covariates, in our case the two EM measurements, as predictors. The fitted model is then used to predict the study variable for all unsampled population units.

The predicted value of the study variable at an unsampled prediction location \(\mathbf{s}_0\) is predicted by
\begin{equation}
\widehat{Z}(\mathbf{s}_0) = \mathbf{x}_0 \hat{\pmb{\beta}}_{\text{OLS}}\;,
\label{eq:ZpredMLR}
\end{equation}
with \(\mathbf{x}_0\) the (\(p+1\))-vector with covariate values at prediction location \(\mathbf{s}_0\) and 1 in the first entry (\(p\) is the number of covariates) and \(\hat{\pmb{\beta}}\) the vector with ordinary least squares estimates\index{Ordinary least squares} of the regression coefficients:
\begin{equation}
\hat{\pmb{\beta}}_{\text{OLS}} = (\mathbf{X}^{\mathrm{T}}\mathbf{X})^{-1} (\mathbf{X}^{\mathrm{T}}\mathbf{z})\;,
\label{eq:betaOLS}
\end{equation}
with \(\mathbf{X}\) the \((n \times (p+1))\) matrix with covariate values and ones in the first column (\(n\) is the sample size and \(p\) is the number of covariates), and \(\mathbf{z}\) the \(n\)-vector with observations of the study variable.

\begin{rmdnote}
Although the principal component scores are used to select the sampling locations there is no need to use these principal component scores as predictors in the linear regression model. When all principal components derived from the covariates are used as predictors, the predicted values and standard errors obtained with the model using the principal components as predictors are equal to those obtained with the model using the covariates as predictors.
\end{rmdnote}

The variance of the prediction error can be estimated by
\begin{equation}
\widehat{V}(\widehat{Z}(\mathbf{s}_0)) = \hat{\sigma}^2_{\epsilon}(1+\mathbf{x}_0^{\mathrm{T}}(\mathbf{X}^{\mathrm{T}}\mathbf{X})^{-1}\mathbf{x}_0)\;,
\label{eq:VarZpredMLR}
\end{equation}
with \(\hat{\sigma}^2_{\epsilon}\) the estimated variance of the residuals.

In \textbf{R} the model can be calibrated with function \texttt{lm}, and the predictions can be obtained with function \texttt{predict}. The standard errors of the estimated means can be obtained with argument \texttt{se.fit\ =\ TRUE}. The variances of Equation \eqref{eq:VarZpredMLR} can be computed by squaring these standard errors and adding the squared value of the estimated residual variance, which can be extracted with \texttt{sigma()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mdl }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(lnECe }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnEM100cm }\SpecialCharTok{+}\NormalTok{ lnEM50cm, }\AttributeTok{data =}\NormalTok{ mysample)}
\NormalTok{zpred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mdl, }\AttributeTok{newdata =}\NormalTok{ grdCRF, }\AttributeTok{se.fit =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{v\_zpred }\OtherTok{\textless{}{-}}\NormalTok{ zpred}\SpecialCharTok{$}\NormalTok{se.fit}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{+}\FunctionTok{sigma}\NormalTok{(mdl)}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

The assumption underlying Equations \eqref{eq:betaOLS} and \eqref{eq:VarZpredMLR} is that the model residuals are independent. We assume that all spatial structure of the study variable is explained by the covariates. Even the residuals at two locations close to each other are assumed to be uncorrelated. A drawback of the spatial response surface design is that it is hard or even impossible to check this assumption as the sampling locations are spread out throughout the study area. If the residuals are not independent the covariance of the residuals can be accounted for by generalised least squares estimation of the regression coefficients (Equation @ref(eq:beta\_GLS)). The study variable can then be mapped by kriging with an external drift (Subsection \ref{IntroKED}). However, this requires an estimate of the semivariogram of the residuals (Subsection \ref{ResidualVariogram}).

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5632297 300.8   12043445 643.2  12043445  643.2
Vcells 27375623 208.9   77889393 594.3 189381883 1444.9
\end{verbatim}

\hypertarget{Introkriging}{%
\chapter{Introduction to kriging}\label{Introkriging}}

In the following chapters a geostatistical model\index{Geostatistical model}, i.e.~a statistical model of the spatial variation of the study variable, is used to optimise the sample size and/or spatial pattern of the sampling locations. This chapter is a short introduction to geostatistical modelling.

In Chapter \ref{MBpredictionofDesignVariance} we have already seen how a geostatistical model can be used to optimise probability sampling designs for estimating the population mean or total. In the following chapters the focus is on mapping. A map of the study variable is obtained by predicting the study variable at the nodes of a fine discretisation grid. Spatial prediction using a geostatistical model is referred to as kriging \citep{webster2007}.

With this prediction method, besides a map of the kriging predictions a map of the variance of the prediction error is obtained. I will show hereafter that the prediction error variance is not influenced by the values of the study variable at the sampling locations. For this reason it is possible to search, before the start of the survey, for the sampling locations that lead to the minimum prediction error variance averaged over all nodes of a fine prediction grid, provided that the geostatistical model is known up to some extent.

\hypertarget{OrdinaryKriging}{%
\section{Ordinary kriging}\label{OrdinaryKriging}}

The kriging predictions and prediction error variances are derived from a statistical model of the spatial variation of the study variable. There are several versions of kriging, but most of them are special cases of the following generic model:

\begin{equation}
\begin{split}
Z(\mathbf{s}) &= \mu(\mathbf{s}) + \epsilon(\mathbf{s}) \\
\epsilon(\mathbf{s}) &\sim \mathcal{N}(0,\sigma^2) \\
\mathrm{Cov}(\epsilon(\mathbf{s}),\epsilon(\mathbf{s}^{\prime})) &= C(\mathbf{h})\;,
\end{split}
\label{eq:GeneralKrigingModel}
\end{equation}

with \(Z(\mathbf{s})\) the study variable at location \(\mathbf{s}\), \(\mu(\mathbf{s})\) the mean at location \(\mathbf{s}\), \(\epsilon(\mathbf{s})\) the residual (difference between study variable \(z\) and mean \(\mu(\mathbf{s})\)) at location \(\mathbf{s}\), and \(C(\mathbf{h})\) the covariance of the residuals at two locations separated by vector \(\mathbf{h} = \mathbf{s} - \mathbf{s}^{\prime}\).

In \emph{ordinary kriging}\index{Kriging!ordinary kriging} (OK) it is assumed that the mean of the study variable is constant, i.e.~the same everywhere \citep{webster2007}:

\begin{equation}
Z(\mathbf{s}) = \mu + \epsilon(\mathbf{s}) \;,
\label{eq:OKmodel}
\end{equation}

with \(\mu\) the constant mean, independent of the location \(\mathbf{s}\). Stated otherwise, in OK we assume \emph{stationarity in the mean}\index{Stationarity in the mean} over the area to be mapped.

\(C(\cdot)\) is the covariance function\index{Covariance function}, also referred to as the covariogram\index{Covariogram}, and a scaled version of it, obtained by dividing \(C(\cdot)\) by the variance \(C(0)\), is the correlation function\index{Correlation function} or correlogram\index{Correlogram}.

If the data set is of substantial size, it is possible to define a neighbourhood: not all sample data are used to predict the study variable at a prediction location but only the sample data in this neighbourhood. This implies that the stationarity assumption is relaxed to the often more realistic assumption of a constant mean within neighbourhoods.

In OK, the study variable at a prediction location \(\mathbf{s}_0\), \(\widehat{Z}(\mathbf{s}_0)\), is predicted as a weighted average of the observations at the sampling locations (within the neighbourhood):

\begin{equation}
\widehat{Z}_{\mathrm{OK}}(\mathbf{s}_0)=\sum_{i=1}^{n}\lambda_i \,Z(\mathbf{s}_i) \;,
\label{eq:weightedsumkriging}
\end{equation}

where \(Z(\mathbf{s}_i)\) is the study variable at the \(i^{\mathrm{th}}\) sampling location and \(\lambda _{i}\) is the weight attached to this location. The weights should be related to the correlation of the study variable at the sampling location and the prediction location. Note that as the mean is assumed constant (Equation \eqref{eq:OKmodel}), the correlation of the study variable \(Z\) is equal to the correlation of the residual \(\epsilon\). Roughly speaking, the stronger this correlation, the larger the weight must be. If we have a model for this correlation, then we can use this model to find the optimal weights. Further, if two sampling locations are very close, the weight attached to these two locations should not be twice the weight attached to a single, isolated sampling location at the same distance of the prediction location. This explains that in computing the kriging weights, besides the covariances of the \(n\) pairs of prediction location and sampling location, also the covariances of the \(n(n-1)/2\) pairs that can be formed with the \(n\) sampling units are used, see \citet{isa89} for a nice intuitive explanation. For OK, the optimal weights, i.e.~the weights that lead to the model-unbiased\index{Unbiasedness!model-unbiasedness}\footnote{Model-unbiasedness is explained in Chapter \ref{Approaches}.} predictor with minimum error variance (best linear unbiased predictor\index{Best linear unbiased predictor}), can be found by solving the following \(n+1\) equations:

\begin{equation}
\begin{array}{ccccc}
\sum\limits_{j=1}^{n}\lambda _{j}\,C(\mathbf{s}_1,\mathbf{s}_j)&+&\nu &=&C(\mathbf{s}_1,\mathbf{s}_0)\\
\sum\limits_{j=1}^{n}\lambda _{j}\,C(\mathbf{s}_2,\mathbf{s}_j)&+&\nu &=&C(\mathbf{s}_2,\mathbf{s}_0)\\
&&&\vdots\\
\sum\limits_{j=1}^{n}\lambda _{j}\,C(\mathbf{s}_n,\mathbf{s}_j)&+&\nu &=&C(\mathbf{s}_n,\mathbf{s}_0)\\
\sum\limits_{j=1}^{n}\lambda _{j}&&&=&1
\end{array} \;,
\label{eq:krigingequations}
\end{equation}

where \(C(\mathbf{s}_i,\mathbf{s}_j)\) is the covariance of the \(i\)th and \(j\)th sampling location, \(C(\mathbf{s}_i,\mathbf{s}_0)\) is the covariance of the \(i\)th sampling location and the prediction location \(s_0\), and \(\nu\) is an extra parameter to be estimated, referred to as the Lagrange multiplier\index{Lagrange multiplier}. This Lagrange multiplier must be included in the set of equations because the error variance is minimised under the constraint that the kriging weights sum to 1, see the final line in Equation \eqref{eq:krigingequations}. This constraint ensures that the OK-predictor is model-unbiased. It is convenient to write this system of equations in matrix form:

\begin{eqnarray}
\left[
\begin{array}{ccccc}
C_{11}&C_{12}&\dots&C_{1n}&1\\
C_{21}&C_{22}&\dots&C_{2n}&1\\
\vdots&\vdots&\dots&\vdots&\vdots\\
C_{n1}&C_{n2}&\dots&C_{nn}&1\\
1&1&\dots&1&0\\
\end{array}
\right]
\left[
\begin{array}{c}
\lambda_1\\
\lambda_2\\
\vdots\\
\lambda_n\\
\nu\\
\end{array}
\right]
=
\left[
\begin{array}{c}
C_{10}\\
C_{20}\\
\vdots\\
C_{n0}\\
1\\
\end{array}
\right]\;.
\label{eq:krigingeqsmatrix}
\end{eqnarray}

Replacing submatrices by single symbols results in the shorthand matrix equation:

\begin{eqnarray}
\left[
\begin{array}{cc}
\mathbf{C} & \mathbf{1} \\
\mathbf{1}^{\mathrm{T}} & 0 \\
\end{array}
\right]
\left[
\begin{array}{c}
\pmb{\lambda}\\
\nu\\
\end{array}
\right]
=
\left[
\begin{array}{c}
\mathbf{c}_0\\
1\\
\end{array}
\right]\;.
\label{eq:OKsystemshort}
\end{eqnarray}

The kriging weights\index{Kriging weight} \(\pmb{\lambda}\) and the Lagrange multiplier \(\nu\) can then be computed by pre-multiplying both sides of Equation \eqref{eq:OKsystemshort} with the inverse of the first matrix of this equation:

\begin{eqnarray}
\left[
\begin{array}{c}
\lambda\\
\nu\\
\end{array}
\right]
=
\left[
\begin{array}{cc}
\mathbf{C} & \mathbf{1} \\
\mathbf{1}^{\mathrm{T}} & 0 \\
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
\mathbf{c}_0\\
1\\
\end{array}
\right]\;.
\label{eq:krigingweights}
\end{eqnarray}

The variance of the prediction error (ordinary kriging variance\index{Ordinary kriging variance}, OK variance) at a prediction location equals

\begin{equation}
V_{\mathrm{OK}}(\widehat{Z}(\mathbf{s}_0))= \sigma^2 - \lambda^{\mathrm{T}}\mathbf{c}_0 - \nu \;,
\label{eq:OKvariance}
\end{equation}

with \(\sigma^2\) the a priori variance\index{A priori variance}, see Equation \eqref{eq:OKmodel}. This equation shows that the OK variance is not a function of the data at the sampling locations. Given a covariance function it is fully determined by the spatial pattern of the sampling locations and the prediction location. It is this property of kriging that makes it possible to optimise the grid spacing (Chapter \ref{MBgridspacing}) and, as we will see in Chapter \ref{MBSamplePattern}, to optimise the spatial pattern of the sampling locations, given a requirement on the kriging variance. If the kriging variance were a function of the data at the sampling locations, optimisation would be much more complicated.

In general practice, the covariance function is not used in kriging, rather a semivariogram\index{Semivariogram}. A semivariogram \(\gamma(\mathbf{h})\) is a model of the \emph{dissimilarity} of the study variable at two locations, as a function of the vector \(\mathbf{h}\) separating the two locations. The dissimilarity is quantified by half the variance of the difference of the study variable \(Z\) at two locations. Under the assumption that the expectation of \(Z\) is constant throughout the study area (stationarity in the mean), half the variance of the difference is equal to half the expectation of the squared difference:

\begin{equation}
\gamma(\mathbf{h}) = 0.5V[Z(\mathbf{s})-Z(\mathbf{s}+\mathbf{h})]=0.5E[\{Z(\mathbf{s})-Z(\mathbf{s}+\mathbf{h})\}^2]\;.
\label{eq:semivariogram}
\end{equation}

A covariance function and semivariogram are related by (see Figure \ref{fig:CovFunctionVariogram})

\begin{equation}
\gamma(\mathbf{h}) = \sigma^2 - C(\mathbf{h})\;.
\label{eq:gammavscov}
\end{equation}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/CovFunctionVariogram-1} 

}

\caption{Spherical covariance function (red line and dot) and semivariogram (black line and dot).}\label{fig:CovFunctionVariogram}
\end{figure}

Expressed in terms of the \emph{semivariances}\index{Semivariance} between the sampling locations and a prediction location, the OK variance is

\begin{equation}
V_{\mathrm{OK}}(\widehat{Z}(\mathbf{s}_0))= \lambda^{\mathrm{T}}\pmb{\gamma}_0 + \nu \;,
\label{eq:OKvariancesemivariances}
\end{equation}

with \(\pmb{\gamma}_0\) the vector with semivariances between the sampling locations and a prediction location.

Computing the kriging predictor requires a model for the covariance (or semivariance) as a function of the vector separating two locations. Often the covariance is modelled as a function of the length of the separation vector only, so as a function of the Euclidian distance between two locations. We then assume isotropy\index{Isotropy}: given a separation distance between two locations, the covariance is the same in all directions. Only authorised functions are allowed for modelling the semivariance, ensuring that the variance of any linear combination of random variables, like the kriging predictor, is positive. Commonly used functions are an exponential and a spherical model.

The spherical semivariogram model\index{Semivariogram model!spherical} has three parameters:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  nugget\index{Nugget} (\(c_0\)): this is where the semivariogram touches the y-axis (in Figure \ref{fig:CovFunctionVariogram}: 25);
\item
  partial sill\index{Partial sill} (\(c_1\)): the difference between the maximum semivariance and the nugget (in Figure \ref{fig:CovFunctionVariogram}: 75); and
\item
  range\index{Range} (\(\phi\)): this is the distance at which the semivariance reaches its maximum (in Figure \ref{fig:CovFunctionVariogram}: 250 m).
\end{enumerate}

The formula for the spherical semivariogram is

\begin{equation}
\gamma(h)=\left \{
\begin{array}{ll}
0      &\,\,\,\mathrm{if}\,\,\, h=0 \\
c_0+c_1\left[ 1-\frac{3}{2}\left( \frac{h}{\phi}\right) +\frac{1}{2}\left( \frac{h}{\phi}\right) ^{3}\right] &\,\,\,\mathrm{if}\,\,\, 0 < h \leq \phi \\
c_0+c_1     & \,\,\,\mathrm{if}\,\,\, h>\phi
\end{array}
\right. \;.
\label{eq:spherical}
\end{equation}

The sum of the nugget and the partial sill is referred to as the sill\index{Sill} (or sill variance or a priori variance\index{A priori variance}).

An exponential semivariogram model\index{Semivariogram model!exponential} also has three parameters. Its formula is

\begin{equation}
\gamma(h)=\left \{
\begin{array}{ll}
0      &\,\,\,\text{if}\,\,\, h=0 \\
c_0+c_1\; \mathrm{exp}(-h/\phi) &\,\,\,\text{if}\,\,\, h > 0 \\
\end{array}
\right. \;.
\label{eq:exponential}
\end{equation}

In an exponential semivariogram the semivariance goes asymptotically to a maximum; it never reaches it. In an exponential semivariogram the range parameter is replaced by the distance parameter. In an exponential semivariogram without nugget the semivariance at three times the distance parameter is at 95\% of the sill. Three times the distance parameter is referred to as the \emph{effective} or \emph{practical} range.

In following chapters I also use a correlogram\index{Correlogram}, which is a scaled covariance function, such that the sill of the correlogram equals 1:

\begin{equation}
\rho(\mathbf{h}) = \frac{C(\mathbf{h})}{\sigma^2} \;.
\label{eq:correlogram}
\end{equation}

To illustrate that the OK variance\index{Ordinary kriging variance} is independent of the values of the study variable at the sampling locations, I simulated a spatial population of 50 \(\times\) 50 units. For each unit a value of the study variable is simulated, using the semivariogram of Figure \ref{fig:CovFunctionVariogram}. This is repeated ten times, resulting in ten maps of 2,500 units. Figure \ref{fig:Twokrigingsimulations} shows two of the ten simulated maps. Note that the two maps clearly show spatial structure, i.e.~there are patches of similar values).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/Twokrigingsimulations-1} 

}

\caption{Two maps simulated with the spherical semivariogram of Figure 21.1, the centred square grid of sampling units, and the prediction unit (red cell with coordinates (590,670)).}\label{fig:Twokrigingsimulations}
\end{figure}

The simulated maps are sampled on a centred square grid with a spacing of 100 distance units, resulting in a sample of 100 units. Each sample is used one-by-one to predict the study variable at one prediction location (see Figure \ref{fig:Twokrigingsimulations}), using again the semivariogram of Figure \ref{fig:CovFunctionVariogram}. The semivariogram is passed to function \texttt{vgm} of package \textbf{gstat} \citep{peb04}. Usually, this semivariogram is estimated from a sample, see Chapter \ref{SamplingVariogram}, but here we assume that it is known. Function \texttt{krige} of package \textbf{gstat} is used for kriging. Argument \texttt{formula} specifies the dependent (study variable) and independent variables (covariates). The formula \texttt{z\ \textasciitilde{}\ 1} means that we do not have covariates (we assume that the model-mean is a constant) and that predictions are done by OK (or simple kriging, see Section \ref{IntroKED}). Argument \texttt{locations} is a \texttt{SpatialPointsDataFrame} with the spatial coordinates and observations. Argument \texttt{newdata} is a \texttt{SpatialPoints} object with the locations where we want to predict. Argument \texttt{nmax} can be used to specify the neighbourhood in terms of the number of nearest observations to be used in kriging (not used in the code chunk below, so that all 100 observations are used).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{vgmodel }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{25}\NormalTok{, }\AttributeTok{psill =} \DecValTok{75}\NormalTok{, }\AttributeTok{range =} \DecValTok{250}\NormalTok{)}
\FunctionTok{gridded}\NormalTok{(mypop) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mypop, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{100}\NormalTok{),}
  \AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{zsim\_sample }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(mysample, mypop)}
\FunctionTok{coordinates}\NormalTok{(s\_0) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{zpred\_OK }\OtherTok{\textless{}{-}}\NormalTok{ v\_zpred\_OK }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{ncol}\NormalTok{(Z))) \{}
\NormalTok{  mysample}\SpecialCharTok{$}\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ zsim\_sample[, i]}
\NormalTok{  predictions }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{locations =}\NormalTok{ mysample,}
    \AttributeTok{newdata =}\NormalTok{ s\_0,}
    \AttributeTok{model =}\NormalTok{ vgmodel,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{  zpred\_OK[i] }\OtherTok{\textless{}{-}}\NormalTok{ predictions}\SpecialCharTok{$}\NormalTok{var1.pred}
\NormalTok{  v\_zpred\_OK[i] }\OtherTok{\textless{}{-}}\NormalTok{ predictions}\SpecialCharTok{$}\NormalTok{var1.var}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

As can be seen in Table \ref{tab:OKpredandvar}, unlike the predicted value, the OK variance produced from the different simulations is constant.

\begin{table}

\caption{\label{tab:OKpredandvar}Ordinary kriging predictions and kriging variance at a fixed prediction location for ten data sets with simulated values at a square sampling grid.}
\centering
\begin{tabular}[t]{rr}
\toprule
Kriging prediction & Kriging variance\\
\midrule
51.44286 & 55.30602\\
57.29272 & 55.30602\\
52.44407 & 55.30602\\
51.40719 & 55.30602\\
63.09248 & 55.30602\\
40.57517 & 55.30602\\
54.48507 & 55.30602\\
47.42828 & 55.30602\\
43.65313 & 55.30602\\
44.52740 & 55.30602\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{BlockKriging}{%
\section{Block-kriging}\label{BlockKriging}}

In the previous section the support of the prediction units is equal to that of the sampling units. So, if the observations are done at points (point support\index{Point support}), the support of the predictions are also points, and if means of small blocks are observed, the predictions are predicted means of blocks of the same size and shape. There is no change of support\index{Change of support}. In some cases we may prefer predictions at a larger support than that of the observations. For instance, we may prefer predictions of the average concentration of some soil property of blocks of 5 m \(\times\) 5 m, instead of predictions at points, simply because of practical relevance. If the observations are at points, there is a change of support, from points to blocks. Kriging with a prediction support that is larger than the support of the sample data is referred to as block-kriging\index{Kriging!block-kriging}. Kriging without change of support, sample support and prediction support are equal, is referred to as point-kriging\index{Kriging!point-kriging}. Note that point-kriging does not necessarily imply that the support is a point, it can be, for instance, a small block.

In block-kriging the mean of a prediction block \(\mathcal{B}_0\) is predicted as a weighted average of the observations at the sampling units. The kriging weights are derived much in the same way as in point-kriging (Equations \eqref{eq:krigingequations} to \eqref{eq:krigingweights}). In block-kriging the covariance between a sampling point \(i\) and a prediction point, \(C(\mathbf{s}_i,\mathbf{s}_0)\), is replaced by the \emph{mean} covariance between the sampling point and a prediction block \(\overline{C}(\mathbf{s}_i,\mathcal{B}_0)\) (Equation \eqref{eq:krigingequations}). This mean covariance can be approximated by discretising the prediction block by a fine grid, computing the covariance between a sampling point \(i\) and each of the discretisation points, and averaging.

The variance of the prediction error of the block-mean (block-kriging variance\index{Block-kriging variance}) equals

\begin{equation}
V_{\mathrm{OBK}}(\widehat{\overline{Z}}(\mathcal{B}_0)) = \lambda^{\mathrm{T}}\bar{\pmb{\gamma}}(\mathcal{B}_0) + \nu - \bar{\gamma}(\mathcal{B}_0,\mathcal{B}_0)\;,
\label{eq:OBKvariance}
\end{equation}

with \(\bar{\pmb{\gamma}}(\mathcal{B}_0)\) the vector with mean semivariances between the sampling points and a prediction block and \(\bar{\gamma}(\mathcal{B}_0,\mathcal{B}_0)\) the mean semivariance within the prediction block. Comparing this with Equation \eqref{eq:OKvariancesemivariances} shows that the block-kriging variance is smaller than the point-kriging variance\index{Point-kriging variance} by an amount approximately equal to the mean semivariance within a prediction block\index{Mean semivariance!within a prediction block}. Recall from Chapter \ref{MBpredictionofDesignVariance} that the mean semivariance within a block is a model-based prediction of the variance within a block (Equation \eqref{eq:meansemivariance}).

\hypertarget{IntroKED}{%
\section{Kriging with an external drift}\label{IntroKED}}

In kriging with an external drift\index{Kriging!kriging with an external drift} (KED) the spatial variation of the study variable is modelled as the sum of a linear combination of covariates and a spatially correlated residual:

\begin{equation}
\begin{split}
Z(\mathbf{s}) & = \sum_{k=0}^p \beta_k x_k(\mathbf{s}) + \epsilon(\mathbf{s}) \\
\epsilon(\mathbf{s}) & \sim \mathcal{N}(0,\sigma^2) \\
\mathrm{Cov}(\epsilon(\mathbf{s}),\epsilon(\mathbf{s}^{\prime})) & = C(\mathbf{h}) \;,
\end{split}
\label{eq:KEDmodel2}
\end{equation}

with \(x_k(\mathbf{s})\) the value of the \(k\)th covariate at location \(\mathbf{s}\) (\(x_0\) = 1 for all locations), \(p\) the number of covariates, and \(C(\mathbf{h})\) the covariance of the residuals at two locations separated by vector \(\mathbf{h} = \mathbf{s}-\mathbf{s}^{\prime}\). The constant mean \(\mu\) in Equation \eqref{eq:OKmodel} is replaced by a linear combination of covariates and, as a consequence, the mean is not constant anymore but varies in space.

With KED the study variable at a prediction location \(\mathbf{s}_0\) is predicted by

\begin{equation}
\hat{Z}_{\mathrm{KED}}(\mathbf{s}_0)=\sum_{k=0}^p \hat{\beta}_k x_k(\mathbf{s}_0)+\sum_{i=1}^n \lambda_i\left\{Z(\mathbf{s}_i)-\sum_{k=0}^p \hat{\beta}_k x_k(\mathbf{s}_i)\right\}\;,
\label{eq:KEDpredictor}
\end{equation}

with \(\hat{\beta}_k\) the estimated regression coefficient associated with covariate \(x_k\). The first component of this predictor is the estimated model-mean at the new location based on the covariate values at this location and the estimated regression coefficients. The second component is a weighted sum of the residuals at the sampling locations.

The optimal kriging weights \(\lambda_i,\; i = 1, \dots ,n\) are obtained in a similar way as in OK. The difference is that additional constraints on the weights are needed, to ensure unbiased predictions. Not only the weights must sum to 1, but also for all \(p\) covariates the weighted sum of the covariate values at the sampling locations must equal the covariate value at the prediction location: \(\sum_{i=1}^n \lambda_i x_k(\mathbf{s}_i) = x_k(\mathbf{s}_0)\) for all \(k=1, \dots , p\). This leads to a system of \(n+p+1\) simultaneous equations that must be solved. In matrix notation this system is

\begin{eqnarray}
\left[
\begin{array}{cc}
\mathbf{C} & \mathbf{X} \\
\mathbf{X}^{\mathrm{T}} & \mathbf{0} \\
\end{array}
\right]
\left[
\begin{array}{c}
\pmb{\lambda}\\
\nu\\
\end{array}
\right]
=
\left[
\begin{array}{c}
\mathbf{c}_0\\
\mathbf{x}_0\\
\end{array}
\right]\;,
\label{eq:KEDsystem}
\end{eqnarray}

with

\begin{eqnarray}
\mathbf{X}=
\left[
\begin{array}{ccccc}
1&x_{11}&x_{12}&\dots&x_{1p}\\
1&x_{21}&x_{22}&\dots&x_{2p}\\
\vdots&\vdots&\vdots&\dots&\vdots\\
1&x_{n1}&x_{n2}&\dots&x_{np}\\
\end{array}
\right]\;.
\label{eq:MatrixXinKEDsystem}
\end{eqnarray}

The submatrix \(\mathbf{0}\) is a \(((p+1) \times (p+1))\) matrix with zeroes, \(\nu\) a (\(p+1\)) vector with Lagrange multipliers, and \(\mathbf{x}_0\) a \((p+1)\) vector with covariate values at the prediction location (including a 1 as the first entry).

The kriging variance with KED equals

\begin{equation}
V_{\mathrm{KED}}(\widehat{Z}(\mathbf{s}_0))= \sigma^2 - \lambda^{\mathrm{T}}\mathbf{c}_0 - \nu^{\mathrm{T}} \mathbf{x}_0 \;.
\label{eq:KEDvariance}
\end{equation}

The prediction error variance with KED can also be written as the sum of the variance of the predictor of the mean and the variance of the error in the interpolated residuals \citep{chr91}:

\begin{equation}
\begin{split}
V_{\mathrm{KED}}(\widehat{Z}(\mathbf{s}_0)) &= \sigma^2 - \mathbf{c}_0^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{c}_0 +\\
&(\mathbf{x}_0-\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{c}_0)^{\mathrm{T}}(\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{X})^{-1}(\mathbf{x}_0-\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{c}_0)\;.
\end{split}
\label{eq:KEDvariance2}
\end{equation}

The first two terms constitute the interpolation error variance, the third term the variance of the predictor of the mean.

To illustrate that the kriging variance with KED depends on the values of the covariate at the sampling locations and the prediction location, values of a covariate \(x\) and of a correlated study variable \(z\) are simulated for the \(50 \times 50\) units of a spatial population (Figure \ref{fig:SimulatedXandZ}). First, a field with covariate values is simulated with a model-mean of 10. Next, a field with residuals is simulated. The field of the study variable is then obtained by multiplying the simulated field with covariate values by two (\(\beta_1=2\)), adding a constant of 10 (\(\beta_0=10\)), and finally adding the simulated field with residuals.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#simulate covariate values}
\NormalTok{vgm\_x }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =} \DecValTok{10}\NormalTok{, }\AttributeTok{range =} \DecValTok{200}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgm\_x, }\AttributeTok{dist\_vector =}\NormalTok{ H, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{Upper }\OtherTok{\textless{}{-}} \FunctionTok{chol}\NormalTok{(C)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \FunctionTok{nrow}\NormalTok{(mypop), }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{mypop}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(Upper, N) }\SpecialCharTok{+} \DecValTok{10}
\CommentTok{\#simulate values for residuals}
\NormalTok{vgm\_resi }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =} \DecValTok{5}\NormalTok{, }\AttributeTok{range =} \DecValTok{100}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgm\_resi, }\AttributeTok{dist\_vector =}\NormalTok{ H, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{Upper }\OtherTok{\textless{}{-}} \FunctionTok{chol}\NormalTok{(C)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \FunctionTok{nrow}\NormalTok{(mypop), }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(Upper, N)}
\CommentTok{\#compute mean of study variable}
\NormalTok{betas }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{mu }\OtherTok{\textless{}{-}}\NormalTok{ betas[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ betas[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ mypop}\SpecialCharTok{$}\NormalTok{x}
\CommentTok{\#compute study variable z}
\NormalTok{mypop}\SpecialCharTok{$}\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ mu  }\SpecialCharTok{+}\NormalTok{ e}
\end{Highlighting}
\end{Shaded}

As before, a centred square grid with a spacing of 100 distance units is selected. The simulated values of the study variable \(z\) and covariate \(x\) are used to predict \(z\) at a prediction location \(\mathbf{s}_0\) by kriging with an external drift (red cell in Figure \ref{fig:SimulatedXandZ}). Although at the prediction location we have only one simulated value of covariate \(x\), a series of covariate values is used to predict \(z\) at that location: \(x_0 = 0, 2, 4, \dots, 20\). In practice we have of course only one value of the covariate at a fixed location, but this is for illustration purposes only. Note that we have only one data set with `observations' of \(x\) and \(z\) at the sampling locations (square grid).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/SimulatedXandZ-1} 

}

\caption{Maps with simulated values of covariate $x$ and study variable $z$, the centred square grid of sampling units, and the prediction unit (red cell with coordinates (590,670)).}\label{fig:SimulatedXandZ}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{zxsim\_sample }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(mysample, mypop)}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ zxsim\_sample}\SpecialCharTok{$}\NormalTok{z}
\NormalTok{mysample}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ zxsim\_sample}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{x0 }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)}
\NormalTok{v\_zpred\_KED }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(x0))) \{}
\NormalTok{  s\_0}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x0[i]}
\NormalTok{  predictions  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x,}
    \AttributeTok{locations =}\NormalTok{ mysample,}
    \AttributeTok{newdata =}\NormalTok{ s\_0,}
    \AttributeTok{model =}\NormalTok{ vgm\_resi,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{  v\_zpred\_KED[i] }\OtherTok{\textless{}{-}}\NormalTok{ predictions}\SpecialCharTok{$}\NormalTok{var1.var}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note the formula \texttt{z\ \textasciitilde{}\ x} in the code chunk above, indicating that there is now an independent variable (covariate). The covariate values are attached to the file with the prediction location one-by-one in a for-loop. Also note that for KED we need the semivariogram of the residuals, not of the study variable itself. The residual semivariogram used in prediction is the same as the one used in simulating the fields: a spherical model without nugget, with a sill of 5, and a range of 100 distance units.

To assess the contribution of the uncertainty about the model-mean \(\mu(\mathbf{s})\), I also predict the values assuming that the model-mean is known. In other words, I assume that the two regression coefficients \(\beta_0\) (intercept) and \(\beta_1\) (slope) are known. This type of kriging is referred to as simple kriging\index{Kriging!simple kriging} (SK). With SK the constraints explained above are removed, so that there are no Lagrange multipliers involved. Argument \texttt{beta} is used to specify the known regression coefficients. I use the same values as in simulation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v\_zpred\_SK }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(x0))) \{}
\NormalTok{  s\_0}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x0[i]}
\NormalTok{  prediction  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x,}
    \AttributeTok{locations =}\NormalTok{ mysample,}
    \AttributeTok{newdata =}\NormalTok{ s\_0,}
    \AttributeTok{model =}\NormalTok{ vgm\_resi,}
    \AttributeTok{beta =}\NormalTok{ betas,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{  v\_zpred\_SK[i] }\OtherTok{\textless{}{-}}\NormalTok{ prediction}\SpecialCharTok{$}\NormalTok{var1.var}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:KEDVarSKVar} shows that, contrary to the SK variance, the kriging variance with KED is not constant but depends on the covariate value at the prediction location. It is smallest near the mean of the covariate values at the sampling locations, which is 10.0. The more extreme the covariate value at the prediction location, the larger the kriging variance with KED. This is analogous to the variance of predictions with a linear regression model.

The variance with SK is constant. This is because with SK we assume that the regression coefficients are known, so that we know the model-mean at a prediction location. What remains is the error in the interpolation of the residuals (first two terms in Equation \eqref{eq:KEDvariance2}). This interpolation error is independent of the value of \(x\) at the prediction location. In Figure \ref{fig:KEDVarSKVar} the difference between the variances with KED and SK is the variance of the predictor of the model-mean, due to uncertainty about the regression coefficients. In real-world applications these regression coefficients are unknown and must be \emph{estimated} from the sample data. This variance is smallest for a covariate value about equal to the sample mean of the covariate, and increases with the absolute difference of the covariate value and this sample mean.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/KEDVarSKVar-1} 

}

\caption{Variance of the prediction error as a function of the covariate value at a fixed prediction location, obtained with kriging with an external drift (KED) and simple kriging (SK).}\label{fig:KEDVarSKVar}
\end{figure}

\hypertarget{VariogramEstimation}{%
\section{Estimating the semivariogram}\label{VariogramEstimation}}

Kriging requires a semivariogram or covariance function as input for computing the covariance matrix of the study variable at the sampling locations and the vector of covariance of the study variable at the sampling locations and the prediction location. In most cases the semivariogram model is unknown and must be estimated from sample data. The estimated parameters of the semivariogram model are plugged into the kriging equations. There are two different approaches for estimating the semivariogram parameters from sample data: the \emph{method-of-moments}\index{Method-of-moments} and \emph{maximum likelihood estimation}\index{Maximum likelihood estimation} \citep{lar00b}.

\hypertarget{MoM}{%
\subsection{Method-of-moments}\label{MoM}}

With the method-of-moments (MoM) approach the semivariogram is estimated in two steps. In the first step a sample semivariogram\index{Sample semivariogram}, also referred to as an experimental semivariogram\index{Experimental semivariogram|see{Sample semivariogram}}, is estimated. This is done by choosing a series of distance intervals (bins). If a semivariogram in different directions is required, we must also choose direction intervals.

For each distance interval all pairs of points with a separation distance\index{Separation distance} in that interval are identified. For each pair half the squared difference of the study variable is computed, and these differences are averaged over all point-pairs of that interval. This average is the estimated semivariance of that distance interval. The estimated semivariances for all distance intervals are plotted against the average separation distances per distance interval. In the second step a permissible model is fitted to the sample semivariogram, using some form of weighted least squares. For details, see \citet{webster2007}.

The next code chunk shows how this can be done in \textbf{R}. A simple random sample of 150 points is selected from the first simulated field shown in Figure \ref{fig:Twokrigingsimulations}. Function \texttt{variogram} of package \textbf{gstat} is then used to compute the sample semivariogram. Note that distance intervals need be passed to function \texttt{variogram}. This can be done with argument \texttt{width} or argument \texttt{boundaries}. In their absence, the default value for argument \texttt{width} is equal to the maximum separation distance divided by fifteen, so that there are fifteen points in the sample semivariogram. The maximum separation distance can be set with argument \texttt{cutoff}. The default value for this argument is equal to one-third of the longest diagonal of the bounding box of the point set. The output is a data frame, with the number of point-pairs, average separation distance, and estimated semivariance in the first three columns.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(mypop), }\AttributeTok{size =} \DecValTok{150}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mypop[units, ]}
\FunctionTok{coordinates}\NormalTok{(mysample) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{vg }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample)}
\FunctionTok{head}\NormalTok{(vg[, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   np      dist    gamma
1  35  24.02379 38.73456
2  74  49.02384 42.57199
3 179  78.62401 62.13025
4 213 110.05088 72.41387
5 239 139.20163 82.21432
6 323 170.55712 88.38168
\end{verbatim}

The next step is to fit a model. This can be done with function \texttt{fit.variogram} of the \textbf{gstat} package. Many models can be fitted with this function (type \texttt{vgm()} to see all models). I chose a spherical model. Function \texttt{fit.variogram} requires initial values of the semivariogram parameters. From the sample semivariogram my eyeball estimates are 25 for the nugget, 250 for the range, and 75 for the partial sill. These are passed to function \texttt{vgm}. Figure \ref{fig:semivariogramSimulatedField1} shows the sample semivariogram along with the fitted spherical model.\footnote{The figure is plotted with package \textbf{ggplot2}. The sample semivariogram and the fitted model can also be plotted with \texttt{plot(vg,\ vg\_MoM,\ plot.numbers\ =\ TRUE)}.}.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/semivariogramSimulatedField1-1} 

}

\caption{Sample semivariogram and fitted spherical model estimated from a simple random sample of 150 units selected from the first simulated field shown in Figure \ref{fig:Twokrigingsimulations}. Numbers are numbers of point-pairs used in computing semivariances.}\label{fig:semivariogramSimulatedField1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(vgm\_MoM)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  model    psill    range
1   Nug 26.32048   0.0000
2   Sph 68.36364 227.7999
\end{verbatim}

Function \texttt{fit.variogram} has several options for weighted least squares optimisation, see \texttt{?fit.variogram} for details. Also note that this non-linear fit may not converge to a solution, especially if the starting values passed to \texttt{vgm} are not near their optimal values.

Further, this method depends on the choice of cutoff and distance intervals. We hope that modifying these does not change the fitted model too much, but this is not always the case, especially with smaller data sets.

\hypertarget{MLestimationVariogram}{%
\subsection{Maximum likelihood}\label{MLestimationVariogram}}

In contrast to the MoM, with the maximum likelihood (ML) method the data are not paired into couples and binned into a sample semivariogram. Instead, the semivariogram model is estimated in one step. To apply this method one typically assumes that (possibly after transformation) the \(n\) sample data come from a multivariate normal distribution\index{Multivariate normal distribution}. If we have one observation from a normal distribution, the probability density of that observation is given by

\begin{equation}
f(z|\mu,\sigma ^{2})=
\frac{1}{\sigma \sqrt{2\pi }}\exp \left\{ -\frac{1}{2}\left( \frac{z-\mu }{\sigma }\right) ^{2}\right\} \;,
\label{eq:densitynormal}
\end{equation}

with \(\mu\) the mean and \(\sigma^2\) the variance. With multiple independent observations, each of them coming from a normal distribution, the joint probability density is given by the product of the probability densities per observation. However, if the data are not independent, we must account for the covariances and the joint probability density can be computed by

\begin{equation}
f(\mathbf{z}|\pmb{\mu} ,\pmb{\theta})=
(2\pi )^{-\frac{n}{2}}|\mathbf{C}|^{-\frac{1}{2}}
\exp \left\{ -\frac{1}{2}(\mathbf{z}-\pmb{\mu} )^{\mathrm{T}}\,\mathbf{C}^{-1}\,(\mathbf{z}-\pmb{\mu} )\right\} \;,
\label{eq:densitymvnormal}
\end{equation}

where \(\mathbf{z}\) is the vector with the \(n\) sample data, \(\pmb{\mu}\) is the vector with means, \(\pmb{\theta}\) is the vector with parameters of the covariance function, and \(\mathbf{C}\) is the \(n \times n\) matrix with variances and covariances of the sample data. If the probability density of Equation \eqref{eq:densitymvnormal} is regarded as a function of \(\pmb{\mu}\) and \(\pmb{\theta}\) with the data \(\mathbf{z}\) fixed, this equation defines the likelihood\index{Likelihood}.

ML estimates of the semivariogram can be obtained with function \texttt{likfit} of package \textbf{geoR} \citep{geoR}. First, a geoR object must be made specifying which columns of the data frame contain the spatial coordinates and the study variable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(mysample, }\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(}\AttributeTok{obj =}\NormalTok{ mysample, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{), }\AttributeTok{data.col =} \StringTok{"z"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The model parameters can then be estimated with function \texttt{likfit}. Argument \texttt{trend\ =\ "cte"} means that we assume that the mean is constant throughout the study area.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vgm\_ML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \StringTok{"cte"}\NormalTok{,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{80}\NormalTok{, }\DecValTok{200}\NormalTok{),}
  \AttributeTok{nugget =} \DecValTok{20}\NormalTok{, }\AttributeTok{lik.method =} \StringTok{"ML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Table \ref{tab:VariogramEstimates} shows the ML estimates together with the MoM estimates. As can be seen, the estimates are substantially different, especially the division of the a priori variance (sill) into partial sill and nugget. In general I prefer the ML estimates because the arbitrary choice of distance intervals to compute a sample semivariogram is avoided. Also ML estimates of the parameters are more precise, given a sample size. On the other hand, in ML estimation we need to assume that the data are normally distributed.

\begin{table}

\caption{\label{tab:VariogramEstimates}Estimated parameters of a spherical semivariogram obtained with method-of-moments (MoM) and maximum likelihood (ML) estimation.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Parameter & MoM & ML\\
\midrule
nugget & 26.3 & 19.5\\
partial sill & 68.4 & 83.8\\
range & 227.8 & 217.8\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{ResidualVariogram}{%
\section{Estimating the residual semivariogram}\label{ResidualVariogram}}

For KED, estimates of the regression coefficients and of the parameters of the residual semivariogram are needed. Estimation of these model parameters is not a trivial problem, as the estimated regression coefficients and the estimated residual semivariogram parameters are not independent. The residuals depend on the estimated regression coefficients and, as a consequence, also the parameters of the residual semivariogram depend on the estimated coefficients. Vice versa, the estimated regression coefficients depend on the spatial correlation of the residuals, and so on the estimated residual semivariogram parameters. This is a classic ``which came first, the chicken or the egg?'' problem.

Estimation of the model parameters is illustrated with the simulated field of Figure \ref{fig:SimulatedXandZ}. A simple random sample of size 150 is selected to estimate the model parameters.

\hypertarget{IterativeMoM}{%
\subsection{Iterative method-of-moments}\label{IterativeMoM}}

A simple option is iterative estimation of the regression coefficients followed by MoM estimation of the sample semivariogram and fitting of a semivariogram model. In the first iteration the regression coefficients are estimated by ordinary least squares (OLS). This implies that the data are assumed independent, i.e.~we assume a pure nugget residual semivariogram. The sample semivariogram of the OLS residuals is then computed by the MoM, followed by fitting a model to this sample semivariogram. With package \textbf{gstat} this can be done with one line of \textbf{R} code, using a formula specifying the study variable and the predictors as the first argument of function \texttt{variogram}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(mypop), }\AttributeTok{size =} \DecValTok{150}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ mypop[units, ]}
\NormalTok{vg\_resi }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ mysample)}
\NormalTok{model\_eye }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =} \DecValTok{10}\NormalTok{, }\AttributeTok{range =} \DecValTok{150}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{0}\NormalTok{)}
\NormalTok{vgmresi\_MoM }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vg\_resi, }\AttributeTok{model =}\NormalTok{ model\_eye)}
\end{Highlighting}
\end{Shaded}

Given these estimates of the semivariogram parameters, the regression coefficients are re-estimated by accounting for spatial dependency of the residuals. This can be done by generalised least squares\index{Generalised least squares} (GLS):

\begin{equation}
\pmb{\hat{\beta}}_{\text{GLS}} = (\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{X})^{-1} (\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{z})\;.
(\#eq:beta_GLS)
\end{equation}

The next code chunk shows how the GLS estimates of the regression coefficients can be computed. Function \texttt{spDists} of package \textbf{sp} is used to compute the matrix with distances between the sampling locations, and function \texttt{variogramLine} of package \textbf{gstat} is used to transform the distance matrix into a covariance matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{data =} \DecValTok{1}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(}\FunctionTok{as}\NormalTok{(mysample, }\StringTok{"data.frame"}\NormalTok{)), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\NormalTok{X[, }\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ mysample}\SpecialCharTok{$}\NormalTok{z}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{spDists}\NormalTok{(mysample)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmresi\_MoM, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{Cinv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(C)}
\NormalTok{XCXinv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X, Cinv) }\SpecialCharTok{\%*\%}\NormalTok{ X)}
\NormalTok{XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, Cinv) }\SpecialCharTok{\%*\%}\NormalTok{ z}
\NormalTok{betaGLS }\OtherTok{\textless{}{-}}\NormalTok{ XCXinv }\SpecialCharTok{\%*\%}\NormalTok{ XCz}
\end{Highlighting}
\end{Shaded}

The inversion of the covariance matrix \(\mathbf{C}\) can be avoided as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XCX }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, X))}
\NormalTok{XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, z))}
\NormalTok{betaGLS }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(XCX, XCz)}
\end{Highlighting}
\end{Shaded}

This coding is to be preferred as the inversion of a matrix can be numerically unstable.

The GLS estimates of the regression coefficients can then be used to re-compute the residuals of the mean, and so on, until the changes in the model parameters are negligible.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{  betaGLS.cur }\OtherTok{\textless{}{-}}\NormalTok{ betaGLS}
\NormalTok{  mu }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ betaGLS}
\NormalTok{  mysample}\SpecialCharTok{$}\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{{-}}\NormalTok{ mu}
\NormalTok{  vg\_resi }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(e }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample)}
\NormalTok{  vgmresi\_MoM }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vg\_resi, }\AttributeTok{model =}\NormalTok{ model\_eye)}
\NormalTok{  C }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmresi\_MoM, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  XCX }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, X))}
\NormalTok{  XCz }\OtherTok{\textless{}{-}} \FunctionTok{crossprod}\NormalTok{(X, }\FunctionTok{solve}\NormalTok{(C, z))}
\NormalTok{  betaGLS }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(XCX, XCz)}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(betaGLS }\SpecialCharTok{{-}}\NormalTok{ betaGLS.cur)) }\SpecialCharTok{\textless{}} \FloatTok{0.0001}\NormalTok{) \{}
    \ControlFlowTok{break}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Table \ref{tab:ResidualVariogramEstimates} shows the estimates of the residual semivariogram parameters and regression coefficients, together with the estimates obtained by restricted maximum likelihood, which is explained in the next subsection.

\hypertarget{REML}{%
\subsection{Restricted maximum likelihood}\label{REML}}

The estimates of the residual semivariogram parameters obtained by the iterative MoM\index{Method-of-moments!iterative method-of-moments} procedure are not unbiased. When the mean is not constant but a linear combination of one or more covariates, also ML estimation results in biased estimates of the residual semivariogram parameters. Unbiased estimates of the regression coefficients and residual semivariogram parameters can be obtained by restricted maximum likelihood\index{Restricted maximum likelihood estimation} (REML), also referred to as residual maximum likelihood. In REML the vector with the data is pre-multiplied by a so-called projection matrix \(\mathbf{P}\) \citep{Kitanidis1983}. This projection matrix has the property that a vector with zeroes is obtained when the matrix \(\mathbf{X}\) with the covariate values at the sampling locations (and ones in the first column) is pre-multiplied with \(\mathbf{P}\):

\begin{equation}
\mathbf{P}\mathbf{X}=\mathbf{0} \;.
\label{eq:PX}
\end{equation}

Pre-multiplying both sides of the KED model (Equation \eqref{eq:KEDmodel2}) with \(\mathbf{P}\) gives \citep{webster2007}

\begin{equation}
\mathbf{P}\mathbf{z}(\mathbf{s})=\mathbf{y}(\mathbf{s})=\mathbf{P}\mathbf{X}\pmb{\beta} + \mathbf{P}\pmb{\epsilon}(\mathbf{s})=\mathbf{P}\pmb{\epsilon}(\mathbf{s}) \;.
\label{eq:Pz}
\end{equation}

In words, by pre-multiplying variable \(\mathbf{z}\) with matrix \(\mathbf{P}\) a new variable \(\mathbf{y}\) is obtained that has a constant mean. So, the trend is filtered out, whatever the regression coefficients are. The semivariogram parameters of this new variable can be estimated by ML. The projection matrix \(\mathbf{P}\) can be computed by

\begin{equation}
\mathbf{P}=\mathbf{I}-\mathbf{X}(\mathbf{X}^{\mathrm{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathrm{T}} \;,
\label{eq:P}
\end{equation}

with \(\mathbf{I}\) the \(n \times n\) identity matrix (matrix with ones on the diagonal and zeroes in all off-diagonal elements). The natural log of the residual likelihood can be computed by \citep{lar06}

\begin{equation}
\ell(\pmb{\theta}|\mathbf{z})=\mathrm{constant}-0.5(\mathrm{ln}|\mathbf{C}|+|\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{X}|+\mathbf{y}^{\mathbf{T}}\mathbf{C}^{-1}(\mathbf{I-\mathbf{Q}})\mathbf{z})) \;,
\label{eq:residualloglikhood}
\end{equation}

with \(\mathbf{Q} = \mathbf{X}(\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\mathbf{X})^{-1}\mathbf{X}^{\mathrm{T}}\mathbf{C}^{-1}\)

REML estimates of the semivariogram can be obtained with function \texttt{likfit} of package \textbf{geoR}, used above in ML estimation of the variogram \citep{geoR}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vgm\_REML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ x,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{100}\NormalTok{),}
  \AttributeTok{nugget =} \DecValTok{0}\NormalTok{, }\AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:ResidualVariogramEstimates}Estimated parameters of a spherical semivariogram for the residuals and estimated regression coefficients, obtained with iterative method-of-moments (iMoM) and restricted maximum likelihood (REML) estimation.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Parameter & iMoM & REML\\
\midrule
nugget & 0.000 & 0.000\\
partial sill & 2.137 & 1.909\\
range & 129.147 & 141.491\\
intercept & 3.255 & 3.083\\
x & 2.712 & 2.732\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:ResidualVariogramEstimates} shows that REML yields a smaller estimated (partial) sill and a larger estimated range than iterative MoM. Of the two regression coefficients especially the estimated intercept differs considerably among the two estimation methods.

Realising that this is a rather short introduction to kriging, I refer to \citet{isa89} for an introduction to geostatistics, to \citet{goo97} for an expos\(\acute{\text{e}}\) of the many versions of kriging, and to \citet{webster2007} for an elaborate explanation of kriging. A nice educational tool for getting a feeling for ordinary kriging is \href{https://wiki.52north.org/AI_GEOSTATS/SWEZKriging}{E\{Z\}-Kriging}.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5633432 300.9   12043445 643.2  12043445  643.2
Vcells 27383031 209.0   93547271 713.8 189381883 1444.9
\end{verbatim}

\hypertarget{MBgridspacing}{%
\chapter{Model-based optimisation of the grid spacing}\label{MBgridspacing}}

This is the first chapter on model-based sampling\footnote{Spatial response surface sampling can also be considered as model-based sampling, especially when a model-based criterion is used, see Chapter \ref{SpatialResponseSurface}.}. In Section \ref{SpatialCoverage} and Chapter \ref{kmeans} a geometric criterion is minimised, i.e.~a criterion defined in terms of distances, either in geographic space (Section \ref{SpatialCoverage}) or in covariate space (Chapter \ref{kmeans}). In model-based sampling the minimisation criterion is a function of the variance of the prediction errors.

This chapter on model-based sampling is about optimisation of the spacing of a square grid, i.e.~the distance between neighbouring points in the grid. The grid spacing is derived from a requirement on the accuracy of the map. Here and in following chapters I assume that the map is constructed by kriging, see Chapter \ref{Introkriging} for an introduction. As we have seen in Chapter \ref{Introkriging}, a kriging prediction of the study variable at an unobserved location is accompanied by a variance of the prediction error, referred to as the kriging variance. The map accuracy requirement is a population parameter of this kriging variance, e.g.~the population mean of the kriging variance.

\hypertarget{GridspacingOK}{%
\section{Optimal grid spacing for ordinary kriging}\label{GridspacingOK}}

Suppose that we require the population mean of the kriging variance not to exceed a given threshold. The question then is what the tolerable or maximum possible grid spacing is given this requirement. For finding the tolerable grid spacing\index{Tolerable grid spacing} we must have prior knowledge of the spatial variation. I first consider the situation in which it is reasonable to assume that the model-mean of the study variable is constant throughout the study area, but unknown. When the model-mean is unknown, ordinary kriging (OK) is used for mapping. Furthermore, we need a semivariogram of the study variable. In practice we often do not have a reliable estimate of the semivariogram. In the best case scenario we have some existing data, of sufficient quantity and suitable spatial distribution, that can be used to estimate the semivariogram. In other cases such data are lacking and a best guess of the semivariogram must be made, for instance using data for the same study variable from other, similar areas.

There is no simple equation that relates the grid spacing to the kriging variance. What can be done is to calculate the mean OK variance for a range of grid spacings, plot the mean ordinary kriging variances against the grid spacings, and use this plot inversely to determine the tolerable grid spacing, given a constraint on the mean OK variance.

In the next code chunks this procedure is used to compute the tolerable spacing of a square grid for mapping soil organic matter (SOM) in West-Amhara. The legacy data of the SOM concentration (dag kg\textsuperscript{-1}), used before to design a spatial infill sample (Section \ref{SpatialInfill}), are used here to estimate a semivariogram. A sample semivariogram is estimated by the method-of-moments (MoM), and a spherical model is fitted using functions of package \textbf{gstat} \citep{peb04}. The values for the partial sill, range, and nugget, passed to function \texttt{fit.variogram} with argument \texttt{model}, are guesses from an eyeball examination of the sample semivariogram obtained with function \texttt{variogram}, see Figure \ref{fig:variogramSOMEthiopia}. The ultimate estimates of the semivariogram parameters differ from these eyeball estimates. First, the projected coordinates of the sampling points are changed from m into km using function \texttt{mutate}\footnote{This is mainly done to avoid problems in (restricted) maximum likelihood estimation of the (residual) semivariogram with function \texttt{likfit} of package \textbf{geoR}}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{grdAmhara }\OtherTok{\textless{}{-}}\NormalTok{ grdAmhara }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\NormalTok{sampleAmhara }\OtherTok{\textless{}{-}}\NormalTok{ sampleAmhara }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{, }\AttributeTok{s2 =}\NormalTok{ s2 }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\FunctionTok{coordinates}\NormalTok{(sampleAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{vg }\OtherTok{\textless{}{-}} \FunctionTok{variogram}\NormalTok{(SOM }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ sampleAmhara)}
\NormalTok{model\_eye }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{range =} \DecValTok{40}\NormalTok{, }\AttributeTok{nugget =} \FloatTok{0.6}\NormalTok{)}
\NormalTok{vgm\_MoM }\OtherTok{\textless{}{-}} \FunctionTok{fit.variogram}\NormalTok{(vg, }\AttributeTok{model =}\NormalTok{ model\_eye)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/variogramSOMEthiopia-1} 

}

\caption{Sample semivariogram and fitted spherical model of the SOM concentration in West-Amhara, estimated from the legacy data.}\label{fig:variogramSOMEthiopia}
\end{figure}

The semivariogram of SOM can also be estimated by maximum likelihood (ML) using function \texttt{likfit} of package \textbf{geoR} \citep{geoR}, see Section \ref{VariogramEstimation}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{sampleAmhara }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(sampleAmhara)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(}
  \AttributeTok{obj =}\NormalTok{ sampleAmhara, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{),}
  \AttributeTok{data.col =} \StringTok{"SOM"}\NormalTok{)}
\NormalTok{vgm\_ML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \StringTok{"cte"}\NormalTok{,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{, }\DecValTok{40}\NormalTok{),}
  \AttributeTok{nugget =} \FloatTok{0.6}\NormalTok{, }\AttributeTok{lik.method =} \StringTok{"ML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Table \ref{tab:VariogramEstimatesEthiopia} shows the ML estimates of the parameters of the spherical semivariogram, together with the MoM estimates. Either could be used in the following steps.

\begin{table}

\caption{\label{tab:VariogramEstimatesEthiopia}Method-of-moments (MoM) and maximum likelihood (ML) estimates of the parameters of a spherical semivariogram of the SOM concentration in West-Amhara.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Parameter & MoM & ML\\
\midrule
nugget & 0.62 & 0.56\\
partial sill & 0.56 & 0.68\\
range & 45.40 & 36.90\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{controlling-the-mean-or-a-quantile-of-the-ordinary-kriging-variance}{%
\section{Controlling the mean or a quantile of the ordinary kriging variance}\label{controlling-the-mean-or-a-quantile-of-the-ordinary-kriging-variance}}

To decide on the grid spacing we may require the population mean of the kriging variance (MKV) not to exceed a given threshold. Instead of the population mean, we may use the population median or any other quantile of the cumulative distribution function of the kriging variance, for instance the 0.90 quantile (P90), as a quality criterion. Hereafter the ML semivariogram is used to optimise the grid spacing given a requirement on the mean, median, and P90 of the kriging variance.

As a first step a series of spacings of the square grid with observations is specified. Only spacings are considered which would result in expected sample sizes that are reasonable for kriging. With a spacing of 5 km the expected sample size is 434 points, with a spacing of 12 km these are 75 points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spacing }\OtherTok{\textless{}{-}} \DecValTok{5}\SpecialCharTok{:}\DecValTok{12}
\end{Highlighting}
\end{Shaded}

The next step is to select a simple random sample of evaluation points. It is important to select a large sample, so that the precision of the estimated population mean or quantile of the kriging variance will be high.

\begin{rmdnote}
To check whether the size of the simple random sample of evaluation points is sufficiently large, we may estimate the standard error of the estimator of the MKV, see Chapter \ref{SI}, substituting the kriging variances at the evaluation points for the study variable values.
\end{rmdnote}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ grdAmhara }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =} \DecValTok{5000}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =} \FloatTok{0.5}\NormalTok{),}
         \AttributeTok{s1 =}\NormalTok{ s1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{jitter}\NormalTok{(}\AttributeTok{amount =} \FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The \textbf{R} code below shows the next steps. Given a spacing, a square grid with a fixed starting point is selected with function \texttt{spsample}, using argument \texttt{offset}. A dummy variable is added to the data frame, having value 1 at all grid points, but any other value is also fine. The predicted value at all evaluation points equals 1. However, we are not interested in the predicted value but in the kriging variance only, and we have seen in Chapter \ref{Introkriging} that the kriging variance is independent of the observations of the study variable. The ML estimates of the semivariogram are used in function \texttt{vgm} to define a semivariogram model of class \texttt{variogramModel} that can be handled by function \texttt{krige}. For each grid spacing the population mean, median, and P90 of the kriging variance are estimated from the evaluation sample. The estimated median and P90 can be computed with function \texttt{quantile}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coordinates}\NormalTok{(mysample) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\FunctionTok{gridded}\NormalTok{(grdAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{MKV\_OK }\OtherTok{\textless{}{-}}\NormalTok{ P50KV\_OK }\OtherTok{\textless{}{-}}\NormalTok{ P90KV\_OK }\OtherTok{\textless{}{-}}\NormalTok{ samplesize }\OtherTok{\textless{}{-}} 
  \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(spacing))}
\NormalTok{vgm\_ML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{nugget,}
  \AttributeTok{psill =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{sigmasq, }\AttributeTok{range =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{phi)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(spacing))) \{}
\NormalTok{  mygrid }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdAmhara, }\AttributeTok{cellsize =}\NormalTok{ spacing[i],}
    \AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{  mygrid}\SpecialCharTok{$}\NormalTok{dummy }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{length}\NormalTok{(mygrid))}
\NormalTok{  samplesize[i] }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(mygrid)}
\NormalTok{  predictions  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ dummy }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{locations =}\NormalTok{ mygrid,}
    \AttributeTok{newdata =}\NormalTok{ mysample,}
    \AttributeTok{model =}\NormalTok{ vgm\_ML\_gstat,}
    \AttributeTok{nmax =} \DecValTok{100}\NormalTok{,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{  MKV\_OK[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var)}
\NormalTok{  P50KV\_OK[i] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var, }\AttributeTok{probs =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  P90KV\_OK[i] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var, }\AttributeTok{probs =} \FloatTok{0.9}\NormalTok{)}
\NormalTok{\}}
\NormalTok{dfKV\_OK }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(spacing, samplesize, MKV\_OK, P50KV\_OK, P90KV\_OK)}
\end{Highlighting}
\end{Shaded}

The estimated mean and quantiles of the kriging variance are plotted against the grid spacing (Figure \ref{fig:MOKVvsSpacingEthiopia}).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MOKVvsSpacingEthiopia-1} 

}

\caption{Mean, median (P50), and 0.90 quantile (P90) of the ordinary kriging variance of predictions of the SOM concentration in West-Amhara, as a function of the spacing of a square grid.}\label{fig:MOKVvsSpacingEthiopia}
\end{figure}

The tolerable grid spacing for the three quality indices can be computed with function \texttt{approx} of the \textbf{base} package, as shown below for the median kriging variance\index{Median kriging variance}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spacing\_tol\_P50 }\OtherTok{\textless{}{-}} \FunctionTok{approx}\NormalTok{(}\AttributeTok{x =}\NormalTok{ dfKV\_OK}\SpecialCharTok{$}\NormalTok{P50, }\AttributeTok{y =}\NormalTok{ dfKV\_OK}\SpecialCharTok{$}\NormalTok{spacing, }\AttributeTok{xout =} \FloatTok{0.8}\NormalTok{)}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

For a mean kriging variance of 0.8 (dag kg\textsuperscript{-1})\textsuperscript{2} the tolerable grid spacing is 8.6 km. For the median kriging variance this is 9.2 km, which is somewhat larger leading to a smaller sample size. The smaller grid spacing for the mean can be explained by the right-skewed distribution of the kriging variance, so that the mean kriging variance is larger than the median kriging variance. For the P90 of the kriging variance the tolerable grid spacing is much smaller, 6.9 km, leading to a much larger sample size.

\hypertarget{exercises-27}{%
\subsubsection*{Exercises}\label{exercises-27}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to determine the tolerable grid spacing so that the 0.50, 0.80, and 0.95 quantiles of the variance of OK predictions of SOM in West-Amhara do not exceed 0.85. Estimate the semivariogram by MoM.\\
\item
  In practice we are uncertain about the semivariogram. For this reason it can be wise to explore the sensitivity of the tolerable grid spacing for the semivariogram parameters.

  \begin{itemize}
  \tightlist
  \item
    Increase the nugget parameter of the MoM semivariogram by 5\%, and change the partial sill parameter so that the sill (nugget + partial sill) is unchanged. Compute the tolerable grid spacing and the corresponding required sample size for a mean kriging variance of 0.85 (dag kg\textsuperscript{-1})\textsuperscript{2}. Explain the difference.
  \item
    Reduce the range of the MoM semivariogram by 5\%. Reset the nugget and the partial sill to their original values. Compute the tolerable grid spacing and the corresponding required sample size for a mean kriging variance of 0.85 (dag kg\textsuperscript{-1})\textsuperscript{2}. Explain the difference.
  \end{itemize}
\end{enumerate}

\hypertarget{optimal-grid-spacing-for-block-kriging}{%
\section{Optimal grid spacing for block-kriging}\label{optimal-grid-spacing-for-block-kriging}}

In the previous section the tolerable grid spacing is derived from a constraint on the mean or quantile of the prediction error variances at points. The alternative is to put a constraint on the mean or quantile of the error variances of the predicted means of blocks. These means can be predicted with block-kriging\index{Kriging!block-kriging} (Section \ref{BlockKriging}). Block-kriging predictions can be obtained with function \texttt{krige} of package \textbf{gstat} using argument \texttt{block}. In the code chunk below the means of 100 m \(\times\) 100 m blocks are predicted by ordinary block-kriging.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MKV\_OBK }\OtherTok{\textless{}{-}}\NormalTok{ P50KV\_OBK }\OtherTok{\textless{}{-}}\NormalTok{ P90KV\_OBK }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(spacing))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(spacing))) \{}
\NormalTok{  mygrid }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdAmhara, }\AttributeTok{cellsize =}\NormalTok{ spacing[i],}
    \AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{  mygrid}\SpecialCharTok{$}\NormalTok{dummy }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{length}\NormalTok{(mygrid))}
\NormalTok{  samplesize[i] }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(mygrid)}
\NormalTok{  predictions  }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ dummy }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{locations =}\NormalTok{ mygrid,}
    \AttributeTok{newdata =}\NormalTok{ mysample,}
    \AttributeTok{model =}\NormalTok{ vgm\_ML\_gstat,}
    \AttributeTok{block =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
    \AttributeTok{nmax =} \DecValTok{100}\NormalTok{,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{  MKV\_OBK[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var)}
\NormalTok{  P50KV\_OBK[i] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var, }\AttributeTok{probs =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  P90KV\_OBK[i] }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var, }\AttributeTok{probs =} \FloatTok{0.9}\NormalTok{)}
\NormalTok{\}}
\NormalTok{dfKV\_OBK }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(spacing, MKV\_OBK, P50KV\_OBK, P90KV\_OBK)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:MOBKVvsSpacingEthiopia} shows that the mean, P50, and P90 of the block-kriging predictions are substantially smaller than those of the point-kriging predictions (Figure \ref{fig:MOKVvsSpacingEthiopia}). This can be explained by the large nugget of the semivariogram (Table \ref{tab:VariogramEstimatesEthiopia}). The side length of a prediction block (100 m) is much smaller than the range of the semivariogram (36.9 km), so that in this case the mean semivariance within a prediction block is about equal to the nugget. Roughly speaking, for a given grid spacing the mean point-kriging variance is reduced by an amount about equal to this mean semivariance to yield the mean block-kriging variance for this spacing (Section \ref{BlockKriging}). Recall that the mean semivariance within a block is a model-based prediction of the variance within a block (Subsection \ref{AnalyticalApproach}, Equation \eqref{eq:meansemivariance}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MOBKVvsSpacingEthiopia-1} 

}

\caption{Mean, median (P50), and 0.90 quantile (P90) of the ordinary block-kriging variance of predictions of the mean SOM concentration of blocks of 100 m \(\times\) 100 m, in West-Amhara, as a function of the spacing of a square grid.}\label{fig:MOBKVvsSpacingEthiopia}
\end{figure}

\hypertarget{MBgridspacingKED}{%
\section{Optimal grid spacing for kriging with an external drift}\label{MBgridspacingKED}}

In the previous sections I assumed a constant model-mean for the study variable. I now consider the case where covariates that are related to the study variable are available. A model is calibrated that is the sum of a linear combination of the covariates (spatial trend) and a spatially structured residual, see Equation \eqref{eq:KEDmodel2}. Predictions at the nodes of a fine grid are obtained by kriging with an external drift (KED).

The SOM concentration data of West-Amhara are used to estimate the parameters (regression coefficients and residual semivariogram parameters) of the model by restricted maximum likelihood\index{Restricted maximum likelihood estimation} (REML), see Subsection \ref{REML}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(}\AttributeTok{obj =}\NormalTok{ sampleAmhara, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{), }\AttributeTok{data.col =} \StringTok{"SOM"}\NormalTok{,}
  \AttributeTok{covar.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"dem"}\NormalTok{, }\StringTok{"rfl\_NIR"}\NormalTok{, }\StringTok{"rfl\_red"}\NormalTok{, }\StringTok{"lst"}\NormalTok{))}
\NormalTok{vgm\_REML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
  \AttributeTok{cov.model =} \StringTok{"spherical"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \AttributeTok{nugget =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:VariogramREMLEthiopia}Maximum likelihood (ML) estimates of the parameters of a spherical semivariogram for the SOM concentration and restricted maximum likelihood (REML) estimates of the parameters of a spherical semivariogram for the residuals of a multiple linear regression model, for West-Amhara.}
\centering
\begin{tabular}[t]{lrr}
\toprule
Parameter & ML & REML\\
\midrule
nugget & 0.56 & 0.36\\
partial sill & 0.68 & 0.44\\
range (km) & 36.91 & 5.24\\
\bottomrule
\end{tabular}
\end{table}

The total sill (partial sill + nugget) of the residual semivariogram, estimated by REML, equals 0.80, which is considerably smaller than that of the ML semivariogram of SOM (Table \ref{tab:VariogramREMLEthiopia}). A considerable part of the variance of SOM is explained by the covariates. Besides, note the much smaller range of the residual semivariogram. The smaller sill and range of the residual semivariogram show that the spatial structure of SOM is largely captured by the covariates. The residuals of the model-mean, which is a linear combination of the covariates, do not show much spatial structure anymore.

The mean kriging variance as obtained with KED is used as the evaluation criterion. With KED the kriging variance is also a function of the values of the covariates at the sampling locations and the prediction location (Section \ref{IntroKED}). Compared with the procedure above for OK, in the code chunk below a slightly different procedure is used. The square grid of a given spacing is randomly placed on the area (option \texttt{offset} in function \texttt{spsample} is not used), and this is repeated ten times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{MKV\_KED }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(spacing), }\AttributeTok{ncol =}\NormalTok{ R)}
\NormalTok{vgm\_REML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{nugget =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{nugget,}
  \AttributeTok{psill =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{sigmasq, }\AttributeTok{range =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{phi)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(spacing))) \{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R) \{}
\NormalTok{    mygrid }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ grdAmhara, }\AttributeTok{cellsize =}\NormalTok{ spacing[i], }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{)}
\NormalTok{    mygrid}\SpecialCharTok{$}\NormalTok{dummy }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{length}\NormalTok{(mygrid))}
\NormalTok{    mygrd }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{over}\NormalTok{(mygrid, grdAmhara), mygrid)}
    \FunctionTok{coordinates}\NormalTok{(mygrd) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{    predictions }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
      \AttributeTok{formula =}\NormalTok{ dummy }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
      \AttributeTok{locations =}\NormalTok{ mygrd,}
      \AttributeTok{newdata =}\NormalTok{ mysample,}
      \AttributeTok{model =}\NormalTok{ vgm\_REML\_gstat,}
      \AttributeTok{nmax =} \DecValTok{100}\NormalTok{,}
      \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
\NormalTok{    MKV\_KED[i, j] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(predictions}\SpecialCharTok{$}\NormalTok{var1.var)}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{dfKV\_KED }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(spacing, MKV\_KED)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MKEDVvsSpacingEthiopia-1} 

}

\caption{Mean kriging variance of OK and KED predictions of the SOM concentration in West-Amhara, as a function of the spacing of a square grid. With KED for each spacing ten MKV values are shown obtained by selecting ten randomly placed grids of that spacing.}\label{fig:MKEDVvsSpacingEthiopia}
\end{figure}

Figure \ref{fig:MKEDVvsSpacingEthiopia} shows the mean kriging variances, obtained with OK and KED, as a function of the grid spacing. Interestingly, for grid spacings smaller than about nine km, the mean kriging variance with KED is larger than with OK. In this case only for larger grid spacings KED outperforms OK in terms of the mean kriging variance. Only for mean kriging variances larger than about 0.82 (dag kg\textsuperscript{-1})\textsuperscript{2} we can afford with KED a larger grid spacing (smaller sample size) than with OK. Only with large spacings (small sample sizes) we profit from modelling the mean as a linear function of covariates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MMKV\_KED }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(dfKV\_KED[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\AttributeTok{FUN =}\NormalTok{ mean)}
\NormalTok{spacing\_tol\_KED }\OtherTok{\textless{}{-}} \FunctionTok{approx}\NormalTok{(}\AttributeTok{x =}\NormalTok{ MMKV\_KED, }\AttributeTok{y =}\NormalTok{ dfKV\_KED}\SpecialCharTok{$}\NormalTok{spacing, }\AttributeTok{xout =} \FloatTok{0.8}\NormalTok{)}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

The tolerable grid spacing for a mean kriging variance of 0.8 (dag kg\textsuperscript{-1})\textsuperscript{2}, using KED, equals 7.9 km.

\hypertarget{exercises-28}{%
\subsubsection*{Exercises}\label{exercises-28}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Given a grid spacing the mean kriging variance varies among randomly selected grids, especially for large spacings. Explain why.\\
\item
  Write an \textbf{R} script to compute the tolerable grid spacing for KED of natural logs of the electrical conductivity of the soil across the Cotton Research Farm of Uzbekistan, using natural logs of the electromagnetic induction (EM) measurements (lnEM100cm) as a covariate. Use a nugget of 0.126, a partial sill of 0.083, and a range of 230 m for an exponential semivariogram of the residuals (Table \ref{tab:TableVariogramsCRF4}). Select a simple random sample of size 1,000 of evaluation points from the discretisation grid with interpolated lnEM100cm values to compute the mean kriging variance. Do this by selecting 1,000 grid cells by simple random sampling with replacement and jittering the centres of the selected grid cells by an amount equal to half the size of the grid cell. Use as grid spacings \(70, 75, \dots, 100\) m. With a spacing of 100 m the number of grid points is about 100 (the farm has an area of about 97 ha). What is the tolerable grid spacing for a mean kriging variance of 0.165?
\end{enumerate}

\hypertarget{BayesianGridSpacing}{%
\section{Bayesian approach}\label{BayesianGridSpacing}}

In practice we do not know the semivariogram. In the best case we have prior data that can be used to estimate the semivariogram. However, even in this case we are uncertain about the semivariogram model (spherical, exponential, etc.) and the semivariogram parameters. \citet{Lark2017} showed how in a Bayesian approach\index{Bayesian approach!to grid spacing determination} we can account for uncertainty about the semivariogram parameters when we must decide on the grid spacing. In this approach a prior distribution of the semivariogram parameters is updated with the sample data to a posterior distribution \citep{Gelman2013}:

\begin{equation}
f(\pmb{\theta}|\mathbf{z}) = \frac{f(\pmb{\theta}) f(\mathbf{z}|\pmb{\theta})} {f(\mathbf{z})}\;,
\label{eq:BayesRule}
\end{equation}

with \(f(\pmb{\theta}|\mathbf{z})\) the posterior distribution function, i.e.~the probability density function of the semivariogram parameters given the sample data, \(f(\pmb{\theta})\) our prior belief\index{Prior belief} in the parameters specified by a probability density function, \(f(\mathbf{z}|\pmb{\theta})\) the likelihood\index{Likelihood} of the data, and \(f(\mathbf{z})\) the probability density function of the data. This probability density function \(f(\mathbf{z})\) is hard to obtain.

Problems with analytical derivation of the posterior distribution are avoided by selecting a large sample of units (vectors with semivariogram parameters) from the posterior distribution through Markov chain Monte Carlo (MCMC) sampling\index{Markov chain Monte Carlo sampling}, see Subsection \ref{MBpredSamplingVarBayes}.

In a Bayesian approach we must define the likelihood function of the data, see Subsection \ref{MBpredSamplingVarBayes}. I assume that the SOM concentration data in West-Amhara have a multivariate normal distribution, and that the spatial covariance of the data can be modelled by a spherical model, see Subsection \ref{MLestimationVariogram}. The likelihood is a function of the semivariogram parameters. Given a vector of semivariogram parameters, the variance-covariance matrix of the data is computed from the matrix with geographic distances between the sampling points. Inputs of the loglikelihood function \texttt{ll} are the matrix with distances between the sampling points, the design matrix \texttt{X}, and the vector with observations of the study variable \texttt{z}, see Subsection \ref{MBpredSamplingVarBayes}/

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{dist}\NormalTok{(sampleAmhara[,}\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{,}\StringTok{"s2"}\NormalTok{)]))}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(sampleAmhara), }\DecValTok{1}\NormalTok{)}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ sampleAmhara}\SpecialCharTok{$}\NormalTok{SOM}
\end{Highlighting}
\end{Shaded}

Besides the likelihood function, in a Bayesian approach we must define prior distributions for the semivariogram parameters. Here we combine the partial sill and nugget into the \emph{ratio of spatial dependence}\index{Ratio of spatial dependence}, i.e.~the proportion of the sill attributable to the partial sill. For the ratio of spatial dependence \(\xi\) and the distance parameter \(\phi\) I use uniform distributions as priors, with a lower bound of 0 and an upper bound of 1 for the ratio of spatial dependence, and a lower bound of \(10^{-6}\) km and an upper bound of 100 km for the range. A uniform distribution for the sill is not recommended \citep{Gelman2013}. Instead, I assume a uniform distribution for the \emph{inverse} of the sill, with a lower bound of \(10^{-6}\) and an upper bound of 2.

These priors can be defined by function \texttt{createUniformPrior} of package \textbf{BayesianTools} \citep{Hartig2018}. There are also functions to define a beta density function (commonly used as a prior for proportions) and a truncated normal distribution as a prior. Function \texttt{createBayesianSetup} is then used to define the setup of the MCMC sampling, specifying the likelihood function, the prior, and the vector with best prior estimates of the model parameters, specified with argument \texttt{best}. The ML estimates computed in Section \ref{GridspacingOK} are used as starting values for the inverse of the sill parameter, the ratio of spatial dependence, and the range.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BayesianTools)}
\NormalTok{priors }\OtherTok{\textless{}{-}} \FunctionTok{createUniformPrior}\NormalTok{(}
  \AttributeTok{lower =} \FunctionTok{c}\NormalTok{(}\FloatTok{1E{-}6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{1E{-}6}\NormalTok{), }\AttributeTok{upper =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{100}\NormalTok{))}
\NormalTok{sill\_ML }\OtherTok{\textless{}{-}}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{nugget }\SpecialCharTok{+}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{sigmasq}
\NormalTok{thetas\_ML }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ sill\_ML, vgm\_ML}\SpecialCharTok{$}\NormalTok{sigmasq }\SpecialCharTok{/}\NormalTok{ sill\_ML, vgm\_ML}\SpecialCharTok{$}\NormalTok{phi)}
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"Sph"}
\NormalTok{setup }\OtherTok{\textless{}{-}} \FunctionTok{createBayesianSetup}\NormalTok{(}\AttributeTok{likelihood =}\NormalTok{ ll, }\AttributeTok{prior =}\NormalTok{ priors,}
  \AttributeTok{best =}\NormalTok{ thetas\_ML, }\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{"lambda"}\NormalTok{, }\StringTok{"xi"}\NormalTok{, }\StringTok{"range"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

A sample from the posterior distribution of the semivariogram parameters is then obtained with function \texttt{runMCMC}. Various sampling algorithms are implemented in package \textbf{BayesianTools}. I used the default sampler \texttt{DEzs}, which is based on the differential evolution Markov chain \citep{terBraak2008}. This algorithm is passed to function \texttt{runMCMC} with argument \texttt{sampler}. It is common not to use all sampled units, but to discard the units of the burn-in period that are possibly influenced by the initial arbitrary settings, and to thin the series of units after this period. The extraction of the ultimate sample is done with function \texttt{getSample}. Argument \texttt{start} specifies the unit where the extraction starts, and argument \texttt{numSamples} specifies how many units are selected through systematic sampling of the full MCMC sample. The alternative is to use argument \texttt{thin} which defines the thinning interval.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{runMCMC}\NormalTok{(setup, }\AttributeTok{sampler =} \StringTok{"DEzs"}\NormalTok{)}
\NormalTok{mcmcsample }\OtherTok{\textless{}{-}} \FunctionTok{getSample}\NormalTok{(res, }\AttributeTok{start =} \DecValTok{1000}\NormalTok{, }\AttributeTok{numSamples =} \DecValTok{1000}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Table \ref{tab:MCMCSampleVariogram} shows the first ten units of the MCMC sample from the posterior distribution of the semivariogram parameters.

\begin{table}

\caption{\label{tab:MCMCSampleVariogram}First ten units of a MCMC sample from the posterior distribution of the parameters of a spherical semivariogram for the SOM concentration in West-Amhara.}
\centering
\begin{tabular}[t]{rrr}
\toprule
Inverse of sill & Ratio of spatial dependence & Range (km)\\
\midrule
0.624 & 0.655 & 55.0\\
0.828 & 0.588 & 33.3\\
0.769 & 0.480 & 51.9\\
0.624 & 0.655 & 55.0\\
0.872 & 0.538 & 47.2\\
0.559 & 0.643 & 60.6\\
0.605 & 0.690 & 66.8\\
0.764 & 0.585 & 42.7\\
0.793 & 0.608 & 44.8\\
0.480 & 0.741 & 87.1\\
\bottomrule
\end{tabular}
\end{table}

The units of the MCMC sample (vectors with semivariogram parameters) are used one-by-one to compute the average of the kriging variances at the simple random sample of evaluation points.

For each unit in the MCMC sample the tolerable grid spacing is computed for a target MKV of 0.8. Figure \ref{fig:HistogramTolerableSpacing} shows that for most sampled semivariograms (MCMC sample units) the tolerable grid spacing equals 8 km, which roughly corresponds with the tolerable grid spacing derived above for OK. For 165 sampled semivariograms the tolerable grid spacing exceeds 12 km. However, this grid spacing leads to a sample size that is too small for estimating the semivariogram and kriging.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/HistogramTolerableSpacing-1} 

}

\caption{Frequency distribution of tolerable grid spacings for a target MKV of 0.8.}\label{fig:HistogramTolerableSpacing}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/ProportionMCMCSamples-1} 

}

\caption{Proportion of sampled semivariograms with a MKV smaller than or equal to a target MKV of 0.8.}\label{fig:ProportionMCMCSamples}
\end{figure}

Finally, for each grid spacing the proportion of MCMC samples with a MKV smaller than or equal to the target MKV of 0.8 is computed. Figure \ref{fig:ProportionMCMCSamples} shows, for instance, that if we require a probability of 80\% that the MKV does not exceed the target MKV of 0.8, the tolerable grid spacing is 6.6 km. With a grid spacing of 8.6 km, as determined before, the probability that the MKV exceeds 0.8 is 54\%.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5715712 305.3   12043445 643.2  12043445  643.2
Vcells 27526190 210.1   93569045 713.9 189381883 1444.9
\end{verbatim}

\hypertarget{MBSamplePattern}{%
\chapter{Model-based optimisation of the sampling pattern}\label{MBSamplePattern}}

In Chapter \ref{MBgridspacing} a model of the spatial variation is used to optimise the spacing of a regular grid. The grid spacing determines the number of grid points within the study area, so optimisation of the grid spacing is equivalent to optimisation of the sample size of a square grid.

This chapter is about optimisation of the spatial coordinates of the sampling units \emph{given the sample size}. So, we are searching for the optimal spatial sampling pattern of a fixed number of sampling units. The constraint of sampling on a regular grid is dropped. In general the optimal spatial sampling pattern is irregular. Similar to spatial coverage sampling (Section \ref{SpatialCoverage}), we search for the optimal sampling pattern through minimisation of an explicit criterion. In spatial coverage sampling the minimisation criterion is the mean squared shortest distance (MSSD) which is minimised by k-means. In this chapter the minimisation criterion is the mean kriging variance (MKV) or a quantile of the kriging variance. Algorithm k-means cannot be used for minimising this criterion as it uses (standardised) distances between cluster centres (the sampling locations) and the nodes of a discretisation grid, and the kriging variance is not a simple linear function of these distances. A different optimisation algorithm is needed. Here spatial simulated annealing\index{Simulated annealing} is used which is explained in the next subsection. Non-spatial simulated annealing was used before in conditioned Latin hypercube sampling using package \textbf{clhs} (Chapter \ref{cLHS}).

\hypertarget{SSA}{%
\section{Spatial simulated annealing}\label{SSA}}

Inspired by the potentials of optimisation through simulated annealing \citep{Kirkpatrick1983}, \citet{vgr98} proposed to optimise the sampling pattern by spatial simulated annealing (SSA), see also \citet{vgr99} and \citet{vgr00}. This is an iterative, random search procedure, in which a sequence of samples is generated. A new sample (proposed sample) is obtained by slightly modifying the current sample. One sampling location of the current sample is randomly selected, and this location is shifted to a random location within the neighbourhood of the selected location.

The minimisation criterion is computed for the proposed sample and compared with that of the current sample. If the criterion of the proposed sample is smaller, the sample is accepted. If the criterion is larger, the sample is accepted with a probability equal to

\begin{equation}
P = e^{\frac{-\Delta}{T}}\;,
\label{eq:AcceptanceProb}
\end{equation}

with \(\Delta\) the increase of the criterion and \(T\) the ``temperature''.

\begin{rmdnote}
The name of this parameter shows the link with annealing in metallurgy. Annealing is a heat treatment of a material above its recrystallisation temperature. Simulated annealing mimics the gradual cooling of metal alloys, resulting in an optimum or near-optimum structure of the atoms in the alloy.
\end{rmdnote}

The larger the value of \(T\), the larger the probability that a proposed sample with a given increase of the criterion is accepted (Figure \ref{fig:AcceptanceProbabilitySSA}). The temperature \(T\) is stepwise decreased during the optimisation: \(T_{k+1} = \alpha T_k\). In Figure \ref{fig:AcceptanceProbabilitySSA} \(\alpha\) equals 0.9. The effect of decreasing the temperature is that the acceptance probability of worse samples decreases during the optimisation and approaches 0 towards the end of the optimisation. Note that the temperature remains constant during a number of iterations, referred to as the chain length\index{Chain length}. In Figure \ref{fig:AcceptanceProbabilitySSA} this chain length equals 100 iterations. Finally, a stopping criterion is required. Various stopping criteria are possible; one option is to set the maximum numbers of chains with no improvement. \(T, \alpha\), the chain length, and the stopping criterion are annealing schedule parameters that must be chosen by the user.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/AcceptanceProbabilitySSA-1} 

}

\caption{Acceptance probability as a function of the change in the mean kriging variance (MKV) used as a minimisation criterion, and cooling schedule in spatial simulated annealing. For negative changes (MKV of proposed sample smaller than of current sample) the acceptance probability equals 1.}\label{fig:AcceptanceProbabilitySSA}
\end{figure}

\hypertarget{SamplePatternOK}{%
\section{Optimising the sampling pattern for ordinary kriging}\label{SamplePatternOK}}

In ordinary kriging (OK) we assume a constant model-mean. No covariates are available that are related to the study variable. Optimisation of the sampling pattern for OK is illustrated with the Cotton Research Farm in Uzbekistan which was used before to illustrate spatial response surface sampling (Chapter \ref{SpatialResponseSurface}). The spatial coordinates of 50 sampling locations are optimised for mapping of the soil salinity (as measured by the electrical conductivity, ECe, of the soil) by OK. In this section the coordinates of the sampling points are optimised for OK. In Section \ref{SamplePatternKED} this is done for kriging with an external drift. In that section a map of interpolated electromagnetic induction (EM) measurements is used to further optimise the coordinates of the sampling points.

Model-based optimisation of the sampling pattern for OK requires as input a semivariogram of the study variable. For the Cotton Research Farm I used the ECe (dS m\textsuperscript{-1}) data collected in eight surveys in the period 2008 - 2011 at 142 points to estimate this semivariogram \citep{Akramkhanov2014}. The ECe data are natural-log transformed. The sample semivariogram is shown in Figure \ref{fig:variogramlnECe}. The \textbf{R} code below shows how I fitted the semivariogram model with function \texttt{nls} (``non-linear least squares'') of the \textbf{stat} package. I did not use function \texttt{fit.variogram} of the \textbf{gstat} package \citep{peb04}, because this function requires the output of function \texttt{variogram} as input, whereas the sample semivariogram is here computed in a different way.

\begin{rmdnote}
The sample semivariogram is computed by first estimating sample semivariograms for each of the eight surveys separately, followed by computing weighted averages of semivariances and distances per lag, using the numbers of pairs as weights (\textbf{R} code not shown).
\end{rmdnote}

The semivariogram parameters as estimated by \texttt{nls} are then used to define a semivariogram model of class \texttt{variogramModel} of package \textbf{gstat}, using function \texttt{vgm}. This is done because function \texttt{optimMKV} requires a semivariogram model of this class, see hereafter. As already mentioned in Chapter \ref{MBgridspacing}, in practice we often do not have legacy data from which we can estimate the semivariogram, and a best guess of the semivariogram then must be made.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{res\_nls }\OtherTok{\textless{}{-}} \FunctionTok{nls}\NormalTok{(semivar }\SpecialCharTok{\textasciitilde{}}\NormalTok{ nugget }\SpecialCharTok{+}\NormalTok{ psill }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{h }\SpecialCharTok{/}\NormalTok{ range)),}
  \AttributeTok{start =} \FunctionTok{list}\NormalTok{(}\AttributeTok{nugget =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{psill =} \FloatTok{0.4}\NormalTok{, }\AttributeTok{range =} \DecValTok{200}\NormalTok{), }\AttributeTok{weights =}\NormalTok{ somnp)}
\NormalTok{vgm\_lnECe }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{nugget =} \FunctionTok{coef}\NormalTok{(res\_nls)[}\DecValTok{1}\NormalTok{],}
  \AttributeTok{psill =} \FunctionTok{coef}\NormalTok{(res\_nls)[}\DecValTok{2}\NormalTok{], }\AttributeTok{range =} \FunctionTok{coef}\NormalTok{(res\_nls)[}\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/variogramlnECe-1} 

}

\caption{Sample semivariogram and fitted exponential model of lnECe at the Cotton Research Farm.}\label{fig:variogramlnECe}
\end{figure}

The estimated semivariogram parameters are shown in Table \ref{tab:TableVariogramsCRF4}. The nugget-to-sill ratio\index{Nugget-to-sill ratio} is about 1/4, and the effective range\index{Effective range} is about 575 m (three times the distance parameter of an exponential model).

The coordinates of the sampling points are optimised with function \texttt{optimMKV} of package \textbf{spsann} \citep{Alessandro2016}\footnote{At the moment of writing this book package \textbf{spsann} is not available on CRAN. I have added the file \texttt{spsann\_2.2.0.tar.gz} to the folder \texttt{Rscripts} of the github repository of this book. In this folder you can also find a the file \texttt{pedometrics\_0.7.0.tar.gz} which is a dependency of \texttt{spsann}. The packages can be installed with \textbf{RStudio} by selecting ``Package Archive File (.zip; .tar.gz)'' from the drop-down list in the field ``Install from:''.} First, the candidate sampling points are specified by the nodes of a grid discretising the population. As explained hereafter, this does not necessarily imply that the population is treated as a finite population. Next, the parameters of the annealing schedule are set. Note that both the initial acceptance rate and the initial temperature are set, which may seem weird as the acceptance rate is a function of the temperature, see Equation \eqref{eq:AcceptanceProb}. The initial acceptance rate is used as a threshold value. The optimisation stops when an initial temperature is chosen that leads to an acceptance rate smaller than the chosen value for the initial acceptance rate. In this case a larger value for the initial temperature must be chosen. Arguments \texttt{chain.length} and \texttt{stopping} of function \texttt{scheduleSPSANN} are multipliers. So, for a chain length of five, the number of iterations equals \(5n\), with \(n\) the sample size.

During the optimisation a sample is perturbed by replacing one randomly selected point of the current sample by a new point. This selection of the new point is done in two steps. In the first step one node of the discretisation grid (specified with argument \texttt{candi}) is randomly selected. Only the nodes within a neighbourhood defined by \texttt{x.min}, \texttt{x.max}, \texttt{y.min}, and \texttt{y.max} can be selected. The nodes within this neighbourhood have equal probability of being selected. In the second step one point is selected within a grid cell with the selected node at its centre and a side length specified with argument \texttt{cellsize}. So, it is natural to set \texttt{cellsize} to the spacing of the discretisation grid. With \texttt{cellsize\ =\ 0} the sampling points are restricted to the nodes of the discretisation grid.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spsann)}
\NormalTok{candi }\OtherTok{\textless{}{-}}\NormalTok{ grdCRF[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)]}
\NormalTok{schedule }\OtherTok{\textless{}{-}} \FunctionTok{scheduleSPSANN}\NormalTok{(}
  \AttributeTok{initial.acceptance =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{initial.temperature =} \FloatTok{0.004}\NormalTok{, }\AttributeTok{temperature.decrease =} \FloatTok{0.95}\NormalTok{,}
  \AttributeTok{chains =} \DecValTok{500}\NormalTok{, }\AttributeTok{chain.length =} \DecValTok{2}\NormalTok{, }\AttributeTok{stopping =} \DecValTok{10}\NormalTok{, }\AttributeTok{cellsize =} \DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \textbf{R} code for optimising the sampling pattern is as follows.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimMKV}\NormalTok{(}
  \AttributeTok{points =} \DecValTok{50}\NormalTok{, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{vgm =}\NormalTok{ vgm\_lnECe, }\AttributeTok{eqn =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
  \AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }
  \AttributeTok{plotit =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{track =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{mysample }\OtherTok{\textless{}{-}}\NormalTok{ candi[res}\SpecialCharTok{$}\NormalTok{points}\SpecialCharTok{$}\NormalTok{id, ]}
\NormalTok{trace }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{objective}\SpecialCharTok{$}\NormalTok{energy}
\end{Highlighting}
\end{Shaded}

The spatial pattern of the sample in Figure \ref{fig:ModelBasedSampleOK} and the trace of the MKV in Figure \ref{fig:TraceMOKV} suggest that we are close to the global optimum.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ModelBasedSampleOK-1} 

}

\caption{Optimised sampling pattern for the mean variance of OK predictions of lnECe (model-based sample) and spatial coverage sample of the Cotton Research Farm.}\label{fig:ModelBasedSampleOK}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/TraceMOKV-1} 

}

\caption{Trace of the mean ordinary kriging variance (MOKV).}\label{fig:TraceMOKV}
\end{figure}

For comparison I also computed a spatial coverage sample of the same size. The spatial patterns of the two samples are quite similar (Figure \ref{fig:ModelBasedSampleOK}). The MKV of the spatial coverage sample equals 0.2633 (dS m\textsuperscript{-1})\textsuperscript{2}, whereas for the model-based sample the MKV equals 0.2642 (dS m\textsuperscript{-1})\textsuperscript{2}. So, no gain in precision is achieved by the model-based optimisation of the sampling pattern compared to spatial coverage sampling. With \texttt{cellsize\ =\ 0} the minimised MKV is slightly smaller: 0.2578 (dS m\textsuperscript{-1})\textsuperscript{2}. This outcome is in agreement with the results reported by \citet{bru07c}.

Instead of the mean OK variance (MOKV), we may prefer to use some quantile of the cumulative distribution function of the OK variance as a minimisation criterion. For instance, if we use the 0.90 quantile as criterion, we are searching for the sampling locations so that the 90th percentile (P90) of the OK variance is minimal. This can be done with function \texttt{optimUSER} of package \textbf{spsann}. The objective function\index{Objective function} to be minimised can be passed to this function with argument \texttt{fun}. In this case the objective function is as follows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{QOKV }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(points, esample, model, nmax, prob) \{}
\NormalTok{  points }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(points)}
  \FunctionTok{coordinates}\NormalTok{(points) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ y}
\NormalTok{  points}\SpecialCharTok{$}\NormalTok{dum }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{krige}\NormalTok{(}
    \AttributeTok{formula =}\NormalTok{ dum }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{locations =}\NormalTok{ points,}
    \AttributeTok{newdata =}\NormalTok{ esample,}
    \AttributeTok{model =}\NormalTok{ model,}
    \AttributeTok{nmax =}\NormalTok{ nmax,}
    \AttributeTok{debug.level =} \DecValTok{0}\NormalTok{)}
  \FunctionTok{quantile}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{var1.var, }\AttributeTok{probs =}\NormalTok{ prob)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The next code chunk shows how this objective function can be minimised.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myevalsample }\OtherTok{\textless{}{-}}\NormalTok{ candi}
\FunctionTok{coordinates}\NormalTok{(myevalsample) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ y}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimUSER}\NormalTok{(}
  \AttributeTok{points =} \DecValTok{50}\NormalTok{, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{fun =}\NormalTok{ QOKV,}
  \AttributeTok{esample =}\NormalTok{ myevalsample,}
  \AttributeTok{model =}\NormalTok{ vgm\_lnECe,}
  \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.9}\NormalTok{,}
  \AttributeTok{schedule =}\NormalTok{ schedule)}
\end{Highlighting}
\end{Shaded}

Argument \texttt{esample} specifies a \texttt{SpatialPoints} object with the evaluation points\index{Evaluation point}, i.e.~the points at which the kriging variance is computed. Above I used all candidate sampling points as evaluation points. Computing time can be reduced by selecting a coarser square grid with evaluation points. The number of points used in kriging is specified with argument \texttt{nmax}, and the probability of the cumulative distribution function of the kriging variance is specified with argument \texttt{prob}. Optimisation of the sampling pattern for a quantile of the ordinary kriging variance is left as an exercise.

\hypertarget{exercises-29}{%
\subsubsection*{Exercises}\label{exercises-29}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to optimise the spatial coordinates of sixteen points in a square for OK. First create a discretisation grid of 20 \(\times\) 20 nodes. Use an exponential semivariogram without nugget, with a sill of 2, and a distance parameter of four times the spacing of the discretisation grid. Optimise the sampling pattern with SSA (using functions \texttt{scheduleSPSANN} and \texttt{optimMKV} of package \textbf{spsann}).

  \begin{itemize}
  \tightlist
  \item
    Check whether the optimisation has converged by plotting the trace of the optimisation criterion MKV.
  \item
    Based on the coordinates of the sampling points, do you think the sample is the global optimum, i.e.~the sample with the smallest possible MKV?\\
  \end{itemize}
\item
  Write an \textbf{R} script to optimise the sampling pattern of 50 points, using the P90 of the variance of OK predictions of lnECe on the Cotton Research Farm as a minimisation criterion. Use the semivariogram parameters of Table \ref{tab:TableVariogramsCRF4}. Compare the optimised sample with the sample optimised with the mean OK variance (shown in Figure \ref{fig:ModelBasedSampleOK}).
\end{enumerate}

\hypertarget{SamplePatternKED}{%
\section{Optimising the sampling pattern for kriging with an external drift}\label{SamplePatternKED}}

If we have one or more covariates that are linearly related to the study variable, the study variable can be mapped by kriging with an external drift\index{Kriging!kriging with an external drift} (KED). A requirement is that we have maps of the covariates so that, once we have estimated the parameters of the model for KED from the data collected at the optimised sample, these covariate maps can be used to map the study variable (see Equation \eqref{eq:KEDvariance2}).

Optimisation of the sampling pattern for KED requires as input the semivariogram of the residuals. Besides, we must decide on the covariates for the model-mean. Note that we do not need estimates of the regression coefficients associated with the covariates as input, but just which combination of covariates we want to use for modelling the model-mean of the study variable.

Optimisation of the sampling pattern for KED is illustrated with the Cotton Research Farm. The interpolated natural log of the EM data (with transmitter at 1 m) is used as a covariate, see Figure \ref{fig:EMdataUzbekistan}. The data for fitting the model are in data file \texttt{sampleCRF}. The parameters of the residual semivariogram are estimated by restricted maximum likelihood (REML), see Subsection \ref{REML}.

At several points multiple pairs of observations of the study variable ECe and the covariate EM have been made. These calibration data have exactly the same spatial coordinates. This leads to problems with REML estimation. The covariance matrix is not positive definite, so that it cannot be inverted. To solve this problem I jittered the coordinates of the sampling points by a small amount.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(geoR)}
\NormalTok{sampleCRF}\SpecialCharTok{$}\NormalTok{lnEM100 }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(sampleCRF}\SpecialCharTok{$}\NormalTok{EMv1m)}
\NormalTok{sampleCRF}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(sampleCRF}\SpecialCharTok{$}\NormalTok{x, }\AttributeTok{amount =} \FloatTok{0.001}\NormalTok{)}
\NormalTok{sampleCRF}\SpecialCharTok{$}\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(sampleCRF}\SpecialCharTok{$}\NormalTok{y, }\AttributeTok{amount =} \FloatTok{0.001}\NormalTok{)}
\NormalTok{dGeoR }\OtherTok{\textless{}{-}} \FunctionTok{as.geodata}\NormalTok{(}\AttributeTok{obj =}\NormalTok{ sampleCRF, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{coords.col =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{), }\AttributeTok{data.col =} \StringTok{"lnECe"}\NormalTok{, }\AttributeTok{covar.col =} \StringTok{"lnEM100"}\NormalTok{)}
\NormalTok{vgm\_REML }\OtherTok{\textless{}{-}} \FunctionTok{likfit}\NormalTok{(}\AttributeTok{geodata =}\NormalTok{ dGeoR, }\AttributeTok{trend =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ lnEM100,}
  \AttributeTok{cov.model =} \StringTok{"exponential"}\NormalTok{, }\AttributeTok{ini.cov.pars =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DecValTok{200}\NormalTok{),}
  \AttributeTok{nugget =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{lik.method =} \StringTok{"REML"}\NormalTok{, }\AttributeTok{messages =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The REML estimates of the parameters of the residual semivariogram\index{Residual semivariogram} are shown in Table \ref{tab:TableVariogramsCRF4}. The estimated sill (sum of nugget and partial sill) of the residual semivariogram is substantially smaller than that of lnECe, showing that the linear model for the model-mean explains a considerable part of the spatial variation of lnECe.

\begin{table}

\caption{\label{tab:TableVariogramsCRF4}Estimated parameters of an exponential semivariogram for lnECe (estimated by method-of-moments) and for the residuals of a linear regression model for lnECe using lnEM100cm as a predictor (estimated by REML).}
\centering
\begin{tabular}[t]{lrrr}
\toprule
Variable & Nugget & Partial sill & Distance parameter (m)\\
\midrule
lnECe & 0.116 & 0.336 & 192\\
residuals & 0.126 & 0.083 & 230\\
\bottomrule
\end{tabular}
\end{table}

To optimise the sampling pattern for KED, using the mean KED variance as a minimisation criterion, a data frame with the covariates at the candidate sampling points must be specified with argument \texttt{covars}. The formula for the model-mean is specified with argument \texttt{eqn}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimMKV}\NormalTok{(}
  \AttributeTok{points =} \DecValTok{50}\NormalTok{, }\AttributeTok{candi =}\NormalTok{ candi, }\AttributeTok{covars =}\NormalTok{ grdCRF,}
  \AttributeTok{vgm =}\NormalTok{ vgm\_REML\_gstat, }\AttributeTok{eqn =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lnEM100cm,}
  \AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{nmax =} \DecValTok{20}\NormalTok{,}
  \AttributeTok{plotit =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{track =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:ModelBasedSampleKED} shows the optimised locations of a sample of 50 points. This clearly shows the irregular spatial pattern of the sampling points induced by the covariate lnEM100cm.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ModelBasedSampleKED-1} 

}

\caption{Optimised sampling pattern for KED of lnECe at the Cotton Research Farm, using lnEM100cm as a covariate.}\label{fig:ModelBasedSampleKED}
\end{figure}

Comparing the population and sample histograms of the covariate clearly shows that locations with small and locations with large values for the covariate are preferentially selected (Figure \ref{fig:histogramslnEM}). The optimised sampling pattern is a compromise between spreading in geographic space and covariate space, see also \citet{heu07} and \citet{bru07}. More precisely, locations are selected by spreading them out throughout the study area, while accounting for the values of the covariates at the selected locations, in a way that locations with covariate values near the minimum and maximum are preferred. This can be explained by noting that the variance of the KED prediction error can be decomposed into two components: the variance of the interpolated residuals and the variance of the estimator of the model-mean, see Section \ref{IntroKED}. The contribution of the first variance component is minimised through geographical spreading, that of the second component by selecting locations with covariate values near the minimum and maximum.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/histogramslnEM-1} 

}

\caption{Sample histogram and population histogram of lnEM100cm used as covariate in model-based optimisation of the sampling pattern for mapping with KED.}\label{fig:histogramslnEM}
\end{figure}

\begin{rmdnote}
A sample with covariate values close to the minimum and maximum only is not desirable if we do not want to rely on the assumption of a linear relation between the study variable and the covariates. To identify a non-linear relation, locations with intermediate covariate values are needed. Optimisation using a semivariogram with clear spatial structure leads to geographical spreading of the sampling units, so that most likely also locations with intermediate covariate values are selected.
\end{rmdnote}

When one or more covariates are used in optimisation of the sampling pattern but not used in KED once the data are collected, the sample is suboptimal for the model used in prediction. Inversely, ignoring a covariate in optimisation of the sampling pattern while using this covariate as a predictor also leads to suboptimal samples. The selection of covariates to be used in sampling design therefore should be done with care. Besides, as we will see in the next exercise, the nugget of the residual semivariogram has a strong effect on the optimised sampling pattern\index{Sampling pattern}, stressing the importance of a reliable prior estimate of this semivariogram parameter.

\hypertarget{exercises-30}{%
\subsubsection*{Exercises}\label{exercises-30}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write an \textbf{R} script to optimise the sampling pattern of sixteen points in a square for KED. Use the \(x\)-coordinate as a covariate. First create a discretisation grid of 20 \(\times\) 20 nodes. Use an exponential residual semivariogram without nugget, with a sill of 2, and a distance parameter of four times the spacing of the discretisation grid. Optimise the sampling pattern with SSA (using functions \texttt{scheduleSPSANN} and \texttt{optimMKV} of package \textbf{spsann}).

  \begin{itemize}
  \tightlist
  \item
    What do you think of the spatial coverage of the optimised sample? Compare the sample with the optimised sample for OK, see exercise of Section \ref{SamplePatternOK}.
  \item
    Repeat the optimisation using a residual semivariogram with a nugget of 1.5 and a partial sill of 0.5. Note that the sill is again 2, as before.
  \item
    Compare the optimised sample with the previous sample. What is the most striking difference?
  \item
    How will the optimised sample look like with a pure nugget semivariogram? Check your assumption using such semivariogram in SSA.
  \end{itemize}
\end{enumerate}

\hypertarget{model-based-infill-sampling-for-ordinary-kriging}{%
\section{Model-based infill sampling for ordinary kriging}\label{model-based-infill-sampling-for-ordinary-kriging}}

Similar to spatial infill sampling using MSSD as a minimisation criterion (Section \ref{SpatialInfill}), we may design a model-based infill sample. Package \textbf{spsann} can be used for this, using argument \texttt{points} of function \texttt{optimMKV}.

In Section \ref{GridspacingOK} the legacy data of West-Amhara were used to estimate the parameters of a spherical semivariogram for the SOM concentration. The estimated parameters are shown in Table \ref{tab:VariogramEstimatesEthiopia}. The maximum likelihood estimates are used in this section to optimise the spatial coordinates of the infill sample.

In the next code chunk a list is created, containing a data frame with the coordinates of the fixed points (specified with sub-argument \texttt{fixed}) and an integer of the number of additional points to be selected (specified with sub-argument \texttt{free}). The list is passed to function \texttt{optimMKV} with argument \texttt{points}. For kriging I reduced the number of legacy points by keeping one point only per grid cell of 1 km \(\times\) 1 km. This is done with function \texttt{remove.duplicates} of package \textbf{sp}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{coordinates}\NormalTok{(sampleAmhara) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{legacy }\OtherTok{\textless{}{-}} \FunctionTok{remove.duplicates}\NormalTok{(sampleAmhara, }\AttributeTok{zero =} \DecValTok{1}\NormalTok{, }\AttributeTok{remove.second =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{pnts }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{fixed =} \FunctionTok{coordinates}\NormalTok{(legacy), }\AttributeTok{free =} \DecValTok{100}\NormalTok{)}
\NormalTok{candi }\OtherTok{\textless{}{-}}\NormalTok{ grdAmhara[, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)]}
\FunctionTok{names}\NormalTok{(candi) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The number of points used in kriging can be passed to function \texttt{optimMKV} with argument \texttt{nmax}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{vgm\_ML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{sigmasq,}
  \AttributeTok{range =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{phi, }\AttributeTok{nugget =}\NormalTok{ vgm\_ML}\SpecialCharTok{$}\NormalTok{nugget)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimMKV}\NormalTok{(}
  \AttributeTok{points =}\NormalTok{ pnts, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{vgm =}\NormalTok{ vgm\_ML\_gstat, }\AttributeTok{eqn =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
  \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{track =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{infillSample }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{points }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(free }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:ModelBasedInfill} shows a model-based infill sample of 100 points for OK of the soil organic matter (SOM) concentration (dag kg\textsuperscript{-1}) throughout West-Amhara. Comparison of the model-based infill sample with the spatial infill sample of Figure \ref{fig:spatialinfillEthiopia} shows that in a wider zone on both sides of the roads no new sampling points are selected. This can be explained by the large range, 36.9 km, of the semivariogram.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ModelBasedInfill-1} 

}

\caption{Model-based infill sample for OK of the SOM concentration throughout West-Amhara. Legacy units have free-value 0, infill units have free-value 1.}\label{fig:ModelBasedInfill}
\end{figure}

\hypertarget{model-based-infill-sampling-for-kriging-with-an-external-drift}{%
\section{Model-based infill sampling for kriging with an external drift}\label{model-based-infill-sampling-for-kriging-with-an-external-drift}}

For West-Amhara maps of covariates are available that can be used in KED, see Section \ref{MBgridspacingKED}. The prediction error variance with KED is partly determined by the covariate values (see Section \ref{SamplePatternKED}), and therefore, when filling in the undersampled areas, locations with extreme values for the covariates are preferably selected. In Section \ref{MBgridspacingKED} the legacy data were used to estimate the residual semivariogram by REML, see Table \ref{tab:VariogramREMLEthiopia}. In the next code chunk the estimated parameters of the residual semivariogram are used to optimise the spatial pattern of an infill sample of 100 points for mapping the SOM concentration throughout West-Amhara by KED, using elevation (dem), NIR-reflectance (rfl\_NIR), red-reflectance (rfl\_red), and land surface temperature (lst) as predictors for the model-mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covars }\OtherTok{\textless{}{-}}\NormalTok{ grdAmhara[, }\FunctionTok{c}\NormalTok{(}\StringTok{"dem"}\NormalTok{, }\StringTok{"rfl\_NIR"}\NormalTok{, }\StringTok{"rfl\_red"}\NormalTok{, }\StringTok{"lst"}\NormalTok{)]}
\NormalTok{vgm\_REML\_gstat }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Sph"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{sigmasq,}
  \AttributeTok{range =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{phi, }\AttributeTok{nugget =}\NormalTok{ vgm\_REML}\SpecialCharTok{$}\NormalTok{nugget)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimMKV}\NormalTok{(}
  \AttributeTok{points =}\NormalTok{ pnts, }\AttributeTok{candi =}\NormalTok{ candi, }\AttributeTok{covars =}\NormalTok{ covars,}
  \AttributeTok{vgm =}\NormalTok{ vgm\_REML\_gstat,}
  \AttributeTok{eqn =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}}\NormalTok{ dem }\SpecialCharTok{+}\NormalTok{ rfl\_NIR }\SpecialCharTok{+}\NormalTok{ rfl\_red }\SpecialCharTok{+}\NormalTok{ lst,}
  \AttributeTok{nmax =} \DecValTok{20}\NormalTok{, }\AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{track =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:ModelBasedInfillKED} shows the optimised sample. Again the legacy points are avoided, but the infill sampling of the under-sampled areas is less uniform compared to Figure \ref{fig:ModelBasedInfill}. Spreading in geographical space is less important than with OK because the residual semivariogram has a much smaller range (Table \ref{tab:VariogramREMLEthiopia}). Spreading in covariate space does not play any role with OK, whereas with KED selecting locations with extreme values for the covariates is important to minimise the uncertainty about the estimated model-mean.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ModelBasedInfillKED-1} 

}

\caption{Model-based infill sample for KED of the SOM concentration throughout West-Amhara, plotted on a map of one of the covariates. Legacy units have free-value 0, infill units have free-value 1.}\label{fig:ModelBasedInfillKED}
\end{figure}

The MKV of the optimised sample equals 0.878 (dag kg\textsuperscript{-1})\textsuperscript{2}, which is somewhat larger than the sill (sum of nugget and partial sill) of the residual semivariogram (Table \ref{tab:VariogramREMLEthiopia}). This can be explained by the very small range of the semivariogram, so that ignoring the uncertainty about the model-mean, the kriging variance at nearly all locations in the study area equals the sill. Besides, we are uncertain about the model-mean, explaining that the MKV can be larger than the sill.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5735337 306.4   12043445 643.2  12043445  643.2
Vcells 27586668 210.5   93670004 714.7 189381883 1444.9
\end{verbatim}

\hypertarget{SamplingVariogram}{%
\chapter{Sampling for estimating the semivariogram}\label{SamplingVariogram}}

For model-based sampling as described in Chapters \ref{MBgridspacing} and \ref{MBSamplePattern} we must specify the (residual) semivariogram. In case we do not have a reasonable prior estimate of the semivariogram, we may decide to first collect data with the specific aim of estimating the semivariogram. This semivariogram is subsequently used to design a model-based sample for mapping. This chapter is about how to design a reconnaissance sample survey\index{Reconnaissance sample survey} for estimating the semivariogram.

The first question is how many observations we need for this. \citet{web92} gave as a rule of thumb that 150 to 225 points are needed to obtain a reliable semivariogram when estimated by the method-of-moments (MoM). \citet{lar00b} showed that with maximum likelihood (ML) estimation two-third to only half of the observations are needed to achieve equal precision of the estimated semivariogram parameters.

Once we have decided on the sample size, we must select the locations of the sampling units. Two random sampling designs for semivariogram estimation are described, nested sampling (Section \ref{NestedSampling}) and independent sampling of pairs of points (Section \ref{IndependentSamplingPairs}). Section \ref{samplingforvariogram} is devoted to model-based optimisation of the sampling pattern for semivariogram estimation. Section \ref{SamplingEstimationandPrediction} is about how to design a single sample that can be used both for estimation of the semivariogram and prediction (mapping). In a final section a practical solution is described for the problem of how to design a sample for semivariogram estimation and prediction.

\hypertarget{NestedSampling}{%
\section{Nested sampling}\label{NestedSampling}}

Nested sampling can be used to estimate the semivariance at a limited number of separation distances, see \citet{Oliver1986} and \citet{Webster2006}. First, we must decide on these separation distances. We need point-pairs at various separation distances, especially for small separation distances, so that we get reliable estimates of this part of the semivariogram which has a strong effect on the kriging weights. Usually, separation distances are chosen in a geometric progression, for instance 2, 8, 32, 128, and 512 m. The multiplier, which is four in this example, should not be too small; as a rule of thumb use three or larger.

There are two versions of nested sampling\index{Nested sampling}. In the first stage of the first version several main stations are selected in a way that they cover the study area well, for instance by spatial coverage sampling. In the second stage each of the main stations is used as a starting point to select one point at a distance equal to the largest chosen separation distance (512 m in the example) in a random direction from the main station. This doubles the sample size. In the third stage all points selected in the previous stages (main stations of stage 1 plus the points of stage 2) are used as starting points to select one point at a distance equal to the second largest separation distance (128 m), and so on. All points selected in the various stages are included in the nested sample. The code chunk below shows the function for random selection of one point at distance \(h\) from a starting point. Note the \texttt{while} loop which continues until a point is found that is inside the area. This is checked with function \texttt{over} of package \textbf{sp}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SelectPoint }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(start, h, area) \{}
\NormalTok{  dxy }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{2}\NormalTok{)}
\NormalTok{  inArea }\OtherTok{\textless{}{-}} \ConstantTok{NA}
  \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{is.na}\NormalTok{(inArea)) \{}
\NormalTok{    angle }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ pi)}
\NormalTok{    dxy[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{sin}\NormalTok{(angle); dxy[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{cos}\NormalTok{(angle)}
\NormalTok{    xypnt }\OtherTok{\textless{}{-}}\NormalTok{ start }\SpecialCharTok{+}\NormalTok{ dxy}
    \FunctionTok{coordinates}\NormalTok{(xypnt) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{    inArea }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xypnt, }\AttributeTok{y =}\NormalTok{ area))[}\DecValTok{1}\NormalTok{]}
\NormalTok{  \}}
\NormalTok{  xypoint }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(xypnt)}
\NormalTok{  xypoint}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The first stage of the second version is equal to that of the first version. However, in the second stage each of the main stations serves as a starting point for randomly selecting a \emph{pair of points} with a separation distance equal to the largest chosen separation distance. The main station is halfway the selected pair of points. In the third stage each of the substations is used to select in the same way a pair of points separated by the second largest chosen distance, and so on. Only the points selected in the final stage are used as sampling points. The \textbf{R} code below shows the function for random selection of two points separated by \(h\) distance units with a starting point halfway the pair of points. The \texttt{while} loop continues until both points of a pair are inside the area.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SelectPair }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(start, h, area) \{}
\NormalTok{  dxy }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{2}\NormalTok{)}
\NormalTok{  xypoints }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{  inArea1 }\OtherTok{\textless{}{-}}\NormalTok{ inArea2 }\OtherTok{\textless{}{-}} \ConstantTok{NA}
  \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{is.na}\NormalTok{(inArea1) }\SpecialCharTok{|} \FunctionTok{is.na}\NormalTok{(inArea2)) \{}
\NormalTok{    angle }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ pi)}
\NormalTok{    dxy[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{sin}\NormalTok{(angle) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{; dxy[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{cos}\NormalTok{(angle) }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{    xypnt1 }\OtherTok{\textless{}{-}}\NormalTok{ start }\SpecialCharTok{+}\NormalTok{ dxy}
    \FunctionTok{coordinates}\NormalTok{(xypnt1) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{    inArea1 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xypnt1, }\AttributeTok{y =}\NormalTok{ area))[}\DecValTok{1}\NormalTok{]}
\NormalTok{    dxy[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{dxy[}\DecValTok{1}\NormalTok{]; dxy[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{dxy[}\DecValTok{2}\NormalTok{]}
\NormalTok{    xypnt2 }\OtherTok{\textless{}{-}}\NormalTok{ start }\SpecialCharTok{+}\NormalTok{ dxy}
    \FunctionTok{coordinates}\NormalTok{(xypnt2) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{    inArea2 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xypnt2, }\AttributeTok{y =}\NormalTok{ area))[}\DecValTok{1}\NormalTok{]}
\NormalTok{  \}}
\NormalTok{  xypoints }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(xypnt1), }\FunctionTok{as.data.frame}\NormalTok{(xypnt2))}
\NormalTok{  xypoints}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \textbf{R} code below shows the selection of a nested sample from Hunter Valley using both versions. Only one main station is selected. In total sixteen points are selected in four stages. The separation distances are 2,000, 1,000, 500, and 250 m. Sixteen points is not enough for estimating the semivariogram and a multiplier of two is rather small, but this example is for illustrative purpose only.

Note that the separation distances are in descending order. The largest separation distance should not be chosen too large, because then, when the main station is somewhere in the middle of the study area, it may happen that using the first version no pair can be found with that separation distance. A similar problem may occur with the second version when in subsequent stages a station is selected near the border of the study area. A copy of \texttt{grdHunterValley} is made because both the original data frame is needed, as well as a gridded version of this data frame.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\NormalTok{grid }\OtherTok{\textless{}{-}}\NormalTok{ grdHunterValley}
\FunctionTok{gridded}\NormalTok{(grdHunterValley) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{lags }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{250}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The next code chunk is an implementation of the first version of nested sampling.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{614}\NormalTok{)}
\NormalTok{unit }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grid), }\DecValTok{1}\NormalTok{)}
\NormalTok{mainstation }\OtherTok{\textless{}{-}}\NormalTok{ grid[unit, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)]}
\NormalTok{newpnt }\OtherTok{\textless{}{-}} \FunctionTok{SelectPoint}\NormalTok{(}\AttributeTok{start =}\NormalTok{ mainstation, }\AttributeTok{h =}\NormalTok{ lags[}\DecValTok{1}\NormalTok{], }\AttributeTok{area =}\NormalTok{ grdHunterValley)}
\NormalTok{mysample\_nested }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mainstation, newpnt)}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(lags)) \{}
\NormalTok{  newpnts }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(mysample\_nested))) \{}
\NormalTok{    pnts }\OtherTok{\textless{}{-}} \FunctionTok{SelectPoint}\NormalTok{(}
      \AttributeTok{start =}\NormalTok{ mysample\_nested[i, ], }\AttributeTok{h =}\NormalTok{ lags[j], }\AttributeTok{area =}\NormalTok{ grdHunterValley)}
\NormalTok{    newpnts }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(newpnts, pnts)}
\NormalTok{  \}}
\NormalTok{  mysample\_nested }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysample\_nested, newpnts)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \textbf{R} code for the second version is presented in the next code chunk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{unit }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grid), }\DecValTok{1}\NormalTok{)}
\NormalTok{mainstation }\OtherTok{\textless{}{-}}\NormalTok{ grid[unit, }\FunctionTok{c}\NormalTok{(}\StringTok{"s1"}\NormalTok{, }\StringTok{"s2"}\NormalTok{)]}
\NormalTok{pnt }\OtherTok{\textless{}{-}} \FunctionTok{SelectPoint}\NormalTok{(}\AttributeTok{start =}\NormalTok{ mainstation, }\AttributeTok{h =}\NormalTok{ lags[}\DecValTok{1}\NormalTok{], }\AttributeTok{area =}\NormalTok{ grdHunterValley)}
\NormalTok{stations }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mainstation, pnt)}
\NormalTok{allstations }\OtherTok{\textless{}{-}}  \FunctionTok{rbind}\NormalTok{(mainstation, pnt)}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(lags)) \{}
\NormalTok{  newstations }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(stations))) \{}
\NormalTok{    pnts }\OtherTok{\textless{}{-}} \FunctionTok{SelectPair}\NormalTok{(}
      \AttributeTok{start =}\NormalTok{ stations[i, ], }\AttributeTok{h =}\NormalTok{ lags[j], }\AttributeTok{area =}\NormalTok{ grdHunterValley)}
\NormalTok{    newstations }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(newstations, pnts)}
\NormalTok{    allstations }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(allstations, pnts)}
\NormalTok{  \}}
\NormalTok{  stations }\OtherTok{\textless{}{-}}\NormalTok{ newstations}
\NormalTok{\}}
\NormalTok{mysample\_nested\_2 }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(stations)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:BalancedNestedSample} shows the two selected nested samples. For the sample selected with the second version also the stations that served as starting points for the selection of the point-pairs are plotted.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/BalancedNestedSample-1} 

}

\caption{Balanced nested samples from Hunter Valley, selected with the two versions of nested sampling. In the subfigure of the second version the selected sampling points (symbol x) are plotted together with the selected stations (halfway the two points of a pair).}\label{fig:BalancedNestedSample}
\end{figure}

The samples of Figure \ref{fig:BalancedNestedSample} are examples of \emph{balanced} nested samples\index{Nested sampling!balanced nested sampling}. The number of point-pairs separated by a given distance doubles with every stage. As a consequence, the estimated semivariances for the smallest separation distance are much more precise than for the largest distance. We are most uncertain about the estimated semivariances for the largest separation distances. If in the first stage only one point-pair separated by the largest distance is selected, then we have only one degree of freedom for estimating the variance component associated with this stage. It is more efficient to select more than one main station, say about ten, and to select fewer points in the final stages. For instance, with the second version we may decide to select a point-pair at only half the number of stations selected in the one-but-last stage. The nested sample then becomes unbalanced.

The model for nested sampling with four stages is a hierarchical analysis of variance (ANOVA) model\index{ANOVA model!hierarchical ANOVA model} with random effects:

\begin{equation}
Z_{ijkl}=\mu+A_i+B_{ij}+C_{ijk}+\epsilon_{ijkl} \;,
\label{eq:ANOVAmodelnested}
\end{equation}

with \(\mu\) the mean, \(A_i\) the effect of the \(i\)th first stage station, \(B_{ij}\) the effect of the \(j\)th second stage station within the \(i\)th first stage station, and so on. \(A_i\), \(B_{ij}\), \(C_{ijk}\), and \(\epsilon_{ijkl}\) are random quantities (random effects) all with zero mean and variances \(\sigma^2_1\), \(\sigma^2_2\), \(\sigma^2_3\), and \(\sigma^2_4\) respectively.

For balanced designs the variance components\index{Variance component} can be estimated by the MoM from a hierarchical ANOVA. The first step is to assign factors to the sampling points that indicate the grouping of the sampling points in the various stages. The number of factors needed is the number of stages minus 1. All factors have two levels. Figures \ref{fig:FactorLevelsBalancedNestedSample} and \ref{fig:FactorLevelsBalancedNestedSample2} show the levels of the three factors. The levels of the first factor show the strongest spatial clustering, those of the second factor the one-but-strongest, and so on.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample\_nested}\SpecialCharTok{$}\NormalTok{factor1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{), }\AttributeTok{times =} \DecValTok{8}\NormalTok{)}
\NormalTok{mysample\_nested}\SpecialCharTok{$}\NormalTok{factor2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{each =} \DecValTok{2}\NormalTok{), }\AttributeTok{times =} \DecValTok{4}\NormalTok{)}
\NormalTok{mysample\_nested}\SpecialCharTok{$}\NormalTok{factor3 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{each =} \DecValTok{4}\NormalTok{), }\AttributeTok{times =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/FactorLevelsBalancedNestedSample-1} 

}

\caption{The levels of the three factors assigned to the sampling points of the balanced nested sample selected with the first version.}\label{fig:FactorLevelsBalancedNestedSample}
\end{figure}

The \textbf{R} code below shows the construction of the three factors for the second version of nested sampling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample\_nested\_2}\SpecialCharTok{$}\NormalTok{factor1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{each =} \DecValTok{8}\NormalTok{)}
\NormalTok{mysample\_nested\_2}\SpecialCharTok{$}\NormalTok{factor2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{each =} \DecValTok{4}\NormalTok{), }\AttributeTok{times =} \DecValTok{2}\NormalTok{)}
\NormalTok{mysample\_nested\_2}\SpecialCharTok{$}\NormalTok{factor3 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{each =} \DecValTok{2}\NormalTok{), }\AttributeTok{times =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/FactorLevelsBalancedNestedSample2-1} 

}

\caption{The levels of the three factors assigned to the sampling points of the balanced nested sample selected with the second version.}\label{fig:FactorLevelsBalancedNestedSample2}
\end{figure}

For unbalanced nested designs\index{Nested sampling!unbalanced nested sampling} the variance components can be estimated by restricted maximum likelihood\index{Restricted maximum likelihood estimation} (REML) \citep{Webster2006}. REML estimation is also recommended if in Equation \eqref{eq:ANOVAmodelnested} instead of a constant mean \(\mu\) the mean is a linear combination of one or more covariates (fixed effects). The semivariances at the chosen separation distances are obtained by cumulating the estimated variance components.

The \textbf{R} code below shows how the variance components and the semivariances can be estimated with function \texttt{lme} of the package \textbf{nlme} \citep{nlme}, once the data are collected and added to the data frame. This function fits linear mixed-effects models and allows for nested random effects. It can be used both for balanced and unbalanced nested samples, and for a constant mean or a mean that is a linear combination of covariates. Argument \texttt{fixed} is a formula describing the fixed effects with the response variable on the left-hand side of the \textasciitilde{} operator and the covariates for the mean on the right-hand side. If a constant mean is assumed, as in our example, this is indicated by the 1 on the right-hand side of the \textasciitilde{} operator. Argument \texttt{random} is a one-sided formula (no response variable is on the left-hand side of the \textasciitilde{} operator). On the right-hand side of the \(|\) separator, the nested structure of the data is specified using the factors of Figure \ref{fig:FactorLevelsBalancedNestedSample}. The 1 on the left-hand side of the \(|\) separator means that we assume that all regression coefficients associated with the covariates are fixed (non-random) quantities.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(nlme)}
\NormalTok{lmodel }\OtherTok{\textless{}{-}} \FunctionTok{lme}\NormalTok{(}
  \AttributeTok{fixed =}\NormalTok{ z }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mysample\_nested, }\AttributeTok{random =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{|}\NormalTok{ factor1 }\SpecialCharTok{/}\NormalTok{ factor2 }\SpecialCharTok{/}\NormalTok{ factor3)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{VarCorr}\NormalTok{(lmodel))}
\NormalTok{sigmas }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(res[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{), }\DecValTok{1}\NormalTok{])}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{rev}\NormalTok{(sigmas)}
\NormalTok{semivar }\OtherTok{\textless{}{-}} \FunctionTok{cumsum}\NormalTok{(sigmas)}
\end{Highlighting}
\end{Shaded}

Random sampling of the points is not strictly needed, because a model-based approach is followed here. The model of Equation \eqref{eq:ANOVAmodelnested} is a superpopulation model, i.e.~we assume that the population is generated by this model (see Chapter \ref{Approaches}). \citet{Papritz2011}, for instance, selected the points (using the second version) non-randomly to improve the control of the nested subareas and the average separation distances.

\citet{Lark2011CAGEO} describes a method for optimisation of a nested design, given the total number of points and the chosen separation distances.

\hypertarget{exercises-31}{%
\subsubsection*{Exercises}\label{exercises-31}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an \textbf{R} script to select with the first version a balanced nested sample from Hunter Valley. Use as separation distances 1,000, 500, 200, 100, and 50 m.

  \begin{itemize}
  \tightlist
  \item
    Add the factors that are needed for estimating the variance components to the data frame with the selected sampling points.
  \item
    Overlay the sampling points with the \texttt{SpatialPixelsDataFrame}, and estimate the semivariances for the attribute compound topographic index (cti).
  \end{itemize}
\end{enumerate}

\hypertarget{IndependentSamplingPairs}{%
\section{Independent sampling of pairs of points}\label{IndependentSamplingPairs}}

With the nested design the estimated semivariances for the different separation distances are not independent. Independent estimated semivariances can be obtained by independent random selection of pairs of points (IPP sampling). Independence here means design-independence, see Section \ref{iid}. Similar to a regression model, a semivariogram can be defined as a superpopulation model or as a population model. Only in the current section a semivariogram is defined at the population level. Such a semivariogram is referred to as a non-ergodic semivariogram\index{Non-ergodic semivariogram} or local semivariogram\index{Local semivariogram} \citep{bru94b}.

IPP sampling is straightforward for simple random sampling\index{Simple random sampling of point-pairs|(}. For each separation distance a point-pair is selected by first selecting fully randomly one point from the study area. Then the second point is randomly selected from the circle with the first point at its centre and a radius equal to the chosen separation distance. If this second point is outside the study area, both points are discarded. This is repeated until we have the required point-pairs for this separation distance. The next code chunk is an implementation of this selection procedure.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SIpairs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(h, n, area) \{}
\NormalTok{  topo }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}\FunctionTok{getGridTopology}\NormalTok{(area), }\StringTok{"data.frame"}\NormalTok{)}
\NormalTok{  cell\_size }\OtherTok{\textless{}{-}}\NormalTok{ topo}\SpecialCharTok{$}\NormalTok{cellsize[}\DecValTok{1}\NormalTok{]}
\NormalTok{  xy }\OtherTok{\textless{}{-}} \FunctionTok{coordinates}\NormalTok{(area)}
\NormalTok{  dxy }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{2}\NormalTok{)}
\NormalTok{  xypnts1 }\OtherTok{\textless{}{-}}\NormalTok{ xypnts2 }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{  i }\OtherTok{\textless{}{-}} \DecValTok{1}
  \ControlFlowTok{while}\NormalTok{ (i }\SpecialCharTok{\textless{}=}\NormalTok{ n) \{}
\NormalTok{    unit1 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{length}\NormalTok{(area), }\AttributeTok{size =} \DecValTok{1}\NormalTok{)}
\NormalTok{    xypnt1 }\OtherTok{\textless{}{-}}\NormalTok{ xy[unit1, ]}
\NormalTok{    xypnt1[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(xypnt1[}\DecValTok{1}\NormalTok{], }\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{    xypnt1[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{jitter}\NormalTok{(xypnt1[}\DecValTok{2}\NormalTok{], }\AttributeTok{amount =}\NormalTok{ cell\_size }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\NormalTok{    angle }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ pi)}
\NormalTok{    dxy[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{sin}\NormalTok{(angle); dxy[}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{cos}\NormalTok{(angle)}
\NormalTok{    xypnt2 }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{t}\NormalTok{(xypnt1 }\SpecialCharTok{+}\NormalTok{ dxy))}
    \FunctionTok{coordinates}\NormalTok{(xypnt2) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{    inArea }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xypnt2, }\AttributeTok{y =}\NormalTok{ area))[}\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(inArea)) \{}
\NormalTok{      xypnts1 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(xypnts1, xypnt1)}
\NormalTok{      xypnts2 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(xypnts2, }\FunctionTok{as.data.frame}\NormalTok{(xypnt2))}
\NormalTok{      i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{    \}}
    \FunctionTok{rm}\NormalTok{(xypnt1, xypnt2)}
\NormalTok{  \}}
  \FunctionTok{cbind}\NormalTok{(xypnts1, xypnts2)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

IPP sampling is illustrated with the compound topographic index (cti, which is the same as topographic wetness index) data of Hunter Valley. Five separation distances are chosen, collected in numeric \texttt{h}, and for each distance \(n=100\) point-pairs are selected by simple random sampling.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\NormalTok{h }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{allpairs }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(h))) \{}
\NormalTok{  pairs }\OtherTok{\textless{}{-}} \FunctionTok{SIpairs}\NormalTok{(}\AttributeTok{h =}\NormalTok{ h[i], }\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{area =}\NormalTok{ grdHunterValley)}
\NormalTok{  allpairs }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(allpairs, pairs, }\AttributeTok{make.row.names =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \texttt{data.frame} \texttt{allpairs} has four variables: the spatial coordinates of the first and of the second point of a pair. An overlay is made of the selected points with the \texttt{SpatialPixelsDataFrame}, and the cti values are extracted.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pnt1 }\OtherTok{\textless{}{-}}\NormalTok{ allpairs[, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]}
\FunctionTok{coordinates}\NormalTok{(pnt1) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{z1 }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ pnt1, }\AttributeTok{y =}\NormalTok{ grdHunterValley)[}\StringTok{"cti"}\NormalTok{]}
\NormalTok{pnt2 }\OtherTok{\textless{}{-}}\NormalTok{ allpairs[, }\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)]}
\FunctionTok{coordinates}\NormalTok{(pnt2) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{z2 }\OtherTok{\textless{}{-}} \FunctionTok{over}\NormalTok{(}\AttributeTok{x =}\NormalTok{ pnt2, }\AttributeTok{y =}\NormalTok{ grdHunterValley)[}\StringTok{"cti"}\NormalTok{]}
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{h =} \FunctionTok{rep}\NormalTok{(h, }\AttributeTok{each =}\NormalTok{ n), z1, z2)}
\FunctionTok{names}\NormalTok{(mysample)[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"z1"}\NormalTok{, }\StringTok{"z2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The semivariances for the chosen separation distances are estimated as well as the variance of these estimated semivariances.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gammah }\OtherTok{\textless{}{-}}\NormalTok{ vgammah }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(h))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(h))) \{}
\NormalTok{  units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{h }\SpecialCharTok{==}\NormalTok{ h[i])}
\NormalTok{  pairsh }\OtherTok{\textless{}{-}}\NormalTok{ mysample[units, ]}
\NormalTok{  gammah[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((pairsh}\SpecialCharTok{$}\NormalTok{z1 }\SpecialCharTok{{-}}\NormalTok{ pairsh}\SpecialCharTok{$}\NormalTok{z2)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{  vgammah[i] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{((pairsh}\SpecialCharTok{$}\NormalTok{z1 }\SpecialCharTok{{-}}\NormalTok{ pairsh}\SpecialCharTok{$}\NormalTok{z2)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*} \DecValTok{4}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

A spherical model with nugget is fitted to the sample semivariogram, using function \texttt{nls}, with weights equal to the reciprocal of the estimated variances of the estimated semivariances.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_vg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(h, gammah, vgammah)}
\NormalTok{SphNug }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(h, range, psill, nugget) \{}
\NormalTok{  h }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{/}\NormalTok{ range}
\NormalTok{  nugget }\SpecialCharTok{+}\NormalTok{ psill }\SpecialCharTok{*} \FunctionTok{ifelse}\NormalTok{(h }\SpecialCharTok{\textless{}} \DecValTok{1}\NormalTok{, (}\FloatTok{1.5} \SpecialCharTok{*}\NormalTok{ h }\SpecialCharTok{{-}} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ h}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{), }\DecValTok{1}\NormalTok{)}
\NormalTok{\}}
\NormalTok{fit.var }\OtherTok{\textless{}{-}} \FunctionTok{nls}\NormalTok{(gammah }\SpecialCharTok{\textasciitilde{}} \FunctionTok{SphNug}\NormalTok{(h, range, psill, nugget),}
  \AttributeTok{data =}\NormalTok{ sample\_vg, }\AttributeTok{start =} \FunctionTok{list}\NormalTok{(}\AttributeTok{psill =} \DecValTok{4}\NormalTok{, }\AttributeTok{range =} \DecValTok{200}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{1}\NormalTok{),}
  \AttributeTok{weights =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ vgammah, }\AttributeTok{algorithm =} \StringTok{"port"}\NormalTok{, }\AttributeTok{lower =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\FunctionTok{print}\NormalTok{(pars }\OtherTok{\textless{}{-}} \FunctionTok{signif}\NormalTok{(}\FunctionTok{coef}\NormalTok{(fit.var), }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 psill  range nugget 
  3.29 188.00   1.21 
\end{verbatim}

Figure \ref{fig:variogramCTI} shows the sample semivariogram and the fitted model.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/variogramCTI-1} 

}

\caption{Sample semivariogram, obtained by independent sampling of pairs of points, and fitted spherical model of compount topographic index in Hunter Valley.}\label{fig:variogramCTI}
\end{figure}

The covariances of the estimated semivariances at different separation distances are zero, as the point-pairs are selected independently. This keeps estimation of the variances and covariances of the estimated semivariogram parameters simple. In the next code chunk this is done by bootstrapping\index{Bootstrap sample}.

In bootstrapping for each separation distance a simple random sample \emph{with replacement} of point-pairs is selected from the original sample of point-pairs. A point-pair can be selected more than once. The sample size (number of draws) is equal to the total number of point-pairs per separation distance in the original sample.

Every run of the bootstrap results in as many bootstrap samples as there are separation distances. The bootstrap samples are used to fit a semivariogram model. The whole procedure is repeated 500 times, resulting in 500 vectors with model parameters. These vectors can be used to estimate the variances and covariances of the estimators of the three semivariogram parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allpars }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{R }\OtherTok{\textless{}{-}} \DecValTok{500}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R) \{}
\NormalTok{  gammah }\OtherTok{\textless{}{-}}\NormalTok{ vgammah }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(h))}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(h))) \{}
\NormalTok{    units }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(mysample}\SpecialCharTok{$}\NormalTok{h }\SpecialCharTok{==}\NormalTok{ h[i])}
\NormalTok{    mysam\_btsp }\OtherTok{\textless{}{-}}\NormalTok{ mysample[units, ] }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    gammah[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((mysam\_btsp}\SpecialCharTok{$}\NormalTok{z1 }\SpecialCharTok{{-}}\NormalTok{ mysam\_btsp}\SpecialCharTok{$}\NormalTok{z2)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{    vgammah[i] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{((mysam\_btsp}\SpecialCharTok{$}\NormalTok{z1 }\SpecialCharTok{{-}}\NormalTok{ mysam\_btsp}\SpecialCharTok{$}\NormalTok{z2)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*} \DecValTok{4}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  sample\_vg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(h, gammah, vgammah)}
  \FunctionTok{tryCatch}\NormalTok{(\{}
\NormalTok{    fittedvariogram }\OtherTok{\textless{}{-}} \FunctionTok{nls}\NormalTok{(gammah }\SpecialCharTok{\textasciitilde{}} \FunctionTok{SphNug}\NormalTok{(h, range, psill, nugget),}
    \AttributeTok{data =}\NormalTok{ sample\_vg, }\AttributeTok{start =} \FunctionTok{list}\NormalTok{(}\AttributeTok{psill =} \DecValTok{4}\NormalTok{, }\AttributeTok{range =} \DecValTok{200}\NormalTok{, }\AttributeTok{nugget =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{weights =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ vgammah, }\AttributeTok{algorithm =} \StringTok{"port"}\NormalTok{, }\AttributeTok{lower =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\NormalTok{  pars }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(fittedvariogram)}
\NormalTok{  allpars }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(allpars, pars)\}, }\AttributeTok{error =} \ControlFlowTok{function}\NormalTok{(e) \{\})}
\NormalTok{\}}
\CommentTok{\#compute variance{-}covariance matrix}
\FunctionTok{signif}\NormalTok{(}\FunctionTok{var}\NormalTok{(allpars), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         psill   range  nugget
psill    1.160   -44.6  -0.803
range  -44.600 66700.0 172.000
nugget  -0.803   172.0   1.070
\end{verbatim}

Note the large variance for the range parameter (the standard deviation is 258 m) as well as the negative covariance of the nugget and the partial sill parameter (the Pearson correlation coefficient is -0.72). Histograms of the three estimated semivariogram parameters are shown in Figure \ref{fig:histogramsvariogramparameters}\index{Simple random sampling of point-pairs|}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/histogramsvariogramparameters-1} 

}

\caption{Frequency distributions  of estimated parameters of a spherical semivariogram of compound topographic index in Hunter Valley.}\label{fig:histogramsvariogramparameters}
\end{figure}

\begin{rmdnote}
\citet{Marcelli2019} show how a probability sample of \emph{points} (instead of pairs of points) can be used in design-based estimation of the semivariogram. From the \(n\) randomly selected points all \(n(n-1)/2\) point-pairs are constructed. The \emph{second-order inclusion probabilities} of these point-pairs are used to estimate the mean semivariance for separation distance classes. This sampling strategy makes better use of the data and is therefore potentially more efficient than IPP sampling.
\end{rmdnote}

\hypertarget{exercises-32}{%
\subsubsection*{Exercises}\label{exercises-32}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write an \textbf{R} script to select simple random samples of pairs of points for estimating the semivariogram of cti in Hunter Valley. Use as separation distances 25, 50, 100, 200, and 400 m. Note that these separation distances are smaller than those used above. Select 100 pairs per separation distance.

  \begin{itemize}
  \tightlist
  \item
    Compute the sample semivariogram, and estimate a spherical model with nugget using function \texttt{nls}.
  \item
    Compare the estimated semivariogram parameters with the estimates obtained with the larger separation distances.
  \item
    Estimate the variance-covariance matrix of the estimated semivariogram parameters by bootstrapping.
  \item
    Compare the variances of the estimated semivariogram parameters with the variances obtained with the larger separation distances. Which variance is changed most?
  \end{itemize}
\end{enumerate}

\hypertarget{samplingforvariogram}{%
\section{Optimisation of sampling pattern for semivariogram estimation}\label{samplingforvariogram}}

There is rich literature on model-based optimisation of the sampling locations for semivariogram estimation. Several design criteria (minimisation criteria) have been proposed for optimising the sampling pattern. Various authors have proposed a measure of the uncertainty about the semivariogram parameters as a minimisation criterion. These criteria are described and illustrated in the next subsection. The kriging variance is sensitive to errors in the estimated semivariogram. Therefore \citet{lar02} proposed to use a measure of the uncertainty about the kriging variance as a minimisation criterion (Subsection \ref{UncertainKrigingVariance}).

\hypertarget{UncertainSemivariogramParameters}{%
\subsection{Uncertainty about semivariogram parameters}\label{UncertainSemivariogramParameters}}

\citet{mul99} as well as \citet{bog99} proposed the determinant of the variance-covariance matrix\index{Determinant of variance-covariance matrix} of semivariogram parameters, estimated by generalised least squares to fit the MoM sample semivariogram. For instance, if we have two semivariogram parameters, \(\theta_1\) and \(\theta_2\), the determinant of the 2 \(\times\) 2 variance-covariance matrix equals the sum of the variances of the two estimated parameters minus two times the covariance of the two estimated parameters. If the two estimated parameters are positively correlated, the determinant of the matrix is smaller than if they are uncorrelated, and the covariance term is zero. The determinant is a measure of our \emph{joint} uncertainty about the semivariogram parameters.

\citet{zhu05} proposed as a minimisation criterion the log of the determinant of the inverse Fisher information matrix\index{Fisher information matrix} in ML estimation\index{Maximum likelihood estimation} of the semivariogram, hereafter shortly denoted by logdet. The Fisher information about a semivariogram parameter is a function of the likelihood of the semivariogram parameter; the likelihood of a semivariogram parameter is the probability of the data as a function of the semivariogram parameter. The log of this likelihood can be plotted against values of the parameter. The flatter the log-likelihood surface\index{Log-likelihood surface}, the less information is in the data about the parameter. The flatness of the surface can be measured by the first derivative of the log-likelihood to the semivariogram parameter. Strong negative or positive derivative values indicate a steep surface. The Fisher information for a model parameter is defined as the expectation of the \emph{square} of the first derivative of the log-likelihood to that semivariogram parameter, see \citet{Ly2017} for a nice tutorial on this subject. The more information we have about a semivariogram, the less uncertain we are about that parameter. This explains why the inverse of the Fisher information can be used as a measure of uncertainty. The inverse Fisher information matrix contains the variances and covariances of the estimated semivariogram parameters.

The code chunks hereafter show how logdet can be computed. It makes use of the result of \citet{Kitanidis87} who showed that each element of the Fisher information matrix \(\mathbf{I}(\theta)\) can be obtained with (see also \citet{lar02})

\begin{equation}
[\mathbf{I}(\theta)]_{ij}=\frac{1}{2}\mathrm{Tr}\left[\mathbf{A}^{-1}\frac{\partial\mathbf{A}}{\partial\theta_i}\mathbf{A}^{-1}\frac{\partial\mathbf{A}}{\partial\theta_j}\right]\;,
\label{eq:FisherInformation}
\end{equation}

with \(\mathbf{A}\) the correlation matrix of the sampling points, \(\frac{\partial\mathbf{A}}{\partial\theta_i}\) the partial derivative of the correlation matrix to the \(i\)th semivariogram parameter, and Tr{[}\(\cdot\){]} the trace of a matrix.

As an illustration I selected a simple random sample of 100 points from Hunter Valley. A matrix with distances between the points of a sample is computed. Preliminary values for the semivariogram parameters \(\xi\) (ratio of spatial dependence\index{Ratio of spatial dependence}) and \(\phi\) (distance parameter\index{Distance parameter}) are obtained by visual inspection of the sample semivariogram, and the \textbf{gstat} \citep{peb04} function \texttt{variogramLine} is used to compute the correlation matrix.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sp)}
\FunctionTok{library}\NormalTok{(gstat)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mysample0 }\OtherTok{\textless{}{-}}\NormalTok{ grdHunterValley }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n)}
\FunctionTok{coordinates}\NormalTok{(mysample0) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{spDists}\NormalTok{(mysample0)}
\NormalTok{xi }\OtherTok{\textless{}{-}} \FloatTok{0.8}\NormalTok{; phi }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{thetas }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(xi, phi)}
\NormalTok{vgmodel }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ thetas[}\DecValTok{1}\NormalTok{],}
  \AttributeTok{range =}\NormalTok{ thetas[}\DecValTok{2}\NormalTok{], }\AttributeTok{nugget =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ thetas[}\DecValTok{1}\NormalTok{])}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the next step the semivariogram parameters are slightly changed one-by-one. The changes, referred to as perturbations\index{Perturbation}, are a small fraction of the preliminary semivariogram parameter values. The perturbed semivariogram parameters are used to compute the perturbed correlation matrices (\texttt{pA}) and the partial derivatives of the correlation matrix (\texttt{dA}) for each perturbation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perturbation }\OtherTok{\textless{}{-}} \FloatTok{0.01}
\NormalTok{pA }\OtherTok{\textless{}{-}}\NormalTok{ dA }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  thetas\_pert }\OtherTok{\textless{}{-}}\NormalTok{ thetas}
\NormalTok{  thetas\_pert[i] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ perturbation) }\SpecialCharTok{*}\NormalTok{ thetas[i]}
\NormalTok{  vgmodel\_pert }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ thetas\_pert[}\DecValTok{1}\NormalTok{],}
    \AttributeTok{range =}\NormalTok{ thetas\_pert[}\DecValTok{2}\NormalTok{], }\AttributeTok{nugget =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ thetas\_pert[}\DecValTok{1}\NormalTok{])}
\NormalTok{  pA[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel\_pert, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  dA[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ (pA[[i]] }\SpecialCharTok{{-}}\NormalTok{ A) }\SpecialCharTok{/}\NormalTok{ (thetas[i] }\SpecialCharTok{*}\NormalTok{ perturbation)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Finally, the Fisher information matrix is computed using Equation \eqref{eq:FisherInformation}. We do not need to compute the inverse of the Fisher information matrix, because the determinant of the inverse of a matrix is equal to the inverse of the determinant of the (not inverted) matrix. The determinant is computed with function \texttt{determinant}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{I }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{length}\NormalTok{(thetas), }\FunctionTok{length}\NormalTok{(thetas))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  m\_i }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(A, dA[[i]])}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in}\NormalTok{ i}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(thetas)) \{}
\NormalTok{    m\_j }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(A, dA[[j]])}
\NormalTok{    I[i, j] }\OtherTok{\textless{}{-}}\NormalTok{ I[j, i] }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(m\_i }\SpecialCharTok{\%*\%}\NormalTok{ m\_j))}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{logdet0 }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{determinant}\NormalTok{(I, }\AttributeTok{logarithm =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{modulus}
\end{Highlighting}
\end{Shaded}

The joint uncertainty about the semivariogram parameters, as quantified by the log of the determinant of the inverse of the information matrix, equals 6.286. Hereafter we will see how much this joint uncertainty can be reduced by optimising the spatial pattern of the sample used for semivariogram estimation, compared to the simple random sample used in the above calculation. Note that a preliminary semivariogram is needed to compute an optimised sampling pattern for semivariogram estimation.

Function \texttt{optimUSER} of package \textbf{spsann} can be used to search for the sampling locations with the minimum value of logdet. This function has been used before in Section \ref{SamplePatternOK}. Package \textbf{spsann} cannot deal with the 22,124 candidate grid nodes of Hunter Valley; these are too many. I therefore selected a subgrid of 50 m \(\times\) 50 m.

The sample size for estimation of the semivariogram is passed to function \texttt{optimUSER} with argument \texttt{points}. A simple random sample of size 100 is used as an initial sample (but this is not the simple random sample used above to illustrate the computations). The objective function to be minimised is passed to function \texttt{optimUSER} with argument \texttt{fun}. The objective function \texttt{logdet} is defined in package \textbf{sswr}. Argument \texttt{model} specifies the model \emph{type}, using the characters of \textbf{gstat}. Argument \texttt{thetas} specifies the preliminary semivariogram parameter values. Argument \texttt{perturbation} specifies how much the semivariogram parameters are changed to compute the perturbed correlation matrices (\texttt{pA}) and the partial derivatives of the correlation matrix (\texttt{dA}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{gridded}\NormalTok{(grdHunterValley) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{candi }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(grdHunterValley, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{,}
                  \AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{50}\NormalTok{), }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{candi }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(candi)}
\FunctionTok{names}\NormalTok{(candi) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)}
\NormalTok{schedule }\OtherTok{\textless{}{-}} \FunctionTok{scheduleSPSANN}\NormalTok{(}
  \AttributeTok{initial.acceptance =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{initial.temperature =} \FloatTok{0.03}\NormalTok{, }\AttributeTok{temperature.decrease =} \FloatTok{0.9}\NormalTok{,}
  \AttributeTok{chains =} \DecValTok{500}\NormalTok{, }\AttributeTok{chain.length =} \DecValTok{2}\NormalTok{, }\AttributeTok{stopping =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{x.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{y.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{cellsize =} \DecValTok{50}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimUSER}\NormalTok{(}
  \AttributeTok{points =} \DecValTok{100}\NormalTok{, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{fun =}\NormalTok{ logdet,}
  \AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{thetas =}\NormalTok{ thetas, }\AttributeTok{perturbation =} \FloatTok{0.01}\NormalTok{,}
  \AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{track =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:MBVariogram} shows the optimised sampling pattern of 100 points. The logdet of the optimised sample equals 2.219 which is 35\% of the value of the simple random sample used above to illustrate the computations. The optimised sample shows strong spatial clustering. Connecting neighbouring points of the sample by lines yields a sort of mycelium. Remarkably, there is one isolated point. Besides, there are quite a few pairs of points at very short distance.

\hypertarget{UncertainKrigingVariance}{%
\subsection{Uncertainty about the kriging variance}\label{UncertainKrigingVariance}}

\citet{lar02} proposed as a minimisation criterion the estimation variance of the kriging variance (VKV) due to uncertainty in the ML estimates of the semivariogram parameters. This variance is approximated by a first order Taylor series\index{First order Taylor series}, requiring the partial derivatives of the kriging variance with respect to the semivariogram parameters:

\begin{equation}
VKV(\mathbf{s}_0) = \sum_{i=1}^p \sum_{j=1}^p \mathrm{Cov}(\theta_i,\theta_j) \frac{\partial V_{\mathrm{OK}}(\mathbf{s}_0)} {\partial \theta_i} \frac{\partial V_{\mathrm{OK}}(\mathbf{s}_0)} {\partial \theta_j}\;,
\label{eq:varkrigingvar}
\end{equation}

with \(p\) the number of semivariogram parameters, \(\mathrm{Cov}(\theta_i,\theta_j)\) the covariances of the semivariogram parameters \(\theta_i\) and \(\theta_j\) (elements of the inverse of the Fisher information matrix \(\mathbf{I}^{-1}(\pmb{\theta})\), Equation \eqref{eq:FisherInformation}), and \(\frac{\partial V_{\mathrm{OK}}(\mathbf{s}_0)} {\partial \theta_i}\) the partial derivative of the kriging variance to the \(i\)th semivariogram parameter at prediction location \(\mathbf{s}_0\).

The first step in designing a sample for semivariogram estimation using VKV as a minimisation criterion is to select a sample for the second sampling round. In the code chunk below a spatial coverage sample is selected, using function \texttt{stratify} of package \textbf{spcosa}, see Section \ref{SpatialCoverage}. Once the observations of this sample are collected in the second sampling round, these data are used for mapping by ordinary kriging.

To optimise the sampling pattern of the first sampling round for variogram estimation, the population mean of VKV (MVKV) is used as a minimisation criterion. This population mean is estimated from a centred, square grid of 101 points, the evaluation sample. (In the code chunk below \texttt{n\ =\ 100} is used in function \texttt{spsample}, but actually 101 locations are selected.)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\FunctionTok{gridded}\NormalTok{(grdHunterValley) }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ s1 }\SpecialCharTok{+}\NormalTok{ s2}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mystrata }\OtherTok{\textless{}{-}} \FunctionTok{stratify}\NormalTok{(grdHunterValley, }\AttributeTok{nStrata =}\NormalTok{ n, }\AttributeTok{equalArea =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{nTry =} \DecValTok{10}\NormalTok{)}
\NormalTok{mysample\_SC }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}\FunctionTok{spsample}\NormalTok{(mystrata), }\StringTok{"SpatialPoints"}\NormalTok{)}
\NormalTok{mysample\_eval }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ grdHunterValley, }\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The following code chunks show how VKV at the evaluation point is computed. First, the correlation matrix of the spatial coverage sample (\texttt{A}) is computed as well as the correlation matrix of the spatial coverage sample and the evaluation points (\texttt{A0}). Correlation matrix \texttt{A} is extended with a column and a row with ones, see Equation \eqref{eq:krigingeqsmatrix}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{spDists}\NormalTok{(mysample\_SC)}
\NormalTok{vgmodel }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ thetas[}\DecValTok{1}\NormalTok{], }\AttributeTok{range =}\NormalTok{ thetas[}\DecValTok{2}\NormalTok{],}
  \AttributeTok{nugget =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ thetas[}\DecValTok{1}\NormalTok{])}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(mysample\_SC)}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{data =} \DecValTok{0}\NormalTok{, }\AttributeTok{nrow =}\NormalTok{ nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\AttributeTok{ncol =}\NormalTok{ nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{B[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\OtherTok{\textless{}{-}}\NormalTok{ A}
\NormalTok{B[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs, nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{D0 }\OtherTok{\textless{}{-}} \FunctionTok{spDists}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mysample\_eval, }\AttributeTok{y =}\NormalTok{ mysample\_SC)}
\NormalTok{A0 }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel, }\AttributeTok{dist\_vector =}\NormalTok{ D0, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next, the semivariogram parameters are perturbed one-by-one, and the perturbed correlation matrices \texttt{pA} and \texttt{pA0} are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pA  }\OtherTok{\textless{}{-}}\NormalTok{ pA0 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  thetas\_pert }\OtherTok{\textless{}{-}}\NormalTok{ thetas}
\NormalTok{  thetas\_pert[i] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ perturbation) }\SpecialCharTok{*}\NormalTok{ thetas[i]}
\NormalTok{  vgmodel\_pert }\OtherTok{\textless{}{-}} \FunctionTok{vgm}\NormalTok{(}\AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{psill =}\NormalTok{ thetas\_pert[}\DecValTok{1}\NormalTok{],}
    \AttributeTok{range =}\NormalTok{ thetas\_pert[}\DecValTok{2}\NormalTok{], }\AttributeTok{nugget =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ thetas\_pert[}\DecValTok{1}\NormalTok{])}
\NormalTok{  pA[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel\_pert, }\AttributeTok{dist\_vector =}\NormalTok{ D, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  pA0[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{variogramLine}\NormalTok{(vgmodel\_pert, }\AttributeTok{dist\_vector =}\NormalTok{ D0, }\AttributeTok{covariance =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\NormalTok{pB }\OtherTok{\textless{}{-}}\NormalTok{ pb }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  pB[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ B}
\NormalTok{  pB[[i]][}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\OtherTok{\textless{}{-}}\NormalTok{ pA[[i]]}
\NormalTok{  pb[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(pA0[[i]], }\DecValTok{1}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Next, the kriging variance and the perturbed kriging variances are computed, and the partial derivatives of the kriging variance with respect to the semivariogram parameters are approximated. See Equations \eqref{eq:krigingweights} and \eqref{eq:OKvariance} for how the kriging weights \texttt{l} and the kriging variance \texttt{var} are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(mysample\_eval))}
\NormalTok{pvar }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(mysample\_eval), }\AttributeTok{ncol =} \FunctionTok{length}\NormalTok{(thetas))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(mysample\_eval))) \{}
\NormalTok{  b }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(A0[i, ], }\DecValTok{1}\NormalTok{)}
  \CommentTok{\#compute kriging weights and Lagrange multiplier}
\NormalTok{  l }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(B, b)}
\NormalTok{  var[i] }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ l[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\SpecialCharTok{\%*\%}\NormalTok{ A0[i, ] }\SpecialCharTok{{-}}\NormalTok{ l[nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{    pl }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(pB[[j]], pb[[j]][i, ])}
\NormalTok{    pvar[i, j] }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pl[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\SpecialCharTok{\%*\%}\NormalTok{ pA0[[j]][i, ] }\SpecialCharTok{{-}}\NormalTok{ pl[nobs }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{dvar }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  dvar[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ (pvar[, i] }\SpecialCharTok{{-}}\NormalTok{ var) }\SpecialCharTok{/}\NormalTok{ (thetas[i] }\SpecialCharTok{*}\NormalTok{ perturbation)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Finally, the partial derivatives of the kriging variance are used to approximate VKV at the 101 evaluation points (Equation \eqref{eq:varkrigingvar}). For this the variances and covariances of the estimated semivariogram parameters are needed, estimated by the inverse of the Fisher information matrix. The Fisher information matrix computed in Subsection \ref{UncertainSemivariogramParameters} for the simple random sample of 100 points is also used here. I use the population mean of VKV (MVKV) as a minimisation criterion which is estimated by the average of the VKV values at the simple random sample of evaluation points. Note that the variance-covariance matrix of estimated semivariogram parameters is computed from the sample for semivariogram estimation only. The spatial coverage sample of the second sampling round is not used for estimating the semivariogram, but for prediction only. Section \ref{SamplingEstimationandPrediction} is about designing one sample instead of two samples that is used for estimation of the model parameters and for prediction.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{invI }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(I)}
\NormalTok{VKV }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(var))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{    VKVij }\OtherTok{\textless{}{-}}\NormalTok{ invI[i, j] }\SpecialCharTok{*}\NormalTok{ dvar[[i]] }\SpecialCharTok{*}\NormalTok{ dvar[[j]]}
\NormalTok{    VKV }\OtherTok{\textless{}{-}}\NormalTok{ VKV }\SpecialCharTok{+}\NormalTok{ VKVij}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{MVKV0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(VKV)}
\end{Highlighting}
\end{Shaded}

For the simple random sample the square root of MVKV equals 0.166. The mean kriging variance (MKV) at these points equals 0.768, so the uncertainty about the kriging variance is substantial. Hereafter we will see how much MVKV can be reduced by optimising the sampling pattern with spatial simulated annealing.

As for logdet, the sample with minimum value for MVKV can be searched for using \textbf{spsann} function \texttt{optimUSER}. The objective function \texttt{MVKV} is defined in package \textbf{sswr}. Argument \texttt{points} specifies the size of the sample for semivariogram estimation. A simple random sample of size 100 is used as an initial sample. Argument \texttt{psample} is used to specify the sample used for prediction at the evaluation points (after the second round of sampling). Argument \texttt{esample} is to specify the sample with evaluation points for estimating MVKV.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{schedule }\OtherTok{\textless{}{-}} \FunctionTok{scheduleSPSANN}\NormalTok{(}
  \AttributeTok{initial.acceptance =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{initial.temperature =} \FloatTok{0.0004}\NormalTok{, }\AttributeTok{temperature.decrease =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{chains =} \DecValTok{500}\NormalTok{, }\AttributeTok{chain.length =} \DecValTok{2}\NormalTok{, }\AttributeTok{stopping =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{x.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{y.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{cellsize =} \DecValTok{50}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimUSER}\NormalTok{(}
  \AttributeTok{points =} \DecValTok{100}\NormalTok{, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{fun =}\NormalTok{ MVKV,}
  \AttributeTok{psample =}\NormalTok{ mysample\_SC, }\AttributeTok{esample =}\NormalTok{ mysample\_eval,}
  \AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{thetas =}\NormalTok{ thetas,}
  \AttributeTok{perturbation =} \FloatTok{0.01}\NormalTok{, }\AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{track =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:MBVariogram} shows the optimised sample. The minimised value of MVKV is 26\% of the value of the simple random sample used to illustrate the computations. As for logdet the optimised sample shows strong spatial clustering. However, the shape is quite different. The points are clustered in a circle.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/MBVariogram-1} 

}

\caption{Optimised sampling pattern of 100 points for semivariogram estimation, using the log of the determinant of the inverse Fisher information matrix of the semivariogram parameters (logdet) and the mean estimation variance of the kriging variance (MVKV) as a minimisation criterion.}\label{fig:MBVariogram}
\end{figure}

\begin{rmdnote}
Both minimisation criteria, logdet and MVKV, are a function of the semivariogram parameters \(\pmb{\theta}\), showing that the problem is circular. Using a preliminary estimate of the semivariogram parameters, \(\hat{\pmb{\theta}}\), leads to a locally optimal design at \(\hat{\pmb{\theta}}\). For this reason \citet{bog99} and \citet{zhu05} proposed a Bayesian approach, in which a multivariate prior distribution for the semivariogram parameters is postulated. The expected value over this distribution of the criterion is minimised. \citet{lar02} computed the average of VKV over a number of semivariograms.
\end{rmdnote}

Both methods for sample optimisation rely, amongst others, on the assumption that the mean and the variance are constant throughout the area. Under this assumption it is no problem that the sampling units are spatially clustered. So, we assume that the semivariogram estimated from the data collected in a small portion of the study area is representative for the whole study area. If we do not feel comfortable with this assumption, spreading out the sampling units by the sampling methods described in the next two sections can be a good option.

\hypertarget{exercises-33}{%
\subsubsection*{Exercises}\label{exercises-33}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write an \textbf{R} script to design a model-based sample of 100 points for Hunter Valley, to estimate the semivariogram for a study variable. Use logdet as a minimisation criterion. Use as a prior estimate of the semivariogram an exponential model with a distance parameter of 200 m and a ratio of spatial dependence of 0.5. Compare the sample with the optimised sample in Figure \ref{fig:MBVariogram}, which was obtained with the same value for the distance parameter and a spatial dependence ratio of 0.8.\\
\item
  Repeat this for MVKV as a minimisation criterion.
\end{enumerate}

\hypertarget{SamplingEstimationandPrediction}{%
\section{Optimisation of sampling pattern for semivariogram estimation and mapping}\label{SamplingEstimationandPrediction}}

In practice a reconnaissance survey for semivariogram estimation often is not feasible. A single sample must be designed that is suitable both for estimating the semivariogram parameters and mapping, i.e.~prediction with the estimated semivariogram parameters at the nodes of a fine discretisation grid. Another reason is that in a reconnaissance survey we can seldom afford a sample size large enough to obtain reliable estimates of the semivariogram parameters. \citet{Papritz2011} found that for a sample size of 192 points the estimated variance components with balanced and unbalanced nested designs were highly uncertain. For this reason it is attractive to use also the sampling points designed for spatial prediction (mapping) for estimating the semivariogram. Designing two samples, one for estimation of the semivariogram and one for spatial prediction, is suboptimal. Designing one sample that can be used both for estimation of the semivariogram parameters and for prediction potentially is more efficient.

Finally, with nested sampling and IPP sampling we aim at estimating the semivariogram of the residuals of a constant mean (see Equation \eqref{eq:ANOVAmodelnested}). In other words, with these designs we aim at estimating the parameters of a semivariogram model used in ordinary kriging. In situations where we have covariates that can partly explain the spatial variation of the study variable, kriging with an external drift is more appropriate. In these situations the reconnaissance survey should be tailored to estimating both the regression coefficients associated with the covariates and the parameters of the residual semivariogram.

Model-based methods for designing a single sample for estimation of the model parameters and for prediction with the estimated model parameters are proposed, amongst others, by \citet{zim06}, \citet{zhu06}, \citet{zhu06b}, and \citet{Marchant2007}. The methods use a different minimisation criterion. \citet{zim06} proposed to minimise the kriging variance (at the centre of a square grid cell) that is augmented by an amount that accounts for the additional uncertainty in the kriging predictions due to uncertainty in the estimated semivariogram parameters, hereafter referred to as the augmented kriging variance \index{Augmented kriging variance} (AKV):

\begin{equation}
AKV(\mathbf{s}_0) = V_\mathrm{OK}(\mathbf{s}_0) + \mathrm{E}[\tau^2(\mathbf{s}_0)]\;,
\label{eq:augmentedvar}
\end{equation}

with \(V_\mathrm{OK}(\mathbf{s}_0)\) the ordinary kriging variance, see Equation \eqref{eq:OKvariance}, and \(\mathrm{E}[\tau^2(\mathbf{s}_0)]\) the expectation of the additional variance component due to uncertainty about the semivariogram parameters estimated by ML. The additional variance component is approximated by a first order Taylor series:

\begin{equation}
\mathrm{E}[\tau^2(\mathbf{s}_0)]=\sum_{i=1}^p \sum_{j=1}^p \mathrm{Cov}(\theta_i,\theta_j) \frac{\partial \lambda^{\mathrm{T}}} {\partial \theta_i} \mathbf{A}\frac{\partial \lambda} {\partial \theta_j}\;,
\label{eq:tausq}
\end{equation}

with \(\frac{\partial \lambda} {\partial \theta_j}\) the vector of partial derivatives of the kriging weights with respect to the \(j\)th semivariogram parameter. Comparing Equations \eqref{eq:tausq} and \eqref{eq:varkrigingvar} shows that the two variances differ. VKV quantifies our uncertainty about the estimated kriging variance, whereas \(\mathrm{E}[\tau^2]\) quantifies our uncertainty about the kriging prediction due to uncertainty about the semivariogram parameters. I use the mean of the AKV over the nodes of a prediction grid (evaluation grid) as a minimisation criterion (MAKV). The same criterion can also be used in situations where we have maps of covariates that we want to use in prediction. In that case the aim is to design a single sample that is used both for estimation of the \emph{residual} semivariogram and for prediction by kriging with an external drift. The ordinary kriging variance \(V_\mathrm{OK}(\mathbf{s}_0)\) in Equation \eqref{eq:augmentedvar} is then replaced by the prediction error variance with kriging with an external drift \(V_\mathrm{KED}(\mathbf{s}_0)\), see Equation \eqref{eq:KEDvariance}.

\citet{zhu06} proposed as a minimisation criterion a linear combination of AKV (Equation \eqref{eq:augmentedvar}) and VKV (Equation \eqref{eq:varkrigingvar}), referred to as the estimation adjusted criterion\index{Estimation adjusted criterion} (EAC):

\begin{equation}
EAC(\mathbf{s}_0) = AKV(\mathbf{s}_0) + \frac{1}{2V_{\mathrm{OK}}(\mathbf{s}_0)} VKV(\mathbf{s}_0)\;.
\label{eq:EAC}
\end{equation}

Again, the mean of the EAC values (MEAC) over the nodes of a prediction grid (evaluation) is used as a minimisation criterion.

Computing time for optimisation of the coordinates of a large sample, say \(> 50\) points, can become prohibitively long. To reduce computing time, \citet{zhu06} proposed a two-step approach. In the first step for a fixed proportion \(p \in (0,1)\) the locations of \((1-p)\;n\) points are optimised for prediction with given parameters, for instance by minimising MKV. This `prediction sample' is supplemented with \(p \;n\) points, so that the two combined samples of size \(n\) minimise logdet or MVKV. This is repeated for different values of \(p\). In the second step MEAC is computed for the combined samples of size \(n\), and the proportion and the associated sample with minimum MEAC are selected.

A simplification of this two-step approach is to select in the first step a square grid or a spatial coverage sample (Section \ref{SpatialCoverage}), and to supplement this sample by a fixed number of points whose coordinates are optimised by spatial simulated annealing (SSA), using either MAKV or MEAC computed from both samples (grid sample or spatial coverage sample plus supplemental sample) as a minimisation criterion. In SSA the grid or spatial coverage sample is fixed, i.e.~the locations are not further optimised. \citet{Lark2018} recommended as a rule of thumb to add about 10\% of the fixed sample as short distance points.

The following code chunks show how the AKV and EAC can be computed. First, a spatial coverage sample of 90 points is selected using function \texttt{stratify} of package \textbf{spcosa}, see Section \ref{SpatialCoverage}. In addition, a simple random sample of 10 points is selected. This sample is the initial supplemental sample, whose locations are optimised. A square grid of approximately 100 points is selected as an evaluation sample.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spcosa)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{90}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{mystrata }\OtherTok{\textless{}{-}} \FunctionTok{stratify}\NormalTok{(grdHunterValley, }\AttributeTok{nStrata =}\NormalTok{ n, }\AttributeTok{equalArea =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{nTry =} \DecValTok{10}\NormalTok{)}
\NormalTok{mysample\_SC }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}\FunctionTok{spsample}\NormalTok{(mystrata), }\StringTok{"SpatialPoints"}\NormalTok{)}
\NormalTok{nsup }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(grdHunterValley), nsup)}
\NormalTok{mysample\_sup0 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(grdHunterValley[units, ], }\StringTok{"SpatialPoints"}\NormalTok{)}
\NormalTok{mysample\_eval }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ grdHunterValley, }\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{, }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The next step is to compute the inverse of the Fisher information matrix, given a preliminary semivariogram model, which is used as the variance-covariance matrix of the estimated semivariogram parameters. Contrary to Section \ref{samplingforvariogram} now \emph{all} sampling locations are used to compute this matrix. The locations of the spatial coverage sample and the supplemental sample are merged into one \texttt{SpatialPoints} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mysample }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(mysample\_sup0, mysample\_SC)}
\end{Highlighting}
\end{Shaded}

For how the Fisher information matrix is computed, I refer to the code chunks in Section \ref{samplingforvariogram}. The inverse of this matrix can be computed with function \texttt{solve}.

In the next code chunk for each evaluation point the kriging weights (\texttt{L}), the kriging variance (\texttt{var}), the perturbed kriging weights (\texttt{pL}), and the perturbed kriging variances (\texttt{pvar}) are computed. In the final lines the partial derivatives of the kriging weights (\texttt{dL}) and of the kriging variances (\texttt{dvar}) with respect to the semivariogram parameters are computed. The partial derivatives of the kriging variances with respect to the semivariogram parameters are needed for computing VKV, see Equation \eqref{eq:varkrigingvar}, which in turn is needed for computing criterion EAC, see Equation \eqref{eq:EAC}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(mysample\_eval), }\AttributeTok{ncol =}\NormalTok{ nobs)}
\NormalTok{pL }\OtherTok{\textless{}{-}} \FunctionTok{array}\NormalTok{(}
  \AttributeTok{dim =} \FunctionTok{c}\NormalTok{(}\FunctionTok{length}\NormalTok{(mysample\_eval), }\FunctionTok{length}\NormalTok{(mysample), }\FunctionTok{length}\NormalTok{(thetas)))}
\NormalTok{var }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(mysample\_eval))}
\NormalTok{pvar }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(mysample\_eval), }\AttributeTok{ncol =} \FunctionTok{length}\NormalTok{(thetas))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(mysample\_eval))) \{}
\NormalTok{  b }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(A0[i, ], }\DecValTok{1}\NormalTok{)}
\NormalTok{  l }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(B, b)}
\NormalTok{  L[i, ] }\OtherTok{\textless{}{-}}\NormalTok{ l[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs]}
\NormalTok{  var[i] }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ l[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\SpecialCharTok{\%*\%}\NormalTok{ A0[i, ] }\SpecialCharTok{{-}}\NormalTok{ l[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs)]}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{    pl }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(pB[[j]], pb[[j]][i, ])}
\NormalTok{    pL[i, , j] }\OtherTok{\textless{}{-}}\NormalTok{ pl[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs]}
\NormalTok{    pvar[i, j] }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pl[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs] }\SpecialCharTok{\%*\%}\NormalTok{ pA0[[j]][i, ] }\SpecialCharTok{{-}}\NormalTok{ pl[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nobs)]}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{dL }\OtherTok{\textless{}{-}}\NormalTok{ dvar }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(thetas))) \{}
\NormalTok{  dL[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ (pL[, , i] }\SpecialCharTok{{-}}\NormalTok{ L) }\SpecialCharTok{/}\NormalTok{ (thetas[i] }\SpecialCharTok{*}\NormalTok{ perturbation)}
\NormalTok{  dvar[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ (pvar[, i] }\SpecialCharTok{{-}}\NormalTok{ var) }\SpecialCharTok{/}\NormalTok{ (thetas[i] }\SpecialCharTok{*}\NormalTok{ perturbation)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In the next code chunk the expected variance due to uncertainty about the semivariogram parameters (Equation \eqref{eq:tausq}) is computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tausq }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(mysample\_eval))}
\NormalTok{tausqk }\OtherTok{\textless{}{-}} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ (k }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(mysample\_eval))) \{}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(dL))) \{}
    \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(dL))) \{}
\NormalTok{      tausqijk }\OtherTok{\textless{}{-}}\NormalTok{ invI[i, j] }\SpecialCharTok{*} \FunctionTok{t}\NormalTok{(dL[[i]][k, ]) }\SpecialCharTok{\%*\%}\NormalTok{ A }\SpecialCharTok{\%*\%}\NormalTok{ dL[[j]][k, ]}
\NormalTok{      tausqk }\OtherTok{\textless{}{-}}\NormalTok{ tausqk }\SpecialCharTok{+}\NormalTok{ tausqijk}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{  tausq[k] }\OtherTok{\textless{}{-}}\NormalTok{ tausqk}
\NormalTok{  tausqk }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The AKVs are computed by adding the kriging variances and the extra variances due to semivariogram uncertainty (Equation \eqref{eq:augmentedvar}). The VKV values and the EAC values are computed. Both the AKV and the EAC differ among the evaluation points. As a summary, the mean of the two variables is computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{augmentedvar }\OtherTok{\textless{}{-}}\NormalTok{ var }\SpecialCharTok{+}\NormalTok{ tausq}
\NormalTok{MAKV0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(augmentedvar)}
\NormalTok{VKV }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \FunctionTok{length}\NormalTok{(var))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(dvar))) \{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{length}\NormalTok{(dvar))) \{}
\NormalTok{    VKVij }\OtherTok{\textless{}{-}}\NormalTok{ invI[i, j] }\SpecialCharTok{*}\NormalTok{ dvar[[i]] }\SpecialCharTok{*}\NormalTok{ dvar[[j]]}
\NormalTok{    VKV }\OtherTok{\textless{}{-}}\NormalTok{ VKV }\SpecialCharTok{+}\NormalTok{ VKVij}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{EAC }\OtherTok{\textless{}{-}}\NormalTok{ augmentedvar }\SpecialCharTok{+}\NormalTok{ (VKV }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ var))}
\NormalTok{MEAC0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(EAC)}
\end{Highlighting}
\end{Shaded}

For the spatial coverage sample of 90 points supplemented by a simple random sample of 10 points, MAKV equals 0.846 and MEAC equals 0.896.

The sample can be optimised with \textbf{spsann} function \texttt{optimUSER}. Argument \texttt{points} is a list containing a data frame (or matrix) with the coordinates of the fixed points (assigned to sub-argument \texttt{fixed}) and an integer of the number of supplemental points of which the locations are optimised (assigned to sub-argument \texttt{free}). As already stressed above an important difference with Section \ref{samplingforvariogram} is that the free and the fixed sample are merged and used together both for estimation of the semivariogram and for prediction. The objective functions \texttt{MAKV} and \texttt{MEAC} are defined in package \textbf{sswr}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{candi }\OtherTok{\textless{}{-}} \FunctionTok{spsample}\NormalTok{(grdHunterValley, }\AttributeTok{type =} \StringTok{"regular"}\NormalTok{,}
                  \AttributeTok{cellsize =} \FunctionTok{c}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{50}\NormalTok{), }\AttributeTok{offset =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{))}
\NormalTok{candi }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(candi)}
\FunctionTok{names}\NormalTok{(candi) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)}
\NormalTok{schedule }\OtherTok{\textless{}{-}} \FunctionTok{scheduleSPSANN}\NormalTok{(}
  \AttributeTok{initial.acceptance =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{initial.temperature =} \FloatTok{0.008}\NormalTok{, }\AttributeTok{temperature.decrease =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{chains =} \DecValTok{500}\NormalTok{, }\AttributeTok{chain.length =} \DecValTok{20}\NormalTok{, }\AttributeTok{stopping =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{x.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{y.min =} \DecValTok{0}\NormalTok{, }\AttributeTok{cellsize =} \DecValTok{50}\NormalTok{)}
\NormalTok{fixed }\OtherTok{\textless{}{-}} \FunctionTok{coordinates}\NormalTok{(mysample\_SC)}
\FunctionTok{names}\NormalTok{(fixed) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{)}
\NormalTok{pnts }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{fixed =}\NormalTok{ fixed, }\AttributeTok{free =}\NormalTok{ nsup)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{optimUSER}\NormalTok{(}
  \AttributeTok{points =}\NormalTok{ pnts, }\AttributeTok{candi =}\NormalTok{ candi,}
  \AttributeTok{fun =}\NormalTok{ MAKV,}
  \AttributeTok{esample =}\NormalTok{ mysample\_eval,}
  \AttributeTok{model =} \StringTok{"Exp"}\NormalTok{, }\AttributeTok{thetas =}\NormalTok{ thetas, }\AttributeTok{perturbation =} \FloatTok{0.01}\NormalTok{,}
  \AttributeTok{schedule =}\NormalTok{ schedule, }\AttributeTok{track =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:FigMBEK} shows for Hunter Valley a spatial coverage sample of 90 points, supplemented by 10 points optimised by SSA, using MAKV and MEAC as a minimisation criterion.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/FigMBEK-1} 

}

\caption{Optimised sampling pattern of 10 points supplemented to spatial coverage sample of 90 points, for semivariogram estimation and prediction, using the mean augmented kriging variance (MAKV) and the mean estimation adjusted criterion (MEAC) as a minimisation criterion. The prior semivariogram used in optimising the sampling pattern of the supplemental sample is an exponential semivariogram with a range of 200 m and a ratio of spatial dependence of 0.5.}\label{fig:FigMBEK}
\end{figure}

With MAKV as a minimisation criterion there are two pairs of supplemental points at very short distance (\textless{} 5 m), and with MEAC there is one such pair of supplemental points.

A histogram of the shortest distance to the spatial coverage sample is shown in Figure \ref{fig:HistogramShortestDistance}. With MEAC three supplemental points are at very short distance of the spatial coverage sample (\(<3\) m). The average distance between neighbouring spatial coverage sampling points equals 381 m.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/HistogramShortestDistance-1} 

}

\caption{Frequency distributions of the shortest distance to the spatial coverage sample of the supplemental sample, optimised with the mean augmented kriging variance (MAKV) and the mean estimation adjusted criterion (MEAC).}\label{fig:HistogramShortestDistance}
\end{figure}

MAKV of the optimised sample equals 0.771 which is 91\% of MAKV of the initial sample. MEAC of the optimised sample equals 0.789 which is 88\% of MEAC of the initial sample. The reduction of these two criteria through the optimisation is much smaller than for logdet and MVKV in Section \ref{samplingforvariogram}. This can be explained by the small number of sampling units that is optimised: only the locations of 10 points are optimised, 90 are fixed. In Section \ref{samplingforvariogram} all 100 locations were optimised.

\hypertarget{exercises-34}{%
\subsubsection*{Exercises}\label{exercises-34}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write an \textbf{R} script to select from Hunter Valley a spatial coverage sample of 80 points supplemented by 20 points. Use MEAC as a minimisation criterion, an exponential semivariogram with a distance parameter of 200 m and a ratio of spatial dependence of 0.8. Compare the minimised MEAC with MEAC reported above, obtained by supplementing a spatial coverage sample of 90 points by 10 points.
\end{enumerate}

\hypertarget{a-practical-solution}{%
\section{A practical solution}\label{a-practical-solution}}

Based on the optimised samples shown above, a straightforward, simple sampling design for estimation of the model parameters and for prediction is a spatial coverage sample supplemented with randomly selected points between the points of the spatial coverage sample at some chosen fixed distances. Figure \ref{fig:SpatialCoveragePlus} shows an example. A simple random subsample without replacement of size 10 is selected from the 90 points of the spatial coverage sample. These points are used as starting points to select a point at a distance of 20 m in a random direction.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{m }\OtherTok{\textless{}{-}} \DecValTok{10}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{314}\NormalTok{)}
\NormalTok{units }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(mysample\_SC), m, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{mySCsubsample }\OtherTok{\textless{}{-}}\NormalTok{ mysample\_SC[units, ]}
\NormalTok{dxy }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =}\NormalTok{ m, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\NormalTok{angle }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\AttributeTok{n =}\NormalTok{ m, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ pi)}
\NormalTok{dxy[, }\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{sin}\NormalTok{(angle); dxy[, }\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ h }\SpecialCharTok{*} \FunctionTok{cos}\NormalTok{(angle)}
\NormalTok{mysupsample }\OtherTok{\textless{}{-}}\NormalTok{ mySCsubsample }\SpecialCharTok{+}\NormalTok{ dxy}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SpatialCoveragePlus-1} 

}

\caption{Spatial coverage sample of 90 points supplemented by 10 points at short distance (20 m) from randomly selected spatial coverage points.}\label{fig:SpatialCoveragePlus}
\end{figure}

MAKV of this sample equals 0.801, and MEAC equals 0.809. For MAKV 40\% of the maximal reduction is realised by this practical solution; for MEAC this is 19\%.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5761674 307.8   12043445 643.2  12043445  643.2
Vcells 27969345 213.4   93670004 714.7 189381883 1444.9
\end{verbatim}

\hypertarget{Validation}{%
\chapter{Sampling for validation of maps}\label{Validation}}

In the previous chapters of Part II various methods are described for selecting sampling units with the aim to map the study variable. Once the map has been made, we would like to know how good it is. It should come as no surprise that the value of the study variable at a randomly selected location as shown on the map differs from the value at that location in reality. This difference is a prediction error. The question is how large this error is on average, and how variable it is. In this chapter I describe and illustrate with a real-world case study how to select sampling units at which we will confront the predictions with the true values, and how to estimate map quality indices from the prediction errors of these sampling units.

If the map has been made with a statistical model, then the predictors are typically model-unbiased and the variance of the prediction errors can be computed from the model. Think, for instance, of kriging which also yields a map of the kriging variance. In Chapters \ref{MBgridspacing} and \ref{MBSamplePattern} I showed how this kriging variance can be used to optimise the grid spacing (sample size) and the sampling pattern for mapping, respectively. So, if we have a map of these variances, why do we still need to collect new data for estimating the map quality?

The problem is that the kriging variances rely on the validity\index{Validity} of the assumptions made in modelling the spatial variation of the study variable. Do we assume a constant mean, or a mean that is a linear combination of some covariates? In the latter case, which covariates are assumed to be related to the study variable? Or should we model the mean with a non-linear function as in a random forest model? How certain are we about the semivariogram model type (spherical, exponential, etc.), and how good are our estimates of the semivariogram parameters? If one or more of the modelling assumptions are violated, the variances of the prediction errors as computed with the model may become biased. For this reason the quality of the map is preferably determined through independent validation, i.e.~by comparing predictions with observations not used in mapping, followed by design-based estimation of the map quality indices. This process is often referred to as validation\index{Validation}, perhaps better statistical validation, a subset of the more comprehensive term map quality evaluation\index{Map quality evaluation}, which includes the concept of fitness-for-use.

Statistical validation of maps is often done through data splitting\index{Data splitting} or cross-validation\index{Cross-validation}. In data splitting the data are split into two subsets, one for calibrating the model and mapping, one for validation. In cross-validation the data set is split into a number of disjoint subsets of equal size. Each subset is used one-by-one for calibration and prediction. The remaining subsets are used for validation. Leave-one-out cross-validation\index{Cross-validation!leave-one-out cross-validation} (LOOCV) is a special case of this, in which each sampling unit is left out one-by-one, and all other units are used for calibration and prediction of the study variable of the unit that is left out. The problem with data splitting and cross-validation is that the data used for mapping typically are from non-probability samples. This makes design-based estimation of the map quality indices unfeasible \citep{brus2011d}. Designing a sampling scheme starts with a comprehensive description of the aim of the sampling project \citep{gru06}. Mapping and validation are different aims which ask for different sampling approaches. For validation probability sampling is the best option because then a statistical model of the spatial variation of the prediction errors is not needed. Map quality indices, defined as population parameters, can be estimated model-free, by design-based inference (see also Section \ref{DBvsMB}).

\begin{rmdnote}
In statistical learning using large data sets a common approach is to randomly partition the data set in three subsets: a training subset, a validation subset, and a test subset (\citet{Hastie2009}, chapter 7). The training subset is used for fitting the models, the validation subset is used to estimate prediction error for model selection and hyperparameter tuning, while the test subset is used for assessing the accuracy of the final model. The term validation as used in this chapter is therefore the equivalent of testing as used in statistical learning.
\end{rmdnote}

All probability sampling designs described in Part I are in principle appropriate for validation. \citet{steh99} evaluated five basic probability sampling designs and concluded that in general stratified random sampling is a good choice. For validation of categorical maps natural strata are the map units, i.e.~the groups of polygons or grid cells assigned to each class. Systematic random sampling is less suitable as no unbiased estimator of the sampling variance of the estimator of a population mean exists for this design (see Chapter \ref{SY}). For validation of maps of extensive areas, think of whole continents, travel time between sampling locations can become substantial. In this case sampling designs that lead to spatial clustering of validation locations can become efficient, for instance cluster random sampling (Chapter \ref{Cl}) or two-stage cluster random sampling (Chapter \ref{Twostage}).

\hypertarget{map-quality-indices}{%
\section{Map quality indices}\label{map-quality-indices}}

In validation we want to assess the accuracy of the map as a whole. We are not interested in the accuracy at a sample of population units only. For instance, we would like to know the population mean of the prediction error, i.e.~the average of the errors over all population units, and not merely the average prediction error at a sample of units. Map quality indices are therefore defined as population parameters. We cannot afford to determine the prediction error for each unit of the mapping area to calculate the population means (if we could do that there would be no need for a mapping model). Therefore, we have to take a sample of units at which the predictions of the study variable are confronted with the observations. This sample is then used to \emph{estimate} population parameters of the prediction error and our uncertainty about these population parameters, as quantified, for instance, by their standard errors or confidence interval.

For quantitative maps, i.e.~maps depicting a quantitative study variable\index{Quantitative map}, popular map quality indices\index{Map quality index} are (i) the population mean error\index{Population mean error} (ME); (ii) the population mean absolute error\index{Population mean absolute error} (MAE); and (iii) the population mean squared error\index{Population mean squared error} (MSE), defined as

\begin{align}
ME = \frac{1}{N}\sum_{k=1}^N (\hat{z}_k-z_k) \\
MAE = \frac{1}{N}\sum_{k=1}^N (|\hat{z}_k-z_k|) \\
MSE = \frac{1}{N} \sum_{k=1}^N (\hat{z}_k-z_k)^2\;,
\label{eq:mapqualityindices}
\end{align}

with \(N\) the total number of units (e.g.~raster cells) in the population, \(\hat{z}_k\) the predicted value for unit \(k\), \(z_k\) the true value of that unit, and \(|\cdot|\) the absolute value operator. For infinite populations the sum must be replaced by an integral over all locations in the mapped area and divided by the size of the area. The ME quantifies the systematic error\index{Systematic error} and ideally equals 0. It can be positive (in case of overprediction) and negative (in case of underprediction). Positive and negative errors cancel out and, as a consequence, the ME does not quantify the magnitude of the prediction errors. The MAE and MSE do quantify the magnitude of the errors, they are non-negative. Often the square root of MSE is taken, denoted by RMSE, which is in the same units as the study variable and is therefore more intelligible. The RMSE is strongly affected by outliers (large prediction errors), due to the squaring of the errors, and for this reason I recommend to estimate both MAE and RMSE.

Two other important map quality indices are the population coefficient of determination\index{Population coefficient of determination} (\(R^2\)) and the Nash-Sutcliffe model efficiency coefficient\index{Model efficiency coefficient} (MEC). \(R^2\) is defined as the square of the Pearson correlation coefficient \(r\) of the study variable and the predictions of the study variable, given by

\begin{equation}
r = \frac{\sum_{k=1}^{N}(z_k - \bar{z})(\hat{z}_k-\bar{\hat{z}})}{\sqrt{\sum_{k=1}^{N}(z_k- \bar{z})^2}\sqrt{(\hat{z}_k-\bar{\hat{z}})^2}}=\frac{S^2(z,\hat{z})}{S(z)S(\hat{z})}\;,
\label{eq:r}
\end{equation}

with \(\bar{z}\) the population mean of the study variable, \(\bar{\hat{z}}\) the population mean of the predictions, \(S^2(z,\hat{z})\) the population covariance of the study variable and the predictions of \(z\), \(S(z)\) the population standard deviation of the study variable, and \(S(\hat{z})\) the population standard deviation of the predictions. Note that \(R^2\) is unaffected by bias and therefore should not be used in isolation, but always accompanied by ME.

MEC is defined as \citep{Janssen1995}

\begin{equation}
MEC=1-\frac{\sum_{k=1}^{N}(\hat{z}_k - z_k)^{2}}{\sum_{k=1}^{N}(z_k -\bar{z})^{2}}=1-\frac{MSE}{S^2(z)} \;,
\label{eq:MEC}
\end{equation}

with \(S^2(z)\) the population variance\index{Population variance} of the study variable. MEC quantifies the improvement made by the model over using the mean of the observations as a predictor. An MEC value of 1 indicates a perfect match between the observed and the predicted values of the study variable, whereas a value of 0 indicates that the mean of the observations is as good a predictor as the model. A negative value occurs when the mean of the observations is a better predictor than the model, i.e.~when the residual variance is larger than the variance of the measurements.

For categorical maps\index{Categorical map} a commonly used map quality index is the overall purity\index{Overall purity}, which is defined as the proportion of units that is correctly classified (mapped):

\begin{equation}
P = \frac{1}{N}\sum_{k=1}^N y_k\;,
\label{eq:Purity}
\end{equation}

with \(y_k\) an indicator for unit \(k\), having value 1 if the predicted class equals the true class, and 0 otherwise:

\begin{equation}
y_k = \left\{
\begin{array}{cc}
1 & \;\;\;\mathrm{if}\;\;\; \hat{c}_k = c_k\\
0 & \;\;\;\mathrm{otherwise}\;,
\end{array}
\right.
\label{eq:indfromy}
\end{equation}

with \(c_k\) and \(\hat{c}_k\) the true and the predicted class of unit \(k\), respectively. For infinite populations the purity is the fraction of the area that is correctly classified (mapped).

The population ME, MSE, \(R^2\), MEC, and purity can also be defined for subpopulations. For categorical maps natural subpopulations are the classes depicted in the map, the map units. In that case, for infinite populations the purity of map unit \(u\) is defined as the fraction of the area of map unit \(u\) that is correctly mapped as \(u\).

A different subpopulation is the part of the population that is \emph{in reality} class \(u\) (but possibly not mapped as \(u\)). We are interested in the fraction of the area covered by this subpopulation that is correctly mapped as \(u\). This is referred to as the class representation\index{Class representation} of class \(u\), for which I use hereafter the symbol \(R_u\).

\hypertarget{estimation-of-map-quality-indices}{%
\subsection{Estimation of map quality indices}\label{estimation-of-map-quality-indices}}

The map quality indices are defined as population or subpopulation means. To estimate these (sub)population means a design-based sampling approach is most appropriate. Sampling units are selected by probability sampling, and the map quality indices are estimated by design-based inference. For instance, the ME of a finite population can be estimated by the \(\pi\) estimator (see Equation \eqref{eq:HTMean}):

\begin{equation}
\widehat{ME} =\frac{1}{N} \sum_{k \in \mathcal{S}} \frac{1}{\pi_k}e_k \;,
\label{eq:HTME}
\end{equation}

with \(e_k = \hat{z}_k-z_k\) the prediction error for unit \(k\). By taking the absolute value of the prediction errors \(e_k\) in Equation \eqref{eq:HTME} or by squaring them, the \(\pi\) estimators for the MAE and MSE are obtained, respectively. By replacing \(e_k\) by the indicator \(y_k\) of Equation \eqref{eq:indfromy}, the \(\pi\) estimator for the overall purity is obtained.

With simple random sampling the square of the sample correlation coefficient, i.e.~the correlation of the study variable and the predictions of the study variable in the sample, is an unbiased estimator of \(R^2\). See \citet{sar92} (p.~\(486-491\)) for how to estimate \(R^2\) for other sampling designs.

The population MEC can be estimated by

\begin{equation}
\widehat{MEC}=1-\frac{\widehat{MSE}}{\widehat{S^2}(z)}\;.
\label{eq:HTMEC}
\end{equation}

For simple random sampling the sample variance\index{Sample variance}, i.e.~the variance of the observations of \(z\) in the sample, is an unbiased estimator of the population variance \(S^2(z)\). For other sampling designs this population variance can be estimated by Equation \eqref{eq:EstimatorPopulationVariance4AnyDesign}.

Estimation of the class representations is slightly more difficult, because the sizes of the classes (number of raster cells or area where in reality class \(u\) is present) are unknown and must therefore also be estimated. This leads to the ratio estimator:

\begin{equation}
\hat{R}_{u}=\frac{\sum_{k \in \mathcal{S}}\frac{y_k}{\pi_k}}{\sum_{k \in \mathcal{S}}\frac{x_k}{\pi_k}}\;,
\label{RatioEstimatorClassRepresentation}
\end{equation}

where \(y_{k}\) denotes an indicator defined as

\begin{equation}
y_{k} = \left\{
\begin{array}{cc}
1 & \;\;\;\mathrm{if}\;\;\; \hat{c}_k = c_k = u\\
0 & \;\;\;\mathrm{otherwise}\;,
\end{array}
\right.
\label{eq:indicatorfromy}
\end{equation}

and \(x_k\) denotes an indicator defined as

\begin{equation}
x_k = \left\{
\begin{array}{cc}
1 & \;\;\;\mathrm{if}\;\;\; c_k = u\\
0 & \;\;\;\mathrm{otherwise}\;.
\end{array}
\right.
\label{eq:indicatorfromx}
\end{equation}

This estimator is also recommended for estimating other map quality indices from a sample with a sample size that is not fixed but varies among samples selected with the sampling design. This is the case, for instance, when estimating the mean (absolute or squared) error or the purity of a given map unit from a simple random sample. The number of selected sampling units within the map unit is uncontrolled and varies among the simple random samples. In this case we can estimate the mean error or the purity of a map unit \(u\) by dividing the estimated population total by either the \emph{known} size (number of raster cells, area) of map unit \(u\) or by the \emph{estimated} size. Interestingly, in general using the estimated size in the denominator instead of the known size, yields a more precise estimator \citep{sar92}. See also Section \ref{LargeDomainsDirectEstimator}.

\hypertarget{real-world-case-study}{%
\section{Real-world case study}\label{real-world-case-study}}

As an illustration two soil maps of the three northern counties of Xuancheng (China), both depicting soil organic matter (SOM) concentration (g kg\textsuperscript{-1}) in the topsoil, are evaluated. In Section \ref{Ospats} the data of three samples, including the stratified random sample, were merged to estimate the parameters of a spatial model for the natural log of the SOM concentration. Here only the data of the two non-random samples, the grid sample and the iPSM sample, are used to map the SOM concentration. The stratified simple random sample is used for validation.

Two methods are used in mapping, kriging with an external drift\index{Kriging!kriging with an external drift} (KED) and random forest prediction\index{Random forest} (RF). For mapping with RF seven covariates are used: planar curvature, profile curvature, slope, temperature, precipitation, topographic wetness index, and elevation. For mapping with KED only the two most important covariates in the RF model are used: precipitation and elevation.

The two maps that are to be validated are shown in Figure \ref{fig:validatedmaps}. Note that non-soil areas (built-up, water, roads) are not predicted. The maps are quite similar. The most striking difference between the maps is the smaller range of the RF predictions: they range from 9.8 to 61.5, whereas the KED predictions range from 5.3 to 90.5.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/validatedmaps-1} 

}

\caption{Map of the SOM concentration (g kg\textsuperscript{-1}) in the topsoil of Xuancheng, obtained by kriging with an external drift (KED) and random forest (RF).}\label{fig:validatedmaps}
\end{figure}

The two maps are evaluated by statistical validation with a stratified simple random sample of 62 units (points). The strata are the eight units of a geological map (Figure \ref{fig:validationsample}).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/validationsample-1} 

}

\caption{Stratified simple random sample for validation of the two maps of the SOM concentration in Xuancheng.}\label{fig:validationsample}
\end{figure}

\hypertarget{estimation-of-the-population-mean-error-and-mean-squared-error}{%
\subsection{Estimation of the population mean error and mean squared error}\label{estimation-of-the-population-mean-error-and-mean-squared-error}}

To estimate the population MSE of the two maps, first the squared prediction errors are computed. The name of the measured study variable at the validation sample\index{Validation sample} in \texttt{data.frame} \texttt{sample\_test} is \texttt{SOM\_A\_hori}. Four new variables are added to \texttt{sample\_test} using function \texttt{mutate}, by computing the prediction errors for KED and RF and squaring these errors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_test }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file =} \StringTok{"results/STSI\_Xuancheng\_SOMpred.csv"}\NormalTok{)}
\NormalTok{sample\_test }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{eKED =}\NormalTok{ SOM\_A\_hori }\SpecialCharTok{{-}}\NormalTok{ SOM\_KED,}
      \AttributeTok{eRF =}\NormalTok{ SOM\_A\_hori }\SpecialCharTok{{-}}\NormalTok{ SOM\_RF,}
      \AttributeTok{e2KED =}\NormalTok{ (SOM\_A\_hori }\SpecialCharTok{{-}}\NormalTok{ SOM\_KED)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
      \AttributeTok{e2RF =}\NormalTok{ (SOM\_A\_hori }\SpecialCharTok{{-}}\NormalTok{ SOM\_RF)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

These four new variables now are our study variables of which we would like to estimate the population means. The population means can be estimated as explained in Chapter \ref{STSI}. First, the stratum sizes and stratum weights are computed, i.e.~the number and relative number of raster cells per stratum (Figure \ref{fig:validationsample}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmap }\OtherTok{\textless{}{-}} \FunctionTok{rast}\NormalTok{(}\AttributeTok{x =} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/Geo\_Xuancheng.tif"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sswr"}\NormalTok{))}
\NormalTok{strata\_Xuancheng }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(rmap, }\AttributeTok{xy =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{stratum =}\NormalTok{ Geo\_Xuancheng) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(stratum }\SpecialCharTok{!=} \DecValTok{99}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(stratum) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{N\_h =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{w\_h =}\NormalTok{ N\_h }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_h))}
\end{Highlighting}
\end{Shaded}

Next, the stratum means of the prediction errors, obtained with KED and RF, are estimated by the sample means, and the population mean of the errors are estimated by the weighted mean of the estimated stratum means.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{me }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(stratum) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{meKED\_h =} \FunctionTok{mean}\NormalTok{(eKED),}
      \AttributeTok{meRF\_h =} \FunctionTok{mean}\NormalTok{(eRF)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(strata\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{meKED =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ meKED\_h),}
      \AttributeTok{meRF =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ meRF\_h))}
\end{Highlighting}
\end{Shaded}

This is repeated for the squared prediction errors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mse }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(stratum) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{mseKED\_h =} \FunctionTok{mean}\NormalTok{(e2KED),}
      \AttributeTok{mseRF\_h =} \FunctionTok{mean}\NormalTok{(e2RF)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(strata\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{mseKED =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mseKED\_h),}
      \AttributeTok{mseRF =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ mseRF\_h))}
\end{Highlighting}
\end{Shaded}

The estimated MSE of the KED map equals 89.3 (g kg\textsuperscript{-1})\textsuperscript{2}, that of the RF map 93.8 (g kg\textsuperscript{-1})\textsuperscript{2}.

\hypertarget{exercises-35}{%
\subsubsection*{Exercises}\label{exercises-35}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Are you certain that the population MSE of the KED map is smaller than the population MSE of the RF map?
\end{enumerate}

\hypertarget{estimation-of-the-standard-error-of-the-estimator-of-the-population-mean-error-and-mean-squared-error}{%
\subsection{Estimation of the standard error of the estimator of the population mean error and mean squared error}\label{estimation-of-the-standard-error-of-the-estimator-of-the-population-mean-error-and-mean-squared-error}}

We are uncertain about both population MSEs, as we measured the squared errors at 62 sampling points only. So, we would like to know how uncertain we are. This uncertainty is quantified by the standard error of the estimator of the population MSE. A problem is that in the second stratum we have only one sampling point. So, for this stratum we cannot compute the variance of the squared errors. To compute the variance we need at least two sampling points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_strata }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(stratum) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{())}
\NormalTok{n\_strata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 2
  stratum     n
    <int> <int>
1       1     5
2       2     1
3       3     8
4       4    10
5       5     2
6       6    23
7       7     9
8       8     4
\end{verbatim}

A solution is to merge stratum 2 with stratum 1, which is a similar geological map unit (we know this from the domain expert). This is referred to as collapsing the strata. An identifier for the collapsed strata is added to \texttt{n\_strata}. This table is subsequently used to add the collapsed stratum identifiers to \texttt{sample\_test} and \texttt{strata\_Xuancheng}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_strata }\OtherTok{\textless{}{-}}\NormalTok{ n\_strata }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{stratum\_clp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{7}\NormalTok{))}
\NormalTok{sample\_test }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(n\_strata, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{)}
\NormalTok{strata\_Xuancheng }\OtherTok{\textless{}{-}}\NormalTok{ strata\_Xuancheng }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(n\_strata, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The collapsed strata\index{Collapsed strata} can be used to estimate the standard errors of the estimators of the population MSEs. As a first step the weights and the sample sizes of the collapsed strata are computed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{strata\_clp\_Xuancheng }\OtherTok{\textless{}{-}}\NormalTok{ strata\_Xuancheng }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(stratum\_clp) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}\AttributeTok{N\_hc =} \FunctionTok{sum}\NormalTok{(N\_h)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{w\_hc =}\NormalTok{ N\_hc }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(N\_hc)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      sample\_test }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{group\_by}\NormalTok{(stratum\_clp) }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{summarise}\NormalTok{(}\AttributeTok{n\_hc =} \FunctionTok{n}\NormalTok{()),}
      \AttributeTok{by =} \StringTok{"stratum\_clp"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The sampling variance of the estimator of the mean of the (squared) prediction error can be estimated by Equation \eqref{eq:EstVarMeanSTSI}. The estimated ME and MSE and their estimated standard errors are shown in Table \ref{tab:validationresults}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(stratum\_clp) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{s2e\_KED\_hc =} \FunctionTok{var}\NormalTok{(eKED),}
      \AttributeTok{s2e2\_KED\_hc =} \FunctionTok{var}\NormalTok{(e2KED),}
      \AttributeTok{s2e\_RF\_hc =} \FunctionTok{var}\NormalTok{(eRF),}
      \AttributeTok{s2e2\_RF\_hc =} \FunctionTok{var}\NormalTok{(e2RF)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{left\_join}\NormalTok{(strata\_clp\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum\_clp"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}
      \AttributeTok{se\_me\_KED =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_hc}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ s2e\_KED\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc)),}
      \AttributeTok{se\_mse\_KED =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_hc}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ s2e2\_KED\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc)),}
      \AttributeTok{se\_me\_RF =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_hc}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ s2e\_RF\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc)),      }
      \AttributeTok{se\_mse\_RF =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_hc}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ s2e2\_RF\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc)))}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:validationresults}Estimated population mean error (ME) and population mean squared error (MSE) of KED and RF map, and their standard errors.}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & KED & seKED & RF & seRF\\
\midrule
ME & 0.83 & 1.2 & 0.4 & 1.29\\
MSE & 89.30 & 25.5 & 93.8 & 25.80\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{exercises-36}{%
\subsubsection*{Exercises}\label{exercises-36}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Do you think there is a systematic error in the KED and the RF predictions?\\
\item
  Do you think the difference between the two estimated population MSEs is statistically significant?
\end{enumerate}

\hypertarget{estimation-of-model-efficiency-coefficient}{%
\subsection{Estimation of model efficiency coefficient}\label{estimation-of-model-efficiency-coefficient}}

To estimate the MEC, we must first estimate the population variance of the study variable from the stratified simple random sample (the denominator in Equation \eqref{eq:HTMEC}). First the sizes and the sample sizes of the collapsed strata must be added to \texttt{sample\_test}. Then the population variance is estimated with function \texttt{s2} of package \textbf{surveyplanning} (Subsection \ref{WhyStratify}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(surveyplanning)}
\NormalTok{s2z }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(strata\_clp\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum\_clp"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{s2z =} \FunctionTok{s2}\NormalTok{(SOM\_A\_hori, }\AttributeTok{w =}\NormalTok{ N\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  flatten\_dbl}
\end{Highlighting}
\end{Shaded}

Now the MECs for KED and RF can be estimated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mec }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ mse }\SpecialCharTok{/}\NormalTok{ s2z}
\end{Highlighting}
\end{Shaded}

The estimated MEC for KED equals 0.016 and for RF -0.034, showing that the two models used in mapping are no better than the estimated mean SOM concentration used as a predictor. This is quite a disappointing result.

\hypertarget{statistical-testing-of-hypothesis-about-population-me-and-mse}{%
\subsection{Statistical testing of hypothesis about population ME and MSE}\label{statistical-testing-of-hypothesis-about-population-me-and-mse}}

The hypothesis that the population ME equals 0 can be tested by a one-sample \emph{t}-test\index{\emph{t}-test!one-sample \emph{t}-test}. The alternative hypothesis is that ME is unequal to 0 (two-sided alternative). The number of degrees of freedom of the \emph{t} distribution is approximated by the total sample size minus the number of strata (Section \ref{CISTSI}). Note that we have a two-sided alternative hypothesis\index{Two-sided alternative hypothesis}, so we must compute a two-sided \emph{p}-value\index{\emph{p}-value of a test!two-sided \emph{p}-value}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t\_KED }\OtherTok{\textless{}{-}}\NormalTok{ me}\SpecialCharTok{$}\NormalTok{meKED }\SpecialCharTok{/}\NormalTok{ se}\SpecialCharTok{$}\NormalTok{se\_me\_KED}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(sample\_test) }\SpecialCharTok{{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(sample\_test}\SpecialCharTok{$}\NormalTok{stratum\_clp))}
\NormalTok{p\_KED }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*} \FunctionTok{pt}\NormalTok{(t\_KED, }\AttributeTok{df =}\NormalTok{ df, }\AttributeTok{lower.tail =}\NormalTok{ t\_KED }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The outcomes of the test statistics are 0.690 and 0.309 for KED and RF, respectively, with \emph{p}-values 0.493 and 0.759. So, we clearly have not enough evidence for systematic errors, neither with KED nor with RF mapping.

Now we test whether the two population MSEs differ significantly. This can be done by a paired \emph{t}-test\index{\emph{t}-test!paired \emph{t}-test}. The first step in a paired \emph{t}-test is to compute pairwise differences of squared prediction errors, and then we can proceed as in a one-sample \emph{t}-test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m\_de2 }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{de2 =}\NormalTok{ e2KED }\SpecialCharTok{{-}}\NormalTok{ e2RF) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(stratum) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{m\_de2\_h =} \FunctionTok{mean}\NormalTok{(de2)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(strata\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{m\_de2 =} \FunctionTok{sum}\NormalTok{(w\_h }\SpecialCharTok{*}\NormalTok{ m\_de2\_h)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  flatten\_dbl}

\NormalTok{se\_m\_de2 }\OtherTok{\textless{}{-}}\NormalTok{ sample\_test }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{de2 =}\NormalTok{ e2KED }\SpecialCharTok{{-}}\NormalTok{ e2RF) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(stratum\_clp) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{s2\_de2\_hc =} \FunctionTok{var}\NormalTok{(de2)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(strata\_clp\_Xuancheng, }\AttributeTok{by =} \StringTok{"stratum\_clp"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{se\_m\_de2 =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(w\_hc}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ s2\_de2\_hc }\SpecialCharTok{/}\NormalTok{ n\_hc))) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  flatten\_dbl}

\NormalTok{t }\OtherTok{\textless{}{-}}\NormalTok{ m\_de2 }\SpecialCharTok{/}\NormalTok{ se\_m\_de2}
\NormalTok{p }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*} \FunctionTok{pt}\NormalTok{(t, }\AttributeTok{df =}\NormalTok{ df, }\AttributeTok{lower.tail =}\NormalTok{ t }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The outcome of the test statistic is -0.438, with a \emph{p}-value\index{\emph{p}-value of a test!two-sided \emph{p}-value} of 0.663, so we clearly do not have enough evidence that the population MSEs obtained with the two mapping methods are different.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5744643 306.8   12043445 643.2  12043445  643.2
Vcells 29819437 227.6   93670004 714.7 189381883 1444.9
\end{verbatim}

\hypertarget{Approaches}{%
\chapter{Design-based, model-based, and model-assisted approach for sampling and inference}\label{Approaches}}

In Section \ref{DBvsMB} I already mentioned the design-based and the model-based approach for sampling and statistical inference. In this chapter the fundamental differences between these two approaches are explained in more detail. Several misconceptions about the design-based approach\index{Design-based approach} for sampling and statistical inference, based on classical sampling theory\index{Classical sampling theory}, seem to be quite persistent. These misconceptions are the result of confusion about basic statistical concepts such as independence, expectation, and bias and variance of estimators or predictors. These concepts have a different meaning in the design-based and the model-based approach\index{Model-based approach}. Besides, a population mean is still often confused with a model-mean, and a population variance with a model-variance, leading to invalid formulas for the sampling variance of an estimator of the population mean. The fundamental differences between these two approaches are illustrated with simulations, so that hopefully a better understanding of this subject is obtained. Besides, the difference between model-dependent inference (as used in the model-based approach) and model-assisted inference is explained. This chapter has been published as part of a journal paper, see \citet{Brus2021}.

\hypertarget{two-sources-of-randomness}{%
\section{Two sources of randomness}\label{two-sources-of-randomness}}

In my classes about spatial sampling I ask the participants the following question. Suppose we have measurements of a soil property, for instance soil organic carbon content, at two locations separated by 20 cm. Do you think these two measurements are correlated? I ask them to vote for one of three answers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  yes, they are (\textgreater{} 80\% confident);
\item
  no, they are not (\textgreater{} 80\% confident); or
\item
  I do not know.
\end{enumerate}

Most students vote for answer 1, the other students vote for answer 3, nearly no one votes for answer 2. Then I explain that you cannot say, simply because for correlation we need two series of data, not just two numbers. The question then is how to generate two series of data. We need some random process\index{Random process} for this. This random process differs between the design-based and the model-based approach.

In the design-based approach the random process is the random selection of sampling units, whereas in the model-based approach randomness is introduced via the statistical model of the spatial variation (Table \ref{tab:approach}). So, the design-based approach requires probability sampling, i.e.~random sampling, using a random number generator\index{Random number generator}, in such way that all population units have a positive probability of being included in the sample and that these inclusion probabilities are known for at least the selected population units \citep{sar92}. A probability sampling\index{Probability sampling} design can be used to generate an infinite number of samples in theory, although in practical applications only one is selected.

The spatial variation model\index{Spatial variation model} used in the model-based approach contains two terms, one for the mean (deterministic part) and one for the error with a specified probability distribution. For instance, Equation \eqref{eq:OKmodel} in Chapter \ref{Introkriging} describes the model used in ordinary kriging. This model can be used to simulate an infinite number of spatial populations. All these populations together are referred to as a superpopulation (\citet{sar92}, \citet{loh99}). Depending on the model of spatial variation, the simulated populations may show spatial structure\index{Spatial structure} because the mean is a function of covariates, as in kriging with an external drift, and/or because the errors are spatially autocorrelated. A superpopulation\index{Superpopulation} is a construct, the populations do not exist in the real world. The populations are similar, but not identical. For instance, the mean differs among the populations. The expectation of the population mean, i.e.~the average over all possible simulated populations, equals the superpopulation mean\index{Superpopulation mean}, commonly referred to as the model-mean\index{Model-mean}, parameter \(\mu\) in Equation \eqref{eq:OKmodel}. The variance also differs among the populations. Contrary to the mean, the average of the population variance over all populations generally is not equal to the model-variance, parameter \(\sigma^2\) in Equation \eqref{eq:OKmodel}, but smaller. I will come to this later. The differences between the simulated spatial populations illustrate our uncertainty about the spatial variation of the study variable in the population that is sampled or will be sampled.

In the design-based approach only one population is considered, the one sampled, but the statistical inference is based on all samples that can be generated by a probability sampling. The top row of Figure \ref{fig:plotsimulationsDBMB} shows five simple random samples of size ten. The population is the same in all plots. Proponents of the design-based approach do not like to consider other populations than the one sampled. Their challenge is to characterise this one population from a probability sample.

On the contrary, in the model-based approach only one sample is considered, but the statistical inference is based on all populations that can be generated with the spatial variation model. Proponents of the model-based approach do not like to consider other samples than the one selected. Their challenge is to get most out of the sample that is selected. The bottom row of Figure \ref{fig:plotsimulationsDBMB} shows a spatial coverage sample, superimposed on five different populations simulated with an ordinary kriging model, using a spherical semivariogram with a nugget of 0.1, partial sill of 0.6, and a range of 75 m. Note that in the model-based approach there is no need to select a probability sample (see Table \ref{tab:approach}), there are no requirements on how the units are selected.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/plotsimulationsDBMB-1} 

}

\caption{Random process considered in the design-based (top row) and the model-based approach (bottom row). The design-based approach considers only the sampled population, but all samples that can be generated by the sampling design. The model-based approach considers only the selected sample, but all populations that can be generated by the model.}\label{fig:plotsimulationsDBMB}
\end{figure}

As stressed by \citet{dgr90} and \citet{bru97} both approaches have their strengths and weaknesses. Broadly speaking, the design-based approach is most appropriate if interest is in the population mean (total, proportion) or the population means (totals, proportions) of a restricted number of subpopulations (subareas). The model-based approach is most appropriate if our aim is to map the study variable. Further, the strength of the design-based approach is the strict validity\index{Validity} of the estimates. Validity means that an objective assessment of the uncertainty of the estimator is warranted and that the coverage of confidence intervals is (almost) correct, provided that the sample is large enough to assume an approximately normal distribution of the estimator and design-unbiasedness of the variance estimator \citep{sar92}. The strength of the model-based approach is efficiency, i.e.~more precise estimates of the (sub)population mean given the sample size, provided that a reasonably good model is used. So, if validity is more important than efficiency, the design-based approach is the best choice; in the reverse case, the model-based approach is preferable. For further reading I recommend \citet{Cassel1977} and \citet{han83}.

\hypertarget{iid}{%
\section{``Identically and independently distributed'' (i.i.d.)}\label{iid}}

In a review paper on spatial sampling by \citet{Wang2012} there is a section with the caption `Sampling of i.i.d populations'. Here i.i.d. stands for ``identically and independently distributed\index{Identically and independently distributed}''. In this section of \citet{Wang2012} we can read: ``In SRS (simple random sampling) it is assumed that the population is independent and identically distributed''. This is one of the old misconceptions revitalised by this review paper. I will make clear that in statistics i.i.d is not a characteristic of populations, so the concept of i.i.d. populations does not make sense. The same misconception can be found in \citet{Plant2012}: ``There is considerable literature on sample size estimation, much of which is discussed by Cochran (1977, Chapter 4). This literature, however, is valid for samples of independent data but may not retain its validity for spatial data''. Also according to \citet{Wang2010} the classical formula for the variance of the estimator of the mean with simple random sampling, \(V=\sigma^2/n\), only holds when data are independent. They say: ``However in the case of spatial data, although members of the sample are independent by construction, data values that are near to one another in space, are unlikely to be independent because of a fundamental property of attributes in space, which is that they show spatial structure or continuity (spatial autocorrelation)''. According to \citet{Wang2010} the variance should be approximated by

\begin{equation}
V(\hat{\bar{z}})=\frac{\sigma^2 - \overline{\mathrm{Cov}(z_i,z_j)}}{n} \;,
\label{eq:Wang2010}
\end{equation}

with \(V(\hat{\bar{z}})\) the variance of the estimator of the regional mean (mean of spatial population), \(\sigma^2\) the population variance, \(n\) the sample size, and \(\overline{\mathrm{Cov}(z_i,z_j)}\) the average autocovariance between all pairs of individuals \((i, j)\) in the population (sampled and unsampled). So, according to this formula, ignoring the mean covariance within the population leads to an over-estimation of the variance of the estimator of the mean. In Section \ref{effectivesamplesize} I will make clear that this formula is incorrect and that the classical formula is still valid, also for populations showing spatial structure or continuity.

Remarkably, in other publications we can read that the classical formula for the variance of the estimator of the population mean with simple random sampling \emph{underestimates} the true variance for populations showing spatial structure, see for instance \citet{Griffith2005} and \citet{Plant2012}. The reasoning is that due to the spatial structure, there is less information in the sample data about the population mean. In Section \ref{effectivesamplesize} I explain that this is also a misconception. Do not get confused by these publications and stick to the classical formulas which you can find in standard textbooks on sampling theory, such as \citet{coc77} and \citet{loh99}, as well as in Chapter \ref{SI}.

The concept of independence of random variables is illustrated with a simulation. The top row of Figure \ref{fig:iid} shows five simple random samples of size two. The two points are repeatedly selected from the same population (showing clear spatial structure), so this top row represents the design-based approach. The bottom row shows two points, not selected randomly and independently, but at a fixed distance of 10 m. These two points are placed on different populations generated by the model described above, so the bottom row represents the model-based approach.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/iid-1} 

}

\caption{Illustration of independence in design-based and model-based approach. The top row shows five samples of two points selected randomly and independently from each other from one population (design-based approach). The bottom row shows two points not selected randomly, at a distance of 10 m from each other, from five model realisations (model-based approach).}\label{fig:iid}
\end{figure}



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ScatterplotsTwopoints-1} 

}

\caption{Scatter plots of the values of a study variable \(z\) at two randomly and independently selected points, 1,000 times selected from one population (design-based approach), and at two fixed points with a separation distance of 10 m, selected non-randomly from 1,000 model realisations (model-based approach).}\label{fig:ScatterplotsTwopoints}
\end{figure}

The values measured at the two points are plotted against each other in a scatter plot, but now not for just five simple random samples or five populations, but for 1,000 samples and 1,000 populations (Figure \ref{fig:ScatterplotsTwopoints}). As we can see there is no correlation between the two variables generated by the repeated random selection of the two points (design-based), whereas the two variables generated by the repeated simulation of populations (model-based) are correlated.

Instead of two points, we may select two series of probability samples independently from each other, for instance two series of simple random samples (SI) of size 10, or two series of systematic random samples with random origin (SY) with an average size of 10, see Figure \ref{fig:TwoseriesSISY}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/TwoseriesSISY-1} 

}

\caption{Two series (a and b) of simple random samples of ten points (top) and two series (a and b) of systematic random samples of, on average, ten points (bottom). The samples of series a and b are selected independently from each other.}\label{fig:TwoseriesSISY}
\end{figure}

Again, if we plot the sample means of pairs of simple random samples and pairs of systematic random samples against each other, we see that the two averages are not correlated (Figure \ref{fig:ScatterplotsSISY}). Note that the variation of the averages of the systematic random samples is considerably smaller than that of the simple random samples. The sampled population shows spatial structure. By spreading the sampling units out over the spatial population, the precision of the estimated population mean is increased, see Chapter \ref{SY}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ScatterplotsSISY-1} 

}

\caption{Scatter plots of averages of 1,000 pairs of simple random samples of ten points (SI) and of averages of 1,000 pairs of systematic random samples of ten points on average (SY).}\label{fig:ScatterplotsSISY}
\end{figure}

This sampling experiment shows that independence is not a characteristic of a population, as stated by \citet{Wang2012}, but of random variables (in the experiment the values at points or the sample means) generated by a random process. As the random process differs between the design-based and the model-based approach, independence has a different meaning in these two approaches. For this reason, it is imperative to be more specific when using the term independence, by saying that data are \emph{design-independent}\index{Independence!design-independence} or that you \emph{assume} that the data are \emph{model-independent}\index{Independence!model-independence}.

\hypertarget{BiasandVariance}{%
\section{Bias and variance}\label{BiasandVariance}}

Bias and variance are commonly used statistics to quantify the quality of an estimator. Bias quantifies the systematic error, variance the random error of the estimator. Both are defined as expectations. But expectations over the realisations of which random process? Over realisations of a probability sampling design (samples) or realisations of a statistical model (populations)? Like independence, it is important to distinguish \emph{design-bias}\index{Bias!design-bias} from \emph{model-bias}\index{Bias!model-bias} and \emph{design-variance}\index{design-variance} (commonly referred to as sampling variance) from \emph{model-variance}\index{Model-variance}.

The concept of model-unbiasedness deserves more attention. Figure \ref{fig:preferentialsample} shows a preferential sample\index{Preferential sample} from a population simulated by sequential Gaussian simulation with a constant mean of 10 and an exponential semivariogram without nugget, a sill of 5, and a distance parameter of 20. The points are selected by sampling with draw-by-draw selection probabilities proportional to size (pps sampling, Chapter \ref{pps}), using the square of the simulated values as a size variable. We may have a similar sample that is collected for delineating soil contamination or detecting hot spots of soil bacteria, etc. Many samples are selected at locations with a large value, few points at locations with a small value. The sample data are used in ordinary kriging (Figure \ref{fig:preferentialsample}). The prediction errors are computed by subtracting the kriged map from the simulated population.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/preferentialsample-1} 

}

\caption{Preferential sample (size of open dots is proportional to value of study variable) from a simulated field (z) and map of ordinary kriging predictions (zpred).}\label{fig:preferentialsample}
\end{figure}

Figure \ref{fig:histogramerrorpreferentialsample} shows a histogram of the prediction errors. The population mean error equals 0.483, not 0. You may have expected a positive systematic error because of the overrepresentation of locations with large values, but on the other hand, kriging predictions are best linear unbiased predictions\index{Best linear unbiased predictor} (BLUP), so from that point of view, this systematic error might be unexpected. BLUP means that at individual locations the ordinary kriging predictions are unbiased. However, apparently this does not guarantee that the average of the prediction errors, averaged over all population units, equals 0. The reason is that unbiasedness is defined here over all realisations (populations) of the statistical model of spatial variation. So, the U in BLUP stands for model-unbiasedness. For other model realisations, sampled at the same points, we may have much smaller values, leading to a negative mean error of that population. On average, over all populations, the error at any point will be 0 and consequently also the average over all populations of the mean error.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/histogramerrorpreferentialsample-1} 

}

\caption{Frequency distribution of the errors of ordinary kriging predictions from a preferential sample.}\label{fig:histogramerrorpreferentialsample}
\end{figure}

This experiment shows that model-unbiasedness does not protect us against selection bias\index{Bias!selection bias}, i.e.~bias due to preferential sampling.

\hypertarget{effectivesamplesize}{%
\section{Effective sample size}\label{effectivesamplesize}}

Another persistent misconception is that when estimating the variance of the estimator of the mean of a spatial population or the correlation of two variables of a population we must account for autocorrelation\index{Autocorrelation} of the sample data. This misconception occurs, for instance, in \citet{Griffith2005} and in various sections (for instance, Sections 3.5, 10.1, and 11.2) of \citet{Plant2012}. The reasoning is that, due to the spatial autocorrelation in the sample data, there is less information in the data about the parameter of interest, and so the effective sample size\index{Effective sample size} is smaller than the actual sample size. An early example of this misconception is Barnes' publication on the required sample size for estimating nonparametric tolerance intervals \citep{Barnes1988}. \citet{dgr92} showed that a basic probability sampling design like simple random sampling requires fewer sampling points than the model-based sampling design proposed by Barnes.

The misconception is caused by confusing population parameters with model parameters. Recall that the population mean and the model-mean are not the same; the model-mean \(\mu\) of Equation \eqref{eq:OKmodel} is the expectation of the population means over all populations that can be simulated with the model. The same holds for the variance of a variable as well as for the covariance and the Pearson correlation coefficient of two variables. All these parameters can be defined as parameters of a (finite or infinite) population or of random variables generated by a superpopulation model. Using an effective sample size to quantify the variance of an estimator is perfectly correct for model parameters, but not so for population parameters. For instance, when the correlation coefficient is defined as a population parameter and sampling units are selected by simple random sampling, there is no need to apply the method proposed by \citet{Clifford1989} to correct the \emph{p}-value\index{\emph{p}-value of a test} in a significance test for the presence of spatial autocorrelation.

I elaborate on this for the mean as the parameter of interest. Suppose a sample is selected in some way (need not be random) and the sample mean is used as an estimator of the model-mean. Note that for a model with a constant mean as in Equation \eqref{eq:OKmodel}, the sample mean is a model-unbiased\index{Unbiasedness!model-unbiasedness} estimator of the model-mean, but in general not the best linear unbiased estimator\index{Best linear unbiased estimator} (BLUE) of the model-mean. If the random variables are model-independent, the variance of the sample mean, used as an estimator of the model-mean, can be computed by

\begin{equation}
V(\hat{\mu}) = \frac{\sigma^2}{n} \;,
\label{eq:VindModelMean}
\end{equation}

with \(\sigma^2\) the model-variance of the random variable (see Equation \eqref{eq:OKmodel}). The variance presented in Equation \eqref{eq:VindModelMean} necessarily is a model-variance as it quantifies our uncertainty about the model-mean, which only exists in the model-based approach. If the random variables are not model-independent, the model-variance of the sample mean can be computed by \citep{gru06}

\begin{equation}
    V(\hat{\mu}) = \frac{\sigma^2}{n} \{1+(n-1)\bar{\rho}\} \;,
\label{eq:VdepModelMean}
\end{equation}

with \(\bar{\rho}\) the mean correlation within the sample (the average of the correlation of all pairs of sampling points). The term inside the curly brackets is larger than 1, unless \(\bar{\rho}\) equals 0. So, the variance of the estimator of the model-mean with dependent data is larger than when data are independent. The number of independent observations that is equivalent to a spatially autocorrelated data set's sample size \(n\), referred to as the effective sample size, can be computed by \citep{gru06}

\begin{equation}
    n_{\mathrm{eff}}= \frac{n}{\{1+(n-1)\bar{\rho}\}} \;.
\label{eq:effectivesamplesize}
\end{equation}

So, if we substitute \(n_{\mathrm{eff}}\) for \(n\) in Equation \eqref{eq:VindModelMean}, we obtain the variance presented in Equation \eqref{eq:VdepModelMean}. Equation \eqref{eq:effectivesamplesize} is equivalent to Equation (2) in \citet{Griffith2005}. Figure \ref{fig:effectivesamplesize} shows that the effective sample size decreases sharply with the mean correlation. With a mean correlation of 0 the effective sample size equals the actual sample size, with a mean correlation of 1 the effective sample size equals 1.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/effectivesamplesize-1} 

}

\caption{Effective sample sizes as a function of the mean correlation within the sample, for samples of size 25 and 100.}\label{fig:effectivesamplesize}
\end{figure}

To illustrate the difference between the model-variance and the design-variance of a sample mean, I simulated a finite population of 100 units, located at the nodes of a square grid, with a model-mean of 10, an exponential semivariogram without nugget, an effective range of three times the distance between adjacent population units, and a sill of 1 (Figure \ref{fig:finitepopulation}). The model-variance of the average of a simple random sample \emph{without replacement} of size \(n\) is computed using Equation \eqref{eq:VdepModelMean}, and the design-variance of the sample mean, used as an estimate of the population mean, is computed by (see Equation \eqref{eq:EstVarMeanSI})

\begin{equation}
V(\hat{\bar{z}})=\left(1-\frac{n}{N}\right)\frac{S^2}{n} \;,
\label{eq:varmeanSRSwithout}
\end{equation}

with \(N\) the total number of population units (\(N=100\)). This is done for a range of sample sizes: \(n = 10, 11, \dots ,100\). Note that for \(n < 100\) the model-variance of the sample mean for a given \(n\), differs between samples. For samples showing strong spatial clustering, the mean correlation is relatively large, and consequently the model-variance is relatively large (see Equation \eqref{eq:VdepModelMean}). There is less information in these samples about the model-mean than in samples without spatial clustering of the points. Therefore, to estimate the expectation of the model-variance over repeated simple random sampling for a given \(n\), I selected 200 simple random samples of that size \(n\), and I averaged the 200 model-variances. Figure \ref{fig:MBvarDBvar} shows the result. Both the model-variance and the design-variance of the sample mean decrease with the sample size. For all sample sizes the model-variance is larger than the design-variance. The design-variance goes to 0 for \(n = 100\) (see Equation \eqref{eq:varmeanSRSwithout}), whereas the model-variance for \(n = 100\) equals 0.0509. This can be explained as follows. Although with \(n = 100\) we know the population mean without error, this population mean is only an estimate of the model-mean. Recall that the model-mean is the expectation of the population mean over all realisations of the model.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/finitepopulation-1} 

}

\caption{Simple random sample without replacement of ten points from a  finite population simulated with a model with a model-mean of 10, a model-variance of 1, and an exponential semivariogram (without nugget) with a distance parameter equal to the distance between neighbours (effective range is three times this distance). The mean correlation within the sample equals 0.135, and the model-variance of the estimator of the model-mean equals 0.222.}\label{fig:finitepopulation}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/MBvarDBvar-1} 

}

\caption{Model-variance (MB) and design-variance (DB) of the average of a simple random sample without replacement as a function of the sample size.}\label{fig:MBvarDBvar}
\end{figure}

In Figure \ref{fig:HistogramsMeanVariance} we can see that the population mean shows considerable variation. The variance of 10,000 simulated population means equals 0.0513, which is nearly equal to the value of 0.0509 for the model-variance computed with Equation \eqref{eq:VdepModelMean}.

In observational research I cannot think of situations in which interest is in estimation of the mean of a superpopulation model. This in contrast to experimental research. In experimental research we are interested in the effects of treatments, think for instance of the effects of different types of soil tillage on the soil carbon stock. These treatment effects are quantified by different model-means. Also, in time-series analysis of data collected in observational studies we might be more interested in the model-mean than in the mean over a bounded period of time.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/HistogramsMeanVariance-1} 

}

\caption{Frequency distributions of means and variances of 10,000 simulated populations.}\label{fig:HistogramsMeanVariance}
\end{figure}

Now let us return to Equation \eqref{eq:Wang2010}. What is wrong with this variance estimator? Where \citet{Griffith2005} confused the population mean and the model-mean, \citet{Wang2010} confused the population variance with the sill\index{Sill} (a priori variance) of the random process that has generated the population \citep{webster2007}. The parameter \(\sigma^2\) in their formula is defined as the population variance. In doing so the variance estimator is clearly wrong. However, if we define \(\sigma^2\) in this formula as the sill, the formula makes more sense, but even then, the equation is not fully correct. The variance computed with this equation is not the design-variance of the average of a simple random sample selected from the sampled population, but the \emph{expectation} of this design-variance over all realisations of the model. So, it is a model-based prediction of the design-variance of the estimator of the population mean, estimated from a simple random sample, see Chapter \ref{MBpredictionofDesignVariance}. For the population actually sampled, the design-variance is either smaller or larger than this expectation. Figure \ref{fig:HistogramsMeanVariance} shows that there is considerable variation in the population variance among the 10,000 populations simulated with the model. Consequently, for an individual population the variance of the estimator of the population mean, estimated from a simple random sample, can largely differ from the model-expectation of this variance. Do not use Equation \eqref{eq:Wang2010} for estimating the design-variance of the estimator of the population mean, but simply use Equation \eqref{eq:varmeanSRSwithout} (for simple random sampling with replacement and simple random sampling of infinite populations the term \((1-n/N)\) can be dropped). Equation \eqref{eq:Wang2010} is only relevant for comparing simple random sampling under a variety of models of spatial variation (\citet{Ripley1981}, \citet{dom94}).

\hypertarget{ExploitSpatialStructure}{%
\section{Exploiting spatial structure in design-based approach}\label{ExploitSpatialStructure}}

A further misconception is that in the design-based approach the possibilities of exploiting our knowledge about the spatial structure of the study variable are limited, because the sampling units are selected randomly. This would indeed be a very serious drawback, but happily enough, this is not true. There are various ways of utilising this knowledge. Our knowledge about the spatial structure can be used either at the stage of designing the sample and/or at the stage of the statistical inference once the data are collected (Table \ref{tab:TableExploitingSpatialStructure}).

I distinguish the situation in which maps of covariates are available from the situation in which such maps are lacking. In the first situation, the covariate maps can be used, for instance, to stratify the population (Chapter \ref{STSI}). With a quantitative covariate, optimal stratification methods are available. Other options are, for instance, pps sampling (Chapter \ref{pps}), and balanced sampling and well-spread sampling in covariate space with the local pivotal method (Chapter \ref{BalancedSpreaded}). At the inference stage the covariate maps can be used in a model-assisted approach\index{Model-assisted approach}, using, for instance, a linear regression model to increase the precision of the design-based estimator (Chapter \ref{Modelassisted}, Section \ref{ModelassistedvsModeldependent}).

If no covariate maps are available, we may anticipate the presence of spatial structure by spreading out the sampling units throughout the study area. This spreading can be done in many ways, for instance by systematic random sampling (Chapter \ref{SY}), compact geographical stratification (Section \ref{geostrata}), well-spread sampling in geographical space with the local pivotal method (LPM) (Subsection \ref{LPM}), and generalised random-tessellation stratified (GRTS) sampling (Subsection \ref{GRTS}). At the inference stage, again a model-assisted approach can be advantageous, using the spatial coordinates in a regression model.

\begin{table}

\caption{\label{tab:TableExploitingSpatialStructure}Strategies in the design-based approach for exploiting knowledge about the spatial structure of the study variable. LPM: local pivotal method.}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lll}
\toprule
Stage & Covariates available & No covariates\\
\midrule
Sampling & Stratified random sampling & Systematic random sampling\\
 & pps sampling & Compact geographical stratification\\
 & Balanced sampling & Geographical spreading with LPM\\
 & Covariate-space spreading with LPM & GRTS sampling\\
Inference & Model-assisted: regression model & Model-assisted: spatial regression model\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{ModelassistedvsModeldependent}{%
\section{Model-assisted versus model-dependent}\label{ModelassistedvsModeldependent}}

In this section the difference between the model-assisted approach and the model-based approach is explained. The model-assisted approach is a hybrid approach in between the design-based and the model-based approach. It tries to build the strength of the model-based approach, a potential increase of the accuracy of estimates, into the design-based approach. As in the design-based approach, sampling units are selected by probability sampling, and consequently bias and variance are defined as design-bias and design-variance (Table \ref{tab:threeapproaches}). As in the model-based approach, a superpopulation model is used. However, the role of this model in the two approaches is fundamentally different. In both approaches we assume that the population of interest is a realisation of the superpopulation model. However, as explained above, in the model-based approach, the statistical properties of the estimators (predictors), such as bias and variance, are defined over all possible realisations of the model (Table \ref{tab:threeapproaches}). So, unbiasedness and minimum variance of an estimator (predictor) means \emph{model}-unbiasedness and minimum \emph{model}-variance. On the contrary, in the model-assisted approach the model is used to derive an efficient estimator (Chapter \ref{Modelassisted}). To stress its different role in the model-assisted approach, the model is referred to as a working model\index{Working model}.

\begin{table}

\caption{\label{tab:threeapproaches}Three statistical approaches for sampling and inference.}
\centering
\fontsize{7}{9}\selectfont
\begin{tabular}[t]{lllll}
\toprule
Approach & Sampling & Inference & Regression coefficients & Quality criteria\\
\midrule
Design-based & Prob. sampling & Design-based & No model & Design-bias,  Design-variance\\
Model-assisted & Prob. sampling & Model-assisted & Population par. & Design-bias,  Design-variance\\
Model-based & No requirement & Model-depend. & Superpop. par. & Model-bias, Model-variance\\
\bottomrule
\end{tabular}
\end{table}

An important property of model-assisted estimators is that, if a poor working model is used (our assumptions about how our population is generated are incorrect), then for moderate sample sizes the results are still valid, i.e.~the empirical coverage rate\index{Empirical coverage rate} of a model-assisted estimate of the confidence interval of the population mean still is approximately equal to the nominal coverage rate. This is because the mismatch of the superpopulation model and the applied model-assisted estimator results in a large design-variance of the estimator of the population mean. This is illustrated with a simulation study, in which I compare the effect of using a correct versus an incorrect model in estimation.

A population is simulated with a simple linear regression model with an intercept of 15 (\(\beta_0 = 15\)), a slope coefficient of 0.5 (\(\beta_1 = 0.5\)), and a constant residual standard deviation of 2 (\(\sigma_{\epsilon}=2\)). This is done by first simulating a population with covariate values with a model-mean of 20 (\(\mu(x)=20\)), using an exponential semivariogram without nugget, a sill variance of 25, and a distance parameter of 20 distance units. This field with covariate values is then linearly transformed using the above mentioned regression coefficients. Finally, `white noise\index{White noise}' is added by drawing independently for each population unit a random number from a normal distribution with zero mean and a standard deviation of 2 (Figure \ref{fig:plotsimulatedbivariatepopulation}).

The population mean of the study variable equals 25.052, which is pretty close to the known model-mean \(\mu(z)\): \(\beta_0 + \beta_1 \mu(x)= 15 + 0.5 \cdot 20\).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/plotsimulatedbivariatepopulation-1} 

}

\caption{Realisation of simple linear regression model. x is the covariate, z is the study variable}\label{fig:plotsimulatedbivariatepopulation}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{SpatialSampling_files/figure-latex/scatterplotbivariatepopulation-1} 

}

\caption{Exhaustive scatter plot of the simulated population, with population fit of a simple linear regression model (green line), and of a ratio model fitted with weights inversely proportional to the covariate (red line).}\label{fig:scatterplotbivariatepopulation}
\end{figure}

Figure \ref{fig:scatterplotbivariatepopulation} shows a scatter plot for all population units. The Pearson correlation coefficient equals 0.745. Two models are fitted to the exhaustive scatter plot, a simple linear regression model and a ratio model. The ratio model assumes that the intercept \(\beta_0\) equals 0 and that the residual variance is proportional to the covariate values: \(\sigma^2_{\epsilon} \propto x\). The population fits of the coefficients of the simple linear regression model are 14.9989 and 0.4997, which are very close to the model regression coefficients. The fitted ratio model is clearly very poor. The residual standard deviation of the population fit of the ratio model equals 3.887, which is much larger than 2.001 of the simple linear regression model.

The population mean of the study variable is estimated by selecting 5,000 times a simple random sample of 25 units. Each sample is used to estimate the population mean by two model-assisted estimators, the simple regression estimator and the ratio estimator (Chapter \ref{Modelassisted}). The first estimator correctly assumes that the population is a realisation of a simple linear regression model, whereas the latter incorrectly assumes that it is a realisation of a ratio model. For each sample the standard error of the two estimators are estimated as well, which is used to compute a 95\% confidence interval of the population mean. Then the empirical coverage rate is computed, i.e.~the proportion of samples for which the population mean is inside the 95\% confidence interval. Ideally, this empirical coverage rate is equal to the nominal coverage rate of 0.95.

The coverage rates of the simple regression estimator and the ratio estimator equal 0.931 and 0.948, respectively. Both coverage rates are very close to the nominal coverage rate of 0.95. So, despite that the ratio estimator assumes an improper superpopulation model, the estimated confidence interval is still valid. The price we pay for the invalid model assumption is not an overestimated coverage rate of a confidence interval, but an increased standard error of the estimated population mean. The average over the 5,000 samples of the estimated standard error of the regression estimator equals 0.387, whereas that of the ratio estimator equals 0.772. The larger standard error of the ratio estimator leads to wider confidence intervals, which explains that the coverage rate is still correct.

This sampling experiment is now repeated for samples sizes \(n=10, 25, 50 , 100\) and for confidence levels \(1-\alpha=0.01,0.02, \dots , 0.99\).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/coveragerates-1} 

}

\caption{Empirical versus nominal coverage rates of confidence intervals for the population mean, estimated by the simple regression estimator, for sample sizes 10, 25, 50, and 100.}\label{fig:coveragerates}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/plotcoverageratesratioestimator-1} 

}

\caption{Empirical versus nominal coverage rates of confidence intervals for the population mean, estimated by the ratio estimator, for sample sizes 10, 25, 50, and 100.}\label{fig:plotcoverageratesratioestimator}
\end{figure}

\begin{table}

\caption{\label{tab:TableRegressionRatioEstimator}Estimated relative bias of the regression estimator and ratio estimator, standard deviation of 5,000 regression/ratio estimates, and average of 5,000 estimated standard errors of the regression/ratio estimator. n: sample size.}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
Estimator & n & Bias (\%) & Standard deviation & Average standard error\\
\midrule
Regression & 10 & 0.0037 & 0.678 & 0.609\\
Regression & 25 & 0.0086 & 0.411 & 0.397\\
Regression & 50 & 0.0172 & 0.282 & 0.282\\
Regression & 100 & 0.0058 & 0.202 & 0.200\\
Ratio & 10 & -0.3191 & 1.273 & 1.206\\
Ratio & 25 & -0.1318 & 0.776 & 0.769\\
Ratio & 50 & -0.0611 & 0.548 & 0.549\\
Ratio & 100 & 0.0175 & 0.390 & 0.388\\
\bottomrule
\end{tabular}
\end{table}

Figures \ref{fig:coveragerates} and \ref{fig:plotcoverageratesratioestimator} show that the empirical coverage rates are close to the nominal coverage rate, for all four sample sizes, both estimators, and all confidence levels. For the regression estimator and \(n=10\) the empirical coverage rate is somewhat too small. This is because the standard error of the regression estimator is slightly underestimated at this sample size. The average of the estimated standard errors (square root of estimated variance of regression estimator) equals 0.609, which is somewhat smaller than the standard deviation of the 5,000 regression estimates of 0.678. For all sample sizes the standard deviation of the 5,000 ratio estimates is considerably larger than that of the 5,000 regression estimates (Table \ref{tab:TableRegressionRatioEstimator}). For \(n=10\) also the standard error of the ratio estimator is underestimated (the average of the 5,000 estimated standard errors is smaller than the standard deviation of the 5,000 ratio estimates), but as a percentage of the standard deviation of the 5,000 ratio estimates this underestimation is smaller than for the regression estimator.

The relative bias, computed by

\begin{equation}
bias = \frac{\frac{1}{5000}\sum_{s=1}^{5000} (\hat{\bar{z}}_s-\bar{z})}{\bar{z}} \;,
\end{equation}

is about 0 for both estimators and all four sample sizes.

Contrarily, if in the model-based approach a poor superpopulation model is used, the predictions and the prediction error variances still are model-unbiased. However, for the sampled population we may have serious systematic error in the estimated population mean and the variance of local predictions may be seriously over- or underestimated. For this reason, model-based inference is also referred to as \emph{model-dependent} inference\index{Model-dependent predictor}, stressing that we fully rely on the model and that the validity\index{Validity} of the estimates and predictions depends on the quality of the model \citep{han83}.

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5780083 308.7   12043445 643.2  12043445  643.2
Vcells 27773448 211.9   93670004 714.7 189381883 1444.9
\end{verbatim}

\hypertarget{appendix-appendices}{%
\appendix \addcontentsline{toc}{chapter}{\appendixname}}


\hypertarget{Answers}{%
\chapter{Answers to exercises}\label{Answers}}

\textbf{R} scripts of the answers to the exercises are available at the Exercises folder of the github repository of this book.

\hypertarget{introduction-to-probability-sampling}{%
\section*{Introduction to probability sampling}\label{introduction-to-probability-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  No, this is not a probability sample because with this implementation the probabilities of selection of the units are unknown.\\
\item
  For simple random sampling without replacement the inclusion probability is 0.5 (\(\pi_k= n/N = 2/4\)). For simple random sampling with replacement the inclusion probability is 0.4375 (\(\pi_k = 1- (1-1/N)^n = 1-0.75^2\)).
\end{enumerate}

\hypertarget{simple-random-sampling-1}{%
\section*{Simple random sampling}\label{simple-random-sampling-1}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The most remarkable difference is the much smaller range of values in the sampling distribution of the estimator of the population mean (Figure \ref{fig:SamplingDistributionSI}). This can be explained by the smaller variance of the average of \(n\) randomly selected values compared to the variance of an individual randomly selected value. A second difference is that the sampling distribution is more symmetric, less skewed to the right. This is an illustration of the central limit theorem.\\
\item
  The variance (and so the standard deviation) becomes smaller.\\
\item
  Then the difference between the average of the estimated population means and the true population mean will be very close to 0, showing that the estimator is unbiased.\\
\item
  For simple random sampling without replacement (from a finite population) the sampling variance will be smaller. When units are selected with replacement, a unit can be selected more than once. This is inefficient as there is no extra information in the unit that has been selected before.\\
\item
  The larger the population size \(N\), the smaller the difference between the sampling variances of the estimator of the mean for simple random sampling with replacement and simple random sampling without replacement (given a sample size \(n\)).\\
\item
  The true sampling variance of the estimator of the mean for simple random sampling from an infinite population can be computed with the population variance divided by the sample size: \(V(\hat{\bar{z}})=S^2(z)/n\).\\
\item
  In reality we cannot compute the true sampling variance because we do not know the values of \(z\) for all units in the population, so that we do not know the population variance \(S^2(z)\).\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SI.R}{\texttt{SI.R}}. The 90\% confidence interval is less wide than the 95\% interval because a larger proportion of samples is allowed not to cover the population mean. The estimated standard error of the estimated total underestimates the true standard error because a constant bulk density is used. In reality this bulk density also varies.
\end{enumerate}

\hypertarget{stratified-simple-random-sampling-1}{%
\section*{Stratified simple random sampling}\label{stratified-simple-random-sampling-1}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/STSI1.R}{\texttt{STSI1.R}}.\\
\item
  Strata EA and PA can be merged without losing much precision: their means are about equal.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/STSI2.R}{\texttt{STSI2.R}}. The true sampling variance of the \(\pi\) estimator of the mean SOM obtained by collapsing strata EA and PA equals 42.89, whereas the sampling variance with the original stratification equals 42.53. So, the new stratification with four strata is only slightly worse.\\
\item
  The proof is as follows: \(\sum_N \pi_k=\sum_H \sum_{N_h}\pi_{hk}=\sum_H \sum_{N_h}n_h/N_h=\sum_H n_h=n\).\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/STSIcumrootf.R}{\texttt{STSIcumrootf.R}}. The default allocation is Neyman allocation, see help of function \texttt{strata.cumrootf}. The true sampling variance of the estimator of the mean equals 20.0. The stratification effect equals 4.26.\\
\item
  With at least two points per geostratum, the variance of the estimator of the stratum mean can be estimated without bias by the estimated stratum variance divided by the number of points in that stratum.\\
\item
  On average the sampling variance of the estimator of the mean with 100 \(\times\) 1 point is smaller than with \(50 \times 2\) points because the geographical spreading will be somewhat better (less spatial clustering).\\
\item
  With geostrata of equal size and equal number of sampling points per geostratum, the sampling intensity is equal for all strata, so that the sample mean is an unbiased estimator of the population mean. In formula: \(\hat{\bar{z}}= \sum\limits_{h=1}^{H} w_{h}\,\bar{z}_{\mathcal{S}h} = \frac{1}{H} \sum\limits_{h=1}^{H} \bar{z}_{\mathcal{S}h} = \bar{z}_{\mathcal{S}}\), with \(\bar{z}_{\mathcal{S}h}\) the average of the sample from stratum \(h\) and \(\bar{z}_{\mathcal{S}}\) the average of all sampling points.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/STSIgeostrata.R}{\texttt{STSIgeostrata.R}}.

  \begin{itemize}
  \tightlist
  \item
    Collapsing the geostrata on the basis of the measurements of the study variable is not a proper way, as it will lead to a biased estimator of the sampling variance of the estimator of the mean. The estimated stratum variances \(\widehat{S}^2(z)\) will be small, and so the estimated sampling variance will underestimate the true sampling variance.
  \item
    I propose to group neighbouring geostrata, i.e.~geostrata that are close to each other.
  \item
    The sampling variance estimator is not unbiased. The sampling variance is slightly overestimated because we assume that the two (or three) points within a collapsed stratum are selected by simple random sampling, whereas they are selected by stratified random sampling (a collapsed stratum consists of two or three geostrata), and so there is less spatial clustering compared to simple random sampling.\\
  \end{itemize}
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/STSIgeostrata_composite.R}{\texttt{STSIgeostrata\_composite.R}}.

  \begin{itemize}
  \tightlist
  \item
    No, with bulking within strata the sampling variance cannot be estimated, because then we cannot estimate the sampling variances of the estimated stratum means, which are needed for estimating the sampling variance of the estimator of the population mean.
  \item
    If all aliquots are analysed separately, the estimated population mean is more precise than with composite sampling (variance of the estimator of the mean is smaller) because the contribution of the measurement error to the total variance of the estimator of the mean is smaller.
  \item
    This combination of arguments of function \texttt{stratify} does not work because with geostrata of unequal area the mean of a composite sample is a biased estimator of the population mean. All aliquots bulked into a composite get equal weight, but they should get different weights because they do not represent equal fractions of the population.
  \end{itemize}
\end{enumerate}

\hypertarget{systematic-random-sampling-2}{%
\section*{Systematic random sampling}\label{systematic-random-sampling-2}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SY.R}{\texttt{SY.R}}.\\
\item
  As can be seen in the plot, the spatial coverage of the study area by the two systematic random samples can be quite poor. So, I expect that the variance of the estimator of the mean using the data of two systematic random samples of half the expected size is larger than the variance of the estimator of the mean based on the data of a single systematic random sample.
\end{enumerate}

\hypertarget{cluster-random-sampling}{%
\section*{Cluster random sampling}\label{cluster-random-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/Cluster.R}{\texttt{Cluster.R}}.\\
\item
  I expect that the sampling variance with three transects is larger than with six transects of half the length, as the sampling points are more spatially clustered.\\
\item
  With two independently selected clusters per stratum the sampling variance of the estimator of the mean can be estimated without bias, as the variance of cluster means within the strata can be estimated from the two cluster means.
\end{enumerate}

\hypertarget{two-stage-cluster-random-sampling-1}{%
\section*{Two-stage cluster random sampling}\label{two-stage-cluster-random-sampling-1}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/TwoStage.R}{\texttt{TwoStage.R}}.\\
\item
  With ten PSU draws and four SSUs per PSU draw (10 \(\times\) 4) the expected standard error of the estimator of the population mean is smaller than with four PSU draws and ten SSUs per PSU draw (\(4 \times 10\)) because spatial clustering of the sampling points is less strong.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/TwoStage.R}{\texttt{TwoStage.R}}.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/TwoStage.R}{\texttt{TwoStage.R}}.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/TwoStage.R}{\texttt{TwoStage.R}}.\\
\item
  For the first variance component:
  \begin{equation}
  \begin{split}
  \frac{1}{n} \sum_{j=1}^N p_j\left(\frac{t_j(z)}{p_j}-t(z)\right)^2 = \frac{1}{n} \sum_{j=1}^N p_j\left(M\frac{t_j(z)}{M_j}-M\bar{z}\right)^2 \\
  = \frac{1}{n} \sum_{j=1}^N p_j\left(M\left(\bar{z}_j-\bar{z}\right)\right)^2 = \frac{M^2}{n} \sum_{j=1}^N p_j\left(\bar{z}_j-\bar{z}\right)^2  \;.
  \end{split}
  \end{equation}

  For the second variance component:
  \begin{equation}
  \begin{split}
  \frac{1}{n} \sum_{j=1}^N \frac{M_j^2 S^2_j}{m_j p_j} =\frac{1}{nm} \sum_{j=1}^N \frac{M_j^2 S^2_j}{p_j} =
  \frac{1}{nm} \sum_{j=1}^N M M_j S^2_j \\
  =\frac{1}{nm} \sum_{j=1}^N M^2 \frac{M_j}{M} S^2_j =\frac{M^2}{nm} \sum_{j=1}^N p_j S^2_j \;.
  \end{split}
  \end{equation}

  Division of both variance components by \(M^2\) yields the variance of the estimator of the population mean, Equations \eqref{eq:TrueVarEstMeanTwostage}, \eqref{eq:PooledBetweenClusterVariance}, and \eqref{eq:PooledWithinClusterVariance}.
\end{enumerate}

\hypertarget{sampling-with-probabilities-proportional-to-size}{%
\section*{Sampling with probabilities proportional to size}\label{sampling-with-probabilities-proportional-to-size}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/pps.R}{\texttt{pps.R}}.\\
\item
  No, this field should not be included in the poppy area of that sampling unit because it is located outside the target area.\\
\item
  Yes, this field must be included in the poppy area of that sampling unit as it is located inside the target area. The target area is the territory of Kandahar, regardless of how an area inside this territory is depicted on the map, as agricultural land or otherwise.
\end{enumerate}

\hypertarget{balanced-and-well-spread-sampling}{%
\section*{Balanced and well-spread sampling}\label{balanced-and-well-spread-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/Balanced.R}{\texttt{Balanced.R}}.\\
\item
  Spatial clustering of sampling units with balanced sampling may lead to a less precise estimate of the population mean. This will be the case when the residuals of the regression model are spatially correlated (show spatial structure). The residuals will be correlated when the spatial variation of the study variable is also determined by covariates or factors that are not used in balancing the sample. If the residuals are not spatially correlated (white noise), spatial clustering does no harm.\\
\item
  One advantage is that unequal inclusion probabilities can be used in the LPM design. If the sampling units have unequal size (as in the poppy survey of Kandahar) or if a covariate is available that is linearly related to the study variable (as in the AGB survey of Eastern Amazonia), the sampling efficiency can be increased by sampling with (inclusion) probabilities proportional to size. The only option for random sampling from geostrata is then to select the unit(s) \emph{within geostrata} by pps sampling.
\end{enumerate}

\hypertarget{model-assisted-estimation}{%
\section*{Model-assisted estimation}\label{model-assisted-estimation}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/RegressionEstimator.R}{\texttt{RegressionEstimator.R}}. The approximate standard error estimator that uses the \(g\)-weights (computed with functions \texttt{calibrate} and \texttt{svymean} of package \textbf{survey}) has a larger mean (7.194) than the approximated standard error computed with Equation \eqref{eq:VarianceRegressionEstimatorSI} (7.130).\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/VarianceRegressionEstimator.R}{\texttt{VarianceRegressionEstimator.R}}. In reality we do not have a population fit of the regression coefficients, but these coefficients must be estimated from a sample. The estimated coefficients vary among the samples, which explains that the experimental variance, i.e.~the variance of the 10,000 regression estimates obtained by estimating the coefficients from the sample (Sample in Figure \ref{fig:RegressionEstimatorsAmazonia}), is larger than the variance as computed with the population fit of the regression coefficients (Exhaust in Figure \ref{fig:RegressionEstimatorsAmazonia}).

  The difference between the experimental variance (variance of regression estimator with sample fit of coefficients) and the variance obtained with the population fit, as a proportion of the experimental variance, decreases with the sample size. The same holds for the difference between the approximated variance and the experimental variance as a proportion of the experimental variance. Both findings can be explained by the smaller contribution of the variance of the estimated regression coefficients to the variance of the regression estimator with the large sample size. The approximated variance does not account for the uncertainty about the regression coefficients, so that for all three sample sizes this approximated variance is about equal to the variance of the regression estimator as computed with the population fit of the regression coefficients.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/RegressionEstimatorsAmazonia-1} 

}

\caption{Variance of the regression estimator of the mean AGB in Eastern Amazonia with population fit of regression coefficients (Exhaust), with sample fit of regression coefficients (Sample), and approximated variance of regression estimator (Approx).}\label{fig:RegressionEstimatorsAmazonia}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/RatioEstimator.R}{\texttt{RatioEstimator.R}}. The population fit of the slope coefficient of the homoscedastic model differs from the ratio of the population total poppy area to the population total agricultural area. For the heteroscedastic model these are equal.
\end{enumerate}

\hypertarget{two-phase-random-sampling}{%
\section*{Two-phase random sampling}\label{two-phase-random-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/RegressionEstimator_Twophase.R}{\texttt{RegressionEstimator\_Twophase.R}}. Figure \ref{fig:RegressionEstimatorsAmazoniaTwoPhase} shows the approximated sampling distribution of the simple regression estimator of the mean AGB in Eastern Amazonia when lnSWIR2 is observed for all sampling units (One-phase) and when AGB is observed for the subsample only (Two-phase). The variance of the regression estimator with two-phase sampling is considerably larger. Without subsampling the regression estimator exploits our knowledge of the population mean of the covariate lnSWIR2, whereas in two-phase sampling this population mean must be estimated from the first-phase sample, introducing additional uncertainty.

  The average of the 10,000 approximated variances equals 40.5 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}, which is considerably smaller than the variance of the 10,000 regression estimates for two-phase sampling, which is equal to 51.2 (10\textsuperscript{9} kg ha\textsuperscript{-1})\textsuperscript{2}.
\end{enumerate}



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/RegressionEstimatorsAmazoniaTwoPhase-1} 

}

\caption{Approximated sampling distribution of the simple regression estimator of the mean AGB (10\textsuperscript{9} kg ha\textsuperscript{-1}) in Eastern Amazonia in the case that the covariate is observed for all sampling units (One-phase) and for the subsample only (Two-phase).}\label{fig:RegressionEstimatorsAmazoniaTwoPhase}
\end{figure}

\hypertarget{computing-the-required-sample-size}{%
\section*{Computing the required sample size}\label{computing-the-required-sample-size}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/RequiredSampleSize_CIprop.R}{\texttt{RequiredSampleSize\_CIprop.R}}. Figure \ref{fig:ReqSamSize} shows that the required sample size decreases sharply with the length of the confidence interval and increases with the prior (anticipated) proportion.

  A prior for the proportion is needed because the standard error of the estimated proportion is a function of the estimated proportion \(\hat{p}\) itself: \(se(\hat{p})=\frac{\sqrt{\hat{p}(1-\hat{p})}}{\sqrt{n}}\), so that the length of the confidence interval, computed with the normal approximation, is also a function of \(\hat{p}\), see Equation \eqref{eq:nreqwidthCIprop}.

  For a prior proportion \(p^*\) of 0.5 the standard deviation \(\sqrt{p^*(1-p^*)}\) is maximum. The closer the prior proportion to zero or one, the smaller the standard error of the estimated proportion, the smaller the required sample size.
\end{enumerate}



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/ReqSamSize-1} 

}

\caption{Required sample size as a function of the half-length of a 95\% confidence interval of the population proportion, for a prior proportion of 0.1 (left subfigure), and as a function of the prior proportion for a half-length of a 95\% confidence interval of 0.2 (right subfigure).}\label{fig:ReqSamSize}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/RequiredSampleSize_CIprop.R}{\texttt{RequiredSampleSize\_CIprop.R}}. There is no need to compute the required sample size for prior proportions \(> 0.5\), as this required sample size is symmetric. For instance, the required sample size for \(p^*=0.7\) is equal to the required sample size for \(p^*=0.3\).
\end{enumerate}

\hypertarget{model-based-optimisation-of-probability-sampling-designs}{%
\section*{Model-based optimisation of probability sampling designs}\label{model-based-optimisation-of-probability-sampling-designs}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSamplingVarSI_VariogramwithNugget.R}{\texttt{MBSamplingVarSI\_VariogramwithNugget.R}}. The predicted sampling variance is slightly larger compared to the predicted sampling variance obtained with the semivariogram without nugget (and the same sill and range), because 50\% of the spatial variation is not spatially structured, so that the model-expectation of the population variance (the predicted population variance) is larger.\\
\item
  See first part of \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBRequiredSampleSize_SIandSY.R}{\texttt{MBRequiredSampleSize\_SIandSY.R}}.\\
\item
  See second part of \texttt{MBRequiredSampleSize\_SIandSY.R}. The model-based prediction of the required sample size for simple random sampling is 34 and for systematic random sampling 13. The design effect at a sample size of 34 equals 0.185. The design effect decreases with the sample size, i.e.~the ratio of the variance with systematic random sampling to the variance with simple random sampling becomes smaller. This is because the larger the sample size, the more we profit from the spatial correlation.
\end{enumerate}

\hypertarget{repeated-sample-surveys-for-monitoring-population-parameters}{%
\section*{Repeated sample surveys for monitoring population parameters}\label{repeated-sample-surveys-for-monitoring-population-parameters}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SE_STparameters.R}{\texttt{SE\_STparameters.R}}. For the designs SP and RP the true standard errors of all space-time parameters are slightly smaller than the standard deviations in Table \ref{tab:TableRepeatedEstimatesSpaceTimeParameters} because in the sampling experiment the \emph{estimated} covariances of the elementary estimates are used in the GLS estimator of the spatial means, whereas in this exercise the true covariances are used. The estimated covariances vary among the space-time samples. This variation propagates to the GLS estimates of the spatial means and so to the estimated space-time parameters.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SE_ChangeofMean_HT.R}{\texttt{SE\_ChangeofMean\_HT.R}}. The standard error of the change with the GLS estimators of the two spatial means is much smaller than the standard error of the change with the \(\pi\) estimators, because the GLS estimators use the data of all four years to estimate the spatial means of 2004 and 2019, whereas with the \(\pi\) estimators only the data of 2004 and 2019 are used.
\end{enumerate}

\hypertarget{regular-grid-and-spatial-coverage-sampling}{%
\section*{Regular grid and spatial coverage sampling}\label{regular-grid-and-spatial-coverage-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SquareGrid.R}{\texttt{SquareGrid.R}}. The number of grid points specified with argument \texttt{n} is the expected number of grid points over repeated selection of square grids with a random start. With a fixed start (using argument \texttt{offset}) the number of grid points can differ from the expected sample size.\\
\item
  The optimal spatial coverage sample (optimal in terms of MSSD) consists of the four points in the centre of the four subsquares of equal size.\\
\item
  If we are also interested in the accuracy of the estimated plot means, the sampling units can best be selected by probability sampling, for instance by simple random sampling, from the subsquares (strata). Preferably at least two points should then be selected from the strata, see Section \ref{geostrata}.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SpatialCoverageCircularPlot.R}{\texttt{SpatialCoverageCircularPlot.R}}. See Figure \ref{fig:SCScircularplot}.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SCScircularplot-1} 

}

\caption{Spatial coverage samples of five and six points in a circular plot.}\label{fig:SCScircularplot}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Bias can be avoided by constructing strata of equal size. Note that in this case we cannot use function \texttt{spsample} to select the centres of these geostrata. These centres must be computed by hand.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SpatialInfill.R}{\texttt{SpatialInfill.R}}.
\end{enumerate}

\hypertarget{covariate-space-coverage-sampling}{%
\section*{Covariate space coverage sampling}\label{covariate-space-coverage-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/CovariateSpaceCoverageSample.R}{\texttt{CovariateSpaceCoverageSample.R}}. See Figure \ref{fig:CSCsamplingHunterValley}.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/CSCsamplingHunterValley-1} 

}

\caption{Covariate space coverage sample from  Hunter valley, using cti, ndvi, and elevation as clustering variables, plotted on a map of cti.}\label{fig:CSCsamplingHunterValley}
\end{figure}

\hypertarget{conditioned-latin-hypercube-sampling}{%
\section*{Conditioned Latin hypercube sampling}\label{conditioned-latin-hypercube-sampling}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/cLHS.R}{\texttt{cLHS.R}}. Most units are selected in the part of the diagram with the highest density of raster cells. Raster cells with a large cti value and low elevation and raster cells with high elevation and small cti value are (nearly) absent in the sample. In the population not many raster cells are present with these combinations of covariate values.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/cLHS_Square.R}{\texttt{cLHS\_Square.R}}.

  \begin{itemize}
  \tightlist
  \item
    Spatial coverage is improved by using the spatial coordinates as covariates, but it is not optimal in terms of MSSD.
  \item
    It may happen that not all marginal strata of \(s1\) and \(s2\) are sampled. Even when all these marginal strata are sampled, this does not guarantee a perfect spatial coverage.
  \item
    With \texttt{set.seed(314)} and default values for the arguments of function \texttt{clhs} there is one unsampled marginal stratum and one marginal stratum with two sampling locations. So, component O1 equals 2. The minimised value (2.62) is slightly larger due to the contribution of O3 to the criterion.
  \end{itemize}
\end{enumerate}

\hypertarget{model-based-optimisation-of-the-grid-spacing}{%
\section*{Model-based optimisation of the grid spacing}\label{model-based-optimisation-of-the-grid-spacing}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBGridspacing_QOKV.Rmd}{\texttt{MBGridspacing\_QOKV.Rmd}}. For P50 not to exceed 0.85 the tolerable grid spacing is about 11.7 km, for P80 9.4 km, and for P95 7.1 km (Figure \ref{fig:QuantilesOKVarGridspacing}).
\end{enumerate}



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/QuantilesOKVarGridspacing-1} 

}

\caption{Three quantiles of the ordinary kriging variance of predicted SOM concentrations in West-Amhara, as a function of the grid spacing.}\label{fig:QuantilesOKVarGridspacing}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBGridspacing_Sensitivity.Rmd}{\texttt{MBGridspacing\_Sensitivity.Rmd}}. Increasing the nugget by 5\% and decreasing the range by 5\% yields a tolerable grid spacing that is smaller than that with the original semivariogram (Figure \ref{fig:SensitivityMKV}). The tolerable grid spacings for a mean kriging variance of 0.85 are 10.6, 8.9, and 7.4 km for the original semivariogram, the semivariogram with increased nugget and the semivariogram with the smaller range, respectively, leading to a required expected sample size of
  97, 137, and 200 points.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SensitivityMKV-1} 

}

\caption{Mean ordinary kriging variance of predicted SOM concentrations in West-Amhara, as a function of grid spacing for three semivariograms.}\label{fig:SensitivityMKV}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The variation in MKV for a given grid spacing can be explained by the random sample size: for a given spacing the number of points of a randomly selected grid inside the study area is not fixed but varies. Besides, the covariate values at the grid points vary, so that also the variance of the estimator of the mean (which contributes to the kriging variance) differs among grid samples.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBGridspacing_MKEDV.Rmd}{\texttt{MBGridspacing\_MKEDV.Rmd}}. The tolerable grid spacing for a mean kriging variance of 0.165 is 79 m.
\end{enumerate}

\hypertarget{model-based-optimisation-of-the-sampling-pattern}{%
\section*{Model-based optimisation of the sampling pattern}\label{model-based-optimisation-of-the-sampling-pattern}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSampleSquare_OK.Rmd}{\texttt{MBSampleSquare\_OK.Rmd}}. The optimised sample (Figure \ref{fig:SixteenPntsInSquare}) is most likely not the global optimum. The spatial pattern is somewhat irregular. I expect the optimal sampling locations to be close to the centres of the subsquares.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{SpatialSampling_files/figure-latex/SixteenPntsInSquare-1} 

}

\caption{Optimised sampling pattern of sixteen  points in a square for ordinary kriging.}\label{fig:SixteenPntsInSquare}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSample_QOKV.Rmd}{\texttt{MBSample\_QOKV.Rmd}}. Figure \ref{fig:MBsampleP90OKVCRF} shows the optimised sampling pattern. Compared with the optimised sampling pattern using the \emph{mean} ordinary kriging variance (MOKV) as a minimisation criterion (Figure \ref{fig:ModelBasedSampleOK}), the sampling locations are pushed more to the border of the study area. This is because with a sample optimised for MOKV (and a spatial coverage sample) near the border the kriging variances are the largest. By pushing sampling locations towards the border, the kriging variances in this border zone are strongly reduced.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/MBsampleP90OKVCRF-1} 

}

\caption{Optimised sampling pattern of 50 points on the Cotton Research Farm, using the P90 of ordinary kriging predictions of lnECe as a minimisation criterion.}\label{fig:MBsampleP90OKVCRF}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSampleSquare_KED.Rmd}{\texttt{MBSampleSquare\_KED.Rmd}}. Figure \ref{fig:EffectNuggetOptimalSamplePattern} shows the optimised sampling patterns with the three semivariograms.

  \begin{itemize}
  \tightlist
  \item
    With zero nugget and a (partial) sill of 2 the sampling points are well spread throughout the area (subfigure on the left).
  \item
    With a nugget of 1.5 and a partial sill of 0.5 the sampling points are pushed towards the left and right side of the square. With this residual semivariogram the contribution of the variance of the predictor of the mean (as a proportion) to the total kriging variance is larger than with the previous semivariogram. By shifting the sampling points towards the left and right side of the square this contribution becomes smaller. At the same time the variance of the interpolation error increases as the spatial coverage becomes worse. The optimised sample is the right balance of these two variance components (subfigure in the middle).
  \item
    With a pure nugget semivariogram all sampling points are at the left and right side of the square. This is because with a pure nugget semivariogram the variance of the interpolation error is independent of the locations (the variance equals the nugget variance everywhere), while the variance of the predictor of the mean is minimal for this sample (subfigure on the right).
  \end{itemize}
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/EffectNuggetOptimalSamplePattern-1} 

}

\caption{Effect of the nugget (no nugget, large nugget, pure nugget) on the optimised sampling pattern of sixteen points for KED, using Easting as a covariate for the mean.}\label{fig:EffectNuggetOptimalSamplePattern}
\end{figure}

\hypertarget{sampling-for-estimating-the-semivariogram}{%
\section*{Sampling for estimating the semivariogram}\label{sampling-for-estimating-the-semivariogram}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/NestedSampling_v1.R}{\texttt{NestedSampling\_v1.R}}.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/SI_PointPairs.R}{\texttt{SI\_PointPairs.R}}. With the seed I used (314) the variance of the estimator of the range parameter with the smaller separation distances is much smaller compared to that obtained with the larger separation distances (the estimated standard error is 115 m).\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSample_SSA_logdet.R}{\texttt{MBSample\_SSA\_logdet.R}}. Figure \ref{fig:MBSupSamples} shows the optimised sampling pattern. With the smaller ratio of spatial dependence of 0.5 the cluster of sampling points covers a larger area as compared to the sampling pattern obtained with a ratio of spatial dependence of 0.8 (see Figure \ref{fig:MBVariogram}). Again, quite a few pairs of points at very short distance can be seen.\\
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSample_SSA_MVKV.R}{\texttt{MBSample\_SSA\_MVKV.R}}. Figure \ref{fig:MBSupSamples} shows the optimised sampling pattern. The circular cluster of sampling points covers a larger area than the cluster obtained with a ratio of spatial dependence of 0.8.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/MBSupSamples-1} 

}

\caption{Model-based sample for estimating the semivariogram, using the log of the determinant of the inverse Fisher information matrix (logdet) and the mean variance of the kriging variance (MVKV) as a minimisation criterion. The sampling pattern is optimised with an exponential semivariogram with a range of 200 m and a ratio of spatial dependence of 0.5.}\label{fig:MBSupSamples}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  See \href{https://github.com/DickBrus/SpatialSamplingwithR/tree/master/Exercises/MBSample_SSA_MEAC.R}{\texttt{MBSample\_SSA\_MEAC.R}}. Figure \ref{fig:MBSampleMEACHV} shows the optimised sampling pattern of the 20 sampling points together with the 80 spatial coverage sampling points. The minimised MEAC value equals 0.759, which is smaller than that for the spatial coverage sample of 90 points supplemented by 10 points (0.788).
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{SpatialSampling_files/figure-latex/MBSampleMEACHV-1} 

}

\caption{Optimised sample of 20 points supplemented to a spatial coverage sample of 80 points, using MEAC as a minimisation criterion. The sampling pattern of the supplemental sample is optimised with an exponential semivariogram with a range of 200 m and a ratio of spatial dependence of 0.8.}\label{fig:MBSampleMEACHV}
\end{figure}

\hypertarget{sampling-for-validation-of-maps}{%
\section*{Sampling for validation of maps}\label{sampling-for-validation-of-maps}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  I am not certain about that, because the computed MSEs are estimates of the population MSEs only and I am uncertain about both population MSEs.\\
\item
  The standard errors of the estimated MEs are large when related to the estimated MEs, so my guess is that we do not have enough evidence against the hypothesis that there is no systematic error.\\
\item
  Both standard errors are large compared to the difference in MSEs, so maybe there is no significant difference. However we must be careful, because the variance of the difference in MSEs cannot be computed as the sum of the variances of estimated MSEs. This is because the two prediction errors at the same location are correlated, so the covariance must be subtracted from the sum of the variances to obtain the variance of the estimator of the difference in MSEs.
\end{enumerate}

\begin{verbatim}
           used  (Mb) gc trigger  (Mb)  max used   (Mb)
Ncells  5873724 313.7   12043445 643.2  12043445  643.2
Vcells 28075174 214.2   93670004 714.7 189381883 1444.9
\end{verbatim}

  \bibliography{referencesSampling.bib}

%\includepdf{backcover.pdf}
\backmatter
\printindex

\end{document}
